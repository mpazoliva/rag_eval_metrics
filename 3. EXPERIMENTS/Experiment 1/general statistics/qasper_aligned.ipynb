{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL ALIGNED/qasper_aligned_iris.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL ALIGNED/qasper_aligned_iris_100.csv\"\n",
    "df_100 = pd.read_csv(path_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'Faithfullness',\n",
       "       'Relevancy', 'RSim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bleurt', 'BEM', 'Bart',\n",
       "       'Prometheus', 'Faithfullness', 'Relevancy', 'Correctness', 'RSim',\n",
       "       'Consistency', 'TSim', 'LLM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          int64\n",
      "question           object\n",
      "context            object\n",
      "correct_answer     object\n",
      "iris_answer        object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "ChrfPlus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm              object\n",
      "Bart              float64\n",
      "Faithfullness     float64\n",
      "Relevancy         float64\n",
      "RSim              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.058\n",
      "std       0.066\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.040\n",
      "75%       0.090\n",
      "max       0.548\n",
      "Name: Rouge1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge1 = df['Rouge1'].describe()\n",
    "print(statistics_rouge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.009\n",
      "std       0.021\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.000\n",
      "75%       0.012\n",
      "max       0.243\n",
      "Name: Rouge2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge2 = df['Rouge2'].describe()\n",
    "print(statistics_rouge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.056\n",
      "std       0.063\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.038\n",
      "75%       0.087\n",
      "max       0.484\n",
      "Name: RougeL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rougel = df['RougeL'].describe()\n",
    "print(statistics_rougel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.132\n",
      "std       0.549\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.000\n",
      "75%       0.010\n",
      "max       8.389\n",
      "Name: Bleu, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleu = df['Bleu'].describe()\n",
    "print(statistics_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.117\n",
      "std       0.094\n",
      "min       0.000\n",
      "25%       0.049\n",
      "50%       0.099\n",
      "75%       0.160\n",
      "max       0.621\n",
      "Name: Meteor, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_meteor = df['Meteor'].describe()\n",
    "print(statistics_meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      7.430\n",
      "std       6.915\n",
      "min       0.000\n",
      "25%       2.664\n",
      "50%       5.395\n",
      "75%      10.048\n",
      "max      50.370\n",
      "Name: Chrf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrf = df['Chrf'].describe()\n",
    "print(statistics_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      6.097\n",
      "std       5.722\n",
      "min       0.000\n",
      "25%       2.158\n",
      "50%       4.388\n",
      "75%       8.172\n",
      "max      44.872\n",
      "Name: ChrfPlus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrfplus = df['ChrfPlus'].describe()\n",
    "print(statistics_chrfplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.010\n",
      "std       0.000\n",
      "min       0.006\n",
      "25%       0.010\n",
      "50%       0.010\n",
      "75%       0.010\n",
      "max       0.014\n",
      "Name: Ter, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_ter = df['Ter'].describe()\n",
    "print(statistics_ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.431\n",
      "std       0.189\n",
      "min      -0.079\n",
      "25%       0.300\n",
      "50%       0.453\n",
      "75%       0.578\n",
      "max       0.860\n",
      "Name: Bert, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bert = df['Bert'].describe()\n",
    "print(statistics_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   968.000\n",
      "mean      0.534\n",
      "std       0.285\n",
      "min      -0.000\n",
      "25%       0.353\n",
      "50%       0.558\n",
      "75%       0.740\n",
      "max       1.000\n",
      "Name: WMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wms = df['WMS'].describe()\n",
    "print(statistics_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   968.000\n",
      "mean      0.531\n",
      "std       0.232\n",
      "min      -0.061\n",
      "25%       0.364\n",
      "50%       0.550\n",
      "75%       0.697\n",
      "max       1.000\n",
      "Name: SMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_sms = df['SMS'].describe()\n",
    "print(statistics_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Wisdm'] = pd.to_numeric(df['Wisdm'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   842.000\n",
      "mean      0.506\n",
      "std       0.224\n",
      "min       0.000\n",
      "25%       0.361\n",
      "50%       0.543\n",
      "75%       0.676\n",
      "max       0.978\n",
      "Name: Wisdm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wisdm = df['Wisdm'].describe()\n",
    "print(statistics_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   99.000\n",
      "mean     0.355\n",
      "std      0.261\n",
      "min      0.050\n",
      "25%      0.150\n",
      "50%      0.277\n",
      "75%      0.457\n",
      "max      0.981\n",
      "Name: Bleurt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleurt = df_100['Bleurt'].describe()\n",
    "print(statistics_bleurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   99.000\n",
      "mean     0.432\n",
      "std      0.308\n",
      "min      0.033\n",
      "25%      0.173\n",
      "50%      0.355\n",
      "75%      0.687\n",
      "max      0.992\n",
      "Name: BEM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bem = df_100['BEM'].describe()\n",
    "print(statistics_bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   968.000\n",
      "mean      0.030\n",
      "std       0.056\n",
      "min       0.000\n",
      "25%       0.005\n",
      "50%       0.014\n",
      "75%       0.029\n",
      "max       0.563\n",
      "Name: Bart, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bart = df['Bart'].describe()\n",
    "print(statistics_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      3.460\n",
      "std       0.744\n",
      "min       1.000\n",
      "25%       3.000\n",
      "50%       4.000\n",
      "75%       4.000\n",
      "max       4.000\n",
      "Name: Prometheus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_prometheus = df_100['Prometheus'].describe()\n",
    "print(statistics_prometheus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   76.000\n",
      "mean     0.795\n",
      "std      0.178\n",
      "min      0.000\n",
      "25%      0.800\n",
      "50%      0.800\n",
      "75%      0.900\n",
      "max      1.000\n",
      "Name: LLM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_llm = df_100['LLM'].describe()\n",
    "print(statistics_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   709.000\n",
      "mean      0.832\n",
      "std       0.285\n",
      "min       0.000\n",
      "25%       0.750\n",
      "50%       1.000\n",
      "75%       1.000\n",
      "max       1.000\n",
      "Name: Faithfullness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_faithfulness = df['Faithfullness'].describe()\n",
    "print(statistics_faithfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.867\n",
      "std       0.245\n",
      "min       0.000\n",
      "25%       0.885\n",
      "50%       0.941\n",
      "75%       0.974\n",
      "max       1.000\n",
      "Name: Relevancy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rrel = df['Relevancy'].describe()\n",
    "print(statistics_rrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   98.000\n",
      "mean     0.574\n",
      "std      0.180\n",
      "min      0.176\n",
      "25%      0.474\n",
      "50%      0.586\n",
      "75%      0.716\n",
      "max      0.962\n",
      "Name: Correctness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_correctness = df_100['Correctness'].describe()\n",
    "print(statistics_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   931.000\n",
      "mean      0.815\n",
      "std       0.050\n",
      "min       0.651\n",
      "25%       0.781\n",
      "50%       0.822\n",
      "75%       0.851\n",
      "max       0.941\n",
      "Name: RSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rsim = df['RSim'].describe()\n",
    "print(statistics_rsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.772\n",
      "std       0.344\n",
      "min       0.000\n",
      "25%       0.667\n",
      "50%       1.000\n",
      "75%       1.000\n",
      "max       1.000\n",
      "Name: Consistency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_consistency = df_100['Consistency'].describe()\n",
    "print(statistics_consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      2.730\n",
      "std       1.601\n",
      "min       0.000\n",
      "25%       1.000\n",
      "50%       4.000\n",
      "75%       4.000\n",
      "max       5.000\n",
      "Name: TSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_tsim = df_100['TSim'].describe()\n",
    "print(statistics_tsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  Rouge1  Rouge2  RougeL    Bleu    Chrf  ChrfPlus  Meteor  \\\n",
      "count     968.000 931.000 931.000 931.000 931.000 931.000   931.000 931.000   \n",
      "mean      483.500   0.058   0.009   0.056   0.132   7.430     6.097   0.117   \n",
      "std       279.582   0.066   0.021   0.063   0.549   6.915     5.722   0.094   \n",
      "min         0.000   0.000   0.000   0.000   0.000   0.000     0.000   0.000   \n",
      "25%       241.750   0.000   0.000   0.000   0.000   2.664     2.158   0.049   \n",
      "50%       483.500   0.040   0.000   0.038   0.000   5.395     4.388   0.099   \n",
      "75%       725.250   0.090   0.012   0.087   0.010  10.048     8.172   0.160   \n",
      "max       967.000   0.548   0.243   0.484   8.389  50.370    44.872   0.621   \n",
      "\n",
      "          Ter    Bert     WMS     SMS   Wisdm    Bart  Faithfullness  \\\n",
      "count 931.000 931.000 968.000 968.000 842.000 968.000        709.000   \n",
      "mean    0.010   0.431   0.534   0.531   0.506   0.030          0.832   \n",
      "std     0.000   0.189   0.285   0.232   0.224   0.056          0.285   \n",
      "min     0.006  -0.079  -0.000  -0.061   0.000   0.000          0.000   \n",
      "25%     0.010   0.300   0.353   0.364   0.361   0.005          0.750   \n",
      "50%     0.010   0.453   0.558   0.550   0.543   0.014          1.000   \n",
      "75%     0.010   0.578   0.740   0.697   0.676   0.029          1.000   \n",
      "max     0.014   0.860   1.000   1.000   0.978   0.563          1.000   \n",
      "\n",
      "       Relevancy    RSim  \n",
      "count    931.000 931.000  \n",
      "mean       0.867   0.815  \n",
      "std        0.245   0.050  \n",
      "min        0.000   0.651  \n",
      "25%        0.885   0.781  \n",
      "50%        0.941   0.822  \n",
      "75%        0.974   0.851  \n",
      "max        1.000   0.941  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  Rouge1  Rouge2  RougeL    Bleu    Chrf  ChrfPlus  Meteor  \\\n",
      "count     100.000 100.000 100.000 100.000 100.000 100.000   100.000 100.000   \n",
      "mean       49.500   0.058   0.009   0.055   0.228   9.198     7.611   0.135   \n",
      "std        29.011   0.062   0.018   0.059   0.662   7.810     6.369   0.086   \n",
      "min         0.000   0.000   0.000   0.000   0.000   0.032     0.136   0.011   \n",
      "25%        24.750   0.000   0.000   0.000   0.000   3.338     2.967   0.072   \n",
      "50%        49.500   0.037   0.000   0.037   0.005   6.757     5.525   0.125   \n",
      "75%        74.250   0.098   0.013   0.094   0.189  13.787    11.200   0.168   \n",
      "max        99.000   0.255   0.097   0.255   5.662  35.070    30.530   0.461   \n",
      "\n",
      "          Ter    Bert  ...    BEM    Bart  Prometheus  Faithfullness  \\\n",
      "count 100.000 100.000  ... 99.000 100.000     100.000         82.000   \n",
      "mean    0.010   0.444  ...  0.432   0.030       3.460          0.835   \n",
      "std     0.001   0.177  ...  0.308   0.056       0.744          0.269   \n",
      "min     0.006   0.009  ...  0.033   0.000       1.000          0.000   \n",
      "25%     0.010   0.318  ...  0.173   0.007       3.000          0.730   \n",
      "50%     0.010   0.451  ...  0.355   0.016       4.000          1.000   \n",
      "75%     0.010   0.586  ...  0.687   0.028       4.000          1.000   \n",
      "max     0.011   0.739  ...  0.992   0.395       4.000          1.000   \n",
      "\n",
      "       Relevancy  Correctness    RSim  Consistency    TSim    LLM  \n",
      "count    100.000       98.000 100.000      100.000 100.000 76.000  \n",
      "mean       0.898        0.574   0.817        0.772   2.730  0.795  \n",
      "std        0.191        0.180   0.046        0.344   1.601  0.178  \n",
      "min        0.000        0.176   0.710        0.000   0.000  0.000  \n",
      "25%        0.895        0.474   0.787        0.667   1.000  0.800  \n",
      "50%        0.944        0.586   0.824        1.000   4.000  0.800  \n",
      "75%        0.977        0.716   0.849        1.000   4.000  0.900  \n",
      "max        1.000        0.962   0.925        1.000   5.000  1.000  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_100.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(df.describe())\n",
    "statistics_100 = pd.DataFrame(df_100.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_statistics_100 = statistics_100[['BEM', 'LLM', 'Correctness', 'Consistency', 'Prometheus', 'TSim']]\n",
    "final_df = pd.concat([statistics, sub_statistics_100], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>ChrfPlus</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Bert</th>\n",
       "      <th>...</th>\n",
       "      <th>Bart</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>RSim</th>\n",
       "      <th>BEM</th>\n",
       "      <th>LLM</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>TSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>968.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>...</td>\n",
       "      <td>968.000</td>\n",
       "      <td>709.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>931.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>76.000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>483.500</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.132</td>\n",
       "      <td>7.430</td>\n",
       "      <td>6.097</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.772</td>\n",
       "      <td>3.460</td>\n",
       "      <td>2.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.582</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.549</td>\n",
       "      <td>6.915</td>\n",
       "      <td>5.722</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>241.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.664</td>\n",
       "      <td>2.158</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.667</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>483.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.395</td>\n",
       "      <td>4.388</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.586</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>725.250</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.048</td>\n",
       "      <td>8.172</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.716</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>967.000</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.484</td>\n",
       "      <td>8.389</td>\n",
       "      <td>50.370</td>\n",
       "      <td>44.872</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Rouge1  Rouge2  RougeL    Bleu    Chrf  ChrfPlus  Meteor  \\\n",
       "count     968.000 931.000 931.000 931.000 931.000 931.000   931.000 931.000   \n",
       "mean      483.500   0.058   0.009   0.056   0.132   7.430     6.097   0.117   \n",
       "std       279.582   0.066   0.021   0.063   0.549   6.915     5.722   0.094   \n",
       "min         0.000   0.000   0.000   0.000   0.000   0.000     0.000   0.000   \n",
       "25%       241.750   0.000   0.000   0.000   0.000   2.664     2.158   0.049   \n",
       "50%       483.500   0.040   0.000   0.038   0.000   5.395     4.388   0.099   \n",
       "75%       725.250   0.090   0.012   0.087   0.010  10.048     8.172   0.160   \n",
       "max       967.000   0.548   0.243   0.484   8.389  50.370    44.872   0.621   \n",
       "\n",
       "          Ter    Bert  ...    Bart  Faithfullness  Relevancy    RSim    BEM  \\\n",
       "count 931.000 931.000  ... 968.000        709.000    931.000 931.000 99.000   \n",
       "mean    0.010   0.431  ...   0.030          0.832      0.867   0.815  0.432   \n",
       "std     0.000   0.189  ...   0.056          0.285      0.245   0.050  0.308   \n",
       "min     0.006  -0.079  ...   0.000          0.000      0.000   0.651  0.033   \n",
       "25%     0.010   0.300  ...   0.005          0.750      0.885   0.781  0.173   \n",
       "50%     0.010   0.453  ...   0.014          1.000      0.941   0.822  0.355   \n",
       "75%     0.010   0.578  ...   0.029          1.000      0.974   0.851  0.687   \n",
       "max     0.014   0.860  ...   0.563          1.000      1.000   0.941  0.992   \n",
       "\n",
       "         LLM  Correctness  Consistency  Prometheus    TSim  \n",
       "count 76.000       98.000      100.000     100.000 100.000  \n",
       "mean   0.795        0.574        0.772       3.460   2.730  \n",
       "std    0.178        0.180        0.344       0.744   1.601  \n",
       "min    0.000        0.176        0.000       1.000   0.000  \n",
       "25%    0.800        0.474        0.667       3.000   1.000  \n",
       "50%    0.800        0.586        1.000       4.000   4.000  \n",
       "75%    0.900        0.716        1.000       4.000   4.000  \n",
       "max    1.000        0.962        1.000       4.000   5.000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasper_aligned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_100['std'] = df_100.select_dtypes(include=['number']).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_100.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasper_aligned_std.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'std'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2999/3604761373.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_100\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlowest_std_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7172\u001b[0m             )\n\u001b[1;32m   7173\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7174\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7176\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7178\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1906\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1910\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'std'"
     ]
    }
   ],
   "source": [
    "sorted_df = df_100.sort_values(by='std')\n",
    "\n",
    "lowest_std_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_std_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options to ensure full display\n",
    "pd.set_option('display.max_columns', None)      # Show all columns\n",
    "pd.set_option('display.max_rows', None)         # Show all rows\n",
    "pd.set_option('display.max_colwidth', None)     # No truncation of column content\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Standard Deviation:\n",
      "                                                    question  \\\n",
      "45           What useful information does attention capture?   \n",
      "64  Which other approaches do they compare their model with?   \n",
      "43             How large is their MNER SnapCaptions dataset?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       context  \\\n",
      "45                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ['analysis shows attention models traditional alignment cases closely captures information beyond alignment others . instance attention agrees traditional alignments high degree case nouns . however captures information rather translational equivalent case verbs .', 'better understand attention accuracy affects translation quality analyse relationship attention loss word prediction loss individual partofspeech classes . figure figref shows attention loss differs generating different pos tags . one see attention loss varies substantially across different pos tags . particular focus cases noun verb frequent pos tags dataset . shown attention noun closest alignments average . average attention loss verb almost two times larger loss noun .', 'one notice less half attention paid alignment points pos tags . examine rest attention case distributed source sentence measure attention distribution dependency roles source side . first parse source side rwth data using parzu parser bibref . compute attention probability mass given words alignment points distributed dependency roles . table tabref gives attended roles pos tag . focus pos tags discussed earlier . one see attended roles translating nouns include adjectives determiners case translating verbs includes auxiliary verbs adverbs including negation subjects objects .']   \n",
      "64                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ['float selected table comparison existing models .', 'paper present deep neural network model task finegrained named entity classification using elmo embeddings wikidata . proposed model learns representations entity mentions based context incorporates rich structure wikidata augment labels finergrained subtypes . see comparisons model made wikigold table tabref . note model performs similarly existing systems without trained tuned particular dataset . future work may include refining clustering method described section . extend types person location organization also include disambiguation entity types .', 'float selected table comparison existing models .']   \n",
      "43  ['snapcaptions dataset composed k usergenerated image snap textual caption pairs named entities captions manually labeled expert human annotators entity types per loc org misc . captions collected exclusively snaps submitted public crowdsourced stories aka snapchat live stories stories . examples public crowdsourced stories new york story thanksgiving story comprise snaps aggregated various public events venues etc . snaps posted year contain raw images associated information textual captions obfuscated visual descriptor features extracted pretrained inceptionnet available . split dataset train validation test sets . captions data average length . characters . words vocabulary size considered unknown tokens stanford glove embeddings bibref . named entities annotated snapcaptions dataset include many new emerging entities found various surface forms various nicknames typos etc . best knowledge snapcaptions dataset contains natural imagecaption pairs expertannotated named entities .', 'snapcaptions dataset composed k usergenerated image snap textual caption pairs named entities captions manually labeled expert human annotators entity types per loc org misc . captions collected exclusively snaps submitted public crowdsourced stories aka snapchat live stories stories . examples public crowdsourced stories new york story thanksgiving story comprise snaps aggregated various public events venues etc . snaps posted year contain raw images associated information textual captions obfuscated visual descriptor features extracted pretrained inceptionnet available . split dataset train validation test sets . captions data average length . characters . words vocabulary size considered unknown tokens stanford glove embeddings bibref . named entities annotated snapcaptions dataset include many new emerging entities found various surface forms various nicknames typos etc . best knowledge snapcaptions dataset contains natural imagecaption pairs expertannotated named entities .']   \n",
      "\n",
      "                                                            correct_answer  \\\n",
      "45                                     ['', 'alignment points pos tags .']   \n",
      "64  ['akbik et al . link et al .', 'compare akbik et al . link et al . .']   \n",
      "43                                                                ['', '']   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           iris_answer  \\\n",
      "45                                     Based on the given context, attention captures the following useful information:\\n\\n1. Information beyond alignment: The analysis shows that attention models can capture information beyond traditional alignment cases, providing a more comprehensive understanding of the relationship between words in a sentence.\\n2. Translational equivalents: Attention agrees with traditional alignments for high-degree case nouns, but captures information about translational equivalents for verbs, including auxiliary verbs and adverbs.\\n3. Word prediction loss: Attention loss is related to translation quality, and analyzing the relationship between attention loss and word prediction loss can provide insights into the impact of attention on translation accuracy.\\n4. Distribution of attention: Attention is not equally distributed across all parts of speech, and the distribution of attention can vary substantially across different pos tags.\\n5. Dependency roles: Attention can capture the dependency roles of words in a sentence, such as subject-verb-object relationships, and this information can be useful for improving translation accuracy.\\n6. Translating nouns and verbs: Attention can help identify the roles of nouns and verbs in a sentence, including adjectives, determiners, and auxiliary verbs, which can be useful for improving the accuracy of translations   \n",
      "64  Based on the text, the authors compare their proposed model with existing systems or approaches. They mention that their model performs similarly to existing systems without being trained or tuned on a particular dataset. This implies that they compare their model with other state-of-the-art models for finegrained named entity classification using ELMO embeddings and Wikidata.\\n\\nSome of the other approaches that they may be comparing their model with include:\\n\\n1. Existing deep neural network models for named entity recognition and classification, such as LSTM-CRF, BERT, and RoBERTa.\\n2. Other models that use ELMO embeddings for named entity recognition and classification, such as the ELMO-CRF model proposed by the same authors in a previous paper.\\n3. Models that incorporate rich structure from Wikidata, such as the Wiki-based NER model proposed by Zhang et al. (2019).\\n4. Models that use transfer learning and fine-tuning on specific datasets for named entity recognition and classification, such as the BERT-based models proposed by Chen et al. (2020) and Liu et al. (2020).\\n\\nThe authors note that their proposed model performs similarly to existing systems without being trained or tuned on a particular dataset, which suggests that their model is competitive with other state-of-the-art models for finegrained named entity classification using ELMO embeddings and Wikidata   \n",
      "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Based on the information provided in the two texts, the MNER SnapCaptions dataset contains:\\n\\n* \"k\" user-generated image snap textual caption pairs (where k is a positive integer)\\n* Named entities are manually labeled by expert human annotators\\n* Entity types per loc org misc. (which suggests that the dataset includes a variety of entity types, such as locations, organizations, and miscellaneous entities)\\n\\nHowever, the exact size of the dataset is not specified. The texts only mention that the dataset contains \"many new emerging entities found in various surface forms, nicknames, and typos,\" and that it includes \"expert-annotated named entities.\"\\n\\nTherefore, without more information, it is not possible to determine the exact size of the MNER SnapCaptions dataset   \n",
      "\n",
      "    Rouge1  Rouge2  RougeL  Bleu  Chrf  ChrfPlus  Meteor   Ter  Bert   WMS   SMS       Wisdm  Bleurt   BEM  Bart  Prometheus  Faithfullness  Relevancy  Correctness  RSim  Consistency  TSim   LLM   std  \n",
      "45   0.034   0.011   0.034 0.000 1.620     1.572   0.121 0.010 0.180 0.620 0.623  0.15735744   0.040 0.054 0.103           1          1.000      0.948        0.180 0.743        1.000 0.000   NaN 0.536  \n",
      "64   0.037   0.013   0.037 0.001 1.862     2.518   0.243 0.010 0.197 0.507 0.502    0.389836  -0.484 0.096 0.020           1          1.000      0.939        0.497 0.761        1.000 1.000 0.800 0.685  \n",
      "43   0.000   0.000   0.000 0.000 0.032     0.136   0.080 0.010 0.013 0.099 0.689       Error  -0.675 0.348 0.019           3          0.833      0.000        0.188 0.718        0.600 0.000 0.500 0.689  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Standard Deviation:\")\n",
    "print(lowest_std_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples with Highest Standard Deviation:\n",
      "                                     question  \\\n",
      "47  Which baselines did they compare against?   \n",
      "40                   Which datasets are used?   \n",
      "59       What was the baseline for this task?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 context  \\\n",
      "47                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ['float selected table comparison various models different sentence classification tasks . report test accuracy model percentage . sata treelstm shows superior competitive performance tasks compared previous treestructured models well sophisticated models . latent treestructured models . models pretrained large external corpora .', 'experimental results snli dataset shown table . table report test accuracy number trainable parameters model . satalstm demonstrates decent performance compared neural models built syntactic trees latent trees well nontree models . latent syntax treelstm bibref bibref treebased cnn bibref bibref gumbel treelstm bibref bibref nse bibref bibref reinforced selfattention network bibref bibref residual stacked encoders bibref bibref bilstm generalized pooling bibref bibref . note number learned parameters model also comparable sophisticated models showing efficiency model .', 'float selected table comparison various models different sentence classification tasks . report test accuracy model percentage . sata treelstm shows superior competitive performance tasks compared previous treestructured models well sophisticated models . latent treestructured models . models pretrained large external corpora .', 'experimental results snli dataset shown table . table report test accuracy number trainable parameters model . satalstm demonstrates decent performance compared neural models built syntactic trees latent trees well nontree models . latent syntax treelstm bibref bibref treebased cnn bibref bibref gumbel treelstm bibref bibref nse bibref bibref reinforced selfattention network bibref bibref residual stacked encoders bibref bibref bilstm generalized pooling bibref bibref . note number learned parameters model also comparable sophisticated models showing efficiency model .']   \n",
      "40  ['develop variety shapeworldice datasets similar idea skill tasks babi framework bibref . table tabref gives overview different shapeworldice datasets use paper . consider three different types captioning tasks focuses distinct aspect reasoning abilities . existential descriptions examine whether certain object present image . spatial descriptions identify spatial relationships among visual objects . quantification descriptions involve countbased ratiobased statements explicit focus inspecting models counting ability . develop two variants type dataset enable different levels visual complexity specific aspects reasoning type . training test captions sampled work english .', 'float selected table sample captions images shapeworldice datasets truthful captions blue false red . images existentialoneshape contain one object images spatialtwoshapes contain two objects . images four datasets follow distribution multiple abstract objects present visual scene .', 'practical evaluation gtd currently possible synthetic data . construct range datasets designed image captioning evaluation . call diagnostic evaluation benchmark shapeworldice shapeworld image captioning evaluation . illustrate evaluation specific image captioning models shapeworldice . empirically demonstrate existing metrics bleu spice capture true captionimage agreement scenarios gtd framework allows finegrained investigation well existing models cope varied visual situations linguistic constructions .', 'develop variety shapeworldice datasets similar idea skill tasks babi framework bibref . table tabref gives overview different shapeworldice datasets use paper . consider three different types captioning tasks focuses distinct aspect reasoning abilities . existential descriptions examine whether certain object present image . spatial descriptions identify spatial relationships among visual objects . quantification descriptions involve countbased ratiobased statements explicit focus inspecting models counting ability . develop two variants type dataset enable different levels visual complexity specific aspects reasoning type . training test captions sampled work english .', 'float selected table sample captions images shapeworldice datasets truthful captions blue false red . images existentialoneshape contain one object images spatialtwoshapes contain two objects . images four datasets follow distribution multiple abstract objects present visual scene .']   \n",
      "59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ['baseline system slc task simple logistic regression classifier default parameters represent input instances single feature length sentence . performance baseline slc task shown tables tabref tabref .', 'baseline flc task generates spans selects one techniques randomly . inefficacy simple random baseline illustrated tables tabref tabref .', 'baseline system slc task simple logistic regression classifier default parameters represent input instances single feature length sentence . performance baseline slc task shown tables tabref tabref .', 'baseline flc task generates spans selects one techniques randomly . inefficacy simple random baseline illustrated tables tabref tabref .']   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            correct_answer  \\\n",
      "47  ['various tree structured neural networks including variants treelstm treebased cnn rntn nontree models including variants lstms cnns residual selfattention based networks', 'sentence classification baselines rntn socher et al . adamcrntn dong et al . terntn qian et al . tbcnn mou et al . treelstm tai socher manning adahtlstmcm liu qiu huang dctreelstm liu qiu huang telstm huang qian zhu bicontree teng zhang gumbel treelstm choi yoo lee treenet cheng et al . cnn kim adasent zhao lu poupart lstmcnn zhou et al . bytemlstm radford jozefowicz sutskever bcn char cove mccann et al . bcn char elmo peters et al . . stanford natural language inference baselines latent syntax treelstm yogatama et al . treebased cnn mou et al . gumbel treelstm choi yoo lee nse munkhdalai yu reinforced self attention network shen et al . residual stacked encoders nie bansal bilstm generalized pooling chen ling zhu .']   \n",
      "40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ['existential oneshape multishapes spacial twoshapes multishapes quantification count ratio datasets generated shapeworldice', 'shapeworldice datasets oneshape multishapes twoshapes multishapes count ratio']   \n",
      "59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ['baseline system slc task simple logistic regression classifier default parameters . baseline flc task generates spans selects one techniques randomly .', '']   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        iris_answer  Rouge1  Rouge2  RougeL  Bleu   Chrf  ChrfPlus  Meteor   Ter  Bert   WMS   SMS       Wisdm  Bleurt   BEM  Bart  Prometheus  Faithfullness  Relevancy  Correctness  RSim  Consistency  TSim   LLM   std  \n",
      "47  Based on the text you provided, the authors compared their model (SATa-STM) against the following baselines:\\n\\n1. Previous treestructured models (e.g., Tree-LSTM, Tree-CNN)\\n2. Latent treestructured models (e.g., Latent Tree-LSTM, Latent Tree-CNN)\\n3. Models pretrained on large external corpora (e.g., BERT, RoBERTa)\\n4. Nontree models (e.g., BilSTM, Residual Stacked Encoders)\\n\\nThey also compared their model with a variant of the SATa-STM model that uses a different type of self-attention mechanism (Gumbel TreelSTM) and a variant that uses a different type of pooling mechanism (Generalized Pooling)   0.027   0.000   0.027 0.467 29.543    23.012   0.105 0.006 0.657 0.534 0.453  0.09275683  -0.633 0.216 0.003           4          1.000      0.875        0.511 0.859        1.000 4.000 0.750 7.665  \n",
      "40                                                                                                                                                                                                                                                                                                                                                     Based on the text, the following datasets are used:\\n\\n1. ShapeWorldice datasets\\n2. GTD (Generalized Truth Discovery) framework\\n3. Existential oneshape dataset\\n4. Spatial twoshapes dataset\\n5. Four datasets with multiple abstract objects present in the visual scene   0.130   0.000   0.130 0.867 33.529    26.670   0.147 0.011 0.679 0.547 0.561  0.52771264  -0.859 0.056 0.013           3          0.800      0.923        0.205 0.868        1.000 2.000   NaN 8.979  \n",
      "59                                                                                                                                                                                                                                                                                                                                                                Based on the text, the baseline for the task is a simple logistic regression classifier with default parameters, which is used to represent input instances with a single feature length sentence. This is mentioned in the first and third sentences of the text   0.255   0.097   0.255 5.662 35.070    30.530   0.319 0.011 0.593 0.350 0.304  0.85500926  -0.913 0.853 0.046           4          1.000      0.977        0.731 0.883        1.000 4.000 0.700 9.490  \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples with Highest Standard Deviation:\")\n",
    "print(highest_std_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['general_score'] = df_100.select_dtypes(include=['number']).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_100.sort_values(by='general_score')\n",
    "\n",
    "lowest_score_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_score_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Score:\n",
      "                                                                                                            question  \\\n",
      "43                                                                     How large is their MNER SnapCaptions dataset?   \n",
      "45                                                                   What useful information does attention capture?   \n",
      "4   On how many language pairs do they show that preordering assisting language sentences helps translation quality?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       context  \\\n",
      "43  ['snapcaptions dataset composed k usergenerated image snap textual caption pairs named entities captions manually labeled expert human annotators entity types per loc org misc . captions collected exclusively snaps submitted public crowdsourced stories aka snapchat live stories stories . examples public crowdsourced stories new york story thanksgiving story comprise snaps aggregated various public events venues etc . snaps posted year contain raw images associated information textual captions obfuscated visual descriptor features extracted pretrained inceptionnet available . split dataset train validation test sets . captions data average length . characters . words vocabulary size considered unknown tokens stanford glove embeddings bibref . named entities annotated snapcaptions dataset include many new emerging entities found various surface forms various nicknames typos etc . best knowledge snapcaptions dataset contains natural imagecaption pairs expertannotated named entities .', 'snapcaptions dataset composed k usergenerated image snap textual caption pairs named entities captions manually labeled expert human annotators entity types per loc org misc . captions collected exclusively snaps submitted public crowdsourced stories aka snapchat live stories stories . examples public crowdsourced stories new york story thanksgiving story comprise snaps aggregated various public events venues etc . snaps posted year contain raw images associated information textual captions obfuscated visual descriptor features extracted pretrained inceptionnet available . split dataset train validation test sets . captions data average length . characters . words vocabulary size considered unknown tokens stanford glove embeddings bibref . named entities annotated snapcaptions dataset include many new emerging entities found various surface forms various nicknames typos etc . best knowledge snapcaptions dataset contains natural imagecaption pairs expertannotated named entities .']   \n",
      "45                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ['analysis shows attention models traditional alignment cases closely captures information beyond alignment others . instance attention agrees traditional alignments high degree case nouns . however captures information rather translational equivalent case verbs .', 'better understand attention accuracy affects translation quality analyse relationship attention loss word prediction loss individual partofspeech classes . figure figref shows attention loss differs generating different pos tags . one see attention loss varies substantially across different pos tags . particular focus cases noun verb frequent pos tags dataset . shown attention noun closest alignments average . average attention loss verb almost two times larger loss noun .', 'one notice less half attention paid alignment points pos tags . examine rest attention case distributed source sentence measure attention distribution dependency roles source side . first parse source side rwth data using parzu parser bibref . compute attention probability mass given words alignment points distributed dependency roles . table tabref gives attended roles pos tag . focus pos tags discussed earlier . one see attended roles translating nouns include adjectives determiners case translating verbs includes auxiliary verbs adverbs including negation subjects objects .']   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ['experimented english inlineform hindi translation parent task . english assisting source language . bengali gujarati marathi malayalam tamil primary source languages translation hindi constitute child tasks . hindi bengali gujarati marathi indoaryan languages malayalam tamil dravidian languages . languages canonical sov word order .', 'languages', 'experimented english inlineform hindi translation parent task . english assisting source language . bengali gujarati marathi malayalam tamil primary source languages translation hindi constitute child tasks . hindi bengali gujarati marathi indoaryan languages malayalam tamil dravidian languages . languages canonical sov word order .']   \n",
      "\n",
      "                         correct_answer  \\\n",
      "43                             ['', '']   \n",
      "45  ['', 'alignment points pos tags .']   \n",
      "4                              ['', '']   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        iris_answer  \\\n",
      "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Based on the information provided in the two texts, the MNER SnapCaptions dataset contains:\\n\\n* \"k\" user-generated image snap textual caption pairs (where k is a positive integer)\\n* Named entities are manually labeled by expert human annotators\\n* Entity types per loc org misc. (which suggests that the dataset includes a variety of entity types, such as locations, organizations, and miscellaneous entities)\\n\\nHowever, the exact size of the dataset is not specified. The texts only mention that the dataset contains \"many new emerging entities found in various surface forms, nicknames, and typos,\" and that it includes \"expert-annotated named entities.\"\\n\\nTherefore, without more information, it is not possible to determine the exact size of the MNER SnapCaptions dataset   \n",
      "45  Based on the given context, attention captures the following useful information:\\n\\n1. Information beyond alignment: The analysis shows that attention models can capture information beyond traditional alignment cases, providing a more comprehensive understanding of the relationship between words in a sentence.\\n2. Translational equivalents: Attention agrees with traditional alignments for high-degree case nouns, but captures information about translational equivalents for verbs, including auxiliary verbs and adverbs.\\n3. Word prediction loss: Attention loss is related to translation quality, and analyzing the relationship between attention loss and word prediction loss can provide insights into the impact of attention on translation accuracy.\\n4. Distribution of attention: Attention is not equally distributed across all parts of speech, and the distribution of attention can vary substantially across different pos tags.\\n5. Dependency roles: Attention can capture the dependency roles of words in a sentence, such as subject-verb-object relationships, and this information can be useful for improving translation accuracy.\\n6. Translating nouns and verbs: Attention can help identify the roles of nouns and verbs in a sentence, including adjectives, determiners, and auxiliary verbs, which can be useful for improving the accuracy of translations   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Based on the given text, they show that preordering assisting language sentences helps translation quality for 6 language pairs:\\n\\n1. English-Hindi\\n2. Bengali-Hindi\\n3. Gujarati-Hindi\\n4. Marathi-Hindi\\n5. Malayalam-Hindi\\n6. Tamil-Hindi\\n\\nThese language pairs are all Indo-Aryan languages, and Hindi is the target language for all of them. The text mentions that preordering the assisting language sentences in Hindi improves the translation quality for these language pairs   \n",
      "\n",
      "    Rouge1  Rouge2  RougeL  Bleu  Chrf  ChrfPlus  Meteor   Ter  Bert   WMS   SMS       Wisdm  Bleurt   BEM  Bart  Prometheus  Faithfullness  Relevancy  Correctness  RSim  Consistency  TSim   LLM  general_score  \n",
      "43   0.000   0.000   0.000 0.000 0.032     0.136   0.080 0.010 0.013 0.099 0.689       Error  -0.675 0.348 0.019           3          0.833      0.000        0.188 0.718        0.600 0.000 0.500          0.300  \n",
      "45   0.034   0.011   0.034 0.000 1.620     1.572   0.121 0.010 0.180 0.620 0.623  0.15735744   0.040 0.054 0.103           1          1.000      0.948        0.180 0.743        1.000 0.000   NaN          0.471  \n",
      "4    0.000   0.000   0.000 0.000 0.052     0.240   0.041 0.010 0.152 0.000 0.930       Error  -0.854 0.262 0.012           3          1.000      0.928        0.510 0.718        1.000 2.000   NaN          0.476  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Score:\")\n",
    "print(lowest_score_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Hihgest Score:\n",
      "                                question  \\\n",
      "51        Where does the data come from?   \n",
      "40              Which datasets are used?   \n",
      "59  What was the baseline for this task?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 context  \\\n",
      "51                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ['introduce new crowdsourced dataset queries including inscope queries covering intents grouped general domains . dataset also includes outofscope queries . table tabref shows examples data .', 'defined intents guidance queries collected using scoping crowdsourcing task prompted crowd workers provide questions commands related topic domains manner would interact artificially intelligent assistant . manually grouped data generated scoping tasks intents . collect additional data intent used rephrase scenario crowdsourcing tasks proposed bibref . intent training queries representative team limited budget could gather developing taskdriven dialog system . along training queries validation testing queries per intent .', 'outofscope queries collected two ways . first using worker mistakes queries written one intents actually match intents . second using scoping scenario tasks prompts based topic areas found quora wikipedia elsewhere . help ensure richness additional outofscope data task prompts contributed four queries . since use crowdsourcing method collecting outofscope data queries similar style inscope counterparts .']   \n",
      "40  ['develop variety shapeworldice datasets similar idea skill tasks babi framework bibref . table tabref gives overview different shapeworldice datasets use paper . consider three different types captioning tasks focuses distinct aspect reasoning abilities . existential descriptions examine whether certain object present image . spatial descriptions identify spatial relationships among visual objects . quantification descriptions involve countbased ratiobased statements explicit focus inspecting models counting ability . develop two variants type dataset enable different levels visual complexity specific aspects reasoning type . training test captions sampled work english .', 'float selected table sample captions images shapeworldice datasets truthful captions blue false red . images existentialoneshape contain one object images spatialtwoshapes contain two objects . images four datasets follow distribution multiple abstract objects present visual scene .', 'practical evaluation gtd currently possible synthetic data . construct range datasets designed image captioning evaluation . call diagnostic evaluation benchmark shapeworldice shapeworld image captioning evaluation . illustrate evaluation specific image captioning models shapeworldice . empirically demonstrate existing metrics bleu spice capture true captionimage agreement scenarios gtd framework allows finegrained investigation well existing models cope varied visual situations linguistic constructions .', 'develop variety shapeworldice datasets similar idea skill tasks babi framework bibref . table tabref gives overview different shapeworldice datasets use paper . consider three different types captioning tasks focuses distinct aspect reasoning abilities . existential descriptions examine whether certain object present image . spatial descriptions identify spatial relationships among visual objects . quantification descriptions involve countbased ratiobased statements explicit focus inspecting models counting ability . develop two variants type dataset enable different levels visual complexity specific aspects reasoning type . training test captions sampled work english .', 'float selected table sample captions images shapeworldice datasets truthful captions blue false red . images existentialoneshape contain one object images spatialtwoshapes contain two objects . images four datasets follow distribution multiple abstract objects present visual scene .']   \n",
      "59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ['baseline system slc task simple logistic regression classifier default parameters represent input instances single feature length sentence . performance baseline slc task shown tables tabref tabref .', 'baseline flc task generates spans selects one techniques randomly . inefficacy simple random baseline illustrated tables tabref tabref .', 'baseline system slc task simple logistic regression classifier default parameters represent input instances single feature length sentence . performance baseline slc task shown tables tabref tabref .', 'baseline flc task generates spans selects one techniques randomly . inefficacy simple random baseline illustrated tables tabref tabref .']   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                         correct_answer  \\\n",
      "51  ['crowsourcing platform', 'ins scope data collectioncrowd workers provide questions commands related topic domains additional data rephrase scenario crowdsourcing tasks proposed bibref used . scope data collection workers mistakesqueries written one intents actually match intents using scoping scenario tasks prompts based topic areas found quora wikipedia elsewhere .']   \n",
      "40                                                                                                                                                                      ['existential oneshape multishapes spacial twoshapes multishapes quantification count ratio datasets generated shapeworldice', 'shapeworldice datasets oneshape multishapes twoshapes multishapes count ratio']   \n",
      "59                                                                                                                                                                                                                      ['baseline system slc task simple logistic regression classifier default parameters . baseline flc task generates spans selects one techniques randomly .', '']   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      iris_answer  Rouge1  Rouge2  RougeL  Bleu   Chrf  ChrfPlus  Meteor   Ter  Bert   WMS   SMS       Wisdm  Bleurt   BEM  Bart  \\\n",
      "51  Based on the text, the data comes from two sources:\\n\\n1. Scoping crowdsourcing tasks: The data is collected using crowdsourcing tasks that are designed to gather questions and commands related to specific topic domains. The tasks are designed to simulate the way a user might interact with an artificially intelligent assistant.\\n2. Outside sources: The data is also collected from two outside sources:\\n\\t* Quora and Wikipedia: These sources are used to gather additional out-of-scope data by using the topic areas found on these platforms.\\n\\t* Elsewhere: This refers to other sources of data that are used to ensure the richness of the out-of-scope data.\\n\\nThe data is manually grouped and generated using the scoping tasks and intents, and the team has a limited budget to gather the data. The data is validated and tested using training and validation queries per intent   0.235   0.060   0.218 0.689 28.001    23.417   0.332 0.011 0.683 0.710 0.596    0.775227  -0.316 0.983 0.106   \n",
      "40                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Based on the text, the following datasets are used:\\n\\n1. ShapeWorldice datasets\\n2. GTD (Generalized Truth Discovery) framework\\n3. Existential oneshape dataset\\n4. Spatial twoshapes dataset\\n5. Four datasets with multiple abstract objects present in the visual scene   0.130   0.000   0.130 0.867 33.529    26.670   0.147 0.011 0.679 0.547 0.561  0.52771264  -0.859 0.056 0.013   \n",
      "59                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Based on the text, the baseline for the task is a simple logistic regression classifier with default parameters, which is used to represent input instances with a single feature length sentence. This is mentioned in the first and third sentences of the text   0.255   0.097   0.255 5.662 35.070    30.530   0.319 0.011 0.593 0.350 0.304  0.85500926  -0.913 0.853 0.046   \n",
      "\n",
      "    Prometheus  Faithfullness  Relevancy  Correctness  RSim  Consistency  TSim   LLM  general_score  \n",
      "51           4          0.800      0.964        0.711 0.892        1.000 4.000 0.980          3.140  \n",
      "40           3          0.800      0.923        0.205 0.868        1.000 2.000   NaN          3.394  \n",
      "59           4          1.000      0.977        0.731 0.883        1.000 4.000 0.700          3.942  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Hihgest Score:\")\n",
    "print(highest_score_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
