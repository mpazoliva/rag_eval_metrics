{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/data/Qasa and Qasper/3. populate data: generate answers/big LLAMA/populated_qasper.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>iris_answer</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what language pairs are explored?</td>\n",
       "      <td>English (En), Arabic (Ar), Spanish (Es), and R...</td>\n",
       "      <td>De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...</td>\n",
       "      <td>For MultiUN corpus, we use four languages: Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the topics pulled from Reddit?</td>\n",
       "      <td>politics, business, science, and AskReddit</td>\n",
       "      <td>training data has posts from politics, busine...</td>\n",
       "      <td>Data collection. Subreddits are sub-communitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What accuracy does the proposed system achieve?</td>\n",
       "      <td>The proposed system achieves an accuracy of [i...</td>\n",
       "      <td>F1 scores of 85.99 on the DL-PS data,  75.15 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Main results on the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What crowdsourcing platform is used?</td>\n",
       "      <td>Amazon Mechanical Turk (MTurk)</td>\n",
       "      <td>They did not use any platform, instead they h...</td>\n",
       "      <td>With the purpose of obtaining evaluation datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On how many language pairs do they show that p...</td>\n",
       "      <td>5.\\n\\nIn the experiment, preordering the assis...</td>\n",
       "      <td>5</td>\n",
       "      <td>We experimented with English INLINEFORM0 Hindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>What is the reward model for the reinforcement...</td>\n",
       "      <td>The reward model for the reinforcement learnin...</td>\n",
       "      <td>reward 1 for successfully completing the task,...</td>\n",
       "      <td>We defined the reward as being 1 for successfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Does this paper propose a new task that others...</td>\n",
       "      <td>No. The paper does not propose a new task, but...</td>\n",
       "      <td>No, there has been previous work on recognizin...</td>\n",
       "      <td>Interesting prior work on quantifying social n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>How big is their dataset?</td>\n",
       "      <td>2.1 million predicate instances</td>\n",
       "      <td>3 million webpages processed with a CCG parser...</td>\n",
       "      <td>Much recent work on semantic parsing has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>What task do they evaluate on?</td>\n",
       "      <td>Open-domain fill-in-the-blank natural language...</td>\n",
       "      <td>Fill-in-the-blank natural language questions</td>\n",
       "      <td>We demonstrate our approach on the task of ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>How many feature maps are generated for a give...</td>\n",
       "      <td>τ feature maps</td>\n",
       "      <td>3 feature maps for a given tuple</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Process involved in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>968 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                    what language pairs are explored?   \n",
       "1              what are the topics pulled from Reddit?   \n",
       "2      What accuracy does the proposed system achieve?   \n",
       "3                 What crowdsourcing platform is used?   \n",
       "4    On how many language pairs do they show that p...   \n",
       "..                                                 ...   \n",
       "963  What is the reward model for the reinforcement...   \n",
       "964  Does this paper propose a new task that others...   \n",
       "965                          How big is their dataset?   \n",
       "966                     What task do they evaluate on?   \n",
       "967  How many feature maps are generated for a give...   \n",
       "\n",
       "                                           iris_answer  \\\n",
       "0    English (En), Arabic (Ar), Spanish (Es), and R...   \n",
       "1           politics, business, science, and AskReddit   \n",
       "2    The proposed system achieves an accuracy of [i...   \n",
       "3                       Amazon Mechanical Turk (MTurk)   \n",
       "4    5.\\n\\nIn the experiment, preordering the assis...   \n",
       "..                                                 ...   \n",
       "963  The reward model for the reinforcement learnin...   \n",
       "964  No. The paper does not propose a new task, but...   \n",
       "965                    2.1 million predicate instances   \n",
       "966  Open-domain fill-in-the-blank natural language...   \n",
       "967                                     τ feature maps   \n",
       "\n",
       "                                        correct_answer  \\\n",
       "0    De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...   \n",
       "1     training data has posts from politics, busine...   \n",
       "2    F1 scores of 85.99 on the DL-PS data,  75.15 o...   \n",
       "3     They did not use any platform, instead they h...   \n",
       "4                                                   5    \n",
       "..                                                 ...   \n",
       "963  reward 1 for successfully completing the task,...   \n",
       "964  No, there has been previous work on recognizin...   \n",
       "965  3 million webpages processed with a CCG parser...   \n",
       "966       Fill-in-the-blank natural language questions   \n",
       "967                   3 feature maps for a given tuple   \n",
       "\n",
       "                                               context  \n",
       "0    For MultiUN corpus, we use four languages: Eng...  \n",
       "1    Data collection. Subreddits are sub-communitie...  \n",
       "2    FLOAT SELECTED: Table 2: Main results on the D...  \n",
       "3    With the purpose of obtaining evaluation datas...  \n",
       "4    We experimented with English INLINEFORM0 Hindi...  \n",
       "..                                                 ...  \n",
       "963  We defined the reward as being 1 for successfu...  \n",
       "964  Interesting prior work on quantifying social n...  \n",
       "965  Much recent work on semantic parsing has been ...  \n",
       "966  We demonstrate our approach on the task of ans...  \n",
       "967  FLOAT SELECTED: Figure 1: Process involved in ...  \n",
       "\n",
       "[968 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iris_answer'] = np.random.permutation(df['iris_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>iris_answer</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what language pairs are explored?</td>\n",
       "      <td>No, they do not train a different training met...</td>\n",
       "      <td>De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...</td>\n",
       "      <td>For MultiUN corpus, we use four languages: Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the topics pulled from Reddit?</td>\n",
       "      <td>The offensive dataset is not biased by topic, ...</td>\n",
       "      <td>training data has posts from politics, busine...</td>\n",
       "      <td>Data collection. Subreddits are sub-communitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What accuracy does the proposed system achieve?</td>\n",
       "      <td>Attention mechanism</td>\n",
       "      <td>F1 scores of 85.99 on the DL-PS data,  75.15 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Main results on the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What crowdsourcing platform is used?</td>\n",
       "      <td>* For Wikipedia BIBREF4 and Twitter BIBREF8 da...</td>\n",
       "      <td>They did not use any platform, instead they h...</td>\n",
       "      <td>With the purpose of obtaining evaluation datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On how many language pairs do they show that p...</td>\n",
       "      <td>The slot filling dataset has approximately 22,...</td>\n",
       "      <td>5</td>\n",
       "      <td>We experimented with English INLINEFORM0 Hindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>What is the reward model for the reinforcement...</td>\n",
       "      <td>The authors measure performance using accuracy</td>\n",
       "      <td>reward 1 for successfully completing the task,...</td>\n",
       "      <td>We defined the reward as being 1 for successfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Does this paper propose a new task that others...</td>\n",
       "      <td>The citation intent labels in the datasets are...</td>\n",
       "      <td>No, there has been previous work on recognizin...</td>\n",
       "      <td>Interesting prior work on quantifying social n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>How big is their dataset?</td>\n",
       "      <td>The difficulties in modelling the ironic patte...</td>\n",
       "      <td>3 million webpages processed with a CCG parser...</td>\n",
       "      <td>Much recent work on semantic parsing has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>What task do they evaluate on?</td>\n",
       "      <td>Quantitatively</td>\n",
       "      <td>Fill-in-the-blank natural language questions</td>\n",
       "      <td>We demonstrate our approach on the task of ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>How many feature maps are generated for a give...</td>\n",
       "      <td>The multimodal models (TABREF31) outperform th...</td>\n",
       "      <td>3 feature maps for a given tuple</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Process involved in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>968 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                    what language pairs are explored?   \n",
       "1              what are the topics pulled from Reddit?   \n",
       "2      What accuracy does the proposed system achieve?   \n",
       "3                 What crowdsourcing platform is used?   \n",
       "4    On how many language pairs do they show that p...   \n",
       "..                                                 ...   \n",
       "963  What is the reward model for the reinforcement...   \n",
       "964  Does this paper propose a new task that others...   \n",
       "965                          How big is their dataset?   \n",
       "966                     What task do they evaluate on?   \n",
       "967  How many feature maps are generated for a give...   \n",
       "\n",
       "                                           iris_answer  \\\n",
       "0    No, they do not train a different training met...   \n",
       "1    The offensive dataset is not biased by topic, ...   \n",
       "2                                  Attention mechanism   \n",
       "3    * For Wikipedia BIBREF4 and Twitter BIBREF8 da...   \n",
       "4    The slot filling dataset has approximately 22,...   \n",
       "..                                                 ...   \n",
       "963     The authors measure performance using accuracy   \n",
       "964  The citation intent labels in the datasets are...   \n",
       "965  The difficulties in modelling the ironic patte...   \n",
       "966                                     Quantitatively   \n",
       "967  The multimodal models (TABREF31) outperform th...   \n",
       "\n",
       "                                        correct_answer  \\\n",
       "0    De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...   \n",
       "1     training data has posts from politics, busine...   \n",
       "2    F1 scores of 85.99 on the DL-PS data,  75.15 o...   \n",
       "3     They did not use any platform, instead they h...   \n",
       "4                                                   5    \n",
       "..                                                 ...   \n",
       "963  reward 1 for successfully completing the task,...   \n",
       "964  No, there has been previous work on recognizin...   \n",
       "965  3 million webpages processed with a CCG parser...   \n",
       "966       Fill-in-the-blank natural language questions   \n",
       "967                   3 feature maps for a given tuple   \n",
       "\n",
       "                                               context  \n",
       "0    For MultiUN corpus, we use four languages: Eng...  \n",
       "1    Data collection. Subreddits are sub-communitie...  \n",
       "2    FLOAT SELECTED: Table 2: Main results on the D...  \n",
       "3    With the purpose of obtaining evaluation datas...  \n",
       "4    We experimented with English INLINEFORM0 Hindi...  \n",
       "..                                                 ...  \n",
       "963  We defined the reward as being 1 for successfu...  \n",
       "964  Interesting prior work on quantifying social n...  \n",
       "965  Much recent work on semantic parsing has been ...  \n",
       "966  We demonstrate our approach on the task of ans...  \n",
       "967  FLOAT SELECTED: Figure 1: Process involved in ...  \n",
       "\n",
       "[968 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/data/Qasa and Qasper/4. shuffled/shuffled_qasper.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
