{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aligned = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasper 8-70b/qasper_70b.csv\"\n",
    "df_aligned = pd.read_csv(path_aligned)\n",
    "path_shuffled = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasper 8-70b/qasper_8b.csv\"\n",
    "df_shuffled = pd.read_csv(path_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aligned_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasper 8-70b/qasper_70b_100.csv\"\n",
    "df_aligned_100 = pd.read_csv(path_aligned_100)\n",
    "path_shuffled_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasper 8-70b/qasper_8b_100.csv\"\n",
    "df_shuffled_100 = pd.read_csv(path_shuffled_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'question', 'correct_answer', 'context', 'answer_70b',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'Chrfplus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm'],\n",
      "      dtype='object')\n",
      "(705, 17)\n",
      "Unnamed: 0          int64\n",
      "question           object\n",
      "correct_answer     object\n",
      "context            object\n",
      "answer_70b         object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "Chrfplus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "dtype: object\n",
      "- - - - - - - - - - - - \n",
      "Index(['Unnamed: 0', 'question', 'correct_answer', 'context', 'answer_8b',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'Chrfplus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm'],\n",
      "      dtype='object')\n",
      "(705, 17)\n",
      "Unnamed: 0          int64\n",
      "question           object\n",
      "correct_answer     object\n",
      "context            object\n",
      "answer_8b          object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "Chrfplus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_aligned.columns)\n",
    "print(df_aligned.shape)\n",
    "print(df_aligned.dtypes)\n",
    "print(\"- - - - - - - - - - - - \")\n",
    "print(df_shuffled.columns)\n",
    "print(df_shuffled.shape)\n",
    "print(df_shuffled.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'question', 'correct_answer', 'context',\n",
      "       'answer_70b', 'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'Chrfplus',\n",
      "       'Meteor', 'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'BEM',\n",
      "       'Prometheus', 'Consistency', 'TSim', 'Faithfullness', 'Relevancy',\n",
      "       'Correctness', 'RSim', 'LLM', 'Bleurt'],\n",
      "      dtype='object')\n",
      "(100, 29)\n",
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'question', 'correct_answer', 'context',\n",
      "       'answer_8b', 'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'Chrfplus',\n",
      "       'Meteor', 'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'BEM',\n",
      "       'Prometheus', 'Consistency', 'TSim', 'Faithfullness', 'Relevancy',\n",
      "       'Correctness', 'RSim', 'LLM', 'Bleurt'],\n",
      "      dtype='object')\n",
      "(100, 29)\n"
     ]
    }
   ],
   "source": [
    "print(df_aligned_100.columns)\n",
    "print(df_aligned_100.shape)\n",
    "print(df_shuffled_100.columns)\n",
    "print(df_shuffled_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics to compare\n",
    "metrics = ['Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'Chrfplus', 'Meteor', \n",
    "           'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm']\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric in metrics:\n",
    "    # Drop rows where either df_aligned or df_shuffled has NaN values for the metric\n",
    "    valid_rows = df_aligned[metric].notna() & df_shuffled[metric].notna()\n",
    "    \n",
    "    # Filter the DataFrames to include only these valid rows\n",
    "    aligned_valid = df_aligned[valid_rows]\n",
    "    shuffled_valid = df_shuffled[valid_rows]\n",
    "    \n",
    "    # Compare the values row by row\n",
    "    wins = (aligned_valid[metric] > shuffled_valid[metric]).sum()\n",
    "    \n",
    "    # Calculate the win rate\n",
    "    win_rate = f\"{wins} / {len(aligned_valid)}\"\n",
    "    \n",
    "    # Calculate the win rate percentage\n",
    "    win_rate_percentage = (wins / len(aligned_valid)) * 100\n",
    "    \n",
    "    # Append the result to the list\n",
    "    results.append([metric, win_rate, win_rate_percentage])\n",
    "\n",
    "# Convert the results to a DataFrame to display them neatly\n",
    "win_rates_df = pd.DataFrame(results, columns=['Metric', 'Win Rate', 'Percentage (%)'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Win Rate</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rouge1</td>\n",
       "      <td>73 / 705</td>\n",
       "      <td>10.354610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rouge2</td>\n",
       "      <td>44 / 705</td>\n",
       "      <td>6.241135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RougeL</td>\n",
       "      <td>76 / 705</td>\n",
       "      <td>10.780142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bleu</td>\n",
       "      <td>52 / 705</td>\n",
       "      <td>7.375887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chrf</td>\n",
       "      <td>147 / 705</td>\n",
       "      <td>20.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chrfplus</td>\n",
       "      <td>120 / 705</td>\n",
       "      <td>17.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meteor</td>\n",
       "      <td>76 / 705</td>\n",
       "      <td>10.780142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ter</td>\n",
       "      <td>50 / 705</td>\n",
       "      <td>7.092199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bert</td>\n",
       "      <td>123 / 705</td>\n",
       "      <td>17.446809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMS</td>\n",
       "      <td>184 / 705</td>\n",
       "      <td>26.099291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMS</td>\n",
       "      <td>129 / 705</td>\n",
       "      <td>18.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wisdm</td>\n",
       "      <td>42 / 156</td>\n",
       "      <td>26.923077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric   Win Rate  Percentage (%)\n",
       "0     Rouge1   73 / 705       10.354610\n",
       "1     Rouge2   44 / 705        6.241135\n",
       "2     RougeL   76 / 705       10.780142\n",
       "3       Bleu   52 / 705        7.375887\n",
       "4       Chrf  147 / 705       20.851064\n",
       "5   Chrfplus  120 / 705       17.021277\n",
       "6     Meteor   76 / 705       10.780142\n",
       "7        Ter   50 / 705        7.092199\n",
       "8       Bert  123 / 705       17.446809\n",
       "9        WMS  184 / 705       26.099291\n",
       "10       SMS  129 / 705       18.297872\n",
       "11     Wisdm   42 / 156       26.923077"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics to compare\n",
    "metrics_100 = ['BEM', 'Prometheus', 'Correctness', 'Consistency',\n",
    "       'TSim', 'LLM', 'Faithfullness', 'Relevancy', 'RSim', 'Bart', 'Bleurt']\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_100 = []\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric in metrics_100:\n",
    "    # Drop rows where either df_aligned or df_shuffled has NaN values for the metric\n",
    "    valid_rows = df_aligned_100[metric].notna() & df_shuffled_100[metric].notna()\n",
    "    \n",
    "    # Filter the DataFrames to include only these valid rows\n",
    "    aligned_valid_100 = df_aligned_100[valid_rows]\n",
    "    shuffled_valid_100 = df_shuffled_100[valid_rows]\n",
    "    \n",
    "    # Compare the values row by row\n",
    "    wins = (aligned_valid_100[metric] > shuffled_valid_100[metric]).sum()\n",
    "    \n",
    "    # Calculate the win rate\n",
    "    win_rate_100 = f\"{wins} / {len(aligned_valid_100)}\"\n",
    "    \n",
    "    # Calculate the win rate percentage\n",
    "    win_rate_percentage_100 = (wins / len(aligned_valid_100)) * 100\n",
    "    \n",
    "    # Append the result to the list\n",
    "    results_100.append([metric, win_rate_100, win_rate_percentage_100])\n",
    "\n",
    "# Convert the results to a DataFrame to display them neatly\n",
    "win_rates_df_100 = pd.DataFrame(results_100, columns=['Metric', 'Win Rate', 'Percentage (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Win Rate</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEM</td>\n",
       "      <td>38 / 100</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prometheus</td>\n",
       "      <td>15 / 100</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Correctness</td>\n",
       "      <td>42 / 100</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consistency</td>\n",
       "      <td>11 / 100</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSim</td>\n",
       "      <td>13 / 100</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LLM</td>\n",
       "      <td>20 / 100</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Faithfullness</td>\n",
       "      <td>10 / 53</td>\n",
       "      <td>18.867925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Relevancy</td>\n",
       "      <td>35 / 100</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RSim</td>\n",
       "      <td>36 / 100</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bart</td>\n",
       "      <td>35 / 100</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bleurt</td>\n",
       "      <td>38 / 100</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric  Win Rate  Percentage (%)\n",
       "0             BEM  38 / 100       38.000000\n",
       "1      Prometheus  15 / 100       15.000000\n",
       "2     Correctness  42 / 100       42.000000\n",
       "3     Consistency  11 / 100       11.000000\n",
       "4            TSim  13 / 100       13.000000\n",
       "5             LLM  20 / 100       20.000000\n",
       "6   Faithfullness   10 / 53       18.867925\n",
       "7       Relevancy  35 / 100       35.000000\n",
       "8            RSim  36 / 100       36.000000\n",
       "9            Bart  35 / 100       35.000000\n",
       "10         Bleurt  38 / 100       38.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rates_df_100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
