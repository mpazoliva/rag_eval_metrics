{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasa_shuffled_iris.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasa_shuffled_iris_100.csv\"\n",
    "df_100 = pd.read_csv(path_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'Faithfullness',\n",
       "       'Relevancy', 'RSim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bleurt', 'BEM', 'Bart',\n",
       "       'Prometheus', 'Faithfullness', 'Relevancy', 'Correctness', 'RSim',\n",
       "       'Consistency', 'TSim', 'LLM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>iris_answer</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>...</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Bert</th>\n",
       "      <th>WMS</th>\n",
       "      <th>SMS</th>\n",
       "      <th>Wisdm</th>\n",
       "      <th>Bart</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>RSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How do these automated metrics for human prefe...</td>\n",
       "      <td>The ultimate aim of language technology is to ...</td>\n",
       "      <td>The automated metrics that are mentioned while...</td>\n",
       "      <td>To increase the resolution of the feature maps...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.557</td>\n",
       "      <td>17.691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What does non-differentiable mean here? If the...</td>\n",
       "      <td>The ultimate aim of language technology is to ...</td>\n",
       "      <td>A formal definition of non-differentiability h...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nPretrained Deep Neu...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why is the action space of language modeling p...</td>\n",
       "      <td>Language generation action spaces are orders o...</td>\n",
       "      <td>The action space for language modeling is equa...</td>\n",
       "      <td>A task is a set of observations and correspond...</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.930</td>\n",
       "      <td>24.037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What do the equations for Q-value and value re...</td>\n",
       "      <td>RL4LMs supports fine-tuning and training LMs f...</td>\n",
       "      <td>Q and V are mathematically expressed as: V_{t}...</td>\n",
       "      <td>The various hyperparameters used in the grid s...</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.426</td>\n",
       "      <td>18.837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Why is it helpful to mask out less relevant to...</td>\n",
       "      <td>Specifically, NLPOmaintains a masking policy \\...</td>\n",
       "      <td>The authors hypothesize that their dynamic mas...</td>\n",
       "      <td>KG-Classifier affects zero-shot fusion by enab...</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.750</td>\n",
       "      <td>23.102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>1537</td>\n",
       "      <td>What are the term-based techniques they used i...</td>\n",
       "      <td>Traditional term-based methods like BM25 Rober...</td>\n",
       "      <td>Traditional term-based methods like BM25 Rober...</td>\n",
       "      <td>1. Face detector\\n2. Facial landmark detector\\...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.840</td>\n",
       "      <td>13.640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>1538</td>\n",
       "      <td>How much the quality of generated pseudo-queri...</td>\n",
       "      <td>Another interesting question is how important ...</td>\n",
       "      <td>larger generation models lead to improved gene...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nZero-shot learning ...</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.537</td>\n",
       "      <td>21.678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>1539</td>\n",
       "      <td>Will the pseudo-query generator generalize wel...</td>\n",
       "      <td>Since our approach allows us to generate queri...</td>\n",
       "      <td>The pseudo-query generator generalize well whe...</td>\n",
       "      <td>Invariant to permutations means that the model...</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.184</td>\n",
       "      <td>2.082</td>\n",
       "      <td>29.633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>1540</td>\n",
       "      <td>What if we introduce zero-shot generation for ...</td>\n",
       "      <td>Question generation for data augmentation is a...</td>\n",
       "      <td>if we introduce zero-shot generation for the s...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.115</td>\n",
       "      <td>1.129</td>\n",
       "      <td>24.805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>1541</td>\n",
       "      <td>I am wondering why the authors used community ...</td>\n",
       "      <td>First, we observe that general-domain question...</td>\n",
       "      <td>Using open-domain information retrieval datase...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.309</td>\n",
       "      <td>14.541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1542 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           question  \\\n",
       "0              0  How do these automated metrics for human prefe...   \n",
       "1              1  What does non-differentiable mean here? If the...   \n",
       "2              2  Why is the action space of language modeling p...   \n",
       "3              3  What do the equations for Q-value and value re...   \n",
       "4              4  Why is it helpful to mask out less relevant to...   \n",
       "...          ...                                                ...   \n",
       "1537        1537  What are the term-based techniques they used i...   \n",
       "1538        1538  How much the quality of generated pseudo-queri...   \n",
       "1539        1539  Will the pseudo-query generator generalize wel...   \n",
       "1540        1540  What if we introduce zero-shot generation for ...   \n",
       "1541        1541  I am wondering why the authors used community ...   \n",
       "\n",
       "                                                context  \\\n",
       "0     The ultimate aim of language technology is to ...   \n",
       "1     The ultimate aim of language technology is to ...   \n",
       "2     Language generation action spaces are orders o...   \n",
       "3     RL4LMs supports fine-tuning and training LMs f...   \n",
       "4     Specifically, NLPOmaintains a masking policy \\...   \n",
       "...                                                 ...   \n",
       "1537  Traditional term-based methods like BM25 Rober...   \n",
       "1538  Another interesting question is how important ...   \n",
       "1539  Since our approach allows us to generate queri...   \n",
       "1540  Question generation for data augmentation is a...   \n",
       "1541  First, we observe that general-domain question...   \n",
       "\n",
       "                                         correct_answer  \\\n",
       "0     The automated metrics that are mentioned while...   \n",
       "1     A formal definition of non-differentiability h...   \n",
       "2     The action space for language modeling is equa...   \n",
       "3     Q and V are mathematically expressed as: V_{t}...   \n",
       "4     The authors hypothesize that their dynamic mas...   \n",
       "...                                                 ...   \n",
       "1537  Traditional term-based methods like BM25 Rober...   \n",
       "1538  larger generation models lead to improved gene...   \n",
       "1539  The pseudo-query generator generalize well whe...   \n",
       "1540  if we introduce zero-shot generation for the s...   \n",
       "1541  Using open-domain information retrieval datase...   \n",
       "\n",
       "                                            iris_answer  Rouge1  Rouge2  \\\n",
       "0     To increase the resolution of the feature maps...   0.067   0.000   \n",
       "1     Sure! Here's my answer:\\n\\nPretrained Deep Neu...   0.000   0.000   \n",
       "2     A task is a set of observations and correspond...   0.130   0.018   \n",
       "3     The various hyperparameters used in the grid s...   0.105   0.000   \n",
       "4     KG-Classifier affects zero-shot fusion by enab...   0.110   0.000   \n",
       "...                                                 ...     ...     ...   \n",
       "1537  1. Face detector\\n2. Facial landmark detector\\...   0.000   0.000   \n",
       "1538  Sure! Here's my answer:\\n\\nZero-shot learning ...   0.113   0.000   \n",
       "1539  Invariant to permutations means that the model...   0.207   0.019   \n",
       "1540  Sure! Here's the answer to your question based...   0.115   0.019   \n",
       "1541  Sure! Here's the answer to your question based...   0.033   0.000   \n",
       "\n",
       "      RougeL  Bleu   Chrf  ...  Meteor   Ter  Bert   WMS   SMS  Wisdm  Bart  \\\n",
       "0      0.067 0.557 17.691  ...   0.022 0.002 0.110 0.398 0.121  0.385 0.002   \n",
       "1      0.000 0.000  7.789  ...   0.000 0.001 0.076 0.391 0.106  0.249 0.001   \n",
       "2      0.109 0.930 24.037  ...   0.040 0.003 0.188 0.528 0.275  0.401 0.010   \n",
       "3      0.105 0.426 18.837  ...   0.024 0.005 0.115 0.447 0.164  0.422 0.007   \n",
       "4      0.082 0.750 23.102  ...   0.037 0.004 0.169 0.393 0.164  0.377 0.002   \n",
       "...      ...   ...    ...  ...     ...   ...   ...   ...   ...    ...   ...   \n",
       "1537   0.000 2.840 13.640  ...   0.036 0.010 0.025 0.224 0.130  0.211 0.004   \n",
       "1538   0.075 1.537 21.678  ...   0.082 0.010 0.128 0.446 0.152  0.436 0.004   \n",
       "1539   0.184 2.082 29.633  ...   0.132 0.009 0.020 0.556 0.163  0.456 0.026   \n",
       "1540   0.115 1.129 24.805  ...   0.161 0.011 0.330 0.556 0.287  0.541 0.010   \n",
       "1541   0.033 0.309 14.541  ...   0.087 0.010 0.207 0.492 0.191  0.346 0.008   \n",
       "\n",
       "      Faithfullness  Relevancy  RSim  \n",
       "0             0.000      0.747 0.734  \n",
       "1             1.000      0.744 0.750  \n",
       "2             0.750      0.711 0.760  \n",
       "3             0.000      0.751 0.720  \n",
       "4             0.667      0.771 0.754  \n",
       "...             ...        ...   ...  \n",
       "1537          0.000      0.799 0.742  \n",
       "1538          0.000      0.761 0.743  \n",
       "1539          0.000      0.761 0.765  \n",
       "1540          0.500      0.886 0.792  \n",
       "1541          0.500      0.766 0.734  \n",
       "\n",
       "[1542 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          int64\n",
      "question           object\n",
      "context            object\n",
      "correct_answer     object\n",
      "iris_answer        object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "ChrfPlus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "Bart              float64\n",
      "Faithfullness     float64\n",
      "Relevancy         float64\n",
      "RSim              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1540.000\n",
      "mean       0.086\n",
      "std        0.063\n",
      "min        0.000\n",
      "25%        0.038\n",
      "50%        0.087\n",
      "75%        0.134\n",
      "max        0.270\n",
      "Name: Rouge1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge1 = df['Rouge1'].describe()\n",
    "print(statistics_rouge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1540.000\n",
      "mean       0.004\n",
      "std        0.012\n",
      "min        0.000\n",
      "25%        0.000\n",
      "50%        0.000\n",
      "75%        0.000\n",
      "max        0.108\n",
      "Name: Rouge2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge2 = df['Rouge2'].describe()\n",
    "print(statistics_rouge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1540.000\n",
      "mean       0.074\n",
      "std        0.054\n",
      "min        0.000\n",
      "25%        0.036\n",
      "50%        0.074\n",
      "75%        0.113\n",
      "max        0.259\n",
      "Name: RougeL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rougel = df['RougeL'].describe()\n",
    "print(statistics_rougel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean       0.932\n",
      "std        0.843\n",
      "min        0.000\n",
      "25%        0.173\n",
      "50%        0.847\n",
      "75%        1.397\n",
      "max        8.164\n",
      "Name: Bleu, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleu = df['Bleu'].describe()\n",
    "print(statistics_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean       0.069\n",
      "std        0.054\n",
      "min        0.000\n",
      "25%        0.026\n",
      "50%        0.064\n",
      "75%        0.105\n",
      "max        0.365\n",
      "Name: Meteor, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_meteor = df['Meteor'].describe()\n",
    "print(statistics_meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean      15.601\n",
      "std        7.830\n",
      "min        0.000\n",
      "25%        9.771\n",
      "50%       16.559\n",
      "75%       21.807\n",
      "max       36.171\n",
      "Name: Chrf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrf = df['Chrf'].describe()\n",
    "print(statistics_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean      13.139\n",
      "std        6.719\n",
      "min        0.000\n",
      "25%        8.249\n",
      "50%       13.815\n",
      "75%       18.382\n",
      "max       31.903\n",
      "Name: ChrfPlus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrfplus = df['ChrfPlus'].describe()\n",
    "print(statistics_chrfplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean       0.007\n",
      "std        0.004\n",
      "min        0.000\n",
      "25%        0.003\n",
      "50%        0.008\n",
      "75%        0.010\n",
      "max        0.012\n",
      "Name: Ter, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_ter = df['Ter'].describe()\n",
    "print(statistics_ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean       0.129\n",
      "std        0.107\n",
      "min       -0.139\n",
      "25%        0.052\n",
      "50%        0.121\n",
      "75%        0.197\n",
      "max        0.750\n",
      "Name: Bert, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bert = df['Bert'].describe()\n",
    "print(statistics_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean       0.392\n",
      "std        0.125\n",
      "min       -0.000\n",
      "25%        0.335\n",
      "50%        0.406\n",
      "75%        0.465\n",
      "max        1.000\n",
      "Name: WMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wms = df['WMS'].describe()\n",
    "print(statistics_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean       0.155\n",
      "std        0.100\n",
      "min       -0.101\n",
      "25%        0.082\n",
      "50%        0.149\n",
      "75%        0.215\n",
      "max        0.755\n",
      "Name: SMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_sms = df['SMS'].describe()\n",
    "print(statistics_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1350.000\n",
      "mean       0.351\n",
      "std        0.137\n",
      "min        0.000\n",
      "25%        0.257\n",
      "50%        0.353\n",
      "75%        0.449\n",
      "max        0.750\n",
      "Name: Wisdm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wisdm = df['Wisdm'].describe()\n",
    "print(statistics_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   99.000\n",
      "mean     0.063\n",
      "std      0.029\n",
      "min      0.036\n",
      "25%      0.048\n",
      "50%      0.056\n",
      "75%      0.068\n",
      "max      0.280\n",
      "Name: Bleurt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleurt = df_100['Bleurt'].describe()\n",
    "print(statistics_bleurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   99.000\n",
      "mean     0.057\n",
      "std      0.061\n",
      "min      0.029\n",
      "25%      0.043\n",
      "50%      0.049\n",
      "75%      0.053\n",
      "max      0.586\n",
      "Name: BEM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bem = df_100['BEM'].describe()\n",
    "print(statistics_bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1541.000\n",
      "mean       0.008\n",
      "std        0.007\n",
      "min        0.000\n",
      "25%        0.003\n",
      "50%        0.005\n",
      "75%        0.010\n",
      "max        0.052\n",
      "Name: Bart, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bart = df['Bart'].describe()\n",
    "print(statistics_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      1.090\n",
      "std       0.452\n",
      "min       1.000\n",
      "25%       1.000\n",
      "50%       1.000\n",
      "75%       1.000\n",
      "max       4.000\n",
      "Name: Prometheus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_prometheus = df_100['Prometheus'].describe()\n",
    "print(statistics_prometheus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.019\n",
      "std       0.086\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.000\n",
      "75%       0.000\n",
      "max       0.700\n",
      "Name: LLM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_llm = df_100['LLM'].describe()\n",
    "print(statistics_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1002.000\n",
      "mean       0.207\n",
      "std        0.314\n",
      "min        0.000\n",
      "25%        0.000\n",
      "50%        0.000\n",
      "75%        0.333\n",
      "max        1.000\n",
      "Name: Faithfullness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_faithfulness = df['Faithfullness'].describe()\n",
    "print(statistics_faithfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1541.000\n",
      "mean       0.720\n",
      "std        0.170\n",
      "min        0.000\n",
      "25%        0.727\n",
      "50%        0.750\n",
      "75%        0.775\n",
      "max        0.997\n",
      "Name: Relevancy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rrel = df['Relevancy'].describe()\n",
    "print(statistics_rrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   99.000\n",
      "mean     0.419\n",
      "std      0.232\n",
      "min      0.172\n",
      "25%      0.188\n",
      "50%      0.407\n",
      "75%      0.597\n",
      "max      0.870\n",
      "Name: Correctness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_correctness = df_100['Correctness'].describe()\n",
    "print(statistics_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   1542.000\n",
      "mean       0.745\n",
      "std        0.029\n",
      "min        0.642\n",
      "25%        0.726\n",
      "50%        0.744\n",
      "75%        0.764\n",
      "max        0.868\n",
      "Name: RSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rsim = df['RSim'].describe()\n",
    "print(statistics_rsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.077\n",
      "std       0.200\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.000\n",
      "75%       0.000\n",
      "max       1.000\n",
      "Name: Consistency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_consistency = df_100['Consistency'].describe()\n",
    "print(statistics_consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.020\n",
      "std       0.141\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.000\n",
      "75%       0.000\n",
      "max       1.000\n",
      "Name: TSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_tsim = df_100['TSim'].describe()\n",
    "print(statistics_tsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0   Rouge1   Rouge2   RougeL     Bleu     Chrf  ChrfPlus  \\\n",
      "count    1542.000 1540.000 1540.000 1540.000 1542.000 1542.000  1542.000   \n",
      "mean      770.500    0.086    0.004    0.074    0.932   15.601    13.139   \n",
      "std       445.281    0.063    0.012    0.054    0.843    7.830     6.719   \n",
      "min         0.000    0.000    0.000    0.000    0.000    0.000     0.000   \n",
      "25%       385.250    0.038    0.000    0.036    0.173    9.771     8.249   \n",
      "50%       770.500    0.087    0.000    0.074    0.847   16.559    13.815   \n",
      "75%      1155.750    0.134    0.000    0.113    1.397   21.807    18.382   \n",
      "max      1541.000    0.270    0.108    0.259    8.164   36.171    31.903   \n",
      "\n",
      "        Meteor      Ter     Bert      WMS      SMS    Wisdm     Bart  \\\n",
      "count 1542.000 1542.000 1542.000 1542.000 1542.000 1350.000 1541.000   \n",
      "mean     0.069    0.007    0.129    0.392    0.155    0.351    0.008   \n",
      "std      0.054    0.004    0.107    0.125    0.100    0.137    0.007   \n",
      "min      0.000    0.000   -0.139   -0.000   -0.101    0.000    0.000   \n",
      "25%      0.026    0.003    0.052    0.335    0.082    0.257    0.003   \n",
      "50%      0.064    0.008    0.121    0.406    0.149    0.353    0.005   \n",
      "75%      0.105    0.010    0.197    0.465    0.215    0.449    0.010   \n",
      "max      0.365    0.012    0.750    1.000    0.755    0.750    0.052   \n",
      "\n",
      "       Faithfullness  Relevancy     RSim  \n",
      "count       1002.000   1541.000 1542.000  \n",
      "mean           0.207      0.720    0.745  \n",
      "std            0.314      0.170    0.029  \n",
      "min            0.000      0.000    0.642  \n",
      "25%            0.000      0.727    0.726  \n",
      "50%            0.000      0.750    0.744  \n",
      "75%            0.333      0.775    0.764  \n",
      "max            1.000      0.997    0.868  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  Rouge1  Rouge2  RougeL    Bleu    Chrf  ChrfPlus  Meteor  \\\n",
      "count     100.000 100.000 100.000 100.000 100.000 100.000   100.000 100.000   \n",
      "mean       49.500   0.091   0.006   0.079   0.983  17.025    14.368   0.068   \n",
      "std        29.011   0.061   0.015   0.052   0.945   8.346     7.166   0.050   \n",
      "min         0.000   0.000   0.000   0.000   0.000   0.430     0.286   0.000   \n",
      "25%        24.750   0.050   0.000   0.042   0.205  10.864     8.825   0.027   \n",
      "50%        49.500   0.091   0.000   0.079   0.854  17.803    15.159   0.065   \n",
      "75%        74.250   0.135   0.000   0.114   1.348  24.145    20.580   0.103   \n",
      "max        99.000   0.231   0.080   0.217   5.515  31.308    28.402   0.204   \n",
      "\n",
      "          Ter    Bert  ...    BEM    Bart  Prometheus  Faithfullness  \\\n",
      "count 100.000 100.000  ... 99.000 100.000     100.000         62.000   \n",
      "mean    0.007   0.147  ...  0.057   0.008       1.090          0.245   \n",
      "std     0.004   0.119  ...  0.061   0.007       0.452          0.340   \n",
      "min     0.000  -0.108  ...  0.029   0.000       1.000          0.000   \n",
      "25%     0.003   0.074  ...  0.043   0.003       1.000          0.000   \n",
      "50%     0.007   0.132  ...  0.049   0.006       1.000          0.000   \n",
      "75%     0.010   0.212  ...  0.053   0.012       1.000          0.458   \n",
      "max     0.011   0.750  ...  0.586   0.028       4.000          1.000   \n",
      "\n",
      "       Relevancy  Correctness    RSim  Consistency    TSim     LLM  \n",
      "count    100.000       99.000 100.000      100.000 100.000 100.000  \n",
      "mean       0.716        0.419   0.750        0.077   0.020   0.019  \n",
      "std        0.168        0.232   0.030        0.200   0.141   0.086  \n",
      "min        0.000        0.172   0.687        0.000   0.000   0.000  \n",
      "25%        0.727        0.188   0.733        0.000   0.000   0.000  \n",
      "50%        0.748        0.407   0.747        0.000   0.000   0.000  \n",
      "75%        0.768        0.597   0.768        0.000   0.000   0.000  \n",
      "max        0.881        0.870   0.868        1.000   1.000   0.700  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_100.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(df.describe())\n",
    "statistics_100 = pd.DataFrame(df_100.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_statistics_100 = statistics_100[['BEM', 'LLM', 'Correctness', 'Consistency', 'Prometheus', 'TSim']]\n",
    "final_df = pd.concat([statistics, sub_statistics_100], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>ChrfPlus</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Bert</th>\n",
       "      <th>...</th>\n",
       "      <th>Bart</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>RSim</th>\n",
       "      <th>BEM</th>\n",
       "      <th>LLM</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>TSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1542.000</td>\n",
       "      <td>1540.000</td>\n",
       "      <td>1540.000</td>\n",
       "      <td>1540.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>...</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1002.000</td>\n",
       "      <td>1541.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>770.500</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.932</td>\n",
       "      <td>15.601</td>\n",
       "      <td>13.139</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1.090</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>445.281</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.843</td>\n",
       "      <td>7.830</td>\n",
       "      <td>6.719</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>385.250</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.173</td>\n",
       "      <td>9.771</td>\n",
       "      <td>8.249</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>770.500</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.847</td>\n",
       "      <td>16.559</td>\n",
       "      <td>13.815</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1155.750</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>1.397</td>\n",
       "      <td>21.807</td>\n",
       "      <td>18.382</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1541.000</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.259</td>\n",
       "      <td>8.164</td>\n",
       "      <td>36.171</td>\n",
       "      <td>31.903</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.870</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   Rouge1   Rouge2   RougeL     Bleu     Chrf  ChrfPlus  \\\n",
       "count    1542.000 1540.000 1540.000 1540.000 1542.000 1542.000  1542.000   \n",
       "mean      770.500    0.086    0.004    0.074    0.932   15.601    13.139   \n",
       "std       445.281    0.063    0.012    0.054    0.843    7.830     6.719   \n",
       "min         0.000    0.000    0.000    0.000    0.000    0.000     0.000   \n",
       "25%       385.250    0.038    0.000    0.036    0.173    9.771     8.249   \n",
       "50%       770.500    0.087    0.000    0.074    0.847   16.559    13.815   \n",
       "75%      1155.750    0.134    0.000    0.113    1.397   21.807    18.382   \n",
       "max      1541.000    0.270    0.108    0.259    8.164   36.171    31.903   \n",
       "\n",
       "        Meteor      Ter     Bert  ...     Bart  Faithfullness  Relevancy  \\\n",
       "count 1542.000 1542.000 1542.000  ... 1541.000       1002.000   1541.000   \n",
       "mean     0.069    0.007    0.129  ...    0.008          0.207      0.720   \n",
       "std      0.054    0.004    0.107  ...    0.007          0.314      0.170   \n",
       "min      0.000    0.000   -0.139  ...    0.000          0.000      0.000   \n",
       "25%      0.026    0.003    0.052  ...    0.003          0.000      0.727   \n",
       "50%      0.064    0.008    0.121  ...    0.005          0.000      0.750   \n",
       "75%      0.105    0.010    0.197  ...    0.010          0.333      0.775   \n",
       "max      0.365    0.012    0.750  ...    0.052          1.000      0.997   \n",
       "\n",
       "          RSim    BEM     LLM  Correctness  Consistency  Prometheus    TSim  \n",
       "count 1542.000 99.000 100.000       99.000      100.000     100.000 100.000  \n",
       "mean     0.745  0.057   0.019        0.419        0.077       1.090   0.020  \n",
       "std      0.029  0.061   0.086        0.232        0.200       0.452   0.141  \n",
       "min      0.642  0.029   0.000        0.172        0.000       1.000   0.000  \n",
       "25%      0.726  0.043   0.000        0.188        0.000       1.000   0.000  \n",
       "50%      0.744  0.049   0.000        0.407        0.000       1.000   0.000  \n",
       "75%      0.764  0.053   0.000        0.597        0.000       1.000   0.000  \n",
       "max      0.868  0.586   0.700        0.870        1.000       4.000   1.000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasa_shuffled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['std'] = df_100.select_dtypes(include=['number']).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_100\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasa_shuffled_std.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3962\u001b[0m )\n\u001b[0;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'"
     ]
    }
   ],
   "source": [
    "df_100.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasa_shuffled_std.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_100.sort_values(by='std')\n",
    "\n",
    "lowest_std_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_std_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options to ensure full display\n",
    "pd.set_option('display.max_columns', None)      # Show all columns\n",
    "pd.set_option('display.max_rows', None)         # Show all rows\n",
    "pd.set_option('display.max_colwidth', None)     # No truncation of column content\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Standard Deviation:\n",
      "                                                                                                                                             question  \\\n",
      "95                                                           Why did the authors use a mix of 1x1 and 3x3 filters in the expand layer of fire module?   \n",
      "34  Targeting memory-efficient indexing, can we also prune out redundant tokens in documents while preserving a sufficient level of fine granularity?   \n",
      "54                                   Can the proposed methodology utilize user intent information associated with user interaction data if available?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             context  \\\n",
      "95               Strategy 2. Decrease the number of input channels to 3x3 filters.Consider a convolution layer that is comprised entirely of 3x3 filters.The total quantity of parameters in this layer is (number of input channels) * (number of filters) * (3*3).So, to maintain a small total number of parameters in a CNN, it is important not only to decrease the number of 3x3 filters (see Strategy 1 above), but also to decrease the number of input channels to the 3x3 filters.We decrease the number of input channels to 3x3 filters using squeeze layers, which we describe in the next section.  We define the Fire module as follows.A Fire module is comprised of: a squeeze convolution layer (which has only 1x1 filters), feeding into an expand layer that has a mix of 1x1 and 3x3 convolution filters; we illustrate this in Figure 1.The liberal use of 1x1 filters in Fire modules is an application of Strategy 1 from Section 3.1.We expose three tunable dimensions (hyperparameters) in a Fire module: s_{1x1}, e_{1x1}, and e_{3x3}.In a Fire module, s_{1x1} is the number of filters in the squeeze layer (all 1x1), e_{1x1} is the number of 1x1 filters in the expand layer, and e_{3x3} is the number of 3x3 filters in the expand layer.When we use Fire modules we set s_{1x1} to be less than (e_{1x1} + e_{3x3}), so the squeeze layer helps to limit the number of input channels to the 3x3 filters, as per Strategy 2 from Section 3.1.   \n",
      "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Document Encoder. Our document encoder has a very similar architecture. We first segment a document d into its constituent tokens d_{1}d_{2}...d_{m}, to which we prepend BERT’s start token [CLS] followed by our special token [D] that indicates a document sequence. Unlike queries, we do not append [mask] tokens to documents. After passing this input sequence through BERT and the subsequent linear layer, the document encoder filters out the embeddings corresponding to punctuation symbols, determined via a pre-defined list. This filtering is meant to reduce the number of embeddings per document, as we hypothesize that (even contextualized) embeddings of punctuation are unnecessary for effectiveness.    \n",
      "54  Robustness w.r.t. user interaction frequency.Theuser ‘cold-start’ problem (Caiet al., 2021; Yinet al., 2020) is one of thetypical data-sparsity issues thatrecommender systems often face, i.e.,most users have limited historical behaviors.To check whether ICL improves the robustnessunder such a scenario,wesplit user behavior sequences into three groupsbased on their behavior sequences’ length, and keepthe total number of behavior sequencesthe same.Models are trained and evaluated on each group of usersindependently. Figure 3shows the comparison results on four datasets.We observe that:(1) The proposed ICLRec canconsistentlyperforms better thanSASRec among all user groups whileCL4SRec fails to outperform SASRecin Beauty and Yelpwhen user behavior sequences areshort.This demonstrates thatCL4SRec requires individual userbehavior sequences long enough to provide‘complete’ informationfor auxiliary supervisionwhileICLRec reducesthe need by leveraginguser intent information,thus consistently benefiting userrepresentation learning evenwhen users have limited historical interactions.(2) Compared with CL4SRec,we observe thatthe improvement of ICLRec is mainly becauseit provides betterrecommendations tousers with low interaction frequency.Thisverifies thatuser intent informationis beneficial, especiallywhen the recommender system facesdata-sparsity issues whereinformationin each individual user sequenceis limited.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          correct_answer                                                                                                                                                                                                                                        iris_answer  Rouge1  Rouge2  RougeL  Bleu  Chrf  \\\n",
      "95              Authors used a mix of 1x1 and 3x3 filters in the expand layer of the fire module to reduce the number of parameters while still getting benefits from the desired properties of having reasonable scope of the input receptive field and extracting correlations and useful information by applying the 3*3 filters of the CNN. To have a small number of parameters in a CNN, we need to decrease the number of input channels to the 3x3 filters and here comes the role of 1*1 filters, while the 3x3 filters are used to capture larger spatial features (Assuming only 3*3 and 1*1 kernels). This way, the model get its wide fame of achieving a high level of accuracy with fewer parameters than other networks.                                                                                                                                                                                                                                                 3D   0.000   0.000   0.000 0.000 0.430   \n",
      "34  Targeting memory-efficient indexing, tokens are not appended in documents. We first segment a document d into its constituent tokens d_{1}d_{2}...d_{m}, to which we prepend BERT’s start token [CLS] followed by our special token [D] that indicates a document sequence. Unlike queries, we do not append [mask] tokens to documents. After passing this input sequence through BERT and the subsequent linear layer, the document encoder filters out the embeddings corresponding to punctuation symbols, determined via a pre-defined list. This filtering is meant to reduce the number of embeddings per document, as we hypothesize that (even contextualized) embeddings of punctuation are unnecessary for effectiveness.                                                                                                                                                                                                                                                Yes   0.000   0.000   0.000 0.000 0.810   \n",
      "54                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Yes, it can.  YOLO9000 achieves the feat of predicting detections for classes despite not having labelled data for them by leveraging the shared object categories between COCO and ImageNet, and using the objectness predictions to generalize to new classes   0.000   0.000   0.000 0.018 1.503   \n",
      "\n",
      "    ChrfPlus  Meteor   Ter  Bert   WMS   SMS  Wisdm  Bleurt   BEM  Bart  Prometheus  Faithfullness  Relevancy  Correctness  RSim  Consistency  TSim   LLM   std  \n",
      "95     0.286   0.000 0.000 0.194 0.327 0.210    NaN  -0.822 0.040 0.001           1            NaN      0.842        0.787 0.747        0.000 0.000 0.000 0.402  \n",
      "34     0.608   0.000 0.000 0.052 0.404 0.129    NaN  -0.925 0.070 0.001           1          1.000      0.799        0.867 0.699        0.000 0.000 0.200 0.463  \n",
      "54     1.541   0.061 0.010 0.071 0.248 0.071    NaN  -1.391 0.049 0.003           1          0.333      0.745        0.681 0.726        0.000 0.000 0.000 0.611  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Standard Deviation:\")\n",
    "print(lowest_std_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples with Highest Standard Deviation:\n",
      "                                                                                                                                                            question  \\\n",
      "21  For the paper's pretrained DNN, if the input does not contain a training set class, why does the probability vector show sensitivity towards the noise in input?   \n",
      "79                                                   Would the performance be improved if the PLM model is pre-trained or fine-tuned on bio-medical domain datasets?   \n",
      "66                                               Does utilizing the multi-hop neighbor information in meta-graph help improve the performance of the proposed model?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  context  \\\n",
      "21  •One of the most interesting conclusions so far has been that representations on some layers seem to be surprisingly local. Instead of finding distributed representations on all layers, we see, for example, detectors for text, flowers, fruit, and faces on \\mathsf{conv4} and \\mathsf{conv5}. These conclusions can be drawn either from the live visualization or the optimized images (or, best, by using both in concert) and suggest several directions for future research (discussed in Section 4).•When using direct file input to classify photos from Flickr or Google Images, classifications are often correct and highly confident (softmax probability for correct class near 1). On the other hand, when using input from a webcam, predictions often cannot be correct because no items from the training set are shown in the image. The training set’s 1000 classes, though numerous, do not cover most common household objects. Thus, when shown a typical webcam view of a person with no ImageNet classes present, the output has no single high probability, as is expected. Surprisingly, however, this probability vector is noisy and varies significantly in response to tiny changes in the input, often changing merely in response to the noise from the webcam. We might have instead expected unchanging and low confidence predictions for a given scene when no object the network has been trained to classify is present. Plotting the fully connected layers (\\mathsf{fc6} and \\mathsf{fc7}) also reveals a similar sensitivity to small input changes.•Although the last three layers are sensitive to small input changes, much of the lower layer computation is more robust. For example, when visualizing the \\mathsf{conv5} layer, one can find many invariant detectors for faces, shoulders, text, etc. by moving oneself or objects in front of the camera. Even though the 1000 classes contain no explicitly labeled faces or text, the network learns to identify these concepts simply because they represent useful partial information for making a later classification decision. One face detector, denoted \\mathsf{conv5_{151}} (channel number 151 on \\mathsf{conv5}), is shown in Figure 2 activating for human and lion faces and in Figure 1 activating for a cat face. Zhou et al. (2014) recently observed a similar effect where convnets trained only to recognize different scene types — playgrounds, restaurant patios, living rooms, etc. — learn object detectors (e.g. for chairs, books, and sofas) on intermediate layers.   \n",
      "79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   However, implicit knowledge still has some inherent weaknesses, which limits the applicability of PLMs based re-rankers. First,queries and passages are usually created by different persons and have different expression ways (Nogueiraet al., 2019b), such as word usage and language style.Worse still, the data distributions of search queries and web contents are highly heterogeneous (Liuet al., 2021), where various specialized domains (e.g., bio-medical) may only have few training examples in a general corpus. Domain-specific knowledge can hardly be revealed and captured by the model, and thus the processing of domain-specific queries is often inaccurate. Results are obtained from Table 6. (1) Poor ranking performances of all models on bio-medical domain indicates that it is more challenging in the data scarcity scenario, where textual data is not covered widely in the PLMs’ pretraining datasets. (2) Compared with ERNIE, KERM has a higher relative improvement in bio-medical domain than general domain. This demonstrates that the incorporation of knowledge graph is more useful for a data scarcity domain. To verify this idea, we compare the size of knowledge meta graph used for different domains as follows.   \n",
      "66                                                                                                                                                                                                                                                                                                                                         Knowledge propagation via meta-graph.It is worth noting that, the above-defined knowledge injection process only leverages knowledge embeddings learned by TransE on the global graph \\overline{\\mathcal{G}}. Particularly, it lacks considering the knowledge that bridges the semantics between query and passage. To this end, we introduce a Graph Meta Network (GMN) module that refines knowledge with the constructed meta-graph \\mathbf{G}_{\\mathbf{q},\\mathbf{p}}, The multi-hop paths of \\mathbf{G}_{\\mathbf{q},\\mathbf{p}} allow the knowledge to be propagated between query and passage, which can enhance the relevance signal to be captured by the model, and thus alleviate the semantic gap. By applying a K-layer GMN in each layer of the knowledge injector, the output entity representation \\hat{\\mathbf{E}}_{e_{h}}^{(K)} can ensemble knowledge from all the K-hop neighbors. As described in Section 4.1.2 that all the paths of \\mathbf{G}_{\\mathbf{q},\\mathbf{p}} between \\mathbf{q} and \\mathbf{p} is within K hops, the GMN module can attentively propagate knowledge along the paths from entities in \\mathbf{p} to those in \\mathbf{q}, and vice versa, which can enrich the semantics of the entities that benefit the relevance modeling. Table 3 shows the performance comparisons between different settings of knowledge injector, which is statistically significant. From this table, we can observe the following phenomena. (1) MRR@10 of KERM without interaction and propagation process decreases at least 1\\% respectively. This indicates both knowledge interaction and propagation processes play an indispensable role in ranking performance. (2) The performance of KERM without propagation is comparable to vanilla ERNIE. Not only query and passage entities, but also their multi-hop neighbors are essential for the ranking performance. (3) MRR@10 of KERM without knowledge interaction drops the most. It suggests the simple and straightforward way to aggregate knowledge graph with text does not work in the passage re-ranking scenario. The text and knowledge graph need to be refined with each other mutually in the interaction, which will be further analyzed in detail as follows.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 correct_answer  \\\n",
      "21  The reason is that convolution layers learn parameters that can extract useful information and relations from the feature map that can help it afterwards to judge and give suitable responses of what this category is. Responses from learned detectors can resemble among some set of categories and can also differ among other set of categories. Input -not being in the training classes- still has a feature map that different layers would respond to according to those different detectors which the network has already learned and would still give a probability vector which may not be accurate. Hence, having noise in the input can stimulate different detectors to respond and fire different activations that would lead to changes in the probability output vector.   \n",
      "79                                                                                                                                                                                                                                                                                                                                                                             In their experiments, the authors showed that all of the models performed poorly on the bio-medical domain due to the textual data of the domain not being covered widely in the PLMs’ pretraining dataset. This lack of data can cause the PLM to struggle to reveal and capture knowledge specific to that domain. These results suggest that further training on bio-medical data could increase performance.   \n",
      "66                                                                                                                                                                                                                                                                                                                                                                                         Through experiments, the authors demonstrated that the performance of the model (i.e., MRR@10) decreased without knowledge propagation and that it was comparable to vanilla ERNIE, which demonstrated that multi-hop neighbors were essential for ranking performance. This result can be attributed to how using multi-hope neighbors allows for knowledge to propagate between query and passage.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                       iris_answer  Rouge1  Rouge2  RougeL  Bleu   Chrf  ChrfPlus  Meteor   Ter  Bert   WMS   SMS  Wisdm  Bleurt   BEM  Bart  Prometheus  Faithfullness  Relevancy  Correctness  RSim  Consistency  TSim   LLM   std  \n",
      "21                                                                                 Yes.\\n\\nIn the context of neural language models, the \"one-step-ahead conditional\" refers to the probability of calculating the next token in a sequence, given the previous tokens. This is the same as the modelled probability of calculating the next token   0.139   0.014   0.099 0.962 29.793    25.947   0.105 0.003 0.142 0.498 0.230  0.510  -0.820 0.052 0.010           1          0.000      0.794        0.787 0.748        0.000 0.000 0.000 7.989  \n",
      "79  By annealing the value of beta and decreasing the KL regularization during training, the decoder is able to make greater use of z because the model is no longer penalized as heavily for deviating from the prior distribution. This allows the decoder to explore the latent space more freely and use the information in z more effectively   0.136   0.000   0.136 2.127 30.711    26.934   0.145 0.010 0.236 0.442 0.244  0.305  -0.384 0.052 0.012           1            NaN      0.755        0.407 0.773        0.000 0.000 0.000 8.422  \n",
      "66        Channel shuffle operation for two groups involves dividing the channels in each group into subgroups, feeding each group in the next layer with different subgroups, and then transposing and flattening the output. This allows for efficient and elegant information exchange between groups, improving the performance of the network   0.198   0.080   0.173 5.515 31.308    28.402   0.172 0.010 0.243 0.452 0.269  0.430  -0.591 0.048 0.012           1          0.250      0.744        0.490 0.759        0.600 0.000 0.000 8.540  \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples with Highest Standard Deviation:\")\n",
    "print(highest_std_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
