{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasper 8-70b/qasper_70b.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasper 8-70b/qasper_70b_100.csv\"\n",
    "df_100 = pd.read_csv(path_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'correct_answer', 'context', 'answer_70b',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'Chrfplus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'question', 'correct_answer', 'context',\n",
       "       'answer_70b', 'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'Chrfplus',\n",
       "       'Meteor', 'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'BEM',\n",
       "       'Prometheus', 'Consistency', 'TSim', 'Faithfullness', 'Relevancy',\n",
       "       'Correctness', 'RSim', 'LLM', 'Bleurt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          int64\n",
      "question           object\n",
      "correct_answer     object\n",
      "context            object\n",
      "answer_70b         object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "Chrfplus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean       0.055770\n",
      "std        0.136179\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.909091\n",
      "Name: Rouge1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge1 = df['Rouge1'].describe()\n",
    "print(statistics_rouge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean       0.022427\n",
      "std        0.079700\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.750000\n",
      "Name: Rouge2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge2 = df['Rouge2'].describe()\n",
    "print(statistics_rouge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean       0.052856\n",
      "std        0.129306\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.909091\n",
      "Name: RougeL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rougel = df['RougeL'].describe()\n",
    "print(statistics_rougel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean       2.208941\n",
      "std        6.387843\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        2.147691\n",
      "max       75.627225\n",
      "Name: Bleu, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleu = df['Bleu'].describe()\n",
    "print(statistics_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean       0.056499\n",
      "std        0.129943\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.042017\n",
      "max        0.833333\n",
      "Name: Meteor, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_meteor = df['Meteor'].describe()\n",
    "print(statistics_meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean      13.749996\n",
      "std       16.432307\n",
      "min        0.000000\n",
      "25%        4.887042\n",
      "50%        7.352941\n",
      "75%       12.455447\n",
      "max       90.657876\n",
      "Name: Chrf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrf = df['Chrf'].describe()\n",
    "print(statistics_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean      12.249780\n",
      "std       15.729787\n",
      "min        0.000000\n",
      "25%        3.865979\n",
      "50%        5.899560\n",
      "75%       10.515321\n",
      "max       91.676667\n",
      "Name: Chrfplus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrfplus = df['Chrfplus'].describe()\n",
    "print(statistics_chrfplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean       0.001842\n",
      "std        0.003070\n",
      "min        0.000061\n",
      "25%        0.000500\n",
      "50%        0.000769\n",
      "75%        0.001536\n",
      "max        0.033816\n",
      "Name: Ter, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_ter = df['Ter'].describe()\n",
    "print(statistics_ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    705.000000\n",
      "mean       0.179541\n",
      "std        0.223111\n",
      "min       -0.109856\n",
      "25%        0.035504\n",
      "50%        0.087801\n",
      "75%        0.230378\n",
      "max        0.967299\n",
      "Name: Bert, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bert = df['Bert'].describe()\n",
    "print(statistics_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   705.000\n",
      "mean      0.316\n",
      "std       0.263\n",
      "min       0.000\n",
      "25%       0.140\n",
      "50%       0.240\n",
      "75%       0.390\n",
      "max       1.000\n",
      "Name: WMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wms = df['WMS'].describe()\n",
    "print(statistics_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   705.000\n",
      "mean      0.190\n",
      "std       0.225\n",
      "min      -0.110\n",
      "25%       0.040\n",
      "50%       0.097\n",
      "75%       0.239\n",
      "max       0.967\n",
      "Name: SMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_sms = df['SMS'].describe()\n",
    "print(statistics_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   162.000\n",
      "mean      0.466\n",
      "std       0.286\n",
      "min       0.000\n",
      "25%       0.222\n",
      "50%       0.458\n",
      "75%       0.708\n",
      "max       1.000\n",
      "Name: Wisdm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wisdm = df['Wisdm'].describe()\n",
    "print(statistics_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.256\n",
      "std       0.275\n",
      "min       0.038\n",
      "25%       0.064\n",
      "50%       0.113\n",
      "75%       0.378\n",
      "max       0.990\n",
      "Name: Bleurt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleurt = df_100['Bleurt'].describe()\n",
    "print(statistics_bleurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.256\n",
      "std       0.275\n",
      "min       0.038\n",
      "25%       0.064\n",
      "50%       0.113\n",
      "75%       0.378\n",
      "max       0.990\n",
      "Name: BEM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bem = df_100['BEM'].describe()\n",
    "print(statistics_bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.040\n",
      "std       0.076\n",
      "min       0.000\n",
      "25%       0.004\n",
      "50%       0.008\n",
      "75%       0.047\n",
      "max       0.502\n",
      "Name: Bart, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bart = df_100['Bart'].describe()\n",
    "print(statistics_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      2.500\n",
      "std       1.150\n",
      "min       1.000\n",
      "25%       1.000\n",
      "50%       3.000\n",
      "75%       3.000\n",
      "max       4.000\n",
      "Name: Prometheus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_prometheus = df_100['Prometheus'].describe()\n",
    "print(statistics_prometheus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.485\n",
      "std       0.419\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       0.800\n",
      "75%       0.800\n",
      "max       1.000\n",
      "Name: LLM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_llm = df_100['LLM'].describe()\n",
    "print(statistics_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   56.000\n",
      "mean     0.872\n",
      "std      0.272\n",
      "min      0.000\n",
      "25%      1.000\n",
      "50%      1.000\n",
      "75%      1.000\n",
      "max      1.000\n",
      "Name: Faithfullness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_faithfulness = df_100['Faithfullness'].describe()\n",
    "print(statistics_faithfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.702\n",
      "std       0.300\n",
      "min       0.000\n",
      "25%       0.775\n",
      "50%       0.810\n",
      "75%       0.859\n",
      "max       0.967\n",
      "Name: Relevancy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rrel = df_100['Relevancy'].describe()\n",
    "print(statistics_rrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.508\n",
      "std       0.259\n",
      "min       0.170\n",
      "25%       0.193\n",
      "50%       0.588\n",
      "75%       0.717\n",
      "max       0.940\n",
      "Name: Correctness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_correctness = df_100['Correctness'].describe()\n",
    "print(statistics_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.800\n",
      "std       0.074\n",
      "min       0.680\n",
      "25%       0.735\n",
      "50%       0.786\n",
      "75%       0.861\n",
      "max       0.991\n",
      "Name: RSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rsim = df_100['RSim'].describe()\n",
    "print(statistics_rsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      0.605\n",
      "std       0.455\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       1.000\n",
      "75%       1.000\n",
      "max       1.000\n",
      "Name: Consistency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_consistency = df_100['Consistency'].describe()\n",
    "print(statistics_consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count   100.000\n",
      "mean      1.410\n",
      "std       1.609\n",
      "min       0.000\n",
      "25%       0.000\n",
      "50%       1.000\n",
      "75%       2.000\n",
      "max       5.000\n",
      "Name: TSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_tsim = df_100['TSim'].describe()\n",
    "print(statistics_tsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  Rouge1  Rouge2  RougeL    Bleu    Chrf  Chrfplus  Meteor  \\\n",
      "count     705.000 705.000 705.000 705.000 705.000 705.000   705.000 705.000   \n",
      "mean      352.000   0.056   0.022   0.053   2.209  13.750    12.250   0.056   \n",
      "std       203.660   0.136   0.080   0.129   6.388  16.432    15.730   0.130   \n",
      "min         0.000   0.000   0.000   0.000   0.000   0.000     0.000   0.000   \n",
      "25%       176.000   0.000   0.000   0.000   0.000   4.887     3.866   0.000   \n",
      "50%       352.000   0.000   0.000   0.000   0.000   7.353     5.900   0.000   \n",
      "75%       528.000   0.000   0.000   0.000   2.148  12.455    10.515   0.042   \n",
      "max       704.000   0.909   0.750   0.909  75.627  90.658    91.677   0.833   \n",
      "\n",
      "          Ter    Bert     WMS     SMS   Wisdm  \n",
      "count 705.000 705.000 705.000 705.000 162.000  \n",
      "mean    0.002   0.180   0.316   0.190   0.466  \n",
      "std     0.003   0.223   0.263   0.225   0.286  \n",
      "min     0.000  -0.110   0.000  -0.110   0.000  \n",
      "25%     0.000   0.036   0.140   0.040   0.222  \n",
      "50%     0.001   0.088   0.240   0.097   0.458  \n",
      "75%     0.002   0.230   0.390   0.239   0.708  \n",
      "max     0.034   0.967   1.000   0.967   1.000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0.1  Unnamed: 0  Rouge1  Rouge2  RougeL    Bleu    Chrf  \\\n",
      "count       100.000     100.000 100.000 100.000 100.000 100.000 100.000   \n",
      "mean         49.500      49.500   0.124   0.047   0.119   4.616  22.397   \n",
      "std          29.011      29.011   0.177   0.106   0.169   7.528  21.082   \n",
      "min           0.000       0.000   0.000   0.000   0.000   0.000   0.000   \n",
      "25%          24.750      24.750   0.000   0.000   0.000   1.196   5.383   \n",
      "50%          49.500      49.500   0.017   0.000   0.017   2.092  11.901   \n",
      "75%          74.250      74.250   0.174   0.024   0.174   4.553  37.123   \n",
      "max          99.000      99.000   0.909   0.593   0.909  48.916  84.982   \n",
      "\n",
      "       Chrfplus  Meteor     Ter  ...     BEM  Prometheus  Consistency    TSim  \\\n",
      "count   100.000 100.000 100.000  ... 100.000     100.000      100.000 100.000   \n",
      "mean     21.211   0.125   0.003  ...   0.256       2.500        0.605   1.410   \n",
      "std      19.557   0.166   0.004  ...   0.275       1.150        0.455   1.609   \n",
      "min       0.000   0.000   0.000  ...   0.038       1.000        0.000   0.000   \n",
      "25%       6.717   0.022   0.001  ...   0.064       1.000        0.000   0.000   \n",
      "50%      11.094   0.052   0.002  ...   0.113       3.000        1.000   1.000   \n",
      "75%      35.737   0.177   0.004  ...   0.378       3.000        1.000   2.000   \n",
      "max      82.670   0.833   0.029  ...   0.990       4.000        1.000   5.000   \n",
      "\n",
      "       Faithfullness  Relevancy  Correctness    RSim     LLM  Bleurt  \n",
      "count         56.000    100.000      100.000 100.000 100.000 100.000  \n",
      "mean           0.872      0.702        0.508   0.800   0.485   0.256  \n",
      "std            0.272      0.300        0.259   0.074   0.419   0.275  \n",
      "min            0.000      0.000        0.170   0.680   0.000   0.038  \n",
      "25%            1.000      0.775        0.193   0.735   0.000   0.064  \n",
      "50%            1.000      0.810        0.588   0.786   0.800   0.113  \n",
      "75%            1.000      0.859        0.717   0.861   0.800   0.378  \n",
      "max            1.000      0.967        0.940   0.991   1.000   0.990  \n",
      "\n",
      "[8 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_100.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(df.describe())\n",
    "statistics_100 = pd.DataFrame(df_100.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_statistics_100 = statistics_100[['Bart', 'BEM', 'Prometheus',\n",
    "       'Consistency', 'TSim', 'Faithfullness', 'Relevancy', 'Correctness',\n",
    "       'RSim', 'LLM']]\n",
    "final_df = pd.concat([statistics, sub_statistics_100], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>Chrfplus</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Bert</th>\n",
       "      <th>...</th>\n",
       "      <th>Bart</th>\n",
       "      <th>BEM</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>TSim</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>RSim</th>\n",
       "      <th>LLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>705.000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>352.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.053</td>\n",
       "      <td>2.209</td>\n",
       "      <td>13.750</td>\n",
       "      <td>12.250</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.256</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.605</td>\n",
       "      <td>1.410</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>203.660</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.129</td>\n",
       "      <td>6.388</td>\n",
       "      <td>16.432</td>\n",
       "      <td>15.730</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.275</td>\n",
       "      <td>1.150</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1.609</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>176.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.887</td>\n",
       "      <td>3.866</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.064</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>352.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.353</td>\n",
       "      <td>5.900</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.113</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>528.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.148</td>\n",
       "      <td>12.455</td>\n",
       "      <td>10.515</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.378</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>704.000</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.909</td>\n",
       "      <td>75.627</td>\n",
       "      <td>90.658</td>\n",
       "      <td>91.677</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.991</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Rouge1  Rouge2  RougeL    Bleu    Chrf  Chrfplus  Meteor  \\\n",
       "count     705.000 705.000 705.000 705.000 705.000 705.000   705.000 705.000   \n",
       "mean      352.000   0.056   0.022   0.053   2.209  13.750    12.250   0.056   \n",
       "std       203.660   0.136   0.080   0.129   6.388  16.432    15.730   0.130   \n",
       "min         0.000   0.000   0.000   0.000   0.000   0.000     0.000   0.000   \n",
       "25%       176.000   0.000   0.000   0.000   0.000   4.887     3.866   0.000   \n",
       "50%       352.000   0.000   0.000   0.000   0.000   7.353     5.900   0.000   \n",
       "75%       528.000   0.000   0.000   0.000   2.148  12.455    10.515   0.042   \n",
       "max       704.000   0.909   0.750   0.909  75.627  90.658    91.677   0.833   \n",
       "\n",
       "          Ter    Bert  ...    Bart     BEM  Prometheus  Consistency    TSim  \\\n",
       "count 705.000 705.000  ... 100.000 100.000     100.000      100.000 100.000   \n",
       "mean    0.002   0.180  ...   0.040   0.256       2.500        0.605   1.410   \n",
       "std     0.003   0.223  ...   0.076   0.275       1.150        0.455   1.609   \n",
       "min     0.000  -0.110  ...   0.000   0.038       1.000        0.000   0.000   \n",
       "25%     0.000   0.036  ...   0.004   0.064       1.000        0.000   0.000   \n",
       "50%     0.001   0.088  ...   0.008   0.113       3.000        1.000   1.000   \n",
       "75%     0.002   0.230  ...   0.047   0.378       3.000        1.000   2.000   \n",
       "max     0.034   0.967  ...   0.502   0.990       4.000        1.000   5.000   \n",
       "\n",
       "       Faithfullness  Relevancy  Correctness    RSim     LLM  \n",
       "count         56.000    100.000      100.000 100.000 100.000  \n",
       "mean           0.872      0.702        0.508   0.800   0.485  \n",
       "std            0.272      0.300        0.259   0.074   0.419  \n",
       "min            0.000      0.000        0.170   0.680   0.000  \n",
       "25%            1.000      0.775        0.193   0.735   0.000  \n",
       "50%            1.000      0.810        0.588   0.786   0.800  \n",
       "75%            1.000      0.859        0.717   0.861   0.800  \n",
       "max            1.000      0.967        0.940   0.991   1.000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasper_70b.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3962\u001b[0m )\n\u001b[0;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'"
     ]
    }
   ],
   "source": [
    "final_df.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasper_70b.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['std'] = df_100.select_dtypes(include=['number']).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_70b</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>Chrfplus</th>\n",
       "      <th>...</th>\n",
       "      <th>BEM</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>TSim</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>RSim</th>\n",
       "      <th>LLM</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the seed lexicon?</td>\n",
       "      <td>A vocabulary of positive and negative predicat...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "      <td>Positive and negative predicates.</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.316</td>\n",
       "      <td>9.148</td>\n",
       "      <td>66.258</td>\n",
       "      <td>60.437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.800</td>\n",
       "      <td>18.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the results?</td>\n",
       "      <td>Using all data to train: AL -- BiGRU achieved ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "      <td>Tables 3 and 4.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>Based on the relation between events, the sugg...</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>Through Cause and Concession discourse relations.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.647</td>\n",
       "      <td>23.607</td>\n",
       "      <td>18.950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.800</td>\n",
       "      <td>6.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>Cause relation: both events in the relation sh...</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "      <td>Through Cause and Concession discourse relations.</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1.958</td>\n",
       "      <td>36.336</td>\n",
       "      <td>29.725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.800</td>\n",
       "      <td>9.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How big is the Japanese data?</td>\n",
       "      <td>7000000 pairs of events were extracted from th...</td>\n",
       "      <td>As a raw corpus, we used a Japanese web corpus...</td>\n",
       "      <td>100 million sentences.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.647</td>\n",
       "      <td>11.711</td>\n",
       "      <td>10.387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What is task success rate achieved?</td>\n",
       "      <td>96-97.6% using the objects color or shape and ...</td>\n",
       "      <td>To test our model, we generated 500 new scenar...</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.154</td>\n",
       "      <td>4.574</td>\n",
       "      <td>22.177</td>\n",
       "      <td>19.299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>How is performance of this system measured?</td>\n",
       "      <td>Using the BLEU score as a quantitative metric ...</td>\n",
       "      <td>We use the BLEU BIBREF30 metric on the validat...</td>\n",
       "      <td>BLEU for VQG, human evaluation for chatbot.</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.421</td>\n",
       "      <td>12.011</td>\n",
       "      <td>46.032</td>\n",
       "      <td>43.594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.800</td>\n",
       "      <td>12.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>How big dataset is used for training this system?</td>\n",
       "      <td>For the question generation model 15,000 image...</td>\n",
       "      <td>We use MS COCO, Bing and Flickr datasets from ...</td>\n",
       "      <td>75,000 questions and 467,777 utterances.</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.261</td>\n",
       "      <td>3.916</td>\n",
       "      <td>44.759</td>\n",
       "      <td>40.411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.900</td>\n",
       "      <td>12.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>How do they obtain word lattices from words?</td>\n",
       "      <td>By considering words as vertices and generatin...</td>\n",
       "      <td>Word Lattice\\nAs shown in Figure FIGREF4 , a w...</td>\n",
       "      <td>Treating substrings as vertexes and connecting...</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>3.657</td>\n",
       "      <td>45.667</td>\n",
       "      <td>39.459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.800</td>\n",
       "      <td>12.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How better is proposed method than baselines p...</td>\n",
       "      <td>Perplexity of proposed MEED model is 19.795 vs...</td>\n",
       "      <td>Table TABREF34 gives the perplexity scores obt...</td>\n",
       "      <td>significantly.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.287</td>\n",
       "      <td>7.245</td>\n",
       "      <td>8.042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.800</td>\n",
       "      <td>2.309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0                           What is the seed lexicon?   \n",
       "1                               What are the results?   \n",
       "2       How are relations used to propagate polarity?   \n",
       "3       How are relations used to propagate polarity?   \n",
       "4                       How big is the Japanese data?   \n",
       "..                                                ...   \n",
       "95               What is task success rate achieved?    \n",
       "96        How is performance of this system measured?   \n",
       "97  How big dataset is used for training this system?   \n",
       "98       How do they obtain word lattices from words?   \n",
       "99  How better is proposed method than baselines p...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "0   A vocabulary of positive and negative predicat...   \n",
       "1   Using all data to train: AL -- BiGRU achieved ...   \n",
       "2   Based on the relation between events, the sugg...   \n",
       "3   Cause relation: both events in the relation sh...   \n",
       "4   7000000 pairs of events were extracted from th...   \n",
       "..                                                ...   \n",
       "95  96-97.6% using the objects color or shape and ...   \n",
       "96  Using the BLEU score as a quantitative metric ...   \n",
       "97  For the question generation model 15,000 image...   \n",
       "98  By considering words as vertices and generatin...   \n",
       "99  Perplexity of proposed MEED model is 19.795 vs...   \n",
       "\n",
       "                                              context  \\\n",
       "0   The seed lexicon consists of positive and nega...   \n",
       "1   FLOAT SELECTED: Table 3: Performance of variou...   \n",
       "2   In this paper, we propose a simple and effecti...   \n",
       "3   In this paper, we propose a simple and effecti...   \n",
       "4   As a raw corpus, we used a Japanese web corpus...   \n",
       "..                                                ...   \n",
       "95  To test our model, we generated 500 new scenar...   \n",
       "96  We use the BLEU BIBREF30 metric on the validat...   \n",
       "97  We use MS COCO, Bing and Flickr datasets from ...   \n",
       "98  Word Lattice\\nAs shown in Figure FIGREF4 , a w...   \n",
       "99  Table TABREF34 gives the perplexity scores obt...   \n",
       "\n",
       "                                           answer_70b  Rouge1  Rouge2  RougeL  \\\n",
       "0                   Positive and negative predicates.   0.316   0.222   0.316   \n",
       "1                                     Tables 3 and 4.   0.000   0.000   0.000   \n",
       "2   Through Cause and Concession discourse relations.   0.000   0.000   0.000   \n",
       "3   Through Cause and Concession discourse relations.   0.100   0.000   0.100   \n",
       "4                              100 million sentences.   0.000   0.000   0.000   \n",
       "..                                                ...     ...     ...     ...   \n",
       "95                                              97.6%   0.154   0.000   0.154   \n",
       "96        BLEU for VQG, human evaluation for chatbot.   0.421   0.222   0.421   \n",
       "97           75,000 questions and 467,777 utterances.   0.261   0.091   0.261   \n",
       "98  Treating substrings as vertexes and connecting...   0.333   0.000   0.250   \n",
       "99                                     significantly.   0.000   0.000   0.000   \n",
       "\n",
       "     Bleu   Chrf  Chrfplus  ...   BEM  Prometheus  Consistency  TSim  \\\n",
       "0   9.148 66.258    60.437  ... 0.475           3        1.000 1.000   \n",
       "1   0.259  2.192     2.099  ... 0.088           1        1.000 0.000   \n",
       "2   1.647 23.607    18.950  ... 0.068           3        1.000 2.000   \n",
       "3   1.958 36.336    29.725  ... 0.843           3        1.000 2.000   \n",
       "4   1.647 11.711    10.387  ... 0.051           1        1.000 1.000   \n",
       "..    ...    ...       ...  ...   ...         ...          ...   ...   \n",
       "95  4.574 22.177    19.299  ... 0.284           4        1.000 1.000   \n",
       "96 12.011 46.032    43.594  ... 0.305           4        1.000 4.000   \n",
       "97  3.916 44.759    40.411  ... 0.416           4        0.500 2.000   \n",
       "98  3.657 45.667    39.459  ... 0.111           3        1.000 3.000   \n",
       "99  2.287  7.245     8.042  ... 0.083           3        0.000 1.000   \n",
       "\n",
       "    Faithfullness  Relevancy  Correctness  RSim   LLM    std  \n",
       "0           1.000      0.967        0.725 0.899 0.800 18.046  \n",
       "1           1.000      0.801        0.554 0.718 0.900  0.701  \n",
       "2           1.000      0.891        0.700 0.799 0.800  6.055  \n",
       "3           1.000      0.891        0.815 0.860 0.800  9.388  \n",
       "4           0.000      0.759        0.200 0.801 0.000  3.202  \n",
       "..            ...        ...          ...   ...   ...    ...  \n",
       "95          1.000      0.843        0.715 0.858 0.000  6.012  \n",
       "96          1.000      0.816        0.719 0.878 0.800 12.774  \n",
       "97          0.500      0.858        0.825 0.900 0.900 12.341  \n",
       "98          1.000      0.898        0.721 0.884 0.800 12.082  \n",
       "99            NaN      0.822        0.689 0.754 0.800  2.309  \n",
       "\n",
       "[100 rows x 28 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_100.sort_values(by='std')\n",
    "\n",
    "lowest_std_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_std_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options to ensure full display\n",
    "pd.set_option('display.max_columns', None)      # Show all columns\n",
    "pd.set_option('display.max_rows', None)         # Show all rows\n",
    "pd.set_option('display.max_colwidth', None)     # No truncation of column content\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Standard Deviation:\n",
      "                                                     question                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        correct_answer  \\\n",
      "43                                    How big is their model?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Proposed model has 1.16 million parameters and 11.04 MB.   \n",
      "41  How much better was the BLSTM-CNN-CRF than the BLSTM-CRF?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Best BLSTM-CNN-CRF had F1 score 86.87 vs 86.69 of best BLSTM-CRF.   \n",
      "1                                       What are the results?  Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \\nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                context  \\\n",
      "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          To figure out whether the proposed AEN-GloVe is a lightweight alternative of recurrent models, we study the model size of each model on the Restaurant dataset. Statistical results are reported in Table TABREF37 . We implement all the compared models base on the same source code infrastructure, use the same hyperparameters, and run them on the same GPU .\\nFLOAT SELECTED: Table 3: Model sizes. Memory footprints are evaluated on the Restaurant dataset. Lowest 2 are in bold.   \n",
      "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Table 2 shows our experiments on two models with and without different pre-trained word embedding – KP means the Kyubyong Park’s pre-trained word embeddings and EG means Edouard Grave’s pre-trained word embeddings.\\nFLOAT SELECTED: Table 2. F1 score of two models with different pre-trained word embeddings   \n",
      "1   FLOAT SELECTED: Table 3: Performance of various models on the ACP test set.\\nFLOAT SELECTED: Table 4: Results for small labeled training data. Given the performance with the full dataset, we show BERT trained only with the AL data.\\nAs for ${\\rm Encoder}$, we compared two types of neural networks: BiGRU and BERT. GRU BIBREF16 is a recurrent neural network sequence encoder. BiGRU reads an input sequence forward and backward and the output is the concatenation of the final forward and backward hidden states.\\nWe trained the model with the following four combinations of the datasets: AL, AL+CA+CO (two proposed models), ACP (supervised), and ACP+AL+CA+CO (semi-supervised). The corresponding objective functions were: $\\mathcal {L}_{\\rm AL}$, $\\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$, $\\mathcal {L}_{\\rm ACP}$, and $\\mathcal {L}_{\\rm ACP} + \\mathcal {L}_{\\rm AL} + \\mathcal {L}_{\\rm CA} + \\mathcal {L}_{\\rm CO}$.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           answer_70b  \\\n",
      "43  enicpedpedpedped_Utils　ゝ_Utilsped_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils injector bil_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utilsurrped_Utils_Utils_Utilspedped_Utilsped_Utils_Utils_Utils_Utils_Utils_UtilsUR_Utils_Utilsurre_Utils_Utilscessped_UtilsRetValnectped_UtilsVERNped_Utilscess_UtilsVERNVERNRetVal ThompedunapedVERN Kendrick GreenwoodVERN injectorpedškVERN injectorcess Eu幹VERN　ゝ Thom幹　ゝ幹　ゝ Thomilogy　ゝ Thom.firebaseapp Greenwood　ゝ　ゝUR ::::::::allisped AuthenticationService Greenwoodilogy :::::::: Thom Thom Thom Thom Thom Thom Thom789 Thomombatardi GreenwoodSIGSIG Thomimos Hra MyBaseFINITYrosseardi Greenwoodrosse glossrette gloss SIGientošk Thomrosserosseardi scazscheardi Kendricklakardirosse GreenwoodoserosseUR Recon Weissurre763imos ThomardiURUR AuthenticationServicefinityまず atmos KendrickurreurreURfinityURUR Rah AuthenticationService MyBaseURUR Kendrick Lustome scaomeurre//{{Parms Kendrickome　ゝ　ゝome Kendrickomeomeurฺ lax Greenwood　ゝ Kendrick mere Kendrick二二 sob　ゝ Friendship Greenwooddeenome Friendship Idleomefinity763 Reconfinityfinityfinityfinityfinityfinity intervenurrefinity789 Humanityfinity Humanitynakialiialiurre490789iali rarityfinity Promptfinity rarity Infragistics intervennak Humanitynaknakšk   \n",
      "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     二二 momentffeelingeressenger Padlinger_TBL Uncategorized Pad Dani Padendo949 Pad Padendo Pad Padendoisí Pad Padswire Pad Pad Pad Dani Pad Pad atmos Pad Pad618 Pad_TBLimmer Padendo Thorn Pad_TBL_TBLendoendoendopad Pad Padayar Pad Pad_TBL_qual Padnakpad+len fur Pad+len Neb Pad_TBL乂endoDescriptors Spartanpad Pad_TBLpadimmerForMember Pad Pad Pad pad Padendo pad Pad Pad Pad PadCompression Pad_TBL Baldwin leg Pad_TBL PadendoCompression Pad PadCompression takdir_TBLCompression takdir618immer Pad Bald618 Pad takdir takdir pad takdirisphereisphere Padcroft_TBL takdirCompression   \n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Tables 3 and 4.   \n",
      "\n",
      "    Rouge1  Rouge2  RougeL  Bleu  Chrf  Chrfplus  Meteor   Ter  Bert   WMS   SMS  Wisdm  Bleurt  Bart   BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness  RSim   LLM   std  \n",
      "43   0.000   0.000   0.000 0.000 1.221     0.916   0.000 0.010 0.018 0.197 0.018  0.020  -1.041 0.001 0.053           1        0.000 0.000            NaN      0.000        0.930 0.719 0.000 0.492  \n",
      "41   0.000   0.000   0.000 0.000 1.990     1.492   0.000 0.010 0.116 0.205 0.116  0.148  -1.162 0.000 0.081           1        0.000 0.000          0.000      0.706        0.682 0.727 0.000 0.622  \n",
      "1    0.000   0.000   0.000 0.259 2.192     2.099   0.005 0.000 0.213 0.276 0.242    NaN  -0.801 0.020 0.088           1        1.000 0.000          1.000      0.801        0.554 0.718 0.900 0.701  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Standard Deviation:\")\n",
    "print(lowest_std_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples with Highest Standard Deviation:\n",
      "                                                                                                       question                                                                                                                                                                                           correct_answer  \\\n",
      "53  What difficulties does sentiment analysis on Twitter have, compared to sentiment analysis in other domains?                      Tweets noisy nature, use of creative spelling and punctuation, misspellings, slang, new words, URLs, and genre-specific terminology and abbreviations, short (length limited) text.   \n",
      "12                                                                How is the intensity of the PTSD established?  Given we have four intensity, No PTSD, Low Risk PTSD, Moderate Risk PTSD and High Risk PTSD with a score of 0, 1, 2 and 3 respectively, the estimated intensity  is established as mean  squared error.   \n",
      "79                                                                                     what datasets were used?                                                                                                                                   IWSLT14 German-English, IWSLT14 Turkish-English, WMT14 English-German.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    context  \\\n",
      "53                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Pre-processing. Tweets are subject to standard preprocessing steps for text such as tokenization, stemming, lemmatization, stop-word removal, and part-of-speech tagging. Moreover, due to their noisy nature, they are also processed using some Twitter-specific techniques such as substitution/removal of URLs, of user mentions, of hashtags, and of emoticons, spelling correction, elongation normalization, abbreviation lookup, punctuation removal, detection of amplifiers and diminishers, negation scope detection, etc. For this, one typically uses Twitter-specific NLP tools such as part-of-speech and named entity taggers, syntactic parsers, etc. BIBREF47 , BIBREF48 , BIBREF49 .\\nDespite all these opportunities, the rise of social media has also presented new challenges for natural language processing (NLP) applications, which had largely relied on NLP tools tuned for formal text genres such as newswire, and thus were not readily applicable to the informal language and style of social media. That language proved to be quite challenging with its use of creative spelling and punctuation, misspellings, slang, new words, URLs, and genre-specific terminology and abbreviations, e.g., RT for re-tweet and #hashtags. In addition to the genre difference, there is also a difference in length: social media messages are generally short, often length-limited by design as in Twitter, i.e., a sentence or a headline rather than a full document. How to handle such challenges has only recently been the subject of thorough research BIBREF2 , BIBREF3 , BIBREF4 , BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 .   \n",
      "12  To provide an initial results, we take 50% of users' last week's (the week they responded of having PTSD) data to develop PTSD Linguistic dictionary and apply LAXARY framework to fill up surveys on rest of 50% dataset. The distribution of this training-test dataset segmentation followed a 50% distribution of PTSD and No PTSD from the original dataset. Our final survey based classification results showed an accuracy of 96% in detecting PTSD and mean squared error of 1.2 in estimating its intensity given we have four intensity, No PTSD, Low Risk PTSD, Moderate Risk PTSD and High Risk PTSD with a score of 0, 1, 2 and 3 respectively. Table TABREF29 shows the classification details of our experiment which provide the very good accuracy of our classification. To compare the outperformance of our method, we also implemented Coppersmith et. al. proposed method and achieved an 86% overall accuracy of detecting PTSD users BIBREF11 following the same training-test dataset distribution. Fig FIGREF28 illustrates the comparisons between LAXARY and Coppersmith et. al. proposed method. Here we can see, the outperformance of our proposed method as well as the importance of $s-score$ estimation. We also illustrates the importance of $\\alpha -score$ and $S-score$ in Fig FIGREF30. Fig FIGREF30 illustrates that if we change the number of training samples (%), LAXARY models outperforms Coppersmith et. al. proposed model under any condition. In terms of intensity, Coppersmith et. al. totally fails to provide any idea however LAXARY provides extremely accurate measures of intensity estimation for PTSD sufferers (as shown in Fig FIGREF31) which can be explained simply providing LAXARY model filled out survey details. Table TABREF29 shows the details of accuracies of both PTSD detection and intensity estimation. Fig FIGREF32 shows the classification accuracy changes over the training sample sizes for each survey which shows that DOSPERT scale outperform other surveys. Fig FIGREF33 shows that if we take previous weeks (instead of only the week diagnosis of PTSD was taken), there are no significant patterns of PTSD detection.   \n",
      "79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            We use three datasets for our experiments: IWSLT14 German-English, Turkish-English, and WMT14 English-German.   \n",
      "\n",
      "                                                                                                                                  answer_70b  Rouge1  Rouge2  RougeL   Bleu   Chrf  Chrfplus  Meteor   Ter  Bert   WMS   SMS  Wisdm  Bleurt  Bart   BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness  RSim   LLM    std  \n",
      "53  informal language, creative spelling, misspellings, slang, new words, URLs, genre-specific terminology, abbreviations, and short length.   0.556   0.222   0.500 35.322 70.995    69.984   0.481 0.011 0.782 0.928 0.782  0.770   0.483 0.167 0.124           4        1.000 5.000          1.000      0.793        0.871 0.914 0.900 20.841  \n",
      "12                                  A score of 0, 1, 2 and 3 for No PTSD, Low Risk PTSD, Moderate Risk PTSD and High Risk PTSD respectively.   0.583   0.593   0.333 48.916 74.155    75.093   0.555 0.013 0.642 0.571 0.642  0.946   0.340 0.375 0.689           3        1.000 1.000          1.000      0.865        0.606 0.923 0.800 22.928  \n",
      "79                                                                        IWSLT14 German-English, Turkish-English, and WMT14 English-German.   0.909   0.400   0.909 33.913 84.982    82.670   0.833 0.029 0.966 0.000 0.966  0.000   0.883 0.502 0.989           3        1.000 5.000          0.667      0.916        0.848 0.991 1.000 24.404  \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples with Highest Standard Deviation:\")\n",
    "print(highest_std_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['general_score'] = df_100.select_dtypes(include=['number']).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_100.sort_values(by='general_score')\n",
    "\n",
    "lowest_score_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_score_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Score:\n",
      "                                                     question                                                                                                                                                   correct_answer                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               context  \\\n",
      "43                                    How big is their model?                                                                                                         Proposed model has 1.16 million parameters and 11.04 MB.                                                                                                                           To figure out whether the proposed AEN-GloVe is a lightweight alternative of recurrent models, we study the model size of each model on the Restaurant dataset. Statistical results are reported in Table TABREF37 . We implement all the compared models base on the same source code infrastructure, use the same hyperparameters, and run them on the same GPU .\\nFLOAT SELECTED: Table 3: Model sizes. Memory footprints are evaluated on the Restaurant dataset. Lowest 2 are in bold.   \n",
      "71          What baselines did they compare their model with?  The baseline where path generation uses a standard sequence-to-sequence model augmented with attention mechanism and path verification uses depth-first search.  The baseline approach is based on BIBREF20 . It divides the task of interpreting commands for behavioral navigation into two steps: path generation, and path verification. For path generation, this baseline uses a standard sequence-to-sequence model augmented with an attention mechanism, similar to BIBREF23 , BIBREF6 . For path verification, the baseline uses depth-first search to find a route in the graph that matches the sequence of predicted behaviors. If no route matches perfectly, the baseline changes up to three behaviors in the predicted sequence to try to turn it into a valid path.   \n",
      "41  How much better was the BLSTM-CNN-CRF than the BLSTM-CRF?                                                                                                Best BLSTM-CNN-CRF had F1 score 86.87 vs 86.69 of best BLSTM-CRF.                                                                                                                                                                                                                                                                                                    Table 2 shows our experiments on two models with and without different pre-trained word embedding – KP means the Kyubyong Park’s pre-trained word embeddings and EG means Edouard Grave’s pre-trained word embeddings.\\nFLOAT SELECTED: Table 2. F1 score of two models with different pre-trained word embeddings   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           answer_70b  \\\n",
      "43  enicpedpedpedped_Utils　ゝ_Utilsped_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils injector bil_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utils_Utilsurrped_Utils_Utils_Utilspedped_Utilsped_Utils_Utils_Utils_Utils_Utils_UtilsUR_Utils_Utilsurre_Utils_Utilscessped_UtilsRetValnectped_UtilsVERNped_Utilscess_UtilsVERNVERNRetVal ThompedunapedVERN Kendrick GreenwoodVERN injectorpedškVERN injectorcess Eu幹VERN　ゝ Thom幹　ゝ幹　ゝ Thomilogy　ゝ Thom.firebaseapp Greenwood　ゝ　ゝUR ::::::::allisped AuthenticationService Greenwoodilogy :::::::: Thom Thom Thom Thom Thom Thom Thom789 Thomombatardi GreenwoodSIGSIG Thomimos Hra MyBaseFINITYrosseardi Greenwoodrosse glossrette gloss SIGientošk Thomrosserosseardi scazscheardi Kendricklakardirosse GreenwoodoserosseUR Recon Weissurre763imos ThomardiURUR AuthenticationServicefinityまず atmos KendrickurreurreURfinityURUR Rah AuthenticationService MyBaseURUR Kendrick Lustome scaomeurre//{{Parms Kendrickome　ゝ　ゝome Kendrickomeomeurฺ lax Greenwood　ゝ Kendrick mere Kendrick二二 sob　ゝ Friendship Greenwooddeenome Friendship Idleomefinity763 Reconfinityfinityfinityfinityfinityfinity intervenurrefinity789 Humanityfinity Humanitynakialiialiurre490789iali rarityfinity Promptfinity rarity Infragistics intervennak Humanitynaknakšk   \n",
      "71                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        BIBREF20, BIBREF23, BIBREF6   \n",
      "41                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     二二 momentffeelingeressenger Padlinger_TBL Uncategorized Pad Dani Padendo949 Pad Padendo Pad Padendoisí Pad Padswire Pad Pad Pad Dani Pad Pad atmos Pad Pad618 Pad_TBLimmer Padendo Thorn Pad_TBL_TBLendoendoendopad Pad Padayar Pad Pad_TBL_qual Padnakpad+len fur Pad+len Neb Pad_TBL乂endoDescriptors Spartanpad Pad_TBLpadimmerForMember Pad Pad Pad pad Padendo pad Pad Pad Pad PadCompression Pad_TBL Baldwin leg Pad_TBL PadendoCompression Pad PadCompression takdir_TBLCompression takdir618immer Pad Bald618 Pad takdir takdir pad takdirisphereisphere Padcroft_TBL takdirCompression   \n",
      "\n",
      "    Rouge1  Rouge2  RougeL          Bleu      Chrf  Chrfplus  Meteor       Ter      Bert       WMS       SMS     Wisdm    Bleurt      Bart       BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim  LLM  general_score  \n",
      "43     0.0     0.0     0.0  6.390675e-08  1.221058  0.915793     0.0  0.009901  0.018447  0.197146  0.018447  0.019884 -1.040725  0.001127  0.052959           1          0.0   0.0            NaN   0.000000     0.929711  0.718913  0.0       0.184666  \n",
      "71     0.0     0.0     0.0  0.000000e+00  0.000000  0.000000     0.0  0.001498  0.171325  0.000000  0.171325  0.000000 -1.009400  0.003458  0.039443           3          1.0   0.0            NaN   0.832028     0.180152  0.720608  0.0       0.232293  \n",
      "41     0.0     0.0     0.0  0.000000e+00  1.989816  1.492362     0.0  0.009901  0.115635  0.205281  0.115635  0.148202 -1.161692  0.000309  0.080851           1          0.0   0.0            0.0   0.706218     0.681823  0.727222  0.0       0.265720  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Score:\")\n",
    "print(lowest_score_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Hihgest Score:\n",
      "                                                                                                       question                                                                                                                                                                                           correct_answer  \\\n",
      "53  What difficulties does sentiment analysis on Twitter have, compared to sentiment analysis in other domains?                      Tweets noisy nature, use of creative spelling and punctuation, misspellings, slang, new words, URLs, and genre-specific terminology and abbreviations, short (length limited) text.   \n",
      "12                                                                How is the intensity of the PTSD established?  Given we have four intensity, No PTSD, Low Risk PTSD, Moderate Risk PTSD and High Risk PTSD with a score of 0, 1, 2 and 3 respectively, the estimated intensity  is established as mean  squared error.   \n",
      "79                                                                                     what datasets were used?                                                                                                                                   IWSLT14 German-English, IWSLT14 Turkish-English, WMT14 English-German.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    context  \\\n",
      "53                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Pre-processing. Tweets are subject to standard preprocessing steps for text such as tokenization, stemming, lemmatization, stop-word removal, and part-of-speech tagging. Moreover, due to their noisy nature, they are also processed using some Twitter-specific techniques such as substitution/removal of URLs, of user mentions, of hashtags, and of emoticons, spelling correction, elongation normalization, abbreviation lookup, punctuation removal, detection of amplifiers and diminishers, negation scope detection, etc. For this, one typically uses Twitter-specific NLP tools such as part-of-speech and named entity taggers, syntactic parsers, etc. BIBREF47 , BIBREF48 , BIBREF49 .\\nDespite all these opportunities, the rise of social media has also presented new challenges for natural language processing (NLP) applications, which had largely relied on NLP tools tuned for formal text genres such as newswire, and thus were not readily applicable to the informal language and style of social media. That language proved to be quite challenging with its use of creative spelling and punctuation, misspellings, slang, new words, URLs, and genre-specific terminology and abbreviations, e.g., RT for re-tweet and #hashtags. In addition to the genre difference, there is also a difference in length: social media messages are generally short, often length-limited by design as in Twitter, i.e., a sentence or a headline rather than a full document. How to handle such challenges has only recently been the subject of thorough research BIBREF2 , BIBREF3 , BIBREF4 , BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 .   \n",
      "12  To provide an initial results, we take 50% of users' last week's (the week they responded of having PTSD) data to develop PTSD Linguistic dictionary and apply LAXARY framework to fill up surveys on rest of 50% dataset. The distribution of this training-test dataset segmentation followed a 50% distribution of PTSD and No PTSD from the original dataset. Our final survey based classification results showed an accuracy of 96% in detecting PTSD and mean squared error of 1.2 in estimating its intensity given we have four intensity, No PTSD, Low Risk PTSD, Moderate Risk PTSD and High Risk PTSD with a score of 0, 1, 2 and 3 respectively. Table TABREF29 shows the classification details of our experiment which provide the very good accuracy of our classification. To compare the outperformance of our method, we also implemented Coppersmith et. al. proposed method and achieved an 86% overall accuracy of detecting PTSD users BIBREF11 following the same training-test dataset distribution. Fig FIGREF28 illustrates the comparisons between LAXARY and Coppersmith et. al. proposed method. Here we can see, the outperformance of our proposed method as well as the importance of $s-score$ estimation. We also illustrates the importance of $\\alpha -score$ and $S-score$ in Fig FIGREF30. Fig FIGREF30 illustrates that if we change the number of training samples (%), LAXARY models outperforms Coppersmith et. al. proposed model under any condition. In terms of intensity, Coppersmith et. al. totally fails to provide any idea however LAXARY provides extremely accurate measures of intensity estimation for PTSD sufferers (as shown in Fig FIGREF31) which can be explained simply providing LAXARY model filled out survey details. Table TABREF29 shows the details of accuracies of both PTSD detection and intensity estimation. Fig FIGREF32 shows the classification accuracy changes over the training sample sizes for each survey which shows that DOSPERT scale outperform other surveys. Fig FIGREF33 shows that if we take previous weeks (instead of only the week diagnosis of PTSD was taken), there are no significant patterns of PTSD detection.   \n",
      "79                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            We use three datasets for our experiments: IWSLT14 German-English, Turkish-English, and WMT14 English-German.   \n",
      "\n",
      "                                                                                                                                  answer_70b    Rouge1    Rouge2    RougeL       Bleu       Chrf   Chrfplus    Meteor       Ter      Bert       WMS       SMS     Wisdm    Bleurt      Bart       BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim  LLM  general_score  \n",
      "53  informal language, creative spelling, misspellings, slang, new words, URLs, genre-specific terminology, abbreviations, and short length.  0.555556  0.222222  0.500000  35.322461  70.995086  69.983782  0.480676  0.010601  0.781899  0.928114  0.781899  0.770161  0.483411  0.166788  0.123591           4          1.0   5.0       1.000000   0.793225     0.871313  0.913833  0.9       8.547157  \n",
      "12                                  A score of 0, 1, 2 and 3 for No PTSD, Low Risk PTSD, Moderate Risk PTSD and High Risk PTSD respectively.  0.583333  0.592593  0.333333  48.915901  74.154770  75.092969  0.554841  0.012776  0.641609  0.570796  0.641609  0.945537  0.339782  0.375207  0.689349           3          1.0   1.0       1.000000   0.864709     0.605718  0.922908  0.8       9.288597  \n",
      "79                                                                        IWSLT14 German-English, Turkish-English, and WMT14 English-German.  0.909091  0.400000  0.909091  33.913261  84.981801  82.670462  0.833333  0.029126  0.966236  0.000000  0.966237  0.000000  0.882604  0.502202  0.988759           3          1.0   5.0       0.666667   0.916044     0.847838  0.991386  1.0       9.668441  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Hihgest Score:\")\n",
    "print(highest_score_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
