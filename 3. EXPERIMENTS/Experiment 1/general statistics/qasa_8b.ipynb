{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasa 8-70b/qasa_8b.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/Qasa 8-70b/qasa_8b_100.csv\"\n",
    "df_100 = pd.read_csv(path_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'correct_answer', 'context', 'answer_8b',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'question', 'correct_answer', 'context',\n",
       "       'answer_8b', 'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus',\n",
       "       'Meteor', 'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'BEM',\n",
       "       'Prometheus', 'Consistency', 'TSim', 'Faithfullness', 'Relevancy',\n",
       "       'Correctness', 'RSim', 'LLM', 'Bleurt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          int64\n",
      "question           object\n",
      "correct_answer     object\n",
      "context            object\n",
      "answer_8b          object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "ChrfPlus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.164397\n",
      "std         0.170152\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.127322\n",
      "75%         0.254401\n",
      "max         1.000000\n",
      "Name: Rouge1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge1 = df['Rouge1'].describe()\n",
    "print(statistics_rouge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.063278\n",
      "std         0.122707\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.076923\n",
      "max         1.000000\n",
      "Name: Rouge2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge2 = df['Rouge2'].describe()\n",
    "print(statistics_rouge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.149414\n",
      "std         0.161039\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.115663\n",
      "75%         0.222222\n",
      "max         1.000000\n",
      "Name: RougeL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rougel = df['RougeL'].describe()\n",
    "print(statistics_rougel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        5.507469\n",
      "std         9.637289\n",
      "min         0.000000\n",
      "25%         1.157100\n",
      "50%         2.286957\n",
      "75%         5.242334\n",
      "max       100.000000\n",
      "Name: Bleu, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleu = df['Bleu'].describe()\n",
    "print(statistics_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.138043\n",
      "std         0.149890\n",
      "min         0.000000\n",
      "25%         0.034578\n",
      "50%         0.085146\n",
      "75%         0.190062\n",
      "max         0.937500\n",
      "Name: Meteor, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_meteor = df['Meteor'].describe()\n",
    "print(statistics_meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean       27.014678\n",
      "std        19.892279\n",
      "min         0.000000\n",
      "25%        10.542021\n",
      "50%        23.978609\n",
      "75%        39.125569\n",
      "max       100.000000\n",
      "Name: Chrf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrf = df['Chrf'].describe()\n",
    "print(statistics_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean       25.179070\n",
      "std        18.432673\n",
      "min         0.000000\n",
      "25%        10.623377\n",
      "50%        21.379416\n",
      "75%        35.299603\n",
      "max       100.000000\n",
      "Name: ChrfPlus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrfplus = df['ChrfPlus'].describe()\n",
    "print(statistics_chrfplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.004487\n",
      "std         0.025710\n",
      "min         0.000055\n",
      "25%         0.000883\n",
      "50%         0.002443\n",
      "75%         0.005275\n",
      "max         1.000000\n",
      "Name: Ter, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_ter = df['Ter'].describe()\n",
    "print(statistics_ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.406487\n",
      "std         0.255980\n",
      "min        -0.076508\n",
      "25%         0.166116\n",
      "50%         0.422398\n",
      "75%         0.610845\n",
      "max         1.000000\n",
      "Name: Bert, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bert = df['Bert'].describe()\n",
    "print(statistics_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.556536\n",
      "std         0.271794\n",
      "min         0.000000\n",
      "25%         0.359718\n",
      "50%         0.563041\n",
      "75%         0.764235\n",
      "max         1.000000\n",
      "Name: WMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wms = df['WMS'].describe()\n",
    "print(statistics_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1554.000000\n",
      "mean        0.437473\n",
      "std         0.251099\n",
      "min        -0.075642\n",
      "25%         0.220174\n",
      "50%         0.449785\n",
      "75%         0.638445\n",
      "max         1.000000\n",
      "Name: SMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_sms = df['SMS'].describe()\n",
    "print(statistics_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1060.000000\n",
      "mean        0.542172\n",
      "std         0.217994\n",
      "min         0.000000\n",
      "25%         0.390229\n",
      "50%         0.560866\n",
      "75%         0.704563\n",
      "max         1.000000\n",
      "Name: Wisdm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wisdm = df['Wisdm'].describe()\n",
    "print(statistics_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99.000000\n",
      "mean      0.232012\n",
      "std       0.238244\n",
      "min       0.042119\n",
      "25%       0.067169\n",
      "50%       0.144393\n",
      "75%       0.270228\n",
      "max       0.972918\n",
      "Name: Bleurt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleurt = df_100['Bleurt'].describe()\n",
    "print(statistics_bleurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99.000000\n",
      "mean      0.232012\n",
      "std       0.238244\n",
      "min       0.042119\n",
      "25%       0.067169\n",
      "50%       0.144393\n",
      "75%       0.270228\n",
      "max       0.972918\n",
      "Name: BEM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bem = df_100['BEM'].describe()\n",
    "print(statistics_bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.039021\n",
      "std        0.075254\n",
      "min        0.001324\n",
      "25%        0.005917\n",
      "50%        0.014701\n",
      "75%        0.041820\n",
      "max        0.563158\n",
      "Name: Bart, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bart = df_100['Bart'].describe()\n",
    "print(statistics_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       3.000000\n",
      "std        1.054093\n",
      "min        1.000000\n",
      "25%        3.000000\n",
      "50%        3.000000\n",
      "75%        4.000000\n",
      "max        4.000000\n",
      "Name: Prometheus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_prometheus = df_100['Prometheus'].describe()\n",
    "print(statistics_prometheus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.557500\n",
      "std        0.408704\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.800000\n",
      "75%        0.825000\n",
      "max        1.000000\n",
      "Name: LLM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_llm = df_100['LLM'].describe()\n",
    "print(statistics_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    76.000000\n",
      "mean      0.808114\n",
      "std       0.354605\n",
      "min       0.000000\n",
      "25%       0.729167\n",
      "50%       1.000000\n",
      "75%       1.000000\n",
      "max       1.000000\n",
      "Name: Faithfullness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_faithfulness = df_100['Faithfullness'].describe()\n",
    "print(statistics_faithfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.733595\n",
      "std        0.279013\n",
      "min        0.000000\n",
      "25%        0.757750\n",
      "50%        0.836116\n",
      "75%        0.872702\n",
      "max        0.979133\n",
      "Name: Relevancy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rrel = df_100['Relevancy'].describe()\n",
    "print(statistics_rrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99.000000\n",
      "mean      0.581739\n",
      "std       0.209371\n",
      "min       0.178610\n",
      "25%       0.474051\n",
      "50%       0.588781\n",
      "75%       0.711406\n",
      "max       0.975309\n",
      "Name: Correctness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_correctness = df_100['Correctness'].describe()\n",
    "print(statistics_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.818213\n",
      "std        0.066258\n",
      "min        0.691253\n",
      "25%        0.756923\n",
      "50%        0.824251\n",
      "75%        0.867583\n",
      "max        0.972046\n",
      "Name: RSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rsim = df_100['RSim'].describe()\n",
    "print(statistics_rsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.650833\n",
      "std        0.445727\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "Name: Consistency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_consistency = df_100['Consistency'].describe()\n",
    "print(statistics_consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       2.150000\n",
      "std        1.684001\n",
      "min        0.000000\n",
      "25%        1.000000\n",
      "50%        2.000000\n",
      "75%        4.000000\n",
      "max        5.000000\n",
      "Name: TSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_tsim = df_100['TSim'].describe()\n",
    "print(statistics_tsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0       Rouge1       Rouge2       RougeL         Bleu  \\\n",
      "count  1554.000000  1554.000000  1554.000000  1554.000000  1554.000000   \n",
      "mean    776.500000     0.164397     0.063278     0.149414     5.507469   \n",
      "std     448.745474     0.170152     0.122707     0.161039     9.637289   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%     388.250000     0.000000     0.000000     0.000000     1.157100   \n",
      "50%     776.500000     0.127322     0.000000     0.115663     2.286957   \n",
      "75%    1164.750000     0.254401     0.076923     0.222222     5.242334   \n",
      "max    1553.000000     1.000000     1.000000     1.000000   100.000000   \n",
      "\n",
      "              Chrf     ChrfPlus       Meteor          Ter         Bert  \\\n",
      "count  1554.000000  1554.000000  1554.000000  1554.000000  1554.000000   \n",
      "mean     27.014678    25.179070     0.138043     0.004487     0.406487   \n",
      "std      19.892279    18.432673     0.149890     0.025710     0.255980   \n",
      "min       0.000000     0.000000     0.000000     0.000055    -0.076508   \n",
      "25%      10.542021    10.623377     0.034578     0.000883     0.166116   \n",
      "50%      23.978609    21.379416     0.085146     0.002443     0.422398   \n",
      "75%      39.125569    35.299603     0.190062     0.005275     0.610845   \n",
      "max     100.000000   100.000000     0.937500     1.000000     1.000000   \n",
      "\n",
      "               WMS          SMS        Wisdm  \n",
      "count  1554.000000  1554.000000  1060.000000  \n",
      "mean      0.556536     0.437473     0.542172  \n",
      "std       0.271794     0.251099     0.217994  \n",
      "min       0.000000    -0.075642     0.000000  \n",
      "25%       0.359718     0.220174     0.390229  \n",
      "50%       0.563041     0.449785     0.560866  \n",
      "75%       0.764235     0.638445     0.704563  \n",
      "max       1.000000     1.000000     1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0.1  Unnamed: 0      Rouge1      Rouge2      RougeL  \\\n",
      "count    100.000000  100.000000  100.000000  100.000000  100.000000   \n",
      "mean      49.500000   49.500000    0.119164    0.036281    0.108436   \n",
      "std       29.011492   29.011492    0.135352    0.083985    0.126533   \n",
      "min        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%       24.750000   24.750000    0.000000    0.000000    0.000000   \n",
      "50%       49.500000   49.500000    0.072944    0.000000    0.068966   \n",
      "75%       74.250000   74.250000    0.178788    0.020627    0.154447   \n",
      "max       99.000000   99.000000    0.708333    0.539683    0.708333   \n",
      "\n",
      "             Bleu        Chrf    ChrfPlus      Meteor         Ter  ...  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  ...   \n",
      "mean     4.017091   23.155739   21.383210    0.098525    0.002835  ...   \n",
      "std      6.082553   17.151124   15.892417    0.102410    0.002832  ...   \n",
      "min      0.000000    0.633714    0.666667    0.000000    0.000071  ...   \n",
      "25%      0.701282    9.738647    9.240295    0.029887    0.000740  ...   \n",
      "50%      2.115136   19.872213   17.392418    0.061280    0.001928  ...   \n",
      "75%      4.471592   34.360884   31.576322    0.132418    0.003798  ...   \n",
      "max     38.296291   73.370190   72.671422    0.468750    0.014778  ...   \n",
      "\n",
      "             BEM  Prometheus  Consistency        TSim  Faithfullness  \\\n",
      "count  99.000000  100.000000   100.000000  100.000000      76.000000   \n",
      "mean    0.232012    3.000000     0.650833    2.150000       0.808114   \n",
      "std     0.238244    1.054093     0.445727    1.684001       0.354605   \n",
      "min     0.042119    1.000000     0.000000    0.000000       0.000000   \n",
      "25%     0.067169    3.000000     0.000000    1.000000       0.729167   \n",
      "50%     0.144393    3.000000     1.000000    2.000000       1.000000   \n",
      "75%     0.270228    4.000000     1.000000    4.000000       1.000000   \n",
      "max     0.972918    4.000000     1.000000    5.000000       1.000000   \n",
      "\n",
      "        Relevancy  Correctness        RSim         LLM     Bleurt  \n",
      "count  100.000000    99.000000  100.000000  100.000000  99.000000  \n",
      "mean     0.733595     0.581739    0.818213    0.557500   0.232012  \n",
      "std      0.279013     0.209371    0.066258    0.408704   0.238244  \n",
      "min      0.000000     0.178610    0.691253    0.000000   0.042119  \n",
      "25%      0.757750     0.474051    0.756923    0.000000   0.067169  \n",
      "50%      0.836116     0.588781    0.824251    0.800000   0.144393  \n",
      "75%      0.872702     0.711406    0.867583    0.825000   0.270228  \n",
      "max      0.979133     0.975309    0.972046    1.000000   0.972918  \n",
      "\n",
      "[8 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_100.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(df.describe())\n",
    "statistics_100 = pd.DataFrame(df_100.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_statistics_100 = statistics_100[['Bart', 'BEM', 'Prometheus',\n",
    "       'Consistency', 'TSim', 'Faithfullness', 'Relevancy', 'Correctness',\n",
    "       'RSim', 'LLM']]\n",
    "final_df = pd.concat([statistics, sub_statistics_100], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>ChrfPlus</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Bert</th>\n",
       "      <th>...</th>\n",
       "      <th>Bart</th>\n",
       "      <th>BEM</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>TSim</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>RSim</th>\n",
       "      <th>LLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>1554.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>776.500000</td>\n",
       "      <td>0.164397</td>\n",
       "      <td>0.063278</td>\n",
       "      <td>0.149414</td>\n",
       "      <td>5.507469</td>\n",
       "      <td>27.014678</td>\n",
       "      <td>25.179070</td>\n",
       "      <td>0.138043</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.406487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039021</td>\n",
       "      <td>0.232012</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.650833</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>0.808114</td>\n",
       "      <td>0.733595</td>\n",
       "      <td>0.581739</td>\n",
       "      <td>0.818213</td>\n",
       "      <td>0.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>448.745474</td>\n",
       "      <td>0.170152</td>\n",
       "      <td>0.122707</td>\n",
       "      <td>0.161039</td>\n",
       "      <td>9.637289</td>\n",
       "      <td>19.892279</td>\n",
       "      <td>18.432673</td>\n",
       "      <td>0.149890</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.255980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075254</td>\n",
       "      <td>0.238244</td>\n",
       "      <td>1.054093</td>\n",
       "      <td>0.445727</td>\n",
       "      <td>1.684001</td>\n",
       "      <td>0.354605</td>\n",
       "      <td>0.279013</td>\n",
       "      <td>0.209371</td>\n",
       "      <td>0.066258</td>\n",
       "      <td>0.408704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>-0.076508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.042119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178610</td>\n",
       "      <td>0.691253</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>388.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.157100</td>\n",
       "      <td>10.542021</td>\n",
       "      <td>10.623377</td>\n",
       "      <td>0.034578</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.166116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>0.067169</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.757750</td>\n",
       "      <td>0.474051</td>\n",
       "      <td>0.756923</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>776.500000</td>\n",
       "      <td>0.127322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115663</td>\n",
       "      <td>2.286957</td>\n",
       "      <td>23.978609</td>\n",
       "      <td>21.379416</td>\n",
       "      <td>0.085146</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.422398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.144393</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836116</td>\n",
       "      <td>0.588781</td>\n",
       "      <td>0.824251</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1164.750000</td>\n",
       "      <td>0.254401</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>5.242334</td>\n",
       "      <td>39.125569</td>\n",
       "      <td>35.299603</td>\n",
       "      <td>0.190062</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.610845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041820</td>\n",
       "      <td>0.270228</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872702</td>\n",
       "      <td>0.711406</td>\n",
       "      <td>0.867583</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1553.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563158</td>\n",
       "      <td>0.972918</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979133</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.972046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       Rouge1       Rouge2       RougeL         Bleu  \\\n",
       "count  1554.000000  1554.000000  1554.000000  1554.000000  1554.000000   \n",
       "mean    776.500000     0.164397     0.063278     0.149414     5.507469   \n",
       "std     448.745474     0.170152     0.122707     0.161039     9.637289   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     388.250000     0.000000     0.000000     0.000000     1.157100   \n",
       "50%     776.500000     0.127322     0.000000     0.115663     2.286957   \n",
       "75%    1164.750000     0.254401     0.076923     0.222222     5.242334   \n",
       "max    1553.000000     1.000000     1.000000     1.000000   100.000000   \n",
       "\n",
       "              Chrf     ChrfPlus       Meteor          Ter         Bert  ...  \\\n",
       "count  1554.000000  1554.000000  1554.000000  1554.000000  1554.000000  ...   \n",
       "mean     27.014678    25.179070     0.138043     0.004487     0.406487  ...   \n",
       "std      19.892279    18.432673     0.149890     0.025710     0.255980  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000055    -0.076508  ...   \n",
       "25%      10.542021    10.623377     0.034578     0.000883     0.166116  ...   \n",
       "50%      23.978609    21.379416     0.085146     0.002443     0.422398  ...   \n",
       "75%      39.125569    35.299603     0.190062     0.005275     0.610845  ...   \n",
       "max     100.000000   100.000000     0.937500     1.000000     1.000000  ...   \n",
       "\n",
       "             Bart        BEM  Prometheus  Consistency        TSim  \\\n",
       "count  100.000000  99.000000  100.000000   100.000000  100.000000   \n",
       "mean     0.039021   0.232012    3.000000     0.650833    2.150000   \n",
       "std      0.075254   0.238244    1.054093     0.445727    1.684001   \n",
       "min      0.001324   0.042119    1.000000     0.000000    0.000000   \n",
       "25%      0.005917   0.067169    3.000000     0.000000    1.000000   \n",
       "50%      0.014701   0.144393    3.000000     1.000000    2.000000   \n",
       "75%      0.041820   0.270228    4.000000     1.000000    4.000000   \n",
       "max      0.563158   0.972918    4.000000     1.000000    5.000000   \n",
       "\n",
       "       Faithfullness   Relevancy  Correctness        RSim         LLM  \n",
       "count      76.000000  100.000000    99.000000  100.000000  100.000000  \n",
       "mean        0.808114    0.733595     0.581739    0.818213    0.557500  \n",
       "std         0.354605    0.279013     0.209371    0.066258    0.408704  \n",
       "min         0.000000    0.000000     0.178610    0.691253    0.000000  \n",
       "25%         0.729167    0.757750     0.474051    0.756923    0.000000  \n",
       "50%         1.000000    0.836116     0.588781    0.824251    0.800000  \n",
       "75%         1.000000    0.872702     0.711406    0.867583    0.825000  \n",
       "max         1.000000    0.979133     0.975309    0.972046    1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfinal_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasa_8b.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3962\u001b[0m )\n\u001b[0;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'"
     ]
    }
   ],
   "source": [
    "final_df.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasa_8b.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['std'] = df_100.select_dtypes(include=['number']).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_8b</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>ChrfPlus</th>\n",
       "      <th>...</th>\n",
       "      <th>BEM</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>TSim</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>RSim</th>\n",
       "      <th>LLM</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do these automated metrics for human prefe...</td>\n",
       "      <td>The automated metrics that are mentioned while...</td>\n",
       "      <td>The ultimate aim of language technology is to ...</td>\n",
       "      <td>They differ in their approaches and factors co...</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.732982</td>\n",
       "      <td>27.616201</td>\n",
       "      <td>22.081028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059921</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840209</td>\n",
       "      <td>0.720494</td>\n",
       "      <td>0.881977</td>\n",
       "      <td>0.9</td>\n",
       "      <td>7.084322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does non-differentiable mean here? If the...</td>\n",
       "      <td>A formal definition of non-differentiability h...</td>\n",
       "      <td>The ultimate aim of language technology is to ...</td>\n",
       "      <td>In this context, \"non-differentiable\" refers t...</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>4.898135</td>\n",
       "      <td>43.729479</td>\n",
       "      <td>38.292830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218283</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882265</td>\n",
       "      <td>0.475288</td>\n",
       "      <td>0.901153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.655578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is the action space of language modeling p...</td>\n",
       "      <td>The action space for language modeling is equa...</td>\n",
       "      <td>Language generation action spaces are orders o...</td>\n",
       "      <td>The action space of language modeling is parti...</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>4.009311</td>\n",
       "      <td>41.052898</td>\n",
       "      <td>38.290416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138286</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.899895</td>\n",
       "      <td>0.604296</td>\n",
       "      <td>0.917182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.239924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are actor-critic algorithms and how do th...</td>\n",
       "      <td>Actor critic models are a class of reinforceme...</td>\n",
       "      <td>RL4LMs supports fine-tuning and training LMs f...</td>\n",
       "      <td>Actor-critic algorithms combine policy-based a...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>1.758139</td>\n",
       "      <td>26.757195</td>\n",
       "      <td>21.694115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900103</td>\n",
       "      <td>0.648753</td>\n",
       "      <td>0.880725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.026461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do the equations for Q-value and value re...</td>\n",
       "      <td>Q and V are mathematically expressed as: V_{t}...</td>\n",
       "      <td>RL4LMs supports fine-tuning and training LMs f...</td>\n",
       "      <td>The expected future rewards.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161811</td>\n",
       "      <td>9.871325</td>\n",
       "      <td>8.348569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079438</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777121</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.662598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>How does the choice of layers, in which to dow...</td>\n",
       "      <td>As we can see, downsampling aim to collect sum...</td>\n",
       "      <td>Strategy 3. Downsample late in the network so ...</td>\n",
       "      <td>It controls the size of activation maps.</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>3.330049</td>\n",
       "      <td>23.935368</td>\n",
       "      <td>23.514272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065167</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799973</td>\n",
       "      <td>0.419230</td>\n",
       "      <td>0.819777</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6.707759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Why did the authors use a mix of 1x1 and 3x3 f...</td>\n",
       "      <td>Authors used a mix of 1x1 and 3x3 filters in t...</td>\n",
       "      <td>Strategy 2. Decrease the number of input chann...</td>\n",
       "      <td>To apply Strategy 1 from Section 3.1.</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.363648</td>\n",
       "      <td>7.328948</td>\n",
       "      <td>6.657612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740677</td>\n",
       "      <td>0.832253</td>\n",
       "      <td>0.757520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.028719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>What is the total number of filters in squeeze...</td>\n",
       "      <td>s1x1 is the number of filters in the squeeze l...</td>\n",
       "      <td>We define the Fire module as follows.A Fire mo...</td>\n",
       "      <td>s_{1x1}.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760550</td>\n",
       "      <td>3.217521</td>\n",
       "      <td>3.490909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719685</td>\n",
       "      <td>0.806176</td>\n",
       "      <td>0.824705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.313943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Caffe framework does not natively support ...</td>\n",
       "      <td>The additional cost of using 2 convolutional l...</td>\n",
       "      <td>\\bulletSo that the output activations from 1x1...</td>\n",
       "      <td>None, as the outputs are concatenated.</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.662324</td>\n",
       "      <td>14.051856</td>\n",
       "      <td>12.959493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.721534</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.773410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.827474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Did the authors use AlexNet for evaluation of ...</td>\n",
       "      <td>Yes, as told by authors that they used AlexNet...</td>\n",
       "      <td>We now turn our attention to evaluating Squeez...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791171</td>\n",
       "      <td>6.464850</td>\n",
       "      <td>9.743233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606421</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>0.798309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.509979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   How do these automated metrics for human prefe...   \n",
       "1   What does non-differentiable mean here? If the...   \n",
       "2   Why is the action space of language modeling p...   \n",
       "3   What are actor-critic algorithms and how do th...   \n",
       "4   What do the equations for Q-value and value re...   \n",
       "..                                                ...   \n",
       "95  How does the choice of layers, in which to dow...   \n",
       "96  Why did the authors use a mix of 1x1 and 3x3 f...   \n",
       "97  What is the total number of filters in squeeze...   \n",
       "98  The Caffe framework does not natively support ...   \n",
       "99  Did the authors use AlexNet for evaluation of ...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "0   The automated metrics that are mentioned while...   \n",
       "1   A formal definition of non-differentiability h...   \n",
       "2   The action space for language modeling is equa...   \n",
       "3   Actor critic models are a class of reinforceme...   \n",
       "4   Q and V are mathematically expressed as: V_{t}...   \n",
       "..                                                ...   \n",
       "95  As we can see, downsampling aim to collect sum...   \n",
       "96  Authors used a mix of 1x1 and 3x3 filters in t...   \n",
       "97  s1x1 is the number of filters in the squeeze l...   \n",
       "98  The additional cost of using 2 convolutional l...   \n",
       "99  Yes, as told by authors that they used AlexNet...   \n",
       "\n",
       "                                              context  \\\n",
       "0   The ultimate aim of language technology is to ...   \n",
       "1   The ultimate aim of language technology is to ...   \n",
       "2   Language generation action spaces are orders o...   \n",
       "3   RL4LMs supports fine-tuning and training LMs f...   \n",
       "4   RL4LMs supports fine-tuning and training LMs f...   \n",
       "..                                                ...   \n",
       "95  Strategy 3. Downsample late in the network so ...   \n",
       "96  Strategy 2. Decrease the number of input chann...   \n",
       "97  We define the Fire module as follows.A Fire mo...   \n",
       "98  \\bulletSo that the output activations from 1x1...   \n",
       "99  We now turn our attention to evaluating Squeez...   \n",
       "\n",
       "                                            answer_8b    Rouge1    Rouge2  \\\n",
       "0   They differ in their approaches and factors co...  0.047059  0.000000   \n",
       "1   In this context, \"non-differentiable\" refers t...  0.290076  0.035928   \n",
       "2   The action space of language modeling is parti...  0.313725  0.153846   \n",
       "3   Actor-critic algorithms combine policy-based a...  0.088889  0.000000   \n",
       "4                        The expected future rewards.  0.000000  0.000000   \n",
       "..                                                ...       ...       ...   \n",
       "95           It controls the size of activation maps.  0.156250  0.096386   \n",
       "96              To apply Strategy 1 from Section 3.1.  0.047619  0.000000   \n",
       "97                                           s_{1x1}.  0.000000  0.000000   \n",
       "98             None, as the outputs are concatenated.  0.062500  0.000000   \n",
       "99                                               Yes.  0.000000  0.000000   \n",
       "\n",
       "      RougeL      Bleu       Chrf   ChrfPlus  ...       BEM  Prometheus  \\\n",
       "0   0.047059  0.732982  27.616201  22.081028  ...  0.059921           3   \n",
       "1   0.290076  4.898135  43.729479  38.292830  ...  0.218283           4   \n",
       "2   0.274510  4.009311  41.052898  38.290416  ...  0.138286           4   \n",
       "3   0.088889  1.758139  26.757195  21.694115  ...  0.429823           4   \n",
       "4   0.000000  0.161811   9.871325   8.348569  ...  0.079438           3   \n",
       "..       ...       ...        ...        ...  ...       ...         ...   \n",
       "95  0.156250  3.330049  23.935368  23.514272  ...  0.065167           1   \n",
       "96  0.047619  0.363648   7.328948   6.657612  ...  0.061412           1   \n",
       "97  0.000000  0.760550   3.217521   3.490909  ...  0.188542           3   \n",
       "98  0.062500  0.662324  14.051856  12.959493  ...  0.068957           3   \n",
       "99  0.000000  1.791171   6.464850   9.743233  ...  0.606421           4   \n",
       "\n",
       "    Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim  LLM  \\\n",
       "0      1.000000   4.0       1.000000   0.840209     0.720494  0.881977  0.9   \n",
       "1      0.750000   2.0       1.000000   0.882265     0.475288  0.901153  0.0   \n",
       "2      1.000000   4.0       0.666667   0.899895     0.604296  0.917182  0.0   \n",
       "3      0.666667   4.0            NaN   0.900103     0.648753  0.880725  0.0   \n",
       "4      1.000000   1.0       1.000000   0.713149          NaN  0.777121  0.8   \n",
       "..          ...   ...            ...        ...          ...       ...  ...   \n",
       "95     1.000000   1.0       1.000000   0.799973     0.419230  0.819777  0.8   \n",
       "96     1.000000   0.0            NaN   0.740677     0.832253  0.757520  0.0   \n",
       "97     1.000000   4.0       1.000000   0.719685     0.806176  0.824705  1.0   \n",
       "98     0.500000   1.0       0.666667   0.721534     0.493352  0.773410  0.0   \n",
       "99     0.000000   2.0            NaN   0.870769     0.699577  0.798309  1.0   \n",
       "\n",
       "          std  \n",
       "0    7.084322  \n",
       "1   11.655578  \n",
       "2   11.239924  \n",
       "3    7.026461  \n",
       "4    2.662598  \n",
       "..        ...  \n",
       "95   6.707759  \n",
       "96   2.028719  \n",
       "97   1.313943  \n",
       "98   3.827474  \n",
       "99   2.509979  \n",
       "\n",
       "[100 rows x 28 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_100.sort_values(by='std')\n",
    "\n",
    "lowest_std_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_std_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options to ensure full display\n",
    "pd.set_option('display.max_columns', None)      # Show all columns\n",
    "pd.set_option('display.max_rows', None)         # Show all rows\n",
    "pd.set_option('display.max_colwidth', None)     # No truncation of column content\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Standard Deviation:\n",
      "                                                                                                                                                                                 question  \\\n",
      "89  High accuracy is crucial for safety in autonomous vehicles. Would deploying smaller models using over-the-air updates in Tesla result in a trade-off with accuracy(and hence safety)?   \n",
      "39                      If dense/sparse retrievers are pre-trained on target corpus to enable the retrievers to be corpus-aware, can the fine-tuned retrievers outperform lexical models?   \n",
      "83                                                       Does this method likely to show similar tendency of performance improvement when other backbone model (like BERT_large) is used?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           correct_answer  \\\n",
      "89  Accuracy is crucial for safety but it's not only accuracy vs size relation. We should consider more aspects. For example, response time of a driving car system is very crucial for safety. Communication overhead between servers while model training increases with the size of the model so smaller models train faster. Updating models from company servers to the car or over-the-air updates based on AlexNet at that time would require 240MB of communication from the server to the car. Hence, smaller models require less communication, making frequent updates more feasible. Also, keeping in mind architectural designs such as adjusting some functionalities, introducing new ways of extracting features, or using different objectives and optimizers may make a small model achieve the same level of accuracy or even surpass the larger model; for instance, SqueezeNet is 50x smaller than AlexNet with equivalent accuracy.   \n",
      "39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         If dense/sparse retrievers are pre-trained on target corpus to enable the retrievers to be corpus-aware, the fine-tuned retrievers underperform lexical models   \n",
      "83                                                                                                                                                                                                                                                                                                                                                                                                      Through the experiments, this work demonstrated that the KERM model was able to significantly improve on the performance of its backbone model, ERNIE. The authors posit that this is due to how KERM explicitly introduces external knowledge which can improve semantic matching performance. This suggests that KERM models with other backbone models will be able to improve on the performance of their backbone models. However, the likelihood of performance improvements with other backbone models cannot be answered from this paper.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 context  \\\n",
      "89  Much of the recent research on deep convolutional neural networks (CNNs) has focused on increasing accuracy on computer vision datasets.For a given accuracy level, there typically exist multiple CNN architectures that achieve that accuracy level.Given equivalent accuracy, a CNN architecture with fewer parameters has several advantages:\\bulletMore efficient distributed training.Communication among servers is the limiting factor to the scalability of distributed CNN training.For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the modelÂ Iandola etÂ al. (2016).In short, small models train faster due to requiring less communication.\\bulletLess overhead when exporting new models to clients. For autonomous driving, companies such as Tesla periodically copy new models from their servers to customersâ€™ cars. This practice is often referred to as an over-the-air update. Consumer Reports has found that the safety of Teslaâ€™s Autopilot semi-autonomous driving functionality has incrementally improved with recent over-the-air updatesÂ Consumer Reports (2016). However, over-the-air updates of todayâ€™s typical CNN/DNN models can require large data transfers. With AlexNet, this would require 240MB of communication from the server to the car. Smaller models require less communication, making frequent updates more feasible.\\bulletFeasible FPGA and embedded deployment. FPGAs often have less than 10MB111For example, the Xilinx Vertex-7 FPGA has a maximum of 8.5 MBytes (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory. of on-chip memory and no off-chip memory or storage. For inference, a sufficiently small model could be stored directly on the FPGA instead of being bottlenecked by memory bandwidthÂ Qiu etÂ al. (2016), while video frames stream through the FPGA in real time.Further, when deploying CNNs on Application-Specific Integrated Circuits (ASICs), a sufficiently small model could be stored directly on-chip, and smaller models may enable the ASIC to fit on a smaller die.\\nSo far, we have proposed architectural design strategies for small models, followed these principles to create SqueezeNet, and discovered that SqueezeNet is 50x smaller than AlexNet with equivalent accuracy.However, SqueezeNet and other models reside in a broad and largely unexplored design space of CNN architectures.Now, in SectionsÂ 5 andÂ 6, we explore several aspects of the design space. We divide this architectural exploration into two main topics: microarchitectural exploration (per-module layer dimensions and configurations) and macroarchitectural exploration (high-level end-to-end organization of modules and other layers).    \n",
      "39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             We use beir to evaluate ten diverse retrieval methods from five broad architectures: lexical, sparse, dense, late interaction, and re-ranking. From our analysis, we find that no single approach consistently outperforms other approaches on all datasets. Further, we notice that the in-domain performance of a model does not correlate well with its generalization capabilities: models fine-tuned with identical training data might generalize differently. In terms of efficiency, we find a trade-off between the performances and the computational cost: computationally expensive models, like re-ranking models and late interaction model perform the best. More efficient approaches e.g.Â based on dense or sparse embeddings can substantially underperform traditional lexical models like BM25. Overall, BM25 remains a strong baseline for zero-shot text retrieval.   \n",
      "83                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          We use the traditional sparse retriever BM25Â (YangetÂ al., 2017) as our first stage method. All experiments are conducted under the same BM25 setting with 1000 retrieved candidates. We conduct experiments with the deep learning framework PaddlePaddleÂ (MaetÂ al., 2019) on up to 4 NVIDIA Tesla A100 GPUs (with 40G RAM). For the GMN module, we use Paddle Graph Learning (PGL)Â 222https://github.com/PaddlePaddle/PGL, an efficient and flexible graph learning framework based on PaddlePaddle. For training, we used the Adam optimizerÂ (Kingma and Ba, 2014) with a learning rate of 1e-5 for text encoder and 1e-4 for knowledge injector. The model is trained up to 5 epochs with a batch size of 640 and 240 for base and large models respectively.In our experiments, the PLM small, base and large models have 6, 12 and 24 Transformer layers respectively.The text encoder has 9 layers and 21 layers for base and large model respectively, and the knowledge injector both has 3 layers in our experiment. The dropout rates are set to 0.1. The ratio of the positive to the hard negative is set to 1:19.All transformer layers in KERMâ€™s backbone are initialized from ERNIE-2.0 baseÂ (SunetÂ al., 2020b), which is a BERT-like model pre-trained with a continual pre-training framework on multiple tasks. We perform Knowledge-enhanced pre-training on MARCO passage collection to warm up the parameters in knowledge injector, which has 60,000 iterations under the batch size of 256.For a fair comparison, the same pre-training without knowledge enhancement is also conducted on \\textrm{ERNIE}_{\\textrm{base}} re-ranker and all models in ablation studies.\\n(4) Compared with \\textrm{ERNIE}_{\\textrm{base}} we trained, \\textrm{KERM}_{\\textrm{base}} shows a significant improvement on both two query sets. This indicates the explicit introduction of external knowledge can alleviate the semantic gap and heterogeneity between query and passage, and improve the semantic matching performance.   \n",
      "\n",
      "   answer_8b  Rouge1  Rouge2  RougeL      Bleu      Chrf  ChrfPlus    Meteor       Ter      Bert       WMS       SMS  Wisdm    Bleurt      Bart       BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim   LLM       std  \n",
      "89       No.     0.0     0.0     0.0  0.228843  0.633714  0.999743  0.003534  0.000071  0.036112  0.220234  0.143435    NaN -0.825678  0.001806  0.058424           1          0.0   0.0            0.0   0.000000     0.315318  0.715815  0.00  0.393638  \n",
      "39       No.     0.0     0.0     0.0  0.000000  1.111111  0.666667  0.000000  0.000476  0.076963  0.115182  0.076963    NaN -0.984156  0.001999  0.042119           1          0.0   0.0            NaN   0.000000     0.682730  0.730739  0.75  0.467360  \n",
      "83       No.     0.0     0.0     0.0  0.413548  1.082251  1.732203  0.006297  0.000125  0.114908  0.286932  0.085068    NaN -0.706880  0.001570  0.059101           1          0.0   0.0            0.0   0.812393     0.479097  0.716277  0.00  0.519591  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Standard Deviation:\")\n",
    "print(lowest_std_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples with Highest Standard Deviation:\n",
      "                                                                                                                 question                                                                                                                                                                                                                                                                                                                                                                                                                        correct_answer  \\\n",
      "52  Why does the proposed method introduced EM framework to optimize the model (instead of directly optimizing the loss)?                                                                                                                                                                                                                                                                                                                                                                                                            EM guarantees convergence.   \n",
      "79                                                             What is the difference of RocketQAv1 and RocketQAv2 model?  RocketQAv1 trains dual-encoder and cross-encoder in a cascade manner, which leverages the powerful cross-encoder to empower the dual-encoder. While it inherits the parameters from RocketQAv1, RocketQAv2 extends the first version through a novel approach that jointly trains the dense passage retriever and passage re-ranker, and by using a large PLM for data augmentation and denoising (i.e.,  a distillation procedure).   \n",
      "62                                           In BUIR, how does the online encoder updated compared to the target encoder?                                                                                                                                                                The online encoder is updated to minimize the error between the output and the target and updated by the gradients back-propagated from the loss, but target network is updated based on the momentum update and updated as the moving average of the online encoder .   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
      "52                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Later, we will show that a generalized Expectation-Maximization frameworkprovides a direction to address above problemwith a convergence guarantee.The basic idea of optimizing Eq.Â (7) via EMis to start with an initial guessof the model parameter \\thetaand estimate the expected valuesof the missing variable c, i.e., the E-step.And once we have the values of c,we can maximize the Eq.Â (7) w.r.t theparameter \\theta, i.e., the M step.We can repeat this iterative process until the likelihood cannot increase anymore.\\nTo discover the benefits oflatent intentsand address challenges,we propose theIntent Contrastive Learning (ICL),a general learning paradigm thatleverages the latent intentfactor into SR.It learns usersâ€™ intentdistributionsfrom all user behavior sequencesvia clustering.And it leveragesthe learnt intentsinto the SR modelvia a new contrastive SSL,whichmaximizes the agreementbetween a view of sequenceand its corresponding intent.The intent representation learning moduleand the contrastive SSL module are mutually reinforcedto train a more expressivesequence encoder.We tackle the challenge of intentmining problem byintroducing alatent variable to represent usersâ€™ intentsand learn them alternatelyalong with the SR model optimization throughan expectation-maximization (EM) frameworkto ensure convergence.We suggest fusing learnt intent informationinto SR via the proposed contrastive SSL,as it can improve modelâ€™s performance as wellas robustness.Extensive experiments conducted on four real-world datasetsfurther verify the effectiveness of the proposed learning paradigm,which improves performance and robustness,even when recommender systemsfaceheavy data sparsity issues.\\nIn this work,we propose a new learning paradigm ICL that canmodel latent intent factorsfrom user interactionsand fuse them into a sequential recommendationmodel via a newcontrastive SSL objective.ICL is formulated withinan EM framework, which guaranteesconvergence. Detailed analyses showthe superiority of ICL andexperiments conducted onfour datasets further demonstratethe effectiveness of the proposed method.   \n",
      "79  Existing PLMs based re-rankers typically improve ranking performance from two aspects: (1) By optimizing the ranking procedure: monoBERTÂ (Nogueira and Cho, 2019) is the first work that re-purposed BERT as a passage re-ranker and achieves state-of-the-art results. duoBERTÂ (NogueiraetÂ al., 2019a) integrates monoBERT in a multistage ranking architecture and adopts a pairwise classification approach to passage relevance computation. UEDÂ (YanetÂ al., 2021) proposes a cascade pre-training manner that can jointly enhance the retrieval stage through passage expansion with a pre-trained query generator and thus elevate the re-ranking stage with a pre-trained transformer encoder. The two stages can facilitate each other in a unified pre-training framework. H-ERNIEÂ (ChuetÂ al., 2022) proposes a multi-granularity PLM for web search.(2) By designing rational distillation procedure: LM Distill + Fine-TuningÂ (GaoetÂ al., 2020) explores a variety of distillation methods to equip a smaller re-ranker with both general-purpose language modeling knowledge learned in pre-training and search- specific relevance modeling knowledge learned in fine-tuning, and produces a faster re-ranker with better ranking performance. CAKDÂ (HofstÃ¤tter etÂ al., 2020) proposes a cross-architecture knowledge distillation procedure with a Margin-MSE loss, which can distill knowledge from multiple teachers at the same time. RocketQAv1Â (Qu etÂ al., 2021) trains dual-encoder and cross-encoder in a cascade manner, which leverages the powerful cross-encoder to empower the dual-encoder. RocketQAv2Â (Ren etÂ al., 2021) proposes a novel approach that jointly trains the dense passage retriever and passage re-ranker. The parameters of RocketQAv2 are inherited from RocketQAv1. Besides, RocketQAv2 utilizes a large PLM for data augmentation and denoising, which can also be regarded as a distillation procedure. Notably, these two types of studies anticipate more insightful information to be captured by the advanced ranking and training procedures, while neglecting the limitations of implicit knowledge extracted from noisy and heterogeneous data. Therefore, in this paper, we proposed the first knowledge-enhanced PLM based re-ranker, which thoughtfully leverages explicit external knowledge that improve the effectiveness of the model.\\nWe include several PLMs based re-rankers in our evaluation, including the state-of-the-art:â€¢monoBERTÂ (Nogueira and Cho, 2019): The first study that re-purposes BERT as a re-ranker and achieves state-of-the-art results.â€¢duoBERTÂ (NogueiraetÂ al., 2019a):This work proposes a pairwise classification approach using BERT, which obtains the ability to be more sensitive to semantics through greater computation.â€¢UEDÂ (YanetÂ al., 2021): A unified pre-training framework that jointly refines re-ranker and query generator. For a fair comparison, we only use the re-ranker in UED without passage expansion.â€¢LM Distill+Fine-Tuning (LDFT)Â (GaoetÂ al., 2020):A variety of distillation methods are compared in this paper. The experimental results indicate that a proper distillation procedure (i.e. first distill the language model, and then fine-tune on the ranking task) could produce a faster re-ranker with better ranking performance.â€¢CAKDÂ (HofstÃ¤tter etÂ al., 2020): This work proposes a cross-architecture knowledge distillation procedure with Margin-MSE loss, which can distill knowledge from multiple teachers.â€¢RocketQAv1Â (Qu etÂ al., 2021): This work mainly focuses on the training of PLM based retriever, where the re-ranker is an intermediate product of its training process.â€¢RocketQAv2Â (Ren etÂ al., 2021): Based on RocketQAv1, this work proposes a novel approach that jointly trains the PLM based retriever and re-ranker.To compare the performance of different methods, we resort to two ranking metrics.For MSMARCO-DEV, We adopt Mean Reciprocal Rank (i.e., MRR@10).For TREC 2019 DL, we use Mean Average Precision, i.e., MAP@10 and MAP@30.For Ohsumed, both Mean Reciprocal Rank and Mean Average Precision (i.e., MRR@10 and MAP@10) are employed for comprehensive performance analysis in queries requiring in-depth domain knowledge.   \n",
      "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          BUIR makes use of two distinct encoder networks that have the same structure: online encoder f_{\\theta} and target encoder f_{\\xi}.They are parameterized by \\theta and \\xi, respectively.The key idea of BUIR is to train the online encoder by using outputs of the target encoder as its target, while gradually improving the target encoder as well.The main difference of BUIR from existing end-to-end learning frameworks is that f_{\\theta} and f_{\\xi} are updated in different ways.The online encoder is trained to minimize the error between its output and the target, whereas the target network is slowly updated based on the momentum updateÂ (HeetÂ al., 2020b) so as to keep its output consistent.\\nTo sum up, the parameters of the online encoder and target encoder are optimized by(4)\\begin{split}\\theta&\\leftarrow\\theta-\\eta\\cdot\\nabla_{\\theta}\\mathcal{L}_{\\theta,\\xi}\\\\\\xi&\\leftarrow\\tau\\cdot\\xi+(1-\\tau)\\cdot\\theta.\\end{split}\\eta is the learning rate for stochastic optimization, and \\tau\\in[0,1] is a momentum coefficient (also called as target decay) for momentum-based moving average.The online encoder f_{\\theta} (and the predictor q_{\\theta}) is effectively optimized by the gradients back-propagated from the loss (EquationÂ (3)), while the target encoder f_{\\xi} is updated as the moving average of the online encoder.By taking a large value of \\tau, the target encoder slowly approximates the online encoder.This momentum-based update makes \\xi evolve more slowly than \\theta, which enables to bootstrap the representations by providing enhanced but consistent targets to the online encodersÂ (HeetÂ al., 2020b; Grill etÂ al., 2020).FigureÂ 1 illustrates the overall framework of BUIR with the simple one-hot encoders.\\nBypassing the collapsed solution.Â Â It is obvious that the loss in EquationÂ (3) admits the collapsed solution with respect to \\theta and \\xi, which means both the encoders generate the same representations for all users and items.For this reason, the conventional end-to-end learning strategy, which optimizes both f_{\\theta} and f_{\\xi} to minimize the loss (i.e., cross-prediction error), may easily lead to such collapsed solution.In contrast, our proposed framework updates each of the encoders in different ways.From EquationÂ (4), the online encoder is optimized to minimize the loss, while the target encoder is updated to slowly approximate the online encoder.That is, the direction of updating the target encoder (\\theta-\\xi) totally differs from that of updating the online encoder (-\\nabla_{\\theta}\\mathcal{L}_{\\theta,\\xi}),and this effectively keeps both the encoders from converging to the collapsed solution.Several recent work on bootstrapping-based representation learningÂ (Grill etÂ al., 2020; Chen and He, 2021) empirically demonstrated that this kind of dynamics (i.e., updating two networks differently) allows to avoid the collapsed solution without any explicit term to prevent it.\\nSimilarly to SectionÂ 3.2, the online encoder is trained by minimizing \\mathcal{L}_{\\theta,\\xi}(\\psi(u,\\mathcal{V}_{u}),\\psi(v,\\mathcal{U}_{v})), and the target encoder is slowly updated by the momentum mechanism.After the optimization is finished, the interaction score is inferred by f_{\\theta}(u,\\mathcal{V}_{u}) and f_{\\theta}(v,\\mathcal{U}_{v}) (EquationÂ (5)).FigureÂ 2 shows an example of our data augmentation which injects a certain level of perturbations to the neighbors.   \n",
      "\n",
      "                                                                                                                                                   answer_8b    Rouge1    Rouge2    RougeL       Bleu       Chrf   ChrfPlus    Meteor       Ter      Bert       WMS       SMS     Wisdm    Bleurt      Bart       BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim  LLM        std  \n",
      "52                                                                                                                                    To ensure convergence.  0.333333  0.000000  0.333333  31.947155  56.298532  52.701584  0.468750  0.014778  0.537225  0.571122  0.537225       NaN  0.686127  0.016070  0.966098           4          1.0   5.0            1.0   0.897614     0.712096  0.848385  0.8  16.700715  \n",
      "79  RocketQAv1 trains dual-encoder and cross-encoder in a cascade manner, while RocketQAv2 jointly trains the dense passage retriever and passage re-ranker.  0.468750  0.379747  0.468750  23.716085  70.481771  68.642093  0.296215  0.004975  0.854980  0.647819  0.843796  0.796243  0.007957  0.563158  0.162981           4          1.0   4.0            1.0   0.979133     0.493012  0.972046  1.0  20.052025  \n",
      "62  The online encoder is updated to minimize the error between its output and the target, while the target encoder is updated based on the momentum update.  0.708333  0.539683  0.708333  38.296291  73.370190  72.671422  0.433261  0.010717  0.904643  0.956057  0.904643  0.708953  0.409631  0.331525  0.408583           4          1.0   4.0            1.0   0.966878     0.741574  0.966296  0.9  21.686909  \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples with Highest Standard Deviation:\")\n",
    "print(highest_std_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERAL SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['general_score'] = df_100.select_dtypes(include=['number']).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_8b</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>ChrfPlus</th>\n",
       "      <th>...</th>\n",
       "      <th>BEM</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>TSim</th>\n",
       "      <th>Faithfullness</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>RSim</th>\n",
       "      <th>LLM</th>\n",
       "      <th>general_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do these automated metrics for human prefe...</td>\n",
       "      <td>The automated metrics that are mentioned while...</td>\n",
       "      <td>The ultimate aim of language technology is to ...</td>\n",
       "      <td>They differ in their approaches and factors co...</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.732982</td>\n",
       "      <td>27.616201</td>\n",
       "      <td>22.081028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059921</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840209</td>\n",
       "      <td>0.720494</td>\n",
       "      <td>0.881977</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.777869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does non-differentiable mean here? If the...</td>\n",
       "      <td>A formal definition of non-differentiability h...</td>\n",
       "      <td>The ultimate aim of language technology is to ...</td>\n",
       "      <td>In this context, \"non-differentiable\" refers t...</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>4.898135</td>\n",
       "      <td>43.729479</td>\n",
       "      <td>38.292830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218283</td>\n",
       "      <td>4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882265</td>\n",
       "      <td>0.475288</td>\n",
       "      <td>0.901153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.369798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is the action space of language modeling p...</td>\n",
       "      <td>The action space for language modeling is equa...</td>\n",
       "      <td>Language generation action spaces are orders o...</td>\n",
       "      <td>The action space of language modeling is parti...</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>4.009311</td>\n",
       "      <td>41.052898</td>\n",
       "      <td>38.290416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138286</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.899895</td>\n",
       "      <td>0.604296</td>\n",
       "      <td>0.917182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.306702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are actor-critic algorithms and how do th...</td>\n",
       "      <td>Actor critic models are a class of reinforceme...</td>\n",
       "      <td>RL4LMs supports fine-tuning and training LMs f...</td>\n",
       "      <td>Actor-critic algorithms combine policy-based a...</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>1.758139</td>\n",
       "      <td>26.757195</td>\n",
       "      <td>21.694115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900103</td>\n",
       "      <td>0.648753</td>\n",
       "      <td>0.880725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.938923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What do the equations for Q-value and value re...</td>\n",
       "      <td>Q and V are mathematically expressed as: V_{t}...</td>\n",
       "      <td>RL4LMs supports fine-tuning and training LMs f...</td>\n",
       "      <td>The expected future rewards.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161811</td>\n",
       "      <td>9.871325</td>\n",
       "      <td>8.348569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079438</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777121</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.245680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>How does the choice of layers, in which to dow...</td>\n",
       "      <td>As we can see, downsampling aim to collect sum...</td>\n",
       "      <td>Strategy 3. Downsample late in the network so ...</td>\n",
       "      <td>It controls the size of activation maps.</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>3.330049</td>\n",
       "      <td>23.935368</td>\n",
       "      <td>23.514272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065167</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799973</td>\n",
       "      <td>0.419230</td>\n",
       "      <td>0.819777</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.598328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Why did the authors use a mix of 1x1 and 3x3 f...</td>\n",
       "      <td>Authors used a mix of 1x1 and 3x3 filters in t...</td>\n",
       "      <td>Strategy 2. Decrease the number of input chann...</td>\n",
       "      <td>To apply Strategy 1 from Section 3.1.</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.363648</td>\n",
       "      <td>7.328948</td>\n",
       "      <td>6.657612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061412</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.740677</td>\n",
       "      <td>0.832253</td>\n",
       "      <td>0.757520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.869947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>What is the total number of filters in squeeze...</td>\n",
       "      <td>s1x1 is the number of filters in the squeeze l...</td>\n",
       "      <td>We define the Fire module as follows.A Fire mo...</td>\n",
       "      <td>s_{1x1}.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760550</td>\n",
       "      <td>3.217521</td>\n",
       "      <td>3.490909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188542</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719685</td>\n",
       "      <td>0.806176</td>\n",
       "      <td>0.824705</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Caffe framework does not natively support ...</td>\n",
       "      <td>The additional cost of using 2 convolutional l...</td>\n",
       "      <td>\\bulletSo that the output activations from 1x1...</td>\n",
       "      <td>None, as the outputs are concatenated.</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.662324</td>\n",
       "      <td>14.051856</td>\n",
       "      <td>12.959493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068957</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.721534</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.773410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.575110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Did the authors use AlexNet for evaluation of ...</td>\n",
       "      <td>Yes, as told by authors that they used AlexNet...</td>\n",
       "      <td>We now turn our attention to evaluating Squeez...</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.791171</td>\n",
       "      <td>6.464850</td>\n",
       "      <td>9.743233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606421</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>0.798309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.361005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   How do these automated metrics for human prefe...   \n",
       "1   What does non-differentiable mean here? If the...   \n",
       "2   Why is the action space of language modeling p...   \n",
       "3   What are actor-critic algorithms and how do th...   \n",
       "4   What do the equations for Q-value and value re...   \n",
       "..                                                ...   \n",
       "95  How does the choice of layers, in which to dow...   \n",
       "96  Why did the authors use a mix of 1x1 and 3x3 f...   \n",
       "97  What is the total number of filters in squeeze...   \n",
       "98  The Caffe framework does not natively support ...   \n",
       "99  Did the authors use AlexNet for evaluation of ...   \n",
       "\n",
       "                                       correct_answer  \\\n",
       "0   The automated metrics that are mentioned while...   \n",
       "1   A formal definition of non-differentiability h...   \n",
       "2   The action space for language modeling is equa...   \n",
       "3   Actor critic models are a class of reinforceme...   \n",
       "4   Q and V are mathematically expressed as: V_{t}...   \n",
       "..                                                ...   \n",
       "95  As we can see, downsampling aim to collect sum...   \n",
       "96  Authors used a mix of 1x1 and 3x3 filters in t...   \n",
       "97  s1x1 is the number of filters in the squeeze l...   \n",
       "98  The additional cost of using 2 convolutional l...   \n",
       "99  Yes, as told by authors that they used AlexNet...   \n",
       "\n",
       "                                              context  \\\n",
       "0   The ultimate aim of language technology is to ...   \n",
       "1   The ultimate aim of language technology is to ...   \n",
       "2   Language generation action spaces are orders o...   \n",
       "3   RL4LMs supports fine-tuning and training LMs f...   \n",
       "4   RL4LMs supports fine-tuning and training LMs f...   \n",
       "..                                                ...   \n",
       "95  Strategy 3. Downsample late in the network so ...   \n",
       "96  Strategy 2. Decrease the number of input chann...   \n",
       "97  We define the Fire module as follows.A Fire mo...   \n",
       "98  \\bulletSo that the output activations from 1x1...   \n",
       "99  We now turn our attention to evaluating Squeez...   \n",
       "\n",
       "                                            answer_8b    Rouge1    Rouge2  \\\n",
       "0   They differ in their approaches and factors co...  0.047059  0.000000   \n",
       "1   In this context, \"non-differentiable\" refers t...  0.290076  0.035928   \n",
       "2   The action space of language modeling is parti...  0.313725  0.153846   \n",
       "3   Actor-critic algorithms combine policy-based a...  0.088889  0.000000   \n",
       "4                        The expected future rewards.  0.000000  0.000000   \n",
       "..                                                ...       ...       ...   \n",
       "95           It controls the size of activation maps.  0.156250  0.096386   \n",
       "96              To apply Strategy 1 from Section 3.1.  0.047619  0.000000   \n",
       "97                                           s_{1x1}.  0.000000  0.000000   \n",
       "98             None, as the outputs are concatenated.  0.062500  0.000000   \n",
       "99                                               Yes.  0.000000  0.000000   \n",
       "\n",
       "      RougeL      Bleu       Chrf   ChrfPlus  ...       BEM  Prometheus  \\\n",
       "0   0.047059  0.732982  27.616201  22.081028  ...  0.059921           3   \n",
       "1   0.290076  4.898135  43.729479  38.292830  ...  0.218283           4   \n",
       "2   0.274510  4.009311  41.052898  38.290416  ...  0.138286           4   \n",
       "3   0.088889  1.758139  26.757195  21.694115  ...  0.429823           4   \n",
       "4   0.000000  0.161811   9.871325   8.348569  ...  0.079438           3   \n",
       "..       ...       ...        ...        ...  ...       ...         ...   \n",
       "95  0.156250  3.330049  23.935368  23.514272  ...  0.065167           1   \n",
       "96  0.047619  0.363648   7.328948   6.657612  ...  0.061412           1   \n",
       "97  0.000000  0.760550   3.217521   3.490909  ...  0.188542           3   \n",
       "98  0.062500  0.662324  14.051856  12.959493  ...  0.068957           3   \n",
       "99  0.000000  1.791171   6.464850   9.743233  ...  0.606421           4   \n",
       "\n",
       "    Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim  LLM  \\\n",
       "0      1.000000   4.0       1.000000   0.840209     0.720494  0.881977  0.9   \n",
       "1      0.750000   2.0       1.000000   0.882265     0.475288  0.901153  0.0   \n",
       "2      1.000000   4.0       0.666667   0.899895     0.604296  0.917182  0.0   \n",
       "3      0.666667   4.0            NaN   0.900103     0.648753  0.880725  0.0   \n",
       "4      1.000000   1.0       1.000000   0.713149          NaN  0.777121  0.8   \n",
       "..          ...   ...            ...        ...          ...       ...  ...   \n",
       "95     1.000000   1.0       1.000000   0.799973     0.419230  0.819777  0.8   \n",
       "96     1.000000   0.0            NaN   0.740677     0.832253  0.757520  0.0   \n",
       "97     1.000000   4.0       1.000000   0.719685     0.806176  0.824705  1.0   \n",
       "98     0.500000   1.0       0.666667   0.721534     0.493352  0.773410  0.0   \n",
       "99     0.000000   2.0            NaN   0.870769     0.699577  0.798309  1.0   \n",
       "\n",
       "    general_score  \n",
       "0        2.777869  \n",
       "1        4.369798  \n",
       "2        4.306702  \n",
       "3        2.938923  \n",
       "4        1.245680  \n",
       "..            ...  \n",
       "95       2.598328  \n",
       "96       0.869947  \n",
       "97       0.909039  \n",
       "98       1.575110  \n",
       "99       1.361005  \n",
       "\n",
       "[100 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_100.sort_values(by='general_score')\n",
    "\n",
    "lowest_score_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_score_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Score:\n",
      "                                                                                                                                                                                 question  \\\n",
      "89  High accuracy is crucial for safety in autonomous vehicles. Would deploying smaller models using over-the-air updates in Tesla result in a trade-off with accuracy(and hence safety)?   \n",
      "39                      If dense/sparse retrievers are pre-trained on target corpus to enable the retrievers to be corpus-aware, can the fine-tuned retrievers outperform lexical models?   \n",
      "31                                         What if a query term can be matched to multiple document terms? Does MaxSim suffice for capturing query-document relevance, for this case too?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           correct_answer  \\\n",
      "89  Accuracy is crucial for safety but it's not only accuracy vs size relation. We should consider more aspects. For example, response time of a driving car system is very crucial for safety. Communication overhead between servers while model training increases with the size of the model so smaller models train faster. Updating models from company servers to the car or over-the-air updates based on AlexNet at that time would require 240MB of communication from the server to the car. Hence, smaller models require less communication, making frequent updates more feasible. Also, keeping in mind architectural designs such as adjusting some functionalities, introducing new ways of extracting features, or using different objectives and optimizers may make a small model achieve the same level of accuracy or even surpass the larger model; for instance, SqueezeNet is 50x smaller than AlexNet with equivalent accuracy.   \n",
      "39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         If dense/sparse retrievers are pre-trained on target corpus to enable the retrievers to be corpus-aware, the fine-tuned retrievers underperform lexical models   \n",
      "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           if a query term can be matched to multiple document terms, MaxSim suffice for capturing query-document relevance.  ColBERT computes the relevance score between q and d via late interaction, which we define as a summation of maximum similarity (MaxSim) operators. In particular, we find the maximum cosine similarity of each v\\in E_{q} with vectors in E_{d}, and combine the outputs via summation.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 context  \\\n",
      "89  Much of the recent research on deep convolutional neural networks (CNNs) has focused on increasing accuracy on computer vision datasets.For a given accuracy level, there typically exist multiple CNN architectures that achieve that accuracy level.Given equivalent accuracy, a CNN architecture with fewer parameters has several advantages:\\bulletMore efficient distributed training.Communication among servers is the limiting factor to the scalability of distributed CNN training.For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the modelÂ Iandola etÂ al. (2016).In short, small models train faster due to requiring less communication.\\bulletLess overhead when exporting new models to clients. For autonomous driving, companies such as Tesla periodically copy new models from their servers to customersâ€™ cars. This practice is often referred to as an over-the-air update. Consumer Reports has found that the safety of Teslaâ€™s Autopilot semi-autonomous driving functionality has incrementally improved with recent over-the-air updatesÂ Consumer Reports (2016). However, over-the-air updates of todayâ€™s typical CNN/DNN models can require large data transfers. With AlexNet, this would require 240MB of communication from the server to the car. Smaller models require less communication, making frequent updates more feasible.\\bulletFeasible FPGA and embedded deployment. FPGAs often have less than 10MB111For example, the Xilinx Vertex-7 FPGA has a maximum of 8.5 MBytes (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory. of on-chip memory and no off-chip memory or storage. For inference, a sufficiently small model could be stored directly on the FPGA instead of being bottlenecked by memory bandwidthÂ Qiu etÂ al. (2016), while video frames stream through the FPGA in real time.Further, when deploying CNNs on Application-Specific Integrated Circuits (ASICs), a sufficiently small model could be stored directly on-chip, and smaller models may enable the ASIC to fit on a smaller die.\\nSo far, we have proposed architectural design strategies for small models, followed these principles to create SqueezeNet, and discovered that SqueezeNet is 50x smaller than AlexNet with equivalent accuracy.However, SqueezeNet and other models reside in a broad and largely unexplored design space of CNN architectures.Now, in SectionsÂ 5 andÂ 6, we explore several aspects of the design space. We divide this architectural exploration into two main topics: microarchitectural exploration (per-module layer dimensions and configurations) and macroarchitectural exploration (high-level end-to-end organization of modules and other layers).    \n",
      "39                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             We use beir to evaluate ten diverse retrieval methods from five broad architectures: lexical, sparse, dense, late interaction, and re-ranking. From our analysis, we find that no single approach consistently outperforms other approaches on all datasets. Further, we notice that the in-domain performance of a model does not correlate well with its generalization capabilities: models fine-tuned with identical training data might generalize differently. In terms of efficiency, we find a trade-off between the performances and the computational cost: computationally expensive models, like re-ranking models and late interaction model perform the best. More efficient approaches e.g.Â based on dense or sparse embeddings can substantially underperform traditional lexical models like BM25. Overall, BM25 remains a strong baseline for zero-shot text retrieval.   \n",
      "31                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Using E_{q} and E_{d}, ColBERT computes the relevance score between q and d via late interaction, which we define as a summation of maximum similarity (MaxSim) operators. In particular, we find the maximum cosine similarity of each v\\in E_{q} with vectors in E_{d}, and combine the outputs via summation. Besides cosine, we also evaluate squared L2 distance as a measure of vector similarity. Intuitively, this interaction mechanism softly searches for each query term t_{q}â€”in a manner that reflects its context in the queryâ€”against the documentâ€™s embeddings, quantifying the strength of the â€œmatchâ€ via the largest similarity score between t_{q} and a document term t_{d}. Given these term scores, it then estimates the document relevance by summing the matching evidence across all query terms.\\nGiven the representation of a query q and a document d, the relevance score of d to q, denoted as S_{q,d}, is estimated via late interaction between their bags of contextualized embeddings. As mentioned before, this is conducted as a sum of maximum similarity computations, namely cosine similarity (implemented as dot-products due to the embedding normalization) or squared L2 distance.   \n",
      "\n",
      "   answer_8b  Rouge1  Rouge2  RougeL      Bleu      Chrf  ChrfPlus    Meteor       Ter      Bert       WMS       SMS  Wisdm    Bleurt      Bart       BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim   LLM  general_score  \n",
      "89       No.     0.0     0.0     0.0  0.228843  0.633714  0.999743  0.003534  0.000071  0.036112  0.220234  0.143435    NaN -0.825678  0.001806  0.058424           1          0.0   0.0            0.0        0.0     0.315318  0.715815  0.00       0.160517  \n",
      "39       No.     0.0     0.0     0.0  0.000000  1.111111  0.666667  0.000000  0.000476  0.076963  0.115182  0.076963    NaN -0.984156  0.001999  0.042119           1          0.0   0.0            NaN        0.0     0.682730  0.730739  0.75       0.203371  \n",
      "31       No.     0.0     0.0     0.0  0.444765  0.963391  1.878008  0.007194  0.000161  0.024075  0.315944  0.039580    NaN -0.935061  0.002580  0.051582           1          0.0   0.0            1.0        0.0     0.472813  0.691253  0.00       0.270740  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Score:\")\n",
    "print(lowest_score_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Hihgest Score:\n",
      "                                                                                                                 question                                                                                                                                                                                                                                                                                                                                                                                                                        correct_answer  \\\n",
      "52  Why does the proposed method introduced EM framework to optimize the model (instead of directly optimizing the loss)?                                                                                                                                                                                                                                                                                                                                                                                                            EM guarantees convergence.   \n",
      "79                                                             What is the difference of RocketQAv1 and RocketQAv2 model?  RocketQAv1 trains dual-encoder and cross-encoder in a cascade manner, which leverages the powerful cross-encoder to empower the dual-encoder. While it inherits the parameters from RocketQAv1, RocketQAv2 extends the first version through a novel approach that jointly trains the dense passage retriever and passage re-ranker, and by using a large PLM for data augmentation and denoising (i.e.,  a distillation procedure).   \n",
      "62                                           In BUIR, how does the online encoder updated compared to the target encoder?                                                                                                                                                                The online encoder is updated to minimize the error between the output and the target and updated by the gradients back-propagated from the loss, but target network is updated based on the momentum update and updated as the moving average of the online encoder .   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
      "52                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Later, we will show that a generalized Expectation-Maximization frameworkprovides a direction to address above problemwith a convergence guarantee.The basic idea of optimizing Eq.Â (7) via EMis to start with an initial guessof the model parameter \\thetaand estimate the expected valuesof the missing variable c, i.e., the E-step.And once we have the values of c,we can maximize the Eq.Â (7) w.r.t theparameter \\theta, i.e., the M step.We can repeat this iterative process until the likelihood cannot increase anymore.\\nTo discover the benefits oflatent intentsand address challenges,we propose theIntent Contrastive Learning (ICL),a general learning paradigm thatleverages the latent intentfactor into SR.It learns usersâ€™ intentdistributionsfrom all user behavior sequencesvia clustering.And it leveragesthe learnt intentsinto the SR modelvia a new contrastive SSL,whichmaximizes the agreementbetween a view of sequenceand its corresponding intent.The intent representation learning moduleand the contrastive SSL module are mutually reinforcedto train a more expressivesequence encoder.We tackle the challenge of intentmining problem byintroducing alatent variable to represent usersâ€™ intentsand learn them alternatelyalong with the SR model optimization throughan expectation-maximization (EM) frameworkto ensure convergence.We suggest fusing learnt intent informationinto SR via the proposed contrastive SSL,as it can improve modelâ€™s performance as wellas robustness.Extensive experiments conducted on four real-world datasetsfurther verify the effectiveness of the proposed learning paradigm,which improves performance and robustness,even when recommender systemsfaceheavy data sparsity issues.\\nIn this work,we propose a new learning paradigm ICL that canmodel latent intent factorsfrom user interactionsand fuse them into a sequential recommendationmodel via a newcontrastive SSL objective.ICL is formulated withinan EM framework, which guaranteesconvergence. Detailed analyses showthe superiority of ICL andexperiments conducted onfour datasets further demonstratethe effectiveness of the proposed method.   \n",
      "79  Existing PLMs based re-rankers typically improve ranking performance from two aspects: (1) By optimizing the ranking procedure: monoBERTÂ (Nogueira and Cho, 2019) is the first work that re-purposed BERT as a passage re-ranker and achieves state-of-the-art results. duoBERTÂ (NogueiraetÂ al., 2019a) integrates monoBERT in a multistage ranking architecture and adopts a pairwise classification approach to passage relevance computation. UEDÂ (YanetÂ al., 2021) proposes a cascade pre-training manner that can jointly enhance the retrieval stage through passage expansion with a pre-trained query generator and thus elevate the re-ranking stage with a pre-trained transformer encoder. The two stages can facilitate each other in a unified pre-training framework. H-ERNIEÂ (ChuetÂ al., 2022) proposes a multi-granularity PLM for web search.(2) By designing rational distillation procedure: LM Distill + Fine-TuningÂ (GaoetÂ al., 2020) explores a variety of distillation methods to equip a smaller re-ranker with both general-purpose language modeling knowledge learned in pre-training and search- specific relevance modeling knowledge learned in fine-tuning, and produces a faster re-ranker with better ranking performance. CAKDÂ (HofstÃ¤tter etÂ al., 2020) proposes a cross-architecture knowledge distillation procedure with a Margin-MSE loss, which can distill knowledge from multiple teachers at the same time. RocketQAv1Â (Qu etÂ al., 2021) trains dual-encoder and cross-encoder in a cascade manner, which leverages the powerful cross-encoder to empower the dual-encoder. RocketQAv2Â (Ren etÂ al., 2021) proposes a novel approach that jointly trains the dense passage retriever and passage re-ranker. The parameters of RocketQAv2 are inherited from RocketQAv1. Besides, RocketQAv2 utilizes a large PLM for data augmentation and denoising, which can also be regarded as a distillation procedure. Notably, these two types of studies anticipate more insightful information to be captured by the advanced ranking and training procedures, while neglecting the limitations of implicit knowledge extracted from noisy and heterogeneous data. Therefore, in this paper, we proposed the first knowledge-enhanced PLM based re-ranker, which thoughtfully leverages explicit external knowledge that improve the effectiveness of the model.\\nWe include several PLMs based re-rankers in our evaluation, including the state-of-the-art:â€¢monoBERTÂ (Nogueira and Cho, 2019): The first study that re-purposes BERT as a re-ranker and achieves state-of-the-art results.â€¢duoBERTÂ (NogueiraetÂ al., 2019a):This work proposes a pairwise classification approach using BERT, which obtains the ability to be more sensitive to semantics through greater computation.â€¢UEDÂ (YanetÂ al., 2021): A unified pre-training framework that jointly refines re-ranker and query generator. For a fair comparison, we only use the re-ranker in UED without passage expansion.â€¢LM Distill+Fine-Tuning (LDFT)Â (GaoetÂ al., 2020):A variety of distillation methods are compared in this paper. The experimental results indicate that a proper distillation procedure (i.e. first distill the language model, and then fine-tune on the ranking task) could produce a faster re-ranker with better ranking performance.â€¢CAKDÂ (HofstÃ¤tter etÂ al., 2020): This work proposes a cross-architecture knowledge distillation procedure with Margin-MSE loss, which can distill knowledge from multiple teachers.â€¢RocketQAv1Â (Qu etÂ al., 2021): This work mainly focuses on the training of PLM based retriever, where the re-ranker is an intermediate product of its training process.â€¢RocketQAv2Â (Ren etÂ al., 2021): Based on RocketQAv1, this work proposes a novel approach that jointly trains the PLM based retriever and re-ranker.To compare the performance of different methods, we resort to two ranking metrics.For MSMARCO-DEV, We adopt Mean Reciprocal Rank (i.e., MRR@10).For TREC 2019 DL, we use Mean Average Precision, i.e., MAP@10 and MAP@30.For Ohsumed, both Mean Reciprocal Rank and Mean Average Precision (i.e., MRR@10 and MAP@10) are employed for comprehensive performance analysis in queries requiring in-depth domain knowledge.   \n",
      "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          BUIR makes use of two distinct encoder networks that have the same structure: online encoder f_{\\theta} and target encoder f_{\\xi}.They are parameterized by \\theta and \\xi, respectively.The key idea of BUIR is to train the online encoder by using outputs of the target encoder as its target, while gradually improving the target encoder as well.The main difference of BUIR from existing end-to-end learning frameworks is that f_{\\theta} and f_{\\xi} are updated in different ways.The online encoder is trained to minimize the error between its output and the target, whereas the target network is slowly updated based on the momentum updateÂ (HeetÂ al., 2020b) so as to keep its output consistent.\\nTo sum up, the parameters of the online encoder and target encoder are optimized by(4)\\begin{split}\\theta&\\leftarrow\\theta-\\eta\\cdot\\nabla_{\\theta}\\mathcal{L}_{\\theta,\\xi}\\\\\\xi&\\leftarrow\\tau\\cdot\\xi+(1-\\tau)\\cdot\\theta.\\end{split}\\eta is the learning rate for stochastic optimization, and \\tau\\in[0,1] is a momentum coefficient (also called as target decay) for momentum-based moving average.The online encoder f_{\\theta} (and the predictor q_{\\theta}) is effectively optimized by the gradients back-propagated from the loss (EquationÂ (3)), while the target encoder f_{\\xi} is updated as the moving average of the online encoder.By taking a large value of \\tau, the target encoder slowly approximates the online encoder.This momentum-based update makes \\xi evolve more slowly than \\theta, which enables to bootstrap the representations by providing enhanced but consistent targets to the online encodersÂ (HeetÂ al., 2020b; Grill etÂ al., 2020).FigureÂ 1 illustrates the overall framework of BUIR with the simple one-hot encoders.\\nBypassing the collapsed solution.Â Â It is obvious that the loss in EquationÂ (3) admits the collapsed solution with respect to \\theta and \\xi, which means both the encoders generate the same representations for all users and items.For this reason, the conventional end-to-end learning strategy, which optimizes both f_{\\theta} and f_{\\xi} to minimize the loss (i.e., cross-prediction error), may easily lead to such collapsed solution.In contrast, our proposed framework updates each of the encoders in different ways.From EquationÂ (4), the online encoder is optimized to minimize the loss, while the target encoder is updated to slowly approximate the online encoder.That is, the direction of updating the target encoder (\\theta-\\xi) totally differs from that of updating the online encoder (-\\nabla_{\\theta}\\mathcal{L}_{\\theta,\\xi}),and this effectively keeps both the encoders from converging to the collapsed solution.Several recent work on bootstrapping-based representation learningÂ (Grill etÂ al., 2020; Chen and He, 2021) empirically demonstrated that this kind of dynamics (i.e., updating two networks differently) allows to avoid the collapsed solution without any explicit term to prevent it.\\nSimilarly to SectionÂ 3.2, the online encoder is trained by minimizing \\mathcal{L}_{\\theta,\\xi}(\\psi(u,\\mathcal{V}_{u}),\\psi(v,\\mathcal{U}_{v})), and the target encoder is slowly updated by the momentum mechanism.After the optimization is finished, the interaction score is inferred by f_{\\theta}(u,\\mathcal{V}_{u}) and f_{\\theta}(v,\\mathcal{U}_{v}) (EquationÂ (5)).FigureÂ 2 shows an example of our data augmentation which injects a certain level of perturbations to the neighbors.   \n",
      "\n",
      "                                                                                                                                                   answer_8b    Rouge1    Rouge2    RougeL       Bleu       Chrf   ChrfPlus    Meteor       Ter      Bert       WMS       SMS     Wisdm    Bleurt      Bart       BEM  Prometheus  Consistency  TSim  Faithfullness  Relevancy  Correctness      RSim  LLM  general_score  \n",
      "52                                                                                                                                    To ensure convergence.  0.333333  0.000000  0.333333  31.947155  56.298532  52.701584  0.468750  0.014778  0.537225  0.571122  0.537225       NaN  0.686127  0.016070  0.966098           4          1.0   5.0            1.0   0.897614     0.712096  0.848385  0.8       7.257701  \n",
      "79  RocketQAv1 trains dual-encoder and cross-encoder in a cascade manner, while RocketQAv2 jointly trains the dense passage retriever and passage re-ranker.  0.468750  0.379747  0.468750  23.716085  70.481771  68.642093  0.296215  0.004975  0.854980  0.647819  0.843796  0.796243  0.007957  0.563158  0.162981           4          1.0   4.0            1.0   0.979133     0.493012  0.972046  1.0       7.903457  \n",
      "62  The online encoder is updated to minimize the error between its output and the target, while the target encoder is updated based on the momentum update.  0.708333  0.539683  0.708333  38.296291  73.370190  72.671422  0.433261  0.010717  0.904643  0.956057  0.904643  0.708953  0.409631  0.331525  0.408583           4          1.0   4.0            1.0   0.966878     0.741574  0.966296  0.9       8.910305  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Hihgest Score:\")\n",
    "print(highest_score_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
