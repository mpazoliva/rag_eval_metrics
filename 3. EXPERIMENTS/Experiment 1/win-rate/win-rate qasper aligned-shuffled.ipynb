{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aligned = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL ALIGNED/qasper_aligned_iris.csv\"\n",
    "df_aligned = pd.read_csv(path_aligned)\n",
    "path_shuffled = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasper_shuffled_iris.csv\"\n",
    "df_shuffled = pd.read_csv(path_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aligned_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL ALIGNED/qasper_aligned_iris_100.csv\"\n",
    "df_aligned_100 = pd.read_csv(path_aligned_100)\n",
    "path_shuffled_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasper_shuffled_iris_100.csv\"\n",
    "df_shuffled_100 = pd.read_csv(path_shuffled_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aligned['Wisdm'] = pd.to_numeric(df_aligned['Wisdm'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'Faithfullness',\n",
      "       'Relevancy', 'RSim'],\n",
      "      dtype='object')\n",
      "(968, 21)\n",
      "Unnamed: 0          int64\n",
      "question           object\n",
      "context            object\n",
      "correct_answer     object\n",
      "iris_answer        object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "ChrfPlus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "Bart              float64\n",
      "Faithfullness     float64\n",
      "Relevancy         float64\n",
      "RSim              float64\n",
      "dtype: object\n",
      "- - - - - - - - - - - - \n",
      "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart'],\n",
      "      dtype='object')\n",
      "(968, 18)\n",
      "Unnamed: 0          int64\n",
      "question           object\n",
      "context            object\n",
      "correct_answer     object\n",
      "iris_answer        object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "ChrfPlus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "Bart              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_aligned.columns)\n",
    "print(df_aligned.shape)\n",
    "print(df_aligned.dtypes)\n",
    "print(\"- - - - - - - - - - - - \")\n",
    "print(df_shuffled.columns)\n",
    "print(df_shuffled.shape)\n",
    "print(df_shuffled.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffled_100.rename(columns={'Faithfullnes': 'Faithfullness'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bleurt', 'BEM', 'Bart',\n",
      "       'Prometheus', 'Faithfullness', 'Relevancy', 'Correctness', 'RSim',\n",
      "       'Consistency', 'TSim', 'LLM'],\n",
      "      dtype='object')\n",
      "(100, 28)\n",
      "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bleurt', 'BEM', 'Bart',\n",
      "       'Prometheus', 'Faithfullness', 'Relevancy', 'Correctness', 'RSim',\n",
      "       'Consistency', 'TSim', 'LLM'],\n",
      "      dtype='object')\n",
      "(100, 28)\n"
     ]
    }
   ],
   "source": [
    "print(df_aligned_100.columns)\n",
    "print(df_aligned_100.shape)\n",
    "print(df_shuffled_100.columns)\n",
    "print(df_shuffled_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics to compare\n",
    "metrics = ['Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor', \n",
    "           'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm','Bart']\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric in metrics:\n",
    "    # Drop rows where either df_aligned or df_shuffled has NaN values for the metric\n",
    "    valid_rows = df_aligned[metric].notna() & df_shuffled[metric].notna()\n",
    "    \n",
    "    # Filter the DataFrames to include only these valid rows\n",
    "    aligned_valid = df_aligned[valid_rows]\n",
    "    shuffled_valid = df_shuffled[valid_rows]\n",
    "    \n",
    "    # Compare the values row by row\n",
    "    wins = (aligned_valid[metric] > shuffled_valid[metric]).sum()\n",
    "    \n",
    "    # Calculate the win rate\n",
    "    win_rate = f\"{wins} / {len(aligned_valid)}\"\n",
    "    \n",
    "    # Calculate the win rate percentage\n",
    "    win_rate_percentage = (wins / len(aligned_valid)) * 100\n",
    "    \n",
    "    # Append the result to the list\n",
    "    results.append([metric, win_rate, win_rate_percentage])\n",
    "\n",
    "# Convert the results to a DataFrame to display them neatly\n",
    "win_rates_df = pd.DataFrame(results, columns=['Metric', 'Win Rate', 'Percentage (%)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Win Rate</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rouge1</td>\n",
       "      <td>470 / 931</td>\n",
       "      <td>50.483351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rouge2</td>\n",
       "      <td>281 / 931</td>\n",
       "      <td>30.182599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RougeL</td>\n",
       "      <td>636 / 931</td>\n",
       "      <td>68.313641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bleu</td>\n",
       "      <td>381 / 931</td>\n",
       "      <td>40.923738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chrf</td>\n",
       "      <td>344 / 931</td>\n",
       "      <td>36.949517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChrfPlus</td>\n",
       "      <td>351 / 931</td>\n",
       "      <td>37.701396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meteor</td>\n",
       "      <td>712 / 931</td>\n",
       "      <td>76.476907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ter</td>\n",
       "      <td>615 / 931</td>\n",
       "      <td>66.058002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bert</td>\n",
       "      <td>825 / 931</td>\n",
       "      <td>88.614393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMS</td>\n",
       "      <td>782 / 968</td>\n",
       "      <td>80.785124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMS</td>\n",
       "      <td>894 / 968</td>\n",
       "      <td>92.355372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wisdm</td>\n",
       "      <td>533 / 645</td>\n",
       "      <td>82.635659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bart</td>\n",
       "      <td>743 / 968</td>\n",
       "      <td>76.756198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric   Win Rate  Percentage (%)\n",
       "0     Rouge1  470 / 931       50.483351\n",
       "1     Rouge2  281 / 931       30.182599\n",
       "2     RougeL  636 / 931       68.313641\n",
       "3       Bleu  381 / 931       40.923738\n",
       "4       Chrf  344 / 931       36.949517\n",
       "5   ChrfPlus  351 / 931       37.701396\n",
       "6     Meteor  712 / 931       76.476907\n",
       "7        Ter  615 / 931       66.058002\n",
       "8       Bert  825 / 931       88.614393\n",
       "9        WMS  782 / 968       80.785124\n",
       "10       SMS  894 / 968       92.355372\n",
       "11     Wisdm  533 / 645       82.635659\n",
       "12      Bart  743 / 968       76.756198"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics to compare\n",
    "metrics_100 = ['BEM', 'Prometheus', 'Correctness', 'Consistency',\n",
    "       'TSim', 'LLM', 'Faithfullness', 'Relevancy', 'RSim','Bleurt', ]\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_100 = []\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric in metrics_100:\n",
    "    # Drop rows where either df_aligned or df_shuffled has NaN values for the metric\n",
    "    valid_rows = df_aligned_100[metric].notna() & df_shuffled_100[metric].notna()\n",
    "    \n",
    "    # Filter the DataFrames to include only these valid rows\n",
    "    aligned_valid_100 = df_aligned_100[valid_rows]\n",
    "    shuffled_valid_100 = df_shuffled_100[valid_rows]\n",
    "    \n",
    "    # Compare the values row by row\n",
    "    wins = (aligned_valid_100[metric] > shuffled_valid_100[metric]).sum()\n",
    "    \n",
    "    # Calculate the win rate\n",
    "    win_rate_100 = f\"{wins} / {len(aligned_valid_100)}\"\n",
    "    \n",
    "    # Calculate the win rate percentage\n",
    "    win_rate_percentage_100 = (wins / len(aligned_valid_100)) * 100\n",
    "    \n",
    "    # Append the result to the list\n",
    "    results_100.append([metric, win_rate_100, win_rate_percentage_100])\n",
    "\n",
    "# Convert the results to a DataFrame to display them neatly\n",
    "win_rates_df_100 = pd.DataFrame(results_100, columns=['Metric', 'Win Rate', 'Percentage (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Win Rate</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEM</td>\n",
       "      <td>92 / 98</td>\n",
       "      <td>93.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prometheus</td>\n",
       "      <td>94 / 100</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Correctness</td>\n",
       "      <td>73 / 98</td>\n",
       "      <td>74.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consistency</td>\n",
       "      <td>88 / 100</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSim</td>\n",
       "      <td>88 / 100</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LLM</td>\n",
       "      <td>75 / 76</td>\n",
       "      <td>98.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Faithfullness</td>\n",
       "      <td>45 / 54</td>\n",
       "      <td>83.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Relevancy</td>\n",
       "      <td>95 / 100</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RSim</td>\n",
       "      <td>91 / 100</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bleurt</td>\n",
       "      <td>94 / 98</td>\n",
       "      <td>95.918367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Metric  Win Rate  Percentage (%)\n",
       "0            BEM   92 / 98       93.877551\n",
       "1     Prometheus  94 / 100       94.000000\n",
       "2    Correctness   73 / 98       74.489796\n",
       "3    Consistency  88 / 100       88.000000\n",
       "4           TSim  88 / 100       88.000000\n",
       "5            LLM   75 / 76       98.684211\n",
       "6  Faithfullness   45 / 54       83.333333\n",
       "7      Relevancy  95 / 100       95.000000\n",
       "8           RSim  91 / 100       91.000000\n",
       "9         Bleurt   94 / 98       95.918367"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rates_df_100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
