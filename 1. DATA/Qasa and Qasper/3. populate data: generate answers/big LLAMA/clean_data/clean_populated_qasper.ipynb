{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/ubuntu/iris_repos/data_preparation(QASA-QASPER)/4. populated data: generated answers/with ctx/original_populated_qasper.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what language pairs are explored?</td>\n",
       "      <td>English (En), Arabic (Ar), Spanish (Es), and R...</td>\n",
       "      <td>De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...</td>\n",
       "      <td>For MultiUN corpus, we use four languages: Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the topics pulled from Reddit?</td>\n",
       "      <td>politics, business, science, and AskReddit</td>\n",
       "      <td>training data has posts from politics, busine...</td>\n",
       "      <td>Data collection. Subreddits are sub-communitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What accuracy does the proposed system achieve?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>F1 scores of 85.99 on the DL-PS data,  75.15 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Main results on the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What crowdsourcing platform is used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nAmazon Mechanical T...</td>\n",
       "      <td>They did not use any platform, instead they h...</td>\n",
       "      <td>With the purpose of obtaining evaluation datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On how many language pairs do they show that p...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>5</td>\n",
       "      <td>We experimented with English INLINEFORM0 Hindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Which information about text structure is incl...</td>\n",
       "      <td>Text structure information included in the cor...</td>\n",
       "      <td>paragraph, lines, textspan element (paragraph...</td>\n",
       "      <td>The paper at hand introduces a corpus develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What experiments are proposed to test that upp...</td>\n",
       "      <td>The experiments proposed to test that upper la...</td>\n",
       "      <td>They measure self-similarity, intra-sentence s...</td>\n",
       "      <td>We measure how contextual a word representatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do they calculate a static embedding for e...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>They use the first principal component of a wo...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The performance of va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the performance of BERT on the task?</td>\n",
       "      <td>BERT outperforms all other systems in terms of...</td>\n",
       "      <td>F1 scores are:\\nHUBES-PHI: Detection(0.965), C...</td>\n",
       "      <td>To finish with this experiment set, Table also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how is model compactness measured?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nModel compactness i...</td>\n",
       "      <td>Using file size on disk</td>\n",
       "      <td>Even if LangID-High does not present a more ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Who were the human evaluators used?</td>\n",
       "      <td>20 evaluators were recruited from the institution</td>\n",
       "      <td>20 annotatos from author's institution</td>\n",
       "      <td>Human Evaluation Results. While automated eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Which methods are considered to find examples ...</td>\n",
       "      <td>The answer is:\\n\\n1. Tagging descriptions with...</td>\n",
       "      <td>Looking for adjectives marking the noun \"baby...</td>\n",
       "      <td>It may be difficult to spot patterns by just l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What biases are found in the dataset?</td>\n",
       "      <td>The dataset appears to have biases in the way ...</td>\n",
       "      <td>Ethnic bias</td>\n",
       "      <td>Ethnicity/race One interesting pattern is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What discourse relations does it work best/wor...</td>\n",
       "      <td>The model works best for the Temporal discours...</td>\n",
       "      <td>Best: Expansion (Exp). Worst: Comparison (Comp).</td>\n",
       "      <td>The second row shows the performance of our ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>On top of BERT does the RNN layer work better ...</td>\n",
       "      <td>The Transformer layer works better than the RN...</td>\n",
       "      <td>The transformer layer</td>\n",
       "      <td>In this paper, we propose a method that builds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How was this data collected?</td>\n",
       "      <td>Through crowdsourcing on the platform CrowdFlo...</td>\n",
       "      <td>The crowdsourcing platform CrowdFlower was us...</td>\n",
       "      <td>However, getting access to systems with real u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What is the average length of dialog?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n3.5 turns</td>\n",
       "      <td>4.49 turns 4.5 turns per dialog (8533 turns / ...</td>\n",
       "      <td>We collected the dataset with 1900 dialogs and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How does the IPA label data after interacting ...</td>\n",
       "      <td>The IPA labels data after interacting with use...</td>\n",
       "      <td>It defined a sequence labeling task to extract...</td>\n",
       "      <td>Named Entity Recognition: We defined a sequenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How was the audio data gathered?</td>\n",
       "      <td>The audio data was gathered from the All India...</td>\n",
       "      <td>Through the All India Radio new channel where ...</td>\n",
       "      <td>In this paper, we explore multiple pooling str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the GhostVLAD approach?</td>\n",
       "      <td>GhostVLAD is an extension of the NetVLAD appro...</td>\n",
       "      <td>An extension of NetVLAD which replaces hard a...</td>\n",
       "      <td>GhostVLAD is an extension of the NetVLAD appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Which 7 Indian languages do they experiment with?</td>\n",
       "      <td>Kannada, Hindi, Telugu, Malayalam, Bengali, an...</td>\n",
       "      <td>Hindi, English, Kannada, Telugu, Assamese, Ben...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset In this secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is the invertibility condition?</td>\n",
       "      <td>The invertibility condition is that INLINEFORM...</td>\n",
       "      <td>The neural projector must be invertible.</td>\n",
       "      <td>In this section, we introduce an invertibility...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Which neural architecture do they use as a bas...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>GRU-based encoder, interaction block, and clas...</td>\n",
       "      <td>We create two models both of which constitutes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What metric is used for evaluation?</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>F1, precision, recall, accuracy Precision, rec...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Clustering results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Which eight NER tasks did they evaluate on?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Top: Examples of with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Do they focus on Reading Comprehension or mult...</td>\n",
       "      <td>Multiple choice question answering</td>\n",
       "      <td>MULTIPLE CHOICE QUESTION ANSWERING</td>\n",
       "      <td>Automatically answering questions, especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>After how many hops does accuracy decrease?</td>\n",
       "      <td>2 hops</td>\n",
       "      <td>one additional hop</td>\n",
       "      <td>Our comprehensive assessment reveals several i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What languages are evaluated?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nEnglish and German</td>\n",
       "      <td>German, English, Spanish, Finnish, French, Rus...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Official shared task ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is MSD prediction?</td>\n",
       "      <td>MSD prediction is predicting the morphosyntact...</td>\n",
       "      <td>The task of predicting MSD tags: V, PST, V.PCT...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Example input sentenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What other models do they compare to?</td>\n",
       "      <td>They compare to R.M.-Reader + Verifier, a more...</td>\n",
       "      <td>SAN Baseline, BNA, DocQA, R.M-Reader, R.M-Read...</td>\n",
       "      <td>Table TABREF21 reports comparison results in l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What evaluation metric do they use?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nR...</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>To test all the possible combinations of param...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What are the results from these proposed strat...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Reward of 11.8 for the A2C-chained model, 41.8...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: Ablation results on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>How much better than the baseline is LiLi?</td>\n",
       "      <td>LiLi outperforms the baseline by a significant...</td>\n",
       "      <td>In case of Freebase knowledge base, LiLi model...</td>\n",
       "      <td>Baselines. As none of the existing KBC methods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What are the components of the general knowled...</td>\n",
       "      <td>The components of the general knowledge learni...</td>\n",
       "      <td>Answer with content missing: (list)\\nLiLi shou...</td>\n",
       "      <td>We solve the OKBC problem by mimicking how hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>How many labels do the datasets have?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>719313 Book, Electronics, Beauty and Music eac...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Summary of datasets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What are the source and target domains?</td>\n",
       "      <td>The answer is:\\n\\nSource domain: Book (BK), El...</td>\n",
       "      <td>Book, electronics, beauty, music, IMDB, Yelp, ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Summary of datasets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>How do they deal with unknown distribution sen...</td>\n",
       "      <td>By modifying a naïve Bayesian classifier to re...</td>\n",
       "      <td>The Näive-Bayes classifier is corrected so it ...</td>\n",
       "      <td>Monosemous relatives have been employed multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What conclusions do the authors draw from thei...</td>\n",
       "      <td>The authors conclude that both ISIS and Cathol...</td>\n",
       "      <td>By comparing scores for each word calculated ...</td>\n",
       "      <td>Comparing these topics with those that appeare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>How id Depechemood trained?</td>\n",
       "      <td>Depechemood was trained using a lexicon-based ...</td>\n",
       "      <td>By multiplying crowd-annotated document-emotio...</td>\n",
       "      <td>Depechemood is a lexicon-based emotion detecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How are similarities and differences between t...</td>\n",
       "      <td>Similarities and differences between the texts...</td>\n",
       "      <td>By using topic modeling and unsupervised emoti...</td>\n",
       "      <td>What similarities and/or differences do these ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>How are prominent topics idenified in Dabiq an...</td>\n",
       "      <td>Non-negative matrix factorization (NMF) was us...</td>\n",
       "      <td>Using NMF based topic modeling and their cohe...</td>\n",
       "      <td>Topic modeling methods are the more powerful t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Which datasets are used?</td>\n",
       "      <td>ShapeWorldICE datasets</td>\n",
       "      <td>Existential (OneShape, MultiShapes), Spacial (...</td>\n",
       "      <td>We develop a variety of ShapeWorldICE datasets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What are previous state of the art results?</td>\n",
       "      <td>The previous state-of-the-art results are show...</td>\n",
       "      <td>Overall F1 score:\\n- He and Sun (2017) 58.23\\n...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The results of two pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What source-target language pairs were used in...</td>\n",
       "      <td>En-XX, Zh-XX, Jp-XX, Kr-XX (source-target lang...</td>\n",
       "      <td>En-Fr, En-Zh, En-Jp, En-Kr, Zh-En, Zh-Fr, Zh-J...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: EM/F1 score of multi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>How large is their MNER SnapCaptions dataset?</td>\n",
       "      <td>10,000</td>\n",
       "      <td>10000</td>\n",
       "      <td>The SnapCaptions dataset is composed of 10K us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What is masked document generation?</td>\n",
       "      <td>Masked Document Generation (MDG) is a task tha...</td>\n",
       "      <td>A task for seq2seq model pra-training that rec...</td>\n",
       "      <td>Based on the above observations, we propose St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What useful information does attention capture?</td>\n",
       "      <td>Attention captures information beyond alignmen...</td>\n",
       "      <td>Alignment points of the POS tags.</td>\n",
       "      <td>Our analysis shows that attention models tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>In what cases is attention different from alig...</td>\n",
       "      <td>Attention differs from alignment for VERB and ...</td>\n",
       "      <td>For certain POS tags, e.g. VERB, PRON.</td>\n",
       "      <td>To better understand how attention accuracy af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Which baselines did they compare against?</td>\n",
       "      <td>They compared against previous treestructured ...</td>\n",
       "      <td>Various tree structured neural networks includ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The comparison of var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>What baselines did they consider?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Linear SVM, RBF SVM, and Random Forest</td>\n",
       "      <td>We first use state-of-the-art PDTB taggers for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>How was the dataset annotated?</td>\n",
       "      <td>The dataset was annotated manually by grouping...</td>\n",
       "      <td>intents are annotated manually with guidance f...</td>\n",
       "      <td>We defined the intents with guidance from quer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>What is the size of this dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n2...</td>\n",
       "      <td>23,700 queries, including 22,500 in-scope qu...</td>\n",
       "      <td>This paper fills this gap by analyzing intent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Where does the data come from?</td>\n",
       "      <td>The data comes from crowdsourcing tasks, inclu...</td>\n",
       "      <td>crowsourcing platform For ins scope data colle...</td>\n",
       "      <td>We introduce a new crowdsourced dataset of 23,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ngrams of which length are aligned using PARENT?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Parent subsecti...</td>\n",
       "      <td>We show that existing automatic metrics, inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>How many people participated in their evaluati...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>about 500</td>\n",
       "      <td>The data collection was performed separately f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>By how much more does PARENT correlate with hu...</td>\n",
       "      <td>PARENT correlates significantly better with hu...</td>\n",
       "      <td>Best proposed metric has average correlation w...</td>\n",
       "      <td>We use bootstrap sampling (500 iterations) ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Which stock market sector achieved the best pe...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Energy with accuracy of 0.538 Energy</td>\n",
       "      <td>FLOAT SELECTED: Table 8: Sector-level performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>How do the authors evidence the claim that man...</td>\n",
       "      <td>The authors evidence the claim by surveying en...</td>\n",
       "      <td>By conducting a survey among engineers</td>\n",
       "      <td>The above challenges often hinder the producti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>what datasets did they use?</td>\n",
       "      <td>The dataset used was a collection of 3500 ques...</td>\n",
       "      <td>Dataset of total 3500 questions from the Inter...</td>\n",
       "      <td>Though Bengali is the seventh most spoken lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>How much does their model outperform existing ...</td>\n",
       "      <td>The neural extractive models outperform existi...</td>\n",
       "      <td>Best proposed model result vs best previous re...</td>\n",
       "      <td>The performance of all models on arXiv and Pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>What was the baseline for this task?</td>\n",
       "      <td>A very simple logistic regression classifier w...</td>\n",
       "      <td>The baseline system for the SLC task is a very...</td>\n",
       "      <td>The baseline system for the SLC task is a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>What is a second order co-ocurrence matrix?</td>\n",
       "      <td>A second-order co-occurrence matrix is a matri...</td>\n",
       "      <td>The matrix containing co-occurrences of the w...</td>\n",
       "      <td>However, despite these successes distributiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>How many humans participated?</td>\n",
       "      <td>9 medical coders and 4 medical residents</td>\n",
       "      <td>16</td>\n",
       "      <td>MiniMayoSRS: The MayoSRS, developed by Pakhomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>What word level and character level model base...</td>\n",
       "      <td>The word level and character level model basel...</td>\n",
       "      <td>None Word-level Memory Neural Networks (MemNNs...</td>\n",
       "      <td>In our experiments, the Memory Neural Networks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>How were the human judgements assembled?</td>\n",
       "      <td>The human judgements were assembled by a group...</td>\n",
       "      <td>50 human annotators ranked a random sample of ...</td>\n",
       "      <td>To ensure that the increase in BLEU score corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Which other approaches do they compare their m...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>Akbik et al. (2018), Link et al. (2012) They c...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Comparison with exist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>What results do they achieve using their propo...</td>\n",
       "      <td>The proposed approach achieves F-1 scores betw...</td>\n",
       "      <td>F-1 score on the OntoNotes is 88%, and it is 5...</td>\n",
       "      <td>The results for each class type are shown in T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>How do they combine a deep learning model with...</td>\n",
       "      <td>By using a redirection list and a disambiguati...</td>\n",
       "      <td>Entities from a deep learning model are linked...</td>\n",
       "      <td>While these knowledge bases provide semantical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>What are the models used for the baseline of t...</td>\n",
       "      <td>The baseline models used for the three NLP tas...</td>\n",
       "      <td>For speech synthesis, they build a speech clu...</td>\n",
       "      <td>Baseline Results ::: Speech Synthesis In our p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>How is non-standard pronunciation identified?</td>\n",
       "      <td>Non-standard pronunciation is identified throu...</td>\n",
       "      <td>Original transcription was labeled with addit...</td>\n",
       "      <td>In addition, the transcription includes annota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>What novel PMI variants are introduced?</td>\n",
       "      <td>The answer is:\\n\\nNPMI and NNEGPMI</td>\n",
       "      <td>clipped PMI; NNEGPMI</td>\n",
       "      <td>where * denotes summation over the correspondi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>What are the disadvantages to clipping negativ...</td>\n",
       "      <td>Sure! Here's the answer to the question at the...</td>\n",
       "      <td>It may lead to poor rare word representations ...</td>\n",
       "      <td>Why incorporate -PMI? $\\mathit {\\texttt {+}PPM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Why are statistics from finite corpora unrelia...</td>\n",
       "      <td>The statistics from finite corpora are unrelia...</td>\n",
       "      <td>A finite corpora may entirely omit rare word ...</td>\n",
       "      <td>Unfortunately, $\\mathit {PMI}(w,c)$ goes to ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Which two pairs of ERPs from the literature be...</td>\n",
       "      <td>N400 and P600, and N400 and N200</td>\n",
       "      <td>Answer with content missing: (Whole Method and...</td>\n",
       "      <td>This work is most closely related to the paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>What datasets are used?</td>\n",
       "      <td>The datasets used are ERP data and eye-trackin...</td>\n",
       "      <td>Answer with content missing: (Whole Method and...</td>\n",
       "      <td>This work is most closely related to the paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>which datasets did they experiment with?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nU...</td>\n",
       "      <td>Universal Dependencies v1.2 treebanks for the ...</td>\n",
       "      <td>We carried out our experiments on the Universa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>What kind of celebrities do they obtain tweets...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nTwitter celebrities</td>\n",
       "      <td>Amitabh Bachchan, Ariana Grande, Barack Obama,...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Twitter celebrities i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>How did they extend LAMA evaluation framework ...</td>\n",
       "      <td>They introduced the negated LAMA dataset by si...</td>\n",
       "      <td>Create the negated LAMA dataset and  query th...</td>\n",
       "      <td>This work analyzes the understanding of pretra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>What summarization algorithms did the authors ...</td>\n",
       "      <td>The authors experimented with a few summarizat...</td>\n",
       "      <td>LSA, TextRank, LexRank and ILP-based summary. ...</td>\n",
       "      <td>We considered a dataset of 100 employees, wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>What methods were used for sentence classifica...</td>\n",
       "      <td>The answer is:\\n\\nFor sentence classification,...</td>\n",
       "      <td>Logistic Regression, Multinomial Naive Bayes, ...</td>\n",
       "      <td>We randomly selected 2000 sentences from the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>What modern MRC gold standards are analyzed?</td>\n",
       "      <td>BIBREF15, BIBREF28, BIBREF7, and TABREF19</td>\n",
       "      <td>MSMARCO,  HOTPOTQA, RECORD,  MULTIRC, NEWSQA,...</td>\n",
       "      <td>We select contemporary MRC benchmarks to repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>What language is explored in this paper?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nENGLISH</td>\n",
       "      <td>English language</td>\n",
       "      <td>Figure FIGREF4 pictorially represents our meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>How long of dialog history is captured?</td>\n",
       "      <td>2 dialog turns</td>\n",
       "      <td>two previous turns</td>\n",
       "      <td>The previously proposed contextual language mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>What was the score of the proposed model?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Best results authors obtain is EM 51.10 and F1...</td>\n",
       "      <td>To better demonstrate the effectiveness of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>What hyperparameters are explored?</td>\n",
       "      <td>The hyperparameters explored are the choice of...</td>\n",
       "      <td>Dimension size, window size, architecture, alg...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Hyper-parameter choic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>what aspects of conversation flow do they look...</td>\n",
       "      <td>Conversational flow features such as self-cove...</td>\n",
       "      <td>The time devoted to self-coverage, opponent-co...</td>\n",
       "      <td>The flow of talking points . A side can either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>what is the state of the art?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe answer is:\\n\\nF...</td>\n",
       "      <td>Babelfy, DBpedia Spotlight, Entityclassifier.e...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Comparison of annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>What is the Random Kitchen Sink approach?</td>\n",
       "      <td>The Random Kitchen Sink (RKS) approach is a me...</td>\n",
       "      <td>Random Kitchen Sink method uses a kernel funct...</td>\n",
       "      <td>RKS approach proposed in BIBREF21, BIBREF22, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>How do they define similar equations?</td>\n",
       "      <td>They define similar equations using Euclidean ...</td>\n",
       "      <td>By using Euclidean distance computed between t...</td>\n",
       "      <td>In addition to words, EqEmb models can capture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>What are the three steps to feature elimination?</td>\n",
       "      <td>The answer is:\\n\\nThe three steps to feature e...</td>\n",
       "      <td>reduced the dataset by eliminating features, ...</td>\n",
       "      <td>Feature elimination strategies are often taken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>How is the dataset annotated?</td>\n",
       "      <td>The dataset is annotated with depression-relat...</td>\n",
       "      <td>The annotations are based on evidence of depr...</td>\n",
       "      <td>Specifically, we conducted a feature ablation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Which architecture do they use for the encoder...</td>\n",
       "      <td>The encoder uses a combination of convolutiona...</td>\n",
       "      <td>In encoder they use convolutional, NIN and bi...</td>\n",
       "      <td>In this work, we use the raw waveform as the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>How does their decoder generate text?</td>\n",
       "      <td>The decoder generates text by predicting the t...</td>\n",
       "      <td>Decoder predicts the sequence of phoneme or g...</td>\n",
       "      <td>where INLINEFORM0 , INLINEFORM1 is the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>What dataset is used to train the model?</td>\n",
       "      <td>The dataset used to train the model is the col...</td>\n",
       "      <td>Collected tweets and opening and closing stoc...</td>\n",
       "      <td>A total of 2,50,000 tweets over a period of Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Which race and gender are given higher sentime...</td>\n",
       "      <td>Female and African American</td>\n",
       "      <td>Females are given higher sentiment intensity w...</td>\n",
       "      <td>When predicting anger, joy, or valence, the nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What criteria are used to select the 8,640 Eng...</td>\n",
       "      <td>The 8,640 English sentences were selected base...</td>\n",
       "      <td>Sentences involving at least one race- or gend...</td>\n",
       "      <td>We decided to use sentences involving at least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>what were the baselines?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>LF-MMI Attention\\nSeq2Seq \\nRNN-T \\nChar E2E ...</td>\n",
       "      <td>We also evaluate the Jasper model's performanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>what competitive results did they obtain?</td>\n",
       "      <td>Competitive results were obtained on both WSJ ...</td>\n",
       "      <td>In case of read speech datasets,  their best m...</td>\n",
       "      <td>We trained a smaller Jasper 10x3 model with SG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>By how much is performance improved with multi...</td>\n",
       "      <td>Performance is improved by approximately 0.02 ...</td>\n",
       "      <td>by 2.3-6.8 points in f1 score for intent recog...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Speech Embeddings Exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How much is performance improved on NLI?</td>\n",
       "      <td>4% absolute gain over BERTBase on the NLI task</td>\n",
       "      <td>The average score improved by 1.4 points over...</td>\n",
       "      <td>Table TABREF21 illustrates the experimental re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>What is active learning?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nActive learning is ...</td>\n",
       "      <td>A process of training a model when selected un...</td>\n",
       "      <td>Active learning sharply increases the performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>what was the baseline?</td>\n",
       "      <td>The baseline was a strong NMT system</td>\n",
       "      <td>M2M Transformer</td>\n",
       "      <td>We began with evaluating standard MT paradigms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How is segmentation quality evaluated?</td>\n",
       "      <td>Segmentation quality is evaluated based on the...</td>\n",
       "      <td>Segmentation quality is evaluated by calculati...</td>\n",
       "      <td>Two batch of tests were performed. The first o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>How do they compare lexicons?</td>\n",
       "      <td>The experts and crowd contributors have simila...</td>\n",
       "      <td>Human evaluators were asked to evaluate on a s...</td>\n",
       "      <td>We perform a direct comparison of expert and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>How larger are the training sets of these vers...</td>\n",
       "      <td>The training sets of these versions of ELMo ar...</td>\n",
       "      <td>By 14 times. up to 1.95 times larger</td>\n",
       "      <td>Recently, ELMoForManyLangs BIBREF6 project rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>What is the improvement in performance for Est...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>5 percent points. 0.05 F1</td>\n",
       "      <td>FLOAT SELECTED: Table 4: The results of NER ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>what is the state of the art on WSJ?</td>\n",
       "      <td>INLINEFORM2 WER</td>\n",
       "      <td>CNN-DNN-BLSTM-HMM</td>\n",
       "      <td>Table TABREF11 shows Word Error Rates (WER) on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>what is the size of the augmented dataset?</td>\n",
       "      <td>The size of the augmented dataset is 500 samples</td>\n",
       "      <td>609</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Speech datasets used....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Why are current ELS's not sufficiently effective?</td>\n",
       "      <td>Low precision rates and design challenges in t...</td>\n",
       "      <td>Linked entities may be ambiguous or too common</td>\n",
       "      <td>Despite its usefulness, linked entities extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>How many sentences does the dataset contain?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n6946</td>\n",
       "      <td>3606</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset statistics In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>What is the baseline?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Bam et al. SVM, Ma and Hovy w/glove, Lample e...</td>\n",
       "      <td>Similar approaches has been applied to many So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>What is the size of the dataset?</td>\n",
       "      <td>The size of the dataset is 1000 sentences</td>\n",
       "      <td>Dataset contains 3606 total sentences and 7908...</td>\n",
       "      <td>After much time, we received the dataset from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>How many different types of entities exist in ...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n3</td>\n",
       "      <td>OurNepali contains 3 different types of entiti...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset statistics Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>How big is the new Nepali NER dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>3606 sentences Dataset contains 3606 total sen...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset statistics Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>What is the performance improvement of the gra...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>On OurNepali test dataset Grapheme-level repre...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Comparison of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Which variation provides the best results on t...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>the model with multi-attention mechanism and a...</td>\n",
       "      <td>We have evaluated our models considering the F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>What are the different variations of the atten...</td>\n",
       "      <td>Four variations of the attention-based approac...</td>\n",
       "      <td>classic RNN model, avgRNN model, attentionRNN ...</td>\n",
       "      <td>We compare eight different models in our exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>What dataset is used for this work?</td>\n",
       "      <td>The dataset used for this work is the SociaL M...</td>\n",
       "      <td>Twitter dataset provided by the organizers The...</td>\n",
       "      <td>In this paper we present our work, which is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>What were the datasets used in this paper?</td>\n",
       "      <td>The dataset used in this paper is a Twitter da...</td>\n",
       "      <td>The dataset from the SociaL Media And Harassme...</td>\n",
       "      <td>In this paper we present our work, which is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>What is the performance of classifiers?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Using F1 Micro measure, the KNN classifier pe...</td>\n",
       "      <td>In order to evaluate our classifiers, we perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>What classifiers have been trained?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nK...</td>\n",
       "      <td>KNN\\nRF\\nSVM\\nMLP</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Evaluation metrics fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>How many layers does the UTCNN model have?</td>\n",
       "      <td>4 layers</td>\n",
       "      <td>eight layers</td>\n",
       "      <td>Figure FIGREF10 illustrates the UTCNN model. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>What are the baselines?</td>\n",
       "      <td>SVM with unigram, bigram, and trigram features...</td>\n",
       "      <td>SVM with unigram, bigram, trigram features, w...</td>\n",
       "      <td>We pit our model against the following baselin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>What transfer learning tasks are evaluated?</td>\n",
       "      <td>The seven SentEval transfer tasks evaluated ar...</td>\n",
       "      <td>Semantic Textual Similarity, sentiment predi...</td>\n",
       "      <td>We compare the SBERT sentence embeddings to ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>What other sentence embeddings methods are eva...</td>\n",
       "      <td>InferSent and the Universal Sentence Encoder</td>\n",
       "      <td>GloVe, BERT, Universal Sentence Encoder, TF-ID...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Spearman rank correla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Which shallow approaches did they experiment w...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>SVM with linear kernel using bag-of-words fea...</td>\n",
       "      <td>As a first baseline we use Bag-of-Words, a wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>which non-english language had the best perfor...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Russsian</td>\n",
       "      <td>Considering the improvements over the majority...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>how did the authors translate the reviews to o...</td>\n",
       "      <td>The authors used machine translation to transl...</td>\n",
       "      <td>Using Google translation API.</td>\n",
       "      <td>In order to eliminate the need to find data an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>What are the five different binary classificat...</td>\n",
       "      <td>The answer is:\\n\\nThe five different binary cl...</td>\n",
       "      <td>presence/absence of consonants, presence/abse...</td>\n",
       "      <td>We evaluate our model on a publicly available ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>How was the spatial aspect of the EEG signal c...</td>\n",
       "      <td>The spatial aspect of the EEG signal was compu...</td>\n",
       "      <td>They use four-layered 2D CNN and two fully co...</td>\n",
       "      <td>In order to decode spatial connections between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Which real-world datasets are used?</td>\n",
       "      <td>CyberAttack and PoliticianDeath</td>\n",
       "      <td>Tweets related to CyberAttack and tweets relat...</td>\n",
       "      <td>Datasets. We perform our experiments with two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>How are the interpretability merits of the app...</td>\n",
       "      <td>By providing human-understandable explanations...</td>\n",
       "      <td>By involving humans for post-hoc evaluation of...</td>\n",
       "      <td>Human-in-the-Loop Approaches. Our work extends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>How are the accuracy merits of the approach de...</td>\n",
       "      <td>The approach demonstrates significant improvem...</td>\n",
       "      <td>By evaluating the performance of the approach...</td>\n",
       "      <td>Our approach improves LR by 5.17% (Accuracy) a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>What is a wizard of oz setup?</td>\n",
       "      <td>A Wizard of Oz setup is a simulated informatio...</td>\n",
       "      <td>a setup where the seeker interacts with a rea...</td>\n",
       "      <td>Macaw also supports Wizard of Oz studies or in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>What baseline model is used?</td>\n",
       "      <td>B1. The first baseline uses only the salience-...</td>\n",
       "      <td>For Article-Entity placement, they consider tw...</td>\n",
       "      <td>Here we introduce the evaluation setup and ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>How do they determine the exact section to use...</td>\n",
       "      <td>They use a multi-class classification problem ...</td>\n",
       "      <td>They use a multi-class classifier to determine...</td>\n",
       "      <td>We model the ASP placement task as a successor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>What features are used to represent the novelt...</td>\n",
       "      <td>The novelty of news articles is represented by...</td>\n",
       "      <td>KL-divergences of language models for the news...</td>\n",
       "      <td>An important feature when suggesting an articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>What features are used to represent the salien...</td>\n",
       "      <td>Baseline features, such as positional features...</td>\n",
       "      <td>Salience features positional features, occurre...</td>\n",
       "      <td>Baseline Features. As discussed in Section SEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>How was annotation performed?</td>\n",
       "      <td>Annotation was performed using WebAnno BIBREF7...</td>\n",
       "      <td>Experienced medical doctors used a linguistic ...</td>\n",
       "      <td>We asked medical doctors experienced in extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>What activation function do they use in their ...</td>\n",
       "      <td>$relu$</td>\n",
       "      <td>Activation function is hyperparameter. Possib...</td>\n",
       "      <td>Experimental Setup. We apply a 5 cross-validat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>How are chunks defined?</td>\n",
       "      <td>Chunks are defined as sorted sequences of twee...</td>\n",
       "      <td>Chunks is group of tweets from single account ...</td>\n",
       "      <td>Given a news Twitter account, we read its twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>How big is the dataset used in this work?</td>\n",
       "      <td>The dataset used in this work consists of 212 ...</td>\n",
       "      <td>Total dataset size: 171 account (522967 tweets...</td>\n",
       "      <td>Data. We build a dataset of Twitter accounts b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>How is a \"chunk of posts\" defined in this work?</td>\n",
       "      <td>A \"chunk of posts\" is defined as a sorted sequ...</td>\n",
       "      <td>sequence of $s$ tweets</td>\n",
       "      <td>The main obstacle for detecting suspicious Twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Which evaluation methods are used?</td>\n",
       "      <td>ROGUE-1, ROGUE-2, and ROGUE-L</td>\n",
       "      <td>Quantitative evaluation methods using ROUGE, R...</td>\n",
       "      <td>For the evaluation of summaries we use the sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>How are sentences selected from the summary gr...</td>\n",
       "      <td>The sentences are selected from the summary gr...</td>\n",
       "      <td>Two methods: first is to simply pick initial...</td>\n",
       "      <td>After parsing (Step 1) we have the AMR graphs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>What is the size of the new dataset?</td>\n",
       "      <td>The size of the new dataset is 300 tweets</td>\n",
       "      <td>14,100 tweets Dataset contains total of 14100...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Distribution of label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>What kinds of offensive content are explored?</td>\n",
       "      <td>Targeted and untargeted insults and threats, a...</td>\n",
       "      <td>non-targeted profanity and swearing, targeted ...</td>\n",
       "      <td>Level B categorizes the type of offense and tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>How long is the dataset for each step of hiera...</td>\n",
       "      <td>The answer is:\\n\\nThe dataset size for each st...</td>\n",
       "      <td>Level A: 14100 Tweets\\nLevel B: 4640 Tweets\\nL...</td>\n",
       "      <td>The data included in OLID has been collected f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>In the proposed metric, how is content relevan...</td>\n",
       "      <td>Content relevance is measured using informatio...</td>\n",
       "      <td>The content relevance between the candidate su...</td>\n",
       "      <td>Our proposed metric is based on analysis of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>What different correlations result when using ...</td>\n",
       "      <td>Different correlations result when using diffe...</td>\n",
       "      <td>Using Pearson corelation measure,  for exampl...</td>\n",
       "      <td>Table TABREF23 shows the Pearson, Spearman and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>how is mitigation of gender bias evaluated?</td>\n",
       "      <td>The mitigation of gender bias is evaluated usi...</td>\n",
       "      <td>Using INLINEFORM0 and INLINEFORM1</td>\n",
       "      <td>Results for the experiments are listed in Tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>What tasks were evaluated?</td>\n",
       "      <td>The 8 tasks evaluated in ReviewQA are:\\n\\n1. A...</td>\n",
       "      <td>Detection of an aspect in a review, Predictio...</td>\n",
       "      <td>Table TABREF19 displays the performance of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>What are their results on both datasets?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Combining  pattern based and Machine translati...</td>\n",
       "      <td>The error detection results can be seen in Tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>by how much did their model improve?</td>\n",
       "      <td>The answer is:\\n\\nTheir model improved by 2.11...</td>\n",
       "      <td>For the WikiLarge dataset, the improvement ove...</td>\n",
       "      <td>Results. Table 1 shows the results of all mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>what are the sizes of both datasets?</td>\n",
       "      <td>The answer is:\\n\\nWikiSmall: 89,042 sentence p...</td>\n",
       "      <td>WikiSmall  89 142 sentence pair and  WikiLarg...</td>\n",
       "      <td>Dataset. We use two simplification datasets (W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>What are the distinctive characteristics of ho...</td>\n",
       "      <td>The answer is:\\n\\nArabic speakers use offensiv...</td>\n",
       "      <td>Frequent use of direct animal name calling, us...</td>\n",
       "      <td>Next, we analyzed all tweets labeled as offens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>How many annotators tagged each tweet?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nO...</td>\n",
       "      <td>One One experienced annotator tagged all tweets</td>\n",
       "      <td>We developed the annotation guidelines jointly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>In what way is the offensive dataset not biase...</td>\n",
       "      <td>The offensive dataset is not biased by topic, ...</td>\n",
       "      <td>It does not use a seed list to gather tweets s...</td>\n",
       "      <td>Disclaimer: Due to the nature of the paper, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>What are the difficulties in modelling the iro...</td>\n",
       "      <td>The difficulties in modelling the ironic patte...</td>\n",
       "      <td>ironies are often obscure and hard to understand</td>\n",
       "      <td>Although some previous studies focus on irony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>How did the authors find ironic data on twitter?</td>\n",
       "      <td>The authors crawled over 2M tweets from Twitte...</td>\n",
       "      <td>They developed a classifier to find ironic sen...</td>\n",
       "      <td>As neural networks are proved effective in iro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Who judged the irony accuracy, sentiment prese...</td>\n",
       "      <td>Four annotators who are proficient in English ...</td>\n",
       "      <td>Irony accuracy is judged only by human ; senri...</td>\n",
       "      <td>In order to evaluate sentiment preservation, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>How were the tweets annotated?</td>\n",
       "      <td>The tweets were annotated with stance informat...</td>\n",
       "      <td>tweets are annotated with only Favor or Agains...</td>\n",
       "      <td>We have decided to consider tweets about popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>What are hashtag features?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nH...</td>\n",
       "      <td>hashtag features contain whether there is any ...</td>\n",
       "      <td>With an intention to exploit the contribution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>For how many probe tasks the shallow-syntax-aw...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>3</td>\n",
       "      <td>Results in Table TABREF13 show ten probes. Aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>What are the black-box probes used?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>CCG Supertagging CCGBank , PTB part-of-speech ...</td>\n",
       "      <td>Recent work has probed the knowledge encoded i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>How does this model overcome the assumption th...</td>\n",
       "      <td>The Adversarial-neural Event Model (AEM) overc...</td>\n",
       "      <td>by learning a projection function between the...</td>\n",
       "      <td>To deal with these limitations, in this paper,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>What are the industry classes defined in this ...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe industry classe...</td>\n",
       "      <td>technology, religion, fashion, publishing, spo...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Industry categories a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>What are the hyperparameters of the bi-GRU?</td>\n",
       "      <td>The hyperparameters of the bi-GRU are:\\n\\n* Ba...</td>\n",
       "      <td>They use the embedding layer with a size 35 an...</td>\n",
       "      <td>Minimal pre-processing was done by converting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Does the algorithm improve on the state-of-the...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>From all reported results proposed method (NB...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: LID Accuracy Results....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>What background knowledge do they leverage?</td>\n",
       "      <td>Labeled features as prior knowledge</td>\n",
       "      <td>labelled features, which are words whose pres...</td>\n",
       "      <td>We address the robustness problem on top of GE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>What NLP tasks do they consider?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>text classification for themes including senti...</td>\n",
       "      <td>In this section, we first justify the approach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>How do they define robustness of a model?</td>\n",
       "      <td>The authors define robustness of a model as it...</td>\n",
       "      <td>ability to accurately classify texts even when...</td>\n",
       "      <td>GE-FL reduces the heavy load of instance annot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Are the annotations automatic or manually crea...</td>\n",
       "      <td>Manually created</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>We annotated the dataset at two levels: Part o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>How long are the essays on average?</td>\n",
       "      <td>The average length of the essays is approximat...</td>\n",
       "      <td>204 tokens</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: Histogram of documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>What neural models are used to encode the text?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nN...</td>\n",
       "      <td>NBOW, LSTM, attentive LSTM</td>\n",
       "      <td>In this paper, we use three encoders (NBOW, LS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>What TIMIT datasets are used for testing?</td>\n",
       "      <td>D, H</td>\n",
       "      <td>Once split into 8 subsets (A-H), the test set ...</td>\n",
       "      <td>In order to achieve these configuration the TI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>What state-of-the-art results are achieved?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe state-of-the-ar...</td>\n",
       "      <td>F1 score of 92.19 on homographic pun detection...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>What baselines do they compare with?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThey compare with t...</td>\n",
       "      <td>They compare with the following models: by Ped...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>What datasets are used in evaluation?</td>\n",
       "      <td>BIBREF9</td>\n",
       "      <td>A homographic and heterographic benchmark dat...</td>\n",
       "      <td>We evaluate our model on two benchmark dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>What is the tagging scheme employed?</td>\n",
       "      <td>INLINEFORM0</td>\n",
       "      <td>A new tagging scheme that tags the words befor...</td>\n",
       "      <td>The contexts have the characteristic that each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>How they extract \"structured answer-relevant r...</td>\n",
       "      <td>They extract \"structured answer-relevant relat...</td>\n",
       "      <td>Using the OpenIE toolbox and applying heuristi...</td>\n",
       "      <td>To address this issue, we extract the structur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>How big are significant improvements?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Metrics show better results on all metrics com...</td>\n",
       "      <td>Table TABREF30 shows automatic evaluation resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>They used the Phase B dataset</td>\n",
       "      <td>BioASQ  dataset A dataset provided by BioASQ c...</td>\n",
       "      <td>BioASQ organizers provide the training and tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>What was their highest MRR score?</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Factoid Questions. In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>How do they measure which words are under-tran...</td>\n",
       "      <td>By using estimated word importance to detect u...</td>\n",
       "      <td>They measured the under-translated words with ...</td>\n",
       "      <td>In this experiment, we propose to use the esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>How do their models decide how much improtance...</td>\n",
       "      <td>By using integrated gradients to calculate the...</td>\n",
       "      <td>They compute the gradient of the output at ea...</td>\n",
       "      <td>Following the formula, we can calculate the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Which data do they use as a starting point for...</td>\n",
       "      <td>Nurse-initiated telephone conversations for co...</td>\n",
       "      <td>A sample from nurse-initiated telephone conver...</td>\n",
       "      <td>We used recordings of nurse-initiated telephon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>How do they select instances to their hold-out...</td>\n",
       "      <td>They select instances for their hold-out test ...</td>\n",
       "      <td>1264 instances from simulated data, 1280 insta...</td>\n",
       "      <td>To evaluate the effectiveness of our linguisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>How do the authors examine whether a model is ...</td>\n",
       "      <td>By using adversarial sets, specifically AddSen...</td>\n",
       "      <td>By evaluating their model on adversarial sets ...</td>\n",
       "      <td>MRC Dataset. The MRC dataset used in this pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>What type of system does the baseline classifi...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Classification system use n-grams, bag-of-wor...</td>\n",
       "      <td>We experimented with four different classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>What are the user-defined keywords?</td>\n",
       "      <td>$\\lbrace subway, manhattan\\rbrace $</td>\n",
       "      <td>Words that a user wants them to appear in the ...</td>\n",
       "      <td>Nonetheless, GANs have continued to show their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>What are the baselines used in the paper?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe baselines used ...</td>\n",
       "      <td>GloVe vectors trained on Wikipedia Corpus with...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results of RNN/LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>How better is performance compared to previous...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>F1 score of 97.5 on MSR and 95.7 on AS MSR: 97...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Results on PKU and MS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>How does Gaussian-masked directional multi-hea...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nG...</td>\n",
       "      <td>pays attentions to adjacent characters and cas...</td>\n",
       "      <td>Different from scaled dot-product attention, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>What are strong baselines model is compared to?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Baseline models are:\\n- Chen et al., 2015a\\n- ...</td>\n",
       "      <td>Tables TABREF25 and TABREF26 reports the perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>What additional features and context are propo...</td>\n",
       "      <td>Context tweets are proposed as additional feat...</td>\n",
       "      <td>using tweets that one has replied or quoted to...</td>\n",
       "      <td>While manually analyzing the raw dataset, we n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>What evidence do the authors present that the ...</td>\n",
       "      <td>The authors present evidence that the model ca...</td>\n",
       "      <td>The authors showed few tweets where neither an...</td>\n",
       "      <td>By examining more samples and with respect to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>What are the existing biases?</td>\n",
       "      <td>Existing biases in hate speech detection datas...</td>\n",
       "      <td>sampling tweets from specific keywords create...</td>\n",
       "      <td>As one of the first attempts in neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>What biases does their model capture?</td>\n",
       "      <td>The model captures biases from data collection...</td>\n",
       "      <td>Data annotation biases where tweet containing ...</td>\n",
       "      <td>By examining more samples and with respect to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>which neural embedding model works better?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>the CRX model</td>\n",
       "      <td>FLOAT SELECTED: Table 5 Accuracy of concept ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>What is the degree of dimension reduction of t...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n3</td>\n",
       "      <td>The number of dimensions can be reduced by up ...</td>\n",
       "      <td>FLOAT SELECTED: Table 8 Evaluation results of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>For which languages do they build word embeddi...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nENGLISH</td>\n",
       "      <td>English</td>\n",
       "      <td>FLOAT SELECTED: Table 2: We generate vectors f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What experiments do they use to quantify the e...</td>\n",
       "      <td>Word intrusion test and semantic category-base...</td>\n",
       "      <td>Human evaluation for interpretability using th...</td>\n",
       "      <td>One of the main goals of this study is to impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>What is the additive modification to the objec...</td>\n",
       "      <td>The additive modification to the objective fun...</td>\n",
       "      <td>The cost function for any one of the words of ...</td>\n",
       "      <td>Especially after the introduction of the word2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>How do they encourage understanding of literat...</td>\n",
       "      <td>By categorizing each model based on the optimi...</td>\n",
       "      <td>They group the existing works in terms of the ...</td>\n",
       "      <td>Despite this, there is a lack of prior work wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Why challenges does word segmentation in Vietn...</td>\n",
       "      <td>Word segmentation in Vietnamese poses challeng...</td>\n",
       "      <td>Acquire very large Vietnamese corpus and build...</td>\n",
       "      <td>There are several challenges on supervised lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>How successful are the approaches used to solv...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Their accuracy in word segmentation is about 9...</td>\n",
       "      <td>There are several studies about the Vietnamese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Which two news domains are country-independent?</td>\n",
       "      <td>Mainstream and disinformation news domains are...</td>\n",
       "      <td>mainstream news and disinformation</td>\n",
       "      <td>We collected tweets associated to a dozen US m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>How is the political bias of different sources...</td>\n",
       "      <td>The political bias of different sources is inc...</td>\n",
       "      <td>By assigning a political bias label to each ne...</td>\n",
       "      <td>As it is reported that conservatives and liber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>How was the dataset collected?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>from 3rd to 9th grade science questions collec...</td>\n",
       "      <td>Questions: We make use of the 7,787 science ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>How do they verify generalization ability?</td>\n",
       "      <td>They verify generalization ability by evaluati...</td>\n",
       "      <td>By calculating Macro F1 metric at the document...</td>\n",
       "      <td>Training We collect 50,000 Wikipedia articles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Do they only use adjacent entity mentions or u...</td>\n",
       "      <td>They use more than just adjacent entity mentio...</td>\n",
       "      <td>NCEL considers only adjacent mentions. More th...</td>\n",
       "      <td>Complexity Analysis Compared with local method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Why is lemmatization not necessary in English?</td>\n",
       "      <td>It is not entirely true that lemmatization is ...</td>\n",
       "      <td>Advanced neural architectures and contextualiz...</td>\n",
       "      <td>A long-standing tradition if the field of appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>How big was the corpora they trained ELMo on?</td>\n",
       "      <td>The corpora they trained ELMo on were approxim...</td>\n",
       "      <td>2174000000, 989000000 2174 million tokens for ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Training corpora For ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>What dataset is used?</td>\n",
       "      <td>English WIKIBIO dataset</td>\n",
       "      <td>English WIKIBIO, French WIKIBIO , German WIKIB...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>What does the \"sensitivity\" quantity denote?</td>\n",
       "      <td>The sensitivity quantity denotes the expected ...</td>\n",
       "      <td>The expected number of unique outputs a word ...</td>\n",
       "      <td>In NLP, we often get such invariance for free,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>What end tasks do they evaluate on?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Sentiment analysis and paraphrase detection un...</td>\n",
       "      <td>For sentiment classification, we systematicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>What is a semicharacter architecture?</td>\n",
       "      <td>A semi-character architecture</td>\n",
       "      <td>A semi-character based RNN (ScRNN) treats the ...</td>\n",
       "      <td>Inspired by the psycholinguistic studies BIBRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Why is the adversarial setting appropriate for...</td>\n",
       "      <td>Adversarial misspellings are appropriate for m...</td>\n",
       "      <td>Adversarial misspellings are a real-world problem</td>\n",
       "      <td>For all the interest in adversarial computer v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>How do the backoff strategies work?</td>\n",
       "      <td>The backoff strategies work by either passing ...</td>\n",
       "      <td>In pass-through, the recognizer passes on the ...</td>\n",
       "      <td>While BIBREF7 demonstrate strong word recognit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>which algorithm was the highest performer?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nI...</td>\n",
       "      <td>A hybrid model consisting of best performing p...</td>\n",
       "      <td>Hybrid approaches. Figure FIGREF11 shows the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>what dataset was used?</td>\n",
       "      <td>Amazon search terms and editor tags</td>\n",
       "      <td>E-book annotation data: editor tags, Amazon ...</td>\n",
       "      <td>Data used to generate recommendations. We empl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>How large are the improvements of the Attentio...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Table 2) Accura...</td>\n",
       "      <td>If we take the best psr ensemble trained on CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Which machine learning methods are used in exp...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nS...</td>\n",
       "      <td>Structural Support Vector Machine</td>\n",
       "      <td>We chose SVMhmm BIBREF111 implementation of St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>how was the speech collected?</td>\n",
       "      <td>The speech was collected using an Android appl...</td>\n",
       "      <td>The speech was collected from respondents usin...</td>\n",
       "      <td>DeepMine is publicly available for everybody w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>what topics did they label?</td>\n",
       "      <td>The topics labeled in the HPI notes include de...</td>\n",
       "      <td>Demographics Age, DiagnosisHistory, Medication...</td>\n",
       "      <td>FLOAT SELECTED: Table 1. HPI Categories and An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>what levels of document preprocessing are look...</td>\n",
       "      <td>The answer is:\\n\\nThree incremental levels of ...</td>\n",
       "      <td>Level 1, Level 2 and Level 3.</td>\n",
       "      <td>While previous work clearly states that effici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>what keyphrase extraction models were reassessed?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe keyphrase extra...</td>\n",
       "      <td>Answer with content missing: (LVL1, LVL2, LVL3...</td>\n",
       "      <td>In this study, we concentrate our effort on re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>How many different phenotypes are present in t...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n13</td>\n",
       "      <td>Thirteen different phenotypes are present in ...</td>\n",
       "      <td>We have created a dataset of discharge summari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>What are 10 other phenotypes that are annotated?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Adv. Heart Disease, Adv. Lung Disease, Alcohol...</td>\n",
       "      <td>Table defines each of the considered clinical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>What are the network's baseline features?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n1...</td>\n",
       "      <td>The features extracted from CNN.</td>\n",
       "      <td>CNN can also be employed on the sarcasm datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>What tasks are used for evaluation?</td>\n",
       "      <td>Machine translation tasks</td>\n",
       "      <td>four machine translation tasks: German -&gt; Engl...</td>\n",
       "      <td>We apply our adaptively sparse Transformers on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>HOw does the method perform compared with base...</td>\n",
       "      <td>The method performs similarly or slightly bett...</td>\n",
       "      <td>On the datasets DE-EN, JA-EN, RO-EN, and EN-DE...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Machine translation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>What baseline method is used?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nS...</td>\n",
       "      <td>using word2vec to create features that are use...</td>\n",
       "      <td>In a recent work on sentiment analysis in Turk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>What details are given about the Twitter dataset?</td>\n",
       "      <td>The Twitter dataset has 1,716 tweets, with 973...</td>\n",
       "      <td>one of the Twitter datasets is about Turkish ...</td>\n",
       "      <td>The second Turkish dataset is the Twitter corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>What details are given about the movie domain ...</td>\n",
       "      <td>The answer is:\\n\\nThe movie domain dataset has...</td>\n",
       "      <td>there are 20,244 reviews divided into positive...</td>\n",
       "      <td>For Turkish, as the first dataset, we utilised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>what pretrained word embeddings were used?</td>\n",
       "      <td>GloVe BIBREF13 and Edinburgh embeddings BIBREF14</td>\n",
       "      <td>Pretrained word embeddings  were not used</td>\n",
       "      <td>Word Vectors: We focus primarily on the word v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>What evaluation metrics did look at?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>precision, recall, F1 and accuracy Response ti...</td>\n",
       "      <td>FLOAT SELECTED: Table 15: Evaluation of differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>What datasets are used?</td>\n",
       "      <td>The dataset used is a collection of 124 questi...</td>\n",
       "      <td>Custom dataset with user questions; set of doc...</td>\n",
       "      <td>Given that there is no public dataset availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>How much improvement is gained from Adversaria...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>ARAM has achieved improvement over all baselin...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Automatic evaluation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>why are their techniques cheaper to implement?</td>\n",
       "      <td>Because they do not require the availability o...</td>\n",
       "      <td>They use a slightly modified copy of the targe...</td>\n",
       "      <td>In this paper, we have analyzed various ways t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>what dataset is used?</td>\n",
       "      <td>Europarl corpus BIBREF5</td>\n",
       "      <td>Europarl tests from 2006, 2007, 2008; WMT new...</td>\n",
       "      <td>We are mostly interested with the following tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>what language pairs are explored?</td>\n",
       "      <td>English-German and English-French</td>\n",
       "      <td>English-German, English-French. English-German...</td>\n",
       "      <td>We are mostly interested with the following tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>What are the organic and inorganic ways to sho...</td>\n",
       "      <td>The answer is:\\n\\nOrganic ways to show politic...</td>\n",
       "      <td>Organic: mention of political parties names in...</td>\n",
       "      <td>In this section, we first describe the phenome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>How do profile changes vary for influential le...</td>\n",
       "      <td>Influential leads are more likely to make chan...</td>\n",
       "      <td>Influential leaders are more likely to change ...</td>\n",
       "      <td>INSIGHT 1: Political handles are more likely t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>how small of a dataset did they train on?</td>\n",
       "      <td>1000 hours</td>\n",
       "      <td>23085 hours of data</td>\n",
       "      <td>In this paper, we explore a entire deep LSTM R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>what was their character error rate?</td>\n",
       "      <td>The answer is:\\n\\nThe character error rate (CE...</td>\n",
       "      <td>2.49% for  layer-wise training, 2.63% for dist...</td>\n",
       "      <td>FLOAT SELECTED: Table 3. The CER and RTF of 9-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>which lstm models did they compare with?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Unidirectional LSTM networks with 2, 6, 7, 8, ...</td>\n",
       "      <td>There is a high real time requirement in real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Do they use datasets with transcribed text or ...</td>\n",
       "      <td>They use both datasets with transcribed text a...</td>\n",
       "      <td>They use text transcription. both</td>\n",
       "      <td>We assume that speech transcripts can be extra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>By how much did they improve?</td>\n",
       "      <td>They improved by 2.5% absolute improvement in ...</td>\n",
       "      <td>They decrease MAE in 0.34</td>\n",
       "      <td>Concerning the neural network architecture, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>The dataset used was the fine-grained sentimen...</td>\n",
       "      <td>high-quality datasets  from SemEval-2016 “Sen...</td>\n",
       "      <td>Ternary and fine-grained sentiment classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Which natural language(s) are studied in this ...</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>The Propaganda Techniques Corpus (PTC) dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>What metrics are used for evaluation?</td>\n",
       "      <td>The metrics used for evaluation are:\\n\\n* BPE ...</td>\n",
       "      <td>Byte-Pair Encoding perplexity  (BPE PPL),\\nBLE...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Metrics on generated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>What natural language(s) are the recipes writt...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>English English</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Sample data flow thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Which multiple datasets did they train on duri...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>BioScope Abstracts, SFU, and BioScope Full Pa...</td>\n",
       "      <td>We use a default train-validation-test split o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>what is the size of the real-world civil case ...</td>\n",
       "      <td>The size of the real-world civil case dataset ...</td>\n",
       "      <td>100 000 documents</td>\n",
       "      <td>For experiments, we train and evaluate our mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>What rouge score do they achieve?</td>\n",
       "      <td>The answer is:\\n\\nTheir Rouge scores on the CN...</td>\n",
       "      <td>Best results on unigram:\\nCNN/Daily Mail: Rogu...</td>\n",
       "      <td>We evaluated summarization quality automatical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>What was their performance on emotion detection?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe model achieved ...</td>\n",
       "      <td>Answer with content missing: (Table 3) Best au...</td>\n",
       "      <td>In Table TABREF26 we report the results of our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>What is the benchmark dataset and is its quali...</td>\n",
       "      <td>The benchmark dataset is the Social Honeypot d...</td>\n",
       "      <td>Social Honeypot dataset (public) and Weibo dat...</td>\n",
       "      <td>We use one public dataset Social Honeypot data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>How do they detect spammers?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Extract features from the LDA model and use th...</td>\n",
       "      <td>Using the LDA model, each person in the datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>What are the baselines?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Answer with content missing: (Experimental Se...</td>\n",
       "      <td>Experimental Setup In this section we present ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>What datasets do they use?</td>\n",
       "      <td>They use three datasets: imdb400, yelp50, and ...</td>\n",
       "      <td>1 IMDB dataset and 2 Yelp datasets</td>\n",
       "      <td>We construct three datasets based on IMDB revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>What domains are covered in the corpus?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe corpus covers a...</td>\n",
       "      <td>No specific domain is covered in the corpus.</td>\n",
       "      <td>Common Voice BIBREF10 is a crowdsourcing speec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>By how much does their best model outperform t...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>0.8% F1 better than the best state-of-the-art ...</td>\n",
       "      <td>Table TABREF16 shows the results of our models...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>How does their simple voting scheme work?</td>\n",
       "      <td>The simple voting scheme works by applying mul...</td>\n",
       "      <td>Among all the classes predicted by several mo...</td>\n",
       "      <td>Finally, we combine our CNN and RNN models usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>How do they obtain the new context represetation?</td>\n",
       "      <td>They propose a new context representation call...</td>\n",
       "      <td>They use two independent convolutional and max...</td>\n",
       "      <td>(1) We propose extended middle context, a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>What is the performance of the baseline?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n82.6%</td>\n",
       "      <td>M-Bert had 76.6 F1 macro score. 75.1% and 75.6...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Performance of BERT-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>What was the performance of multilingual BERT?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>BERT had 76.6 F1 macro score on x-stance dataset.</td>\n",
       "      <td>To put the supervised score into context we li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>What is an unordered text document, do these a...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nA...</td>\n",
       "      <td>A unordered text document is one where sentenc...</td>\n",
       "      <td>To structure an unordered document is an essen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Who were the experts used for annotation?</td>\n",
       "      <td>Seven experts with legal training were used fo...</td>\n",
       "      <td>Individuals with legal training</td>\n",
       "      <td>To identify legally sound answers, we recruit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Is this hashtag prediction task an established...</td>\n",
       "      <td>Established</td>\n",
       "      <td>established task</td>\n",
       "      <td>Hashtag prediction for social media has been a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>What other tasks do they test their method on?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>None</td>\n",
       "      <td>We test the character and word-level variants ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>What is the state of the art system mentioned?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nO...</td>\n",
       "      <td>Two knowledge-based systems,\\ntwo traditional ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: F1-score (%) for fine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Do they use large or small BERT?</td>\n",
       "      <td>Small BERT (BERT$_\\text{BASE}$)</td>\n",
       "      <td>small BERT small BERT</td>\n",
       "      <td>We use the pre-trained uncased BERT$_\\mathrm {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>What is their system's absolute accuracy?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>59.4% on wikipedia dataset, 93.4% on peer-revi...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Experimental results....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Which is more useful, visual or textual features?</td>\n",
       "      <td>Both visual and textual features are useful fo...</td>\n",
       "      <td>It depends on the dataset. Experimental result...</td>\n",
       "      <td>We proposed to use visual renderings of docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Which languages do they use?</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>The Wikipedia dataset consists of articles fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>How large is their data set?</td>\n",
       "      <td>Their dataset consists of 29,794 articles</td>\n",
       "      <td>a sample of  29,794 wikipedia articles and 2,7...</td>\n",
       "      <td>We randomly sampled 5,000 articles from each q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>what linguistics features are used?</td>\n",
       "      <td>The answer is:\\n\\nSegmentation, POS tagging, s...</td>\n",
       "      <td>POS, gender/number and stem POS</td>\n",
       "      <td>Table TABREF17 lists the features that we used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>what dataset statistics are provided?</td>\n",
       "      <td>The answer is:\\n\\n* 87% of questions had a cle...</td>\n",
       "      <td>More than 2,100 texts were paired with 15 ques...</td>\n",
       "      <td>More than 2,100 texts were paired with 15 ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>how was the data collected?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The data was collected using 3 components: des...</td>\n",
       "      <td>Machine comprehension datasets consist of thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>What is best performing model among author's s...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe author's best-p...</td>\n",
       "      <td>For SLC task, the \"ltuorp\" team  has the best ...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Comparison of our sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>What extracted features were most influencial ...</td>\n",
       "      <td>The pre-trained embeddings (FastText or BERT) ...</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Did ensemble schemes help in boosting peforman...</td>\n",
       "      <td>Yes, ensemble schemes helped in boosting perfo...</td>\n",
       "      <td>The best ensemble topped the best single model...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Which basic neural architecture perform best b...</td>\n",
       "      <td>Sure! Here's my answer based on the given cont...</td>\n",
       "      <td>BERT</td>\n",
       "      <td>FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>What participating systems had better results ...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nOnly one system (Sy...</td>\n",
       "      <td>For SLC task : Ituorp, ProperGander and YMJA  ...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Comparison of our sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>What is specific to multi-granularity and mult...</td>\n",
       "      <td>Multi-granularity and multi-tasking neural arc...</td>\n",
       "      <td>An output layer for each task Multi-tasking is...</td>\n",
       "      <td>Shared Task: This work addresses the two tasks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>How much training data from the non-English la...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>No data. Pretrained model is used.</td>\n",
       "      <td>Do multilingual models always need to be train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>How is the model transferred to other languages?</td>\n",
       "      <td>The model is transferred to other languages by...</td>\n",
       "      <td>Build a bilingual language model,   learn the ...</td>\n",
       "      <td>Do multilingual models always need to be train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>How was the StackExchange dataset collected?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>they obtained computer science related topics ...</td>\n",
       "      <td>Inspired by the StackLite tag recommendation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>What is the size of the StackExchange dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n10,000</td>\n",
       "      <td>around 332k questions</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistics of dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>What were the baselines?</td>\n",
       "      <td>The baselines were four non-neural extractive ...</td>\n",
       "      <td>CopyRNN (Meng et al., 2017), Multi-Task (Ye an...</td>\n",
       "      <td>We report our model's performance on the prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>What labels for antisocial events are availabl...</td>\n",
       "      <td>Personal attacks and rule violations</td>\n",
       "      <td>The Conversations Gone Awry dataset is labelle...</td>\n",
       "      <td>We consider two datasets, representing related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>What are two datasets model is applied to?</td>\n",
       "      <td>The two datasets the model is applied to are t...</td>\n",
       "      <td>An expanded version of the existing 'Conversa...</td>\n",
       "      <td>To test the effectiveness of this new architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>What is the McGurk effect?</td>\n",
       "      <td>The McGurk effect is a phenomenon where the pe...</td>\n",
       "      <td>a perceptual illusion, where listening to a sp...</td>\n",
       "      <td>For the McGurk effect, we attempt an illusion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>what phenomena do they mention is hard to capt...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Four discourse phenomena - deixis, lexical coh...</td>\n",
       "      <td>We analyze which discourse phenomena are hard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>by how much did the BLEU score improve?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n0...</td>\n",
       "      <td>On average 0.64</td>\n",
       "      <td>The BLEU scores are provided in Table TABREF24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>What is NER?</td>\n",
       "      <td>Named Entity Recognition (NER) in the Biomedic...</td>\n",
       "      <td>Named Entity Recognition, including entities ...</td>\n",
       "      <td>Named Entity Recognition (NER) in the Biomedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>How better does new approach behave than exist...</td>\n",
       "      <td>New approach performs significantly better tha...</td>\n",
       "      <td>On Coin Collector, proposed model finds short...</td>\n",
       "      <td>Results ::: CoinCollector In this setting, we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>How much is classification performance improve...</td>\n",
       "      <td>The answer is:\\n\\nIn experiments for low data ...</td>\n",
       "      <td>Low data: SST-5, TREC, IMDB around 1-2 accurac...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracy of Data Mani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>What subtasks did they participate in?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>Answer with content missing: (Subscript 1: \"We...</td>\n",
       "      <td>Our submissions ranked second (EI-Reg), second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>They used the Affect in Tweets Distant Supervi...</td>\n",
       "      <td>Selection of tweets with for each tweet a lab...</td>\n",
       "      <td>For each task, the training data that was made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>What are the 12 languages covered?</td>\n",
       "      <td>The answer is:\\n\\n12 languages covered in Mult...</td>\n",
       "      <td>Chinese Mandarin, Welsh, English, Estonian, Fi...</td>\n",
       "      <td>Language Selection. Multi-SimLex comprises ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>What type of evaluation is proposed for this t...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nManual evaluation</td>\n",
       "      <td>Answer with content missing: (Evaluation Metri...</td>\n",
       "      <td>Baseline Experiments In this section, we brief...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>What baseline system is proposed?</td>\n",
       "      <td>The proposed baseline system is not specified</td>\n",
       "      <td>Answer with content missing: (Baseline Method ...</td>\n",
       "      <td>Baseline Experiments In this section, we brief...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>How were crowd workers instructed to identify ...</td>\n",
       "      <td>Crowd workers were instructed to identify impo...</td>\n",
       "      <td>They break down the task of importance annota...</td>\n",
       "      <td>We break down the task of importance annotatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>How is pseudo-perplexity defined?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (formulas in sele...</td>\n",
       "      <td>The goal of an language model is to assign mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>What is the model architecture used?</td>\n",
       "      <td>A VQA deep learning architecture that combines...</td>\n",
       "      <td>LSTM to encode the question, VGG16 to extract ...</td>\n",
       "      <td>We next adapt a VQA deep learning architecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>How is the data used for training annotated?</td>\n",
       "      <td>The data used for training is annotated with a...</td>\n",
       "      <td>The number of redundant answers to collect fro...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 6: We propose a novel app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>what quantitative analysis is done?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nDescriptive statist...</td>\n",
       "      <td>Answer with content missing: (Evaluation secti...</td>\n",
       "      <td>Results and Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>by how much did nus outperform abus?</td>\n",
       "      <td>NUS outperformed ABUS by approximately 5.5% (9...</td>\n",
       "      <td>Average success rate is higher by 2.6 percent ...</td>\n",
       "      <td>Table TABREF18 shows the results of the cross-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Which dataset has been used in this work?</td>\n",
       "      <td>Reuters-8 dataset</td>\n",
       "      <td>The Reuters-8 dataset (with stop words removed)</td>\n",
       "      <td>In this section we describe the experiments pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>What can word subspace represent?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Word vectors, usually in the context of others...</td>\n",
       "      <td>To tackle this problem, we introduce the novel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>How big are improvements of small-scale unbala...</td>\n",
       "      <td>Improvements of small-scale unbalanced dataset...</td>\n",
       "      <td>it has 0.024 improvement in accuracy comparin...</td>\n",
       "      <td>The last group contains the results of our pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>How big is dataset for testing?</td>\n",
       "      <td>The testing dataset contains approximately 15 ...</td>\n",
       "      <td>30 terms, each term-sanse pair has around 15 s...</td>\n",
       "      <td>Our testing dataset takes MIMIC-III BIBREF18 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>What are the qualitative experiments performed...</td>\n",
       "      <td>Qualitative experiments were performed on benc...</td>\n",
       "      <td>Spearman correlation values of GM_KL model eva...</td>\n",
       "      <td>Table TABREF18 shows the Spearman correlation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>What were their results on the classification ...</td>\n",
       "      <td>The answer is:\\n\\nOn the classification task, ...</td>\n",
       "      <td>F1 score result of 0.8099</td>\n",
       "      <td>Table TABREF29 gives three results from our su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Which hyperparameters were varied in the exper...</td>\n",
       "      <td>The answer is:\\n\\nThe hyperparameters varied i...</td>\n",
       "      <td>number of clusters, seed value in clustering, ...</td>\n",
       "      <td>We cluster the embeddings with INLINEFORM0 -Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>How were the cluster extracted?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Word clusters are extracted using k-means on w...</td>\n",
       "      <td>We cluster the embeddings with INLINEFORM0 -Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>what were the evaluation metrics?</td>\n",
       "      <td>The evaluation metrics used in the study were ...</td>\n",
       "      <td>Unlabeled sentence-level F1, perplexity, gram...</td>\n",
       "      <td>Table TABREF23 shows the unlabeled INLINEFORM0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>what english datasets were used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe dataset used wa...</td>\n",
       "      <td>Answer with content missing: (Data section) Pe...</td>\n",
       "      <td>Experimental Setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>which chinese datasets were used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nCUHK03 and CUHK07</td>\n",
       "      <td>Answer with content missing: (Data section) Ch...</td>\n",
       "      <td>Experimental Setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>What were their distribution results?</td>\n",
       "      <td>The distribution results for viral tweets cont...</td>\n",
       "      <td>Distributions of Followers, Friends and URLs a...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: For each one of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>How did they determine fake news tweets?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>an expert annotator determined if the tweet fe...</td>\n",
       "      <td>For our study, we used the number of retweets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>What is their definition of tweets going viral?</td>\n",
       "      <td>According to the context, the definition of tw...</td>\n",
       "      <td>Viral tweets are the ones that are retweeted m...</td>\n",
       "      <td>One straightforward way of sharing information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>What are the characteristics of the accounts t...</td>\n",
       "      <td>Accounts spreading fake news have a higher cha...</td>\n",
       "      <td>Accounts that spread fake news are mostly unve...</td>\n",
       "      <td>We found that 82 users within our sample were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>How is the ground truth for fake news establis...</td>\n",
       "      <td>Manually, with limitations</td>\n",
       "      <td>Ground truth is not established in the paper</td>\n",
       "      <td>The 1327 `viral' tweets were manually annotate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Where does the ancient Chinese dataset come from?</td>\n",
       "      <td>Ancient Chinese history records and articles w...</td>\n",
       "      <td>Ancient Chinese history records in several dy...</td>\n",
       "      <td>Data Collection. To build the large ancient-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>How big is the difference in performance betwe...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Metric difference between Aloha and best basel...</td>\n",
       "      <td>Table TABREF44 shows average results of our au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>In what 8 languages is PolyResponse engine use...</td>\n",
       "      <td>English, German, Spanish, Mandarin, Polish, Ru...</td>\n",
       "      <td>English, German, Spanish, Mandarin, Polish, Ru...</td>\n",
       "      <td>The PolyResponse restaurant search is currentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>How many question types do they find in the da...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>7</td>\n",
       "      <td>Fig. FIGREF4 shows the distributions of seven ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>How do they analyze contextual similaries acro...</td>\n",
       "      <td>They do not analyze contextual similarities ac...</td>\n",
       "      <td>They compare the tasks that the datasets are s...</td>\n",
       "      <td>All corpora provide datasets/splits for answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>What were their performance results?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>best model achieves 0.94 F1 score for Wikipedi...</td>\n",
       "      <td>DNN based models coupled with transfer learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>What datasets are used to assess the performan...</td>\n",
       "      <td>The system's performance is assessed using the...</td>\n",
       "      <td>LORELEI datasets of Uzbek, Mandarin and Turkish</td>\n",
       "      <td>For our single-label topic classification expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>IS the graph representation supervised?</td>\n",
       "      <td>NO</td>\n",
       "      <td>The graph representation appears to be semi-su...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: The framework of G-B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Is the G-BERT model useful beyond the task con...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>There is nothing specific about the approach t...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: The framework of G-B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Do they introduce errors in the data or does t...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Data already contain errors</td>\n",
       "      <td>We use three languages in our experiments: Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>What is the difference of the proposed model w...</td>\n",
       "      <td>The proposed model with a Refinement Adjustmen...</td>\n",
       "      <td>Introduce a \"Refinement Adjustment LSTM-based ...</td>\n",
       "      <td>While the RNN-based generators with DA gating-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Does the model evaluated on NLG datasets or di...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nN...</td>\n",
       "      <td>NLG datasets NLG datasets</td>\n",
       "      <td>We assessed the proposed models on four differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>How is the quality of singing voice measured?</td>\n",
       "      <td>The quality of singing voice is measured using...</td>\n",
       "      <td>Automatic: Normalized cross correlation (NCC)...</td>\n",
       "      <td>To compare the conversions between USVC and Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>what previous RNN models do they compare with?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nstate-of-the-art me...</td>\n",
       "      <td>Variational LSTM, CharCNN, Pointer Sentinel-LS...</td>\n",
       "      <td>Table TABREF23 compares the performance of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>What are the languages they use in their exper...</td>\n",
       "      <td>English, Spanish, and Finnish</td>\n",
       "      <td>English\\nFrench\\nSpanish\\nGerman\\nGreek\\nBulga...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: XNLI dev results (acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>How do they match annotators to instances?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Annotations from experts are used if they have...</td>\n",
       "      <td>So far a system was trained on one type of dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>How much data is needed to train the task-spec...</td>\n",
       "      <td>57,505 sentences</td>\n",
       "      <td>57,505 sentences 57,505 sentences</td>\n",
       "      <td>Our contributions in this work are summarized ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Who are the crowdworkers?</td>\n",
       "      <td>Crowdworkers are individuals located in the US...</td>\n",
       "      <td>people in the US that use Amazon Mechanical Turk</td>\n",
       "      <td>We used the 1,000-tweet dataset by BIBREF2 tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Which sentiment class is the most accurately p...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>neutral sentiment</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Average Correct Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>what were the baselines?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN</td>\n",
       "      <td>The experiment results of validation on Friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>What BERT models are used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nBERT-base and BERT-...</td>\n",
       "      <td>BERT-base, BERT-large, BERT-uncased, BERT-cased</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Validation Results (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>What experiments are used to demonstrate the b...</td>\n",
       "      <td>The experiments used to demonstrate the benefi...</td>\n",
       "      <td>Calculate test log-likelihood on the three co...</td>\n",
       "      <td>In this section, we describe the experimental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Which component is the least impactful?</td>\n",
       "      <td>The number of message passing iterations (n) h...</td>\n",
       "      <td>Based on table results provided changing direc...</td>\n",
       "      <td>Results and ablations ::: Ablation studies To ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Which component has the greatest impact on per...</td>\n",
       "      <td>The number of message passing iterations</td>\n",
       "      <td>Increasing number of message passing iteration...</td>\n",
       "      <td>Results and ablations ::: Ablation studies To ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>What is the message passing framework?</td>\n",
       "      <td>The message passing framework is a method for ...</td>\n",
       "      <td>It is a framework used to describe algorithms ...</td>\n",
       "      <td>The MP framework is based on the core idea of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>What is the best reported system?</td>\n",
       "      <td>The MILR classifier</td>\n",
       "      <td>Gaze Sarcasm using Multi Instance Logistic Reg...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Classification result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>What cognitive features are used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nMemory, Attention, ...</td>\n",
       "      <td>Readability (RED),  Number of Words (LEN), Avg...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: The complete set of f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>What approaches do they use towards text analy...</td>\n",
       "      <td>They use a combination of quantitative and qua...</td>\n",
       "      <td>Modeling considerations:  the variables (both...</td>\n",
       "      <td>This contrasts with much of the work in comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>What is the seed lexicon?</td>\n",
       "      <td>The seed lexicon is a set of positive and nega...</td>\n",
       "      <td>a vocabulary of positive and negative predicat...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>What are the results?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Using all data to train: AL -- BiGRU achieved ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>Relations are used to propagate polarity throu...</td>\n",
       "      <td>based on the relation between events, the sugg...</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>How big is the Japanese data?</td>\n",
       "      <td>The Japanese data consists of approximately 10...</td>\n",
       "      <td>7000000 pairs of events were extracted from th...</td>\n",
       "      <td>As a raw corpus, we used a Japanese web corpus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>How big are improvements of supervszed learnin...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nImprovements of sup...</td>\n",
       "      <td>3%</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Results for small lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>How does their model learn using mostly raw data?</td>\n",
       "      <td>By exploiting discourse relations to efficient...</td>\n",
       "      <td>by exploiting discourse relations to propagate...</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>How big is seed lexicon used for training?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n1...</td>\n",
       "      <td>30 words</td>\n",
       "      <td>We constructed our seed lexicon consisting of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>How do the various social phenomena examined m...</td>\n",
       "      <td>Dynamic and distinctive communities have highe...</td>\n",
       "      <td>Dynamic communities have substantially higher ...</td>\n",
       "      <td>We find that dynamic communities, such as Seah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>How did the select the 300 Reddit communities ...</td>\n",
       "      <td>The 300 Reddit communities were selected based...</td>\n",
       "      <td>They selected all the subreddits from January ...</td>\n",
       "      <td>Our full dataset consists of all subreddits on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>How is the clinical text structuring task defi...</td>\n",
       "      <td>The clinical text structuring task is defined ...</td>\n",
       "      <td>CTS is extracting structural data from medica...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 1. An illustrative exampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Is all text in this dataset a question, or are...</td>\n",
       "      <td>No, not all text in this dataset is a question...</td>\n",
       "      <td>the dataset consists of pathology reports incl...</td>\n",
       "      <td>Our dataset is annotated based on Chinese path...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>How many questions are in the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>2,714</td>\n",
       "      <td>Our dataset is annotated based on Chinese path...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>What aspects have been compared between variou...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Quality measures using perplexity and recall, ...</td>\n",
       "      <td>For each model, we examined word-level perplex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>How many attention layers are there in their m...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n1</td>\n",
       "      <td>one</td>\n",
       "      <td>The baseline model is a deep sequence-to-seque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>What are the three measures of bias which are ...</td>\n",
       "      <td>RIPA, WEAT, and Neighborhood bias</td>\n",
       "      <td>RIPA, Neighborhood Metric, WEAT</td>\n",
       "      <td>Geometric bias mitigation uses the cosine dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>How big is the dataset?</td>\n",
       "      <td>The dataset consists of 471,319 references fro...</td>\n",
       "      <td>903019 references</td>\n",
       "      <td>Overall, through the process described in Sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>How is the intensity of the PTSD established?</td>\n",
       "      <td>The intensity of PTSD is established based on ...</td>\n",
       "      <td>Given we have four intensity, No PTSD, Low Ris...</td>\n",
       "      <td>To provide an initial results, we take 50% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>how is quality measured?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Accuracy and the macro-F1 (averaged F1 over po...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison of manuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>What is the accuracy reported by state-of-the-...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Table 1)\\nPrevio...</td>\n",
       "      <td>In Table TABREF1, we summarize the quantitativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>How do the authors define or exemplify 'incorr...</td>\n",
       "      <td>Incorrect words are defined as missing or misp...</td>\n",
       "      <td>typos in spellings or ungrammatical words</td>\n",
       "      <td>Understanding a user's intent and sentiment is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>By how much do they outperform other models in...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>In the sentiment classification task by 6% to ...</td>\n",
       "      <td>Experimental results for the Twitter Sentiment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Which experiments are perfomed?</td>\n",
       "      <td>The experiments performed are on the WNC datas...</td>\n",
       "      <td>They used BERT-based models to detect subjecti...</td>\n",
       "      <td>In natural language, subjectivity refers to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Is ROUGE their only baseline?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, other baseline metrics they use besides R...</td>\n",
       "      <td>Our first baseline is ROUGE-L BIBREF1 , since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>By how much does their system outperform the l...</td>\n",
       "      <td>The proposed model outperforms the lexicon-bas...</td>\n",
       "      <td>Under the retrieval evaluation setting, their ...</td>\n",
       "      <td>NVDM (Lexical, Neural) is a VAE-based approach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>How are the main international development top...</td>\n",
       "      <td>Based on the analysis of exclusive and semanti...</td>\n",
       "      <td>They focus on exclusivity and semantic cohere...</td>\n",
       "      <td>We assess the optimal number of topics that ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Is the semantic hierarchy representation used ...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nYes</td>\n",
       "      <td>Yes, Open IE</td>\n",
       "      <td>An extrinsic evaluation was carried out on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Is the model evaluated?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nY...</td>\n",
       "      <td>the English version is evaluated. The German v...</td>\n",
       "      <td>For the English version, we performed both a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>How better is accuracy of new model compared t...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Average accuracy of proposed model vs best pre...</td>\n",
       "      <td>Table TABREF29 presents the quantitative resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>How does the active learning model work?</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>Active learning methods has a learning engine ...</td>\n",
       "      <td>Active learning methods can generally be descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Did the annotators agreed and how much?</td>\n",
       "      <td>The annotators agreed moderately to substantia...</td>\n",
       "      <td>For event types and participant types, there w...</td>\n",
       "      <td>FLOAT SELECTED: Figure 4: Inter-annotator agre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>What datasets are used to evaluate this approach?</td>\n",
       "      <td>WN18 and YAGO3-10</td>\n",
       "      <td>Kinship and Nations knowledge graphs, YAGO3-1...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Data Statistics of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>How was the dataset collected?</td>\n",
       "      <td>The dataset was collected through a combinatio...</td>\n",
       "      <td>They crawled travel information from the Web ...</td>\n",
       "      <td>Database Construction: we crawled travel infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>What models other than standalone BERT is new ...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>Only Bert base and Bert large are compared to ...</td>\n",
       "      <td>Results on WNLaMPro rare and medium are shown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>How big is the performance difference between ...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe performance dif...</td>\n",
       "      <td>Comparing with the highest performing baseline...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Compare our model wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>What approaches without reinforcement learning...</td>\n",
       "      <td>Neural Network Regressor (NNR) and Neural Netw...</td>\n",
       "      <td>classification, regression, neural methods</td>\n",
       "      <td>We conducted cross-validation experiments usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Which languages do they validate on?</td>\n",
       "      <td>All 31 languages with both UD and UniMorph data</td>\n",
       "      <td>Ar, Bg, Ca, Cs, Da, De, En, Es, Eu, Fa, Fi, Fr...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Token-level recall wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>What is the baseline method for the task?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>For the emotion recognition from text they use...</td>\n",
       "      <td>For the emotion recognition from text, we manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>what amounts of size were used on german-english?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Training data with 159000, 80000, 40000, 20000...</td>\n",
       "      <td>We use the TED data from the IWSLT 2014 German...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>How big is the dataset?</td>\n",
       "      <td>7934 messages</td>\n",
       "      <td>Resulting dataset was 7934 messages for train...</td>\n",
       "      <td>Dataset: Based on some earlier work, only avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>What MC abbreviate for?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nMC abbreviates for ...</td>\n",
       "      <td>machine comprehension</td>\n",
       "      <td>Enabling computers to understand given documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>What are their correlation results?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>High correlation results range from 0.472 to 0...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Spearman’s ρ, Kendall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>What simpler models do they look at?</td>\n",
       "      <td>They look at simpler models such as ROUGE, Lan...</td>\n",
       "      <td>BiGRUs with attention, ROUGE, Language model,...</td>\n",
       "      <td>Methods ::: Baselines ::: BiGRU s with attenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>What linguistic quality aspects are addressed?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nFIVE LINGUISTIC QUA...</td>\n",
       "      <td>Grammaticality, non-redundancy, referential cl...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: SUM-QE rates summari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>What dataset do they use?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>A parallel corpus where the source is an Engli...</td>\n",
       "      <td>SMT techniques require a parallel corpus in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>What is typical GAN architecture for each text...</td>\n",
       "      <td>The answer is:\\n\\n* Semantic Enhancement GANs:...</td>\n",
       "      <td>Semantic Enhancement GANs: DC-GANs, MC-GAN\\nRe...</td>\n",
       "      <td>In this section, we propose a taxonomy to summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>What language do the agents talk in?</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>English</td>\n",
       "      <td>Tourist: I can't go straight any further. Guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>How much better is performance of proposed met...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Accuracy of best proposed method KANE (LSTM+Co...</td>\n",
       "      <td>Experimental results of entity classification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>What baseline model is used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nHUMAN EVALUATORS</td>\n",
       "      <td>Human evaluators</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Performance of human ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>What stylistic features are used to detect dru...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nSentiment analysis,...</td>\n",
       "      <td>LDA unigrams (Presence/Count), POS Ratio, #Nam...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Our Feature Set for D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>What is the accuracy of the proposed technique?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n90.1%</td>\n",
       "      <td>51.7 and 51.6 on 4th and 8th grade question se...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: TUPLEINF is significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Which retrieval system was used for baselines?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The dataset comes with a ranked set of relevan...</td>\n",
       "      <td>Each dataset consists of a collection of recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>How much better was the BLSTM-CNN-CRF than the...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe BLSTM-CNN-CRF o...</td>\n",
       "      <td>Best BLSTM-CNN-CRF had F1 score 86.87 vs 86.69...</td>\n",
       "      <td>Table 2 shows our experiments on two models wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>What supplemental tasks are used for multitask...</td>\n",
       "      <td>Task C, which involves predicting the relation...</td>\n",
       "      <td>Multitask learning is used for the task of pre...</td>\n",
       "      <td>Automation of cQA forums can be divided into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>How much performance gap between their approac...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n10.5% performance gap</td>\n",
       "      <td>0.007 MAP on Task A, 0.032 MAP on Task B, 0.05...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Compared with other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>How big is their model?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Proposed model has 1.16 million parameters and...</td>\n",
       "      <td>To figure out whether the proposed AEN-GloVe i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>How many emotions do they look at?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n9</td>\n",
       "      <td>9</td>\n",
       "      <td>The final annotation categories for the datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>What approach did previous models use for mult...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nP...</td>\n",
       "      <td>Only MTMSM specifically tried to tackle the mu...</td>\n",
       "      <td>MTMSN BIBREF4 is the first, and only model so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>What is difference in peformance between propo...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe proposed model ...</td>\n",
       "      <td>For single-span questions, the proposed LARGE-...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Performance of differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>What is the performance of proposed model on e...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The proposed model achieves  EM 77,63 and F1 8...</td>\n",
       "      <td>Table TABREF25 shows the results on DROP's tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>How accurate is the aspect based sentiment cla...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>BiLSTM-XR-Dev Estimation accuracy is 83.31 for...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Average accuracies an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>What were the non-neural baselines used for th...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The Lemming model in BIBREF17</td>\n",
       "      <td>BIBREF17: The Lemming model is a log-linear mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>What are the models evaluated on?</td>\n",
       "      <td>The models are evaluated on both question answ...</td>\n",
       "      <td>They evaluate F1 score and agent's test perfor...</td>\n",
       "      <td>We build the iSQuAD and iNewsQA datasets based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>What is the results of multimodal compared to ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Unimodal LSTM vs Best Multimodal (FCM)\\n- F sc...</td>\n",
       "      <td>Table TABREF31 shows the F-score, the Area Und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>What were their performance results?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>On SearchSnippets dataset ACC 77.01%, NMI 62.9...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Comparison of ACC of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>By how much did they outperform the other meth...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>on SearchSnippets dataset by 6.72% in ACC, by ...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Comparison of ACC of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>What is the state of the art?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>POS and DP task: CONLL 2018\\nNER task: (no ext...</td>\n",
       "      <td>We will compare to the more recent cross-lingu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>What difficulties does sentiment analysis on T...</td>\n",
       "      <td>The answer is:\\n\\nTwitter sentiment analysis f...</td>\n",
       "      <td>Tweets noisy nature, use of creative spelling ...</td>\n",
       "      <td>Pre-processing. Tweets are subject to standard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>How many sentence transformations on average a...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>27.41 transformation on average of single seed...</td>\n",
       "      <td>In the second round, we collected 293 annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>What annotations are available in the dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe answer is:\\n\\n*...</td>\n",
       "      <td>For each source sentence, transformation sente...</td>\n",
       "      <td>We asked for two distinct paraphrases of each ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>How are possible sentence transformations repr...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe possible senten...</td>\n",
       "      <td>Yes, as new sentences.</td>\n",
       "      <td>In the second round, we collected 293 annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>What are all 15 types of modifications ilustra...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>- paraphrase 1\\n- paraphrase 2\\n- different me...</td>\n",
       "      <td>We selected 15 modifications types to collect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>What were their results on the three datasets?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe authors achieve...</td>\n",
       "      <td>accuracy of 86.63 on STS, 85.14 on Sanders and...</td>\n",
       "      <td>FLOAT SELECTED: Table IV ACCURACY OF DIFFERENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>What semantic rules are proposed?</td>\n",
       "      <td>The proposed semantic rules are displayed in T...</td>\n",
       "      <td>rules that compute polarity of words after POS...</td>\n",
       "      <td>In Twitter social networking, people express t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>What is the performance of the model?</td>\n",
       "      <td>The model achieves a test accuracy of around 0...</td>\n",
       "      <td>Experiment 1: ACC around 0.5 with 50% noise ra...</td>\n",
       "      <td>The test accuracy curves with the noise rates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>What was the performance of both approaches on...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nBoth approaches ach...</td>\n",
       "      <td>ERR of 19.05 with i-vectors and 15.52 with x-v...</td>\n",
       "      <td>FLOAT SELECTED: Table 4. EER(%) results of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>What genres are covered?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nALL GENRES</td>\n",
       "      <td>genre, entertainment, interview, singing, play...</td>\n",
       "      <td>FLOAT SELECTED: Table 1. The distribution over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Which of the two speech recognition models wor...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe x-vector system...</td>\n",
       "      <td>x-vector</td>\n",
       "      <td>FLOAT SELECTED: Table 4. EER(%) results of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>By how much is performance on CN-Celeb inferio...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n12.3%\\n\\nBased on t...</td>\n",
       "      <td>For i-vector system, performances are 11.75% i...</td>\n",
       "      <td>FLOAT SELECTED: Table 4. EER(%) results of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>How do the authors measure performance?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe authors measure...</td>\n",
       "      <td>Accuracy across six datasets</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Accuracies of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>What is the latest paper covered by this survey?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n\"...</td>\n",
       "      <td>Kim et al. (2019)</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Existing NQG models w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>What learning paradigms do they cover in this ...</td>\n",
       "      <td>Both traditional and neural learning paradigms...</td>\n",
       "      <td>Considering \"What\" and \"How\" separately versus...</td>\n",
       "      <td>Past research took a reductionist approach, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>What are all the input modalities considered i...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nt...</td>\n",
       "      <td>Textual inputs, knowledge bases, and images.</td>\n",
       "      <td>Question generation is an NLG task for which t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>How do this framework facilitate demographic i...</td>\n",
       "      <td>This framework facilitates demographic inferen...</td>\n",
       "      <td>Demographic information is predicted using wei...</td>\n",
       "      <td>We employ BIBREF73 's weighted lexicon of term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>How is the data annotated?</td>\n",
       "      <td>The data is annotated with depression symptoms...</td>\n",
       "      <td>The data are self-reported by Twitter users an...</td>\n",
       "      <td>Self-disclosure clues have been extensively ut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Where does the information on individual-level...</td>\n",
       "      <td>The information on individual-level demographi...</td>\n",
       "      <td>From Twitter profile descriptions of the users.</td>\n",
       "      <td>Age Enabled Ground-truth Dataset: We extract u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>What is the source of the user interaction data?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Sociability from ego-network on Twitter</td>\n",
       "      <td>The recent advancements in deep neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>What is the source of the textual data?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Users' tweets</td>\n",
       "      <td>The recent advancements in deep neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>What is the source of the visual data?</td>\n",
       "      <td>The visual data is from posted images</td>\n",
       "      <td>Profile pictures from the Twitter users' profi...</td>\n",
       "      <td>The recent advancements in deep neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>What result from experiments suggest that natu...</td>\n",
       "      <td>The NLP representation outperforms other metho...</td>\n",
       "      <td>Average reward across 5 seeds show that NLP re...</td>\n",
       "      <td>Results of the DQN-based agent are presented i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Which datasets are used in the paper?</td>\n",
       "      <td>The answer is:\\n\\n* BIBREF27: Moral Foundation...</td>\n",
       "      <td>Google N-grams\\nCOHA\\nMoral Foundations Dictio...</td>\n",
       "      <td>To ground moral sentiment in text, we leverage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>How do they quantify moral relevance?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>By complementing morally relevant seed words w...</td>\n",
       "      <td>To implement the first tier of our framework a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>How much is proposed model better in perplexit...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Perplexity of the best model is 65.58 compared...</td>\n",
       "      <td>As illustrated in Table TABREF12 (ID 1). Given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Do they train a different training method exce...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (list missing) \\n...</td>\n",
       "      <td>Since the official test set has not been relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>How do they define upward and downward reasoning?</td>\n",
       "      <td>The answer is:\\n\\nUpward reasoning is defined ...</td>\n",
       "      <td>Upward reasoning is defined as going from one ...</td>\n",
       "      <td>A context is upward entailing (shown by [... $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Do they annotate their own dataset or use an e...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Use an existing one</td>\n",
       "      <td>For our experiments, we select a dataset whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>What kind of neural network architecture do th...</td>\n",
       "      <td>A Siamese Neural Network Architecture with two...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>We adopt the approach in BIBREF4 , modifying i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>What web and user-generated NER datasets are u...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nW...</td>\n",
       "      <td>MUC, CoNLL, ACE, OntoNotes, MSM, Ritter, UMBC</td>\n",
       "      <td>Since the goal of this study is to compare NER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Which unlabeled data do they pretrain with?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nW...</td>\n",
       "      <td>1000 hours of WSJ audio data</td>\n",
       "      <td>We consider pre-training on the audio data (wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>How many convolutional layers does their model...</td>\n",
       "      <td>Sure! Based on the context you provided, the a...</td>\n",
       "      <td>wav2vec has 12 convolutional layers</td>\n",
       "      <td>Given raw audio samples INLINEFORM0 , we apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>How big are the datasets?</td>\n",
       "      <td>The in-house dataset has 15,250 documents, whi...</td>\n",
       "      <td>In-house dataset consists of  3716 documents \\...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Number of documents i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>What baselines did they compare their model with?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>the baseline where path generation uses a stan...</td>\n",
       "      <td>The baseline approach is based on BIBREF20 . I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>What was the performance of their model?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nTheir model achieve...</td>\n",
       "      <td>For test-repeated set, EM score of 61.17, F1 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>What evaluation metrics are used?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>exact match, f1 score, edit distance and goal ...</td>\n",
       "      <td>We compare the performance of translation appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>How were the navigation instructions collected?</td>\n",
       "      <td>The navigation instructions were collected thr...</td>\n",
       "      <td>using Amazon Mechanical Turk using simulated e...</td>\n",
       "      <td>This work also contributes a new dataset of IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>What language is the experiment done in?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>english language</td>\n",
       "      <td>While the dataset was collected with simulated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>What additional features are proposed for futu...</td>\n",
       "      <td>The answer is:\\n\\n* Clinical sentiment analysi...</td>\n",
       "      <td>distinguishing between clinically positive and...</td>\n",
       "      <td>Our current feature set for training a machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>What are their initial results on this task?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe initial results...</td>\n",
       "      <td>Achieved the highest per-domain scores on Subs...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Overall and domain-sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>How is morphology knowledge implemented in the...</td>\n",
       "      <td>By using a morphologically motivated segmentat...</td>\n",
       "      <td>A BPE model is applied to the stem after morph...</td>\n",
       "      <td>The problem with morpheme segmentation is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>How is the performance on the task evaluated?</td>\n",
       "      <td>The performance on the task is evaluated based...</td>\n",
       "      <td>Comparison of test accuracies of neural networ...</td>\n",
       "      <td>Neural network models, and specifically sequen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>what datasets were used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nIWSLT14 German-Engl...</td>\n",
       "      <td>IWSLT14 German-English, IWSLT14 Turkish-Englis...</td>\n",
       "      <td>We use three datasets for our experiments: IWS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>How do they obtain human judgements?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nC...</td>\n",
       "      <td>Using crowdsourcing</td>\n",
       "      <td>As the book is too small to train any models, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Does this approach perform better in the multi...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>single-domain setting</td>\n",
       "      <td>FLOAT SELECTED: Table 3: The joint goal accura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>How many samples did they generate for the art...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n3...</td>\n",
       "      <td>70,000</td>\n",
       "      <td>In a new experiment, we train the models on pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Why does not the approach from English work on...</td>\n",
       "      <td>Because other languages, like Spanish, have gr...</td>\n",
       "      <td>Because, unlike other languages, English does ...</td>\n",
       "      <td>To date, the NLP community has focused primari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>How do they measure grammaticality?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThey measure gramma...</td>\n",
       "      <td>by calculating log ratio of grammatical phrase...</td>\n",
       "      <td>Because our approach is specifically intended ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>What is the difference in recall score between...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe system using Wi...</td>\n",
       "      <td>Between the model and Stanford, Spacy and Flai...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Comparison with Tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>What is their f1 score and recall?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>F1 score and Recall are 68.66, 80.08 with Trad...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Comparison with Tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>How many layers does their system have?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n3 layers</td>\n",
       "      <td>4 layers</td>\n",
       "      <td>FLOAT SELECTED: Figure 1. BERT + Bi-GRU + CRF,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>What context modelling methods are evaluated?</td>\n",
       "      <td>13 different context modeling methods are eval...</td>\n",
       "      <td>Concat\\nTurn\\nGate\\nAction Copy\\nTree Copy\\nSQ...</td>\n",
       "      <td>To conduct a thorough comparison, we evaluate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Is the baseline a non-heirarchical model like ...</td>\n",
       "      <td>No. The baseline is a hierarchical transformer...</td>\n",
       "      <td>There were hierarchical and non-hierarchical b...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results of various mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>How better are results compared to baseline mo...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>F1 score of best authors' model is 55.98 compa...</td>\n",
       "      <td>We see that parent quality is a simple yet eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>How big is dataset used for training/testing?</td>\n",
       "      <td>The dataset used for training/testing consists...</td>\n",
       "      <td>4,261  days for France and 4,748 for the UK</td>\n",
       "      <td>Our work aims at predicting time series using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>What geometric properties do embeddings display?</td>\n",
       "      <td>The embeddings display clustering properties, ...</td>\n",
       "      <td>Winter and summer words formed two separate cl...</td>\n",
       "      <td>The initial analyses of the embedding matrices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>How accurate is model trained on text exclusiv...</td>\n",
       "      <td>The model trained on text exclusively achieves...</td>\n",
       "      <td>Relative error is less than 5%</td>\n",
       "      <td>The main contribution of our paper is to sugge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>What was their result on Stance Sentiment Emot...</td>\n",
       "      <td>The proposed system outperformed the state-of-...</td>\n",
       "      <td>F1 score of 66.66%</td>\n",
       "      <td>FLOAT SELECTED: TABLE II F-SCORE OF VARIOUS MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>What performance did they obtain on the SemEva...</td>\n",
       "      <td>The proposed system obtained an F1-score of 85...</td>\n",
       "      <td>F1 score of 82.10%</td>\n",
       "      <td>We implement our model in Python using Tensorf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>What are the state-of-the-art systems?</td>\n",
       "      <td>The answer is:\\n\\nThe state-of-the-art systems...</td>\n",
       "      <td>For sentiment analysis UWB, INF-UFRGS-OPINION-...</td>\n",
       "      <td>FLOAT SELECTED: TABLE III COMPARISON WITH THE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>What is the size of their collected dataset?</td>\n",
       "      <td>3347 utterances</td>\n",
       "      <td>3347 unique utterances</td>\n",
       "      <td>Our AV in-cabin data-set includes 30 hours of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>What kind of features are used by the HMM mode...</td>\n",
       "      <td>The HMM models in the hybrid approach use feat...</td>\n",
       "      <td>A continuous emission HMM uses the hidden stat...</td>\n",
       "      <td>We compare a hybrid HMM-LSTM approach with a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>What kind of information do the HMMs learn tha...</td>\n",
       "      <td>The HMMs learn information related to spaces a...</td>\n",
       "      <td>The HMM can identify punctuation or pick up on...</td>\n",
       "      <td>We interpret the HMM and LSTM states in the hy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>How large is the gap in performance between th...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe gap in performa...</td>\n",
       "      <td>With similar number of parameters, the log lik...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Predictive loglikelih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>what was their system's f1 performance?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n1...</td>\n",
       "      <td>Proposed model achieves 0.86, 0.924, 0.71 F1 s...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: F1 Results3 The appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>How much more coverage is in the new dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>278 more annotations</td>\n",
       "      <td>The measured precision with respect to PropBan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>How was quality measured?</td>\n",
       "      <td>Quality was measured using F1 score with 5 gen...</td>\n",
       "      <td>Inter-annotator agreement, comparison against ...</td>\n",
       "      <td>Dataset Quality Analysis ::: Inter-Annotator A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>What is different in the improved annotation p...</td>\n",
       "      <td>The improved annotation protocol uses trained ...</td>\n",
       "      <td>a trained worker consolidates existing annotat...</td>\n",
       "      <td>We adopt the annotation machinery of BIBREF5 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>What data were they used to train the multilin...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>WMT 2014 En-Fr parallel corpus</td>\n",
       "      <td>For the MT task, we use the WMT 2014 En $\\left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>From when are many VQA datasets collected?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nL...</td>\n",
       "      <td>late 2014</td>\n",
       "      <td>VQA research began in earnest in late 2014 whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>What is task success rate achieved?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n9...</td>\n",
       "      <td>96-97.6% using the objects color or shape and ...</td>\n",
       "      <td>To test our model, we generated 500 new scenar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Does proposed end-to-end approach learn in rei...</td>\n",
       "      <td>Supervised learning</td>\n",
       "      <td>supervised learning</td>\n",
       "      <td>To train our model, we generated a dataset of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>How is performance of this system measured?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>using the BLEU score as a quantitative metric ...</td>\n",
       "      <td>We use the BLEU BIBREF30 metric on the validat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>How big dataset is used for training this system?</td>\n",
       "      <td>The system is trained on a dataset of 15,000 i...</td>\n",
       "      <td>For the question generation model 15,000 image...</td>\n",
       "      <td>We use MS COCO, Bing and Flickr datasets from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>How do they obtain word lattices from words?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>By considering words as vertices and generatin...</td>\n",
       "      <td>Word Lattice As shown in Figure FIGREF4 , a wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>How better is proposed method than baselines p...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Perplexity of proposed MEED model is 19.795 vs...</td>\n",
       "      <td>Table TABREF34 gives the perplexity scores obt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Who manually annotated the semantic roles for ...</td>\n",
       "      <td>The authors of the paper manually annotated th...</td>\n",
       "      <td>Authors</td>\n",
       "      <td>In this paper, we manually annotate the predic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>How do they obtain region descriptions and obj...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>they are available in the Visual Genome dataset</td>\n",
       "      <td>In this work, we introduce a methodology that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Which training dataset allowed for the best ge...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>MultiNLI</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Test accuracies (%). ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Which models were compared?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and ...</td>\n",
       "      <td>For sentence encoding models, we chose a simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>What is private dashboard?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Private dashboard is leaderboard where competi...</td>\n",
       "      <td>For each model having the best fit on the dev ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>What is public dashboard?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Public dashboard where competitors can see the...</td>\n",
       "      <td>For each model having the best fit on the dev ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>What dataset do they use?</td>\n",
       "      <td>VLSP 2016 Sentiment Analysis, VLSP 2018 Sentim...</td>\n",
       "      <td>They used Wiki Vietnamese language and Vietnam...</td>\n",
       "      <td>The fundamental idea of this system is how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Do the use word embeddings alone or they repla...</td>\n",
       "      <td>The use of word embeddings in the proposed mod...</td>\n",
       "      <td>They use it as addition to previous model - th...</td>\n",
       "      <td>While the co-occurrence representation yields ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>How many natural language explanations are hum...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n1...</td>\n",
       "      <td>Totally 6980 validation and test image-sentenc...</td>\n",
       "      <td>e-SNLI-VE-2.0 is the combination of SNLI-VE-2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>What is the dataset used as input to the Word2...</td>\n",
       "      <td>The dataset used as input to the Word2Vec algo...</td>\n",
       "      <td>Italian Wikipedia and Google News extraction p...</td>\n",
       "      <td>The dataset needed to train the W2V was obtain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>What methodology is used to compensate for lim...</td>\n",
       "      <td>Use of influential tweeters to label tweets in...</td>\n",
       "      <td>Influential tweeters ( who they define as indi...</td>\n",
       "      <td>The first data batch consists of tweets releva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>What are the baseline state of the art models?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe baseline state ...</td>\n",
       "      <td>Stanford NER, BiLSTM+CRF, LSTM+CNN+CRF, T-NER ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Evaluation results of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>How do they extract causality from text?</td>\n",
       "      <td>They extract causality from text by selecting ...</td>\n",
       "      <td>They identify documents that contain the unigr...</td>\n",
       "      <td>Causal documents were chosen to contain one oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>What is the source of the \"control\" corpus?</td>\n",
       "      <td>Temporally matched Twitter posts that do not c...</td>\n",
       "      <td>Randomly selected from a Twitter dump, tempora...</td>\n",
       "      <td>Data was collected from a 10% uniform sample o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>What are the selection criteria for \"causal st...</td>\n",
       "      <td>The answer is:\\n\\nThe selection criteria for \"...</td>\n",
       "      <td>Presence of only the exact unigrams 'caused', ...</td>\n",
       "      <td>Causal documents were chosen to contain one oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Do they use expert annotations, crowdsourcing,...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Only automatic methods</td>\n",
       "      <td>The rest of this paper is organized as follows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>how do they collect the comparable corpus?</td>\n",
       "      <td>They collected the comparable corpus by select...</td>\n",
       "      <td>Randomly from a Twitter dump</td>\n",
       "      <td>Data was collected from a 10% uniform sample o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>How do they collect the control corpus?</td>\n",
       "      <td>Control documents were selected randomly</td>\n",
       "      <td>Randomly from Twitter</td>\n",
       "      <td>Data was collected from a 10% uniform sample o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>What are resolution model variables?</td>\n",
       "      <td>Resolution model variables are $\\Pi = \\lbrace ...</td>\n",
       "      <td>Variables in the set {str, prec, attr} indicat...</td>\n",
       "      <td>According to previous work BIBREF17 , BIBREF18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Is the model presented in the paper state of t...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>No, supervised models perform better for this ...</td>\n",
       "      <td>To make a thorough empirical comparison with p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>What was the result of the highest performing ...</td>\n",
       "      <td>The highest performing system in Task 1 was \"S...</td>\n",
       "      <td>For task 1 best F1 score was 0.9391 on closed ...</td>\n",
       "      <td>There are 74 participants who are signing up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>What do they mean by answer styles?</td>\n",
       "      <td>The answer styles refer to the two types of an...</td>\n",
       "      <td>well-formed sentences vs concise answers</td>\n",
       "      <td>We conducted experiments on the two tasks of M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>What are the baselines that Masque is compared...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Mult...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Performance of our an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>What is the performance achieved on NarrativeQA?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, R...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Performance of our an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>What is an \"answer style\"?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>well-formed sentences vs concise answers</td>\n",
       "      <td>We conducted experiments on the two tasks of M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>How are the EAU text spans annotated?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Data and pre-pro...</td>\n",
       "      <td>Tree-based sentiment annotations are sentiment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Which Twitter corpus was used to train the wor...</td>\n",
       "      <td>The Twitter corpus used to train the word vect...</td>\n",
       "      <td>They collected tweets in Russian language usin...</td>\n",
       "      <td>Twitter provides well-documented API, which al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>How does proposed word embeddings compare to S...</td>\n",
       "      <td>Proposed word embeddings outperform Sindhi fas...</td>\n",
       "      <td>Proposed SG model vs SINDHI FASTTEXT:\\nAverage...</td>\n",
       "      <td>Generally, closer words are considered more im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>How many uniue words are in the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n2...</td>\n",
       "      <td>908456 unique words are available in collected...</td>\n",
       "      <td>The large corpus acquired from multiple resour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Which baseline methods are used?</td>\n",
       "      <td>The baseline methods used are the standard par...</td>\n",
       "      <td>standard parametrized attention and a non-atte...</td>\n",
       "      <td>Table 1 shows the BLEU scores of our model on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>How much is the BLEU score?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n27.4</td>\n",
       "      <td>Ranges from 44.22 to 100.00 depending on K and...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: BLEU scores and compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Which datasets are used in experiments?</td>\n",
       "      <td>The datasets used in experiments are the Seque...</td>\n",
       "      <td>Sequence Copy Task and WMT'17</td>\n",
       "      <td>Due to the reduction of computational time com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>What are new best results on standard benchmark?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>New best results of accuracy (P@1) on Vecmap:\\...</td>\n",
       "      <td>Table TABREF15 shows the final results on Vecm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>How better is performance compared to competit...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Proposed method vs best baseline result on Vec...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Accuracy (P@1) on Vec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>What 6 language pairs is experimented on?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>EN&lt;-&gt;ES\\nEN&lt;-&gt;DE\\nEN&lt;-&gt;IT\\nEN&lt;-&gt;EO\\nEN&lt;-&gt;MS\\nE...</td>\n",
       "      <td>Table TABREF13 shows the inconsistency rates o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>How do they enrich the positional embedding wi...</td>\n",
       "      <td>They enrich the positional embedding with leng...</td>\n",
       "      <td>They introduce new trigonometric encoding whic...</td>\n",
       "      <td>Methods ::: Length Encoding Method Inspired by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>How do they condition the output to a given ta...</td>\n",
       "      <td>They condition the output to a given target-so...</td>\n",
       "      <td>They use three groups short/normal/long transl...</td>\n",
       "      <td>Methods ::: Length Token Method Our first appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Is this library implemented into Torch or is f...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>It uses deep learning framework (pytorch)</td>\n",
       "      <td>With this challenge in mind, we introduce Torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>How does this compare to traditional calibrati...</td>\n",
       "      <td>This method differs from traditional calibrati...</td>\n",
       "      <td>No reliability diagrams are provided and no ex...</td>\n",
       "      <td>Compared to using external models for confiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>What's the input representation of OpenIE tupl...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>word embeddings</td>\n",
       "      <td>Our training method in sec:ours could potentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Is CRWIZ already used for data collection, wha...</td>\n",
       "      <td>CRWIZ has been used for data collection, and t...</td>\n",
       "      <td>Yes, CRWIZ has been used for data collection a...</td>\n",
       "      <td>For the intitial data collection using the CRW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>What contextual features are used?</td>\n",
       "      <td>download, malware, malicious</td>\n",
       "      <td>The words that can indicate the characteristic...</td>\n",
       "      <td>IOCs in cybersecurity articles are often descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>How is the data in RAFAEL labelled?</td>\n",
       "      <td>The data in RAFAEL is labelled with morphosynt...</td>\n",
       "      <td>Using a set of annotation tools such as Morfeu...</td>\n",
       "      <td>Secondly, texts go through a cascade of annota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>How is the fluctuation in the sense of the wor...</td>\n",
       "      <td>Surrounding Uniformity (SU) measures the fluct...</td>\n",
       "      <td>Our method performs a statistical test to dete...</td>\n",
       "      <td>Distributed representation of word sense provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>By how much does SPNet outperforms state-of-th...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>SPNet vs best baseline:\\nROUGE-1: 90.97 vs 90....</td>\n",
       "      <td>We show all the models' results in Table TABRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Is it expected to have speaker role, semantic ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Not at the moment, but summaries can be additi...</td>\n",
       "      <td>Moreover, we can easily extend SPNet to other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>How does new evaluation metric considers criti...</td>\n",
       "      <td>CIC considers critical informative entities by...</td>\n",
       "      <td>Answer with content missing: (formula for CIC)...</td>\n",
       "      <td>In this case, the summary has a high ROUGE sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>What are state of the art methods MMM is compa...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nState-of-the-art me...</td>\n",
       "      <td>FTLM++, BERT-large, XLNet</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Accuracy on the DREAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>What are the problems related to ambiguity in ...</td>\n",
       "      <td>Ambiguity in PICO sentence prediction tasks ca...</td>\n",
       "      <td>Some sentences are associated to ambiguous dim...</td>\n",
       "      <td>Sentences 1 and 2 are labelled incorrectly, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>How is knowledge stored in the memory?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>entity memory and relational memory.</td>\n",
       "      <td>There are three main components to the model: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>How do they measure the diversity of inferences?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>by number of distinct n-grams</td>\n",
       "      <td>We first compare the perplexity of CWVAE with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>By how much do they improve the accuracy of in...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>ON Event2Mind, the accuracy of proposed method...</td>\n",
       "      <td>We first compare the perplexity of CWVAE with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>How does the context-aware variational autoenc...</td>\n",
       "      <td>By learning a context-aware latent variable in...</td>\n",
       "      <td>CWVAE is trained on an auxiliary dataset to l...</td>\n",
       "      <td>In addition to the traditional VAE structure, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>How much improvement does their method get ove...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n2.3 BLEU-4 points</td>\n",
       "      <td>0.08 points on the 2011 test set, 0.44 points ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Domain adaptation res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>By how much do they outpeform previous results...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Their best average precision tops previous bes...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Final test set result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>How many paraphrases are generated per question?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n1...</td>\n",
       "      <td>10*n paraphrases, where n depends on the numbe...</td>\n",
       "      <td>For WebQuestions, we use 8 handcrafted part-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>How strong was the correlation between exercis...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>weak correlation with p-value of 0.08</td>\n",
       "      <td>The main DDEO topics showed some level of inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>How were topics of interest about DDEO identif...</td>\n",
       "      <td>Topics of interest about DDEO were identified ...</td>\n",
       "      <td>using topic modeling model Latent Dirichlet Al...</td>\n",
       "      <td>To discover topics from the collected tweets, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>How do their train their embeddings?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The embeddings are learned several times using...</td>\n",
       "      <td>For each variable in encoding set, learn the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>How do they model travel behavior?</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>The data from collected travel surveys is used...</td>\n",
       "      <td>Differently to textual data, our goal in this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>How do their interpret the coefficients?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe coefficients fr...</td>\n",
       "      <td>The coefficients are projected back to the dum...</td>\n",
       "      <td>We will apply the methodology to the well-know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>By how much do they outperform previous state-...</td>\n",
       "      <td>The answer is:\\n\\nORNN outperforms previous st...</td>\n",
       "      <td>Proposed ORNN has 0.769, 1.238, 0.818, 0.772 c...</td>\n",
       "      <td>All models are trained and evaluated using the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>What is the performance difference between pro...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Difference is around 1 BLEU score lower on ave...</td>\n",
       "      <td>Table TABREF40 illustrates the BLEU scores of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>What benchmarks are created?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (formula) The acc...</td>\n",
       "      <td>In HotpotQA, on average we can find 6 candidat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>What percentage fewer errors did professional ...</td>\n",
       "      <td>Professional translations made 35% fewer error...</td>\n",
       "      <td>36%</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Classification of err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>What was the weakness in Hassan et al's evalua...</td>\n",
       "      <td>The weakness in Hassan et al.'s evaluation des...</td>\n",
       "      <td>MT developers to which crowd workers were comp...</td>\n",
       "      <td>The human evaluation of MT output in research ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>What evidence do they present that the model a...</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>Using model gradients with respect to input fe...</td>\n",
       "      <td>One way to analyze the model is to compute mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>In what way is the input restructured?</td>\n",
       "      <td>The input is restructured to begin with a [STA...</td>\n",
       "      <td>In four entity-centric ways - entity-first, en...</td>\n",
       "      <td>Our approach consists of structuring input to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>What language is the Twitter content in?</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>In this work, we analyze a set of tweets relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>What evaluations did the authors use on their ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>BLEU scores, exact matches of words in both tr...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Experiment results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>What accuracy does CNN model achieve?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n0.75</td>\n",
       "      <td>Combined per-pixel accuracy for character line...</td>\n",
       "      <td>FLOAT SELECTED: TABLE IV: Class-wise average I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>How many documents are in the Indiscapes dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n100 documents</td>\n",
       "      <td>508</td>\n",
       "      <td>FLOAT SELECTED: TABLE III: Scripts in the INDI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>What are simulated datasets collected?</td>\n",
       "      <td>Simulated datasets of document revisions</td>\n",
       "      <td>There are 6 simulated datasets collected which...</td>\n",
       "      <td>The generation process of the simulated data s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>What human evaluation metrics were used in the...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nF...</td>\n",
       "      <td>rating questions on a scale of 1-5 based on fl...</td>\n",
       "      <td>For the human evaluation, we follow the standa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>For the purposes of this paper, how is somethi...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>reviews under distinct product categories are ...</td>\n",
       "      <td>Amazon Reviews Dataset BIBREF24 is a large dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>What type of model are the ELMo representation...</td>\n",
       "      <td>Bidirectional Long Short-Term Memory (BiLSTM) ...</td>\n",
       "      <td>A bi-LSTM with max-pooling on top of it</td>\n",
       "      <td>The usage of a purely character-based input wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>By how much does using phonetic feedback impro...</td>\n",
       "      <td>Using phonetic feedback improves state-of-the-...</td>\n",
       "      <td>Improved AECNN-T by 2.1 and AECNN-T-SM BY 0.9</td>\n",
       "      <td>In addition to the setting without any paralle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>what are the baselines?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>AS Reader, GA Reader, CAS Reader</td>\n",
       "      <td>Table TABREF17 shows our results on CMRC-2017 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>What are the results of the experiment?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>They were able to create a language model from...</td>\n",
       "      <td>The BD-4SK-ASR Dataset ::: The Language Model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>How was the dataset collected?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe dataset was col...</td>\n",
       "      <td>extracted text from Sorani Kurdish books of pr...</td>\n",
       "      <td>To develop the dataset, we extracted 200 sente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>How many annotators participated?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n1</td>\n",
       "      <td>1</td>\n",
       "      <td>Two thousand narration files were created. We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>How do they show their model discovers underly...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>By visualizing syntactic distance estimated by...</td>\n",
       "      <td>In Figure FIGREF32 , we visualize the syntacti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>How do they measure performance of language mo...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>BPC, Perplexity</td>\n",
       "      <td>In Table TABREF39 , our results are comparable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>How are content clusters used to improve the p...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>they are used as additional features in a supe...</td>\n",
       "      <td>As a further application of our work, we have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>What cluster identification method is used in ...</td>\n",
       "      <td>Markov Stability (MS) clustering</td>\n",
       "      <td>A combination of Minimum spanning trees, K-Nea...</td>\n",
       "      <td>The trained Doc2Vec model is subsequently used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Why did they think this was a good idea?</td>\n",
       "      <td>To leverage the knowledge and experience of TC...</td>\n",
       "      <td>They think it will help human TCM practitioner...</td>\n",
       "      <td>During the long history of TCM, there has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>What QA models were used?</td>\n",
       "      <td>The QA models used are GloVe BIBREF40, CharCNN...</td>\n",
       "      <td>A pointer network decodes the answer from a bi...</td>\n",
       "      <td>The input of our model are the words in the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>How do their results compare against other com...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>They achieved best result in the PAN 2017 shar...</td>\n",
       "      <td>FLOAT SELECTED: Table 8. Results (accuracy) on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>On which task does do model do worst?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe gender task</td>\n",
       "      <td>Gender prediction task</td>\n",
       "      <td>N-GrAM ranked first in all cases except for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>On which task does do model do best?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe joint task</td>\n",
       "      <td>Variety prediction task</td>\n",
       "      <td>N-GrAM ranked first in all cases except for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>How does counterfactual data augmentation aim ...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>The training dataset is augmented by swapping ...</td>\n",
       "      <td>One of the solutions that has been proposed fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>In the targeted data collection approach, what...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nReferring nouns or ...</td>\n",
       "      <td>Gendered characters in the dataset</td>\n",
       "      <td>There are a larger number of male-gendered cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>How do they determine which words are informat...</td>\n",
       "      <td>They determine which words are informative bas...</td>\n",
       "      <td>Informative are those that will not be suppres...</td>\n",
       "      <td>Data dependent regularization. As explained in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>What improvement does the MOE model make over ...</td>\n",
       "      <td>The MOE model achieves a lower test perplexity...</td>\n",
       "      <td>Perpexity is improved from 34.7 to 28.0.</td>\n",
       "      <td>The two models achieved test perplexity of INL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>What is the difference in performance between ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Accuracy of best interpretible system was 0.39...</td>\n",
       "      <td>The experimental results are presented in Tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Which language-pair had the better performance?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe English-French ...</td>\n",
       "      <td>French-English</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Results obtained for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Which psycholinguistic and basic linguistic fe...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Emotion Sensor Feature, Part of Speech, Punctu...</td>\n",
       "      <td>Exploiting psycho-linguistic features with bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>How have the differences in communication styl...</td>\n",
       "      <td>The differences in communication styles betwee...</td>\n",
       "      <td>Systems do not perform well both in Facebook a...</td>\n",
       "      <td>Most of the above-discussed systems either sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>What data/studies do the authors provide to su...</td>\n",
       "      <td>The authors do not provide any specific data o...</td>\n",
       "      <td>None</td>\n",
       "      <td>The informal setting/environment of social med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>What datasets are used to evaluate the model?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nW...</td>\n",
       "      <td>WN18, FB15k</td>\n",
       "      <td>As we show below, STransE performs better than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>What baseline models do they compare against?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nAgainst a set of st...</td>\n",
       "      <td>SLQA, Rusalka, HMA Model (single), TriAN (sing...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Experimental Results ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>What are the differences with previous applica...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>This approach considers related images</td>\n",
       "      <td>One common point in all the approaches yet has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>How much improvement is gained from the propos...</td>\n",
       "      <td>The proposed approaches result in a non-termin...</td>\n",
       "      <td>It eliminates non-termination in some models f...</td>\n",
       "      <td>Table TABREF44 shows that consistent nucleus a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Is infinite-length sequence generation a resul...</td>\n",
       "      <td>No</td>\n",
       "      <td>There are is a strong conjecture that it might...</td>\n",
       "      <td>We extended the notion of consistency of a rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>How big is dataset for this challenge?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n123,287 images</td>\n",
       "      <td>133,287 images</td>\n",
       "      <td>We use the VisDial v1.0 BIBREF0 dataset to tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>How better is performance of proposed model co...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe proposed model ...</td>\n",
       "      <td>Proposed model achive 66+-22 win rate, baselin...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Final win rate on sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>What DCGs are used?</td>\n",
       "      <td>DCGs used are Lexicon and 1st/3rd step convers...</td>\n",
       "      <td>Author's own DCG rules are defined from scratch.</td>\n",
       "      <td>convertible.pl: implementing DCG rules for 1st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>What is the performance difference of using a ...</td>\n",
       "      <td>Using a generated summary vs. a user-written o...</td>\n",
       "      <td>2.7 accuracy points</td>\n",
       "      <td>Table TABREF34 and Table TABREF35 show the fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>What evaluation metrics did they look at?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThey looked at norm...</td>\n",
       "      <td>accuracy with standard deviation</td>\n",
       "      <td>Los resultados de la evaluación se presentan e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>What are the datasets used for the task?</td>\n",
       "      <td>CELEX, IIT-Guwahat, and Festival datasets</td>\n",
       "      <td>Datasets used are Celex (English, Dutch), Fest...</td>\n",
       "      <td>FLOAT SELECTED: TABLE I DATASETS AND LANGUAGES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>What is the accuracy of the model for the six ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Authors report their best models have followin...</td>\n",
       "      <td>We tested three model versions against all dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Which models achieve state-of-the-art performa...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>CELEX (Dutch and English) - SVM-HMM\\nFestival,...</td>\n",
       "      <td>FLOAT SELECTED: TABLE II REPORTED ACCURACIES O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Which competitive relational classification mo...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>For relation prediction they test TransE and f...</td>\n",
       "      <td>In this section, we consider two kinds of rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>How do they gather human judgements for simila...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>By assessing similarity of 360 pairs of relati...</td>\n",
       "      <td>Human Judgments Following BIBREF11 , BIBREF12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>What text classification task is considered?</td>\n",
       "      <td>Text classification task is considered as clas...</td>\n",
       "      <td>To classify a text as belonging to one of the ...</td>\n",
       "      <td>We trained word embeddings and a uni-direction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>What novel class of recurrent-like networks is...</td>\n",
       "      <td>Recurrent-like neural networks with nested int...</td>\n",
       "      <td>A network, whose learned functions satisfy a c...</td>\n",
       "      <td>First, we propose a class of recurrent-like ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>How much bigger is Switchboard-2000 than Switc...</td>\n",
       "      <td>Switchboard-2000 is approximately 6 times bigg...</td>\n",
       "      <td>Switchboard-2000 contains 1700 more hours of s...</td>\n",
       "      <td>This study focuses on Switchboard-300, a stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>What domains are detected in this paper?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nNeural activity in ...</td>\n",
       "      <td>Answer with content missing: (Experimental set...</td>\n",
       "      <td>Experimental Setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Why do they think this task is hard?  What is ...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe task is hard be...</td>\n",
       "      <td>1. there may be situations where more than one...</td>\n",
       "      <td>Although not done in this work, an alternative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>How do they generate the synthetic dataset?</td>\n",
       "      <td>They generate the synthetic dataset by samplin...</td>\n",
       "      <td>using generative process</td>\n",
       "      <td>We performed experiments on synthetically gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>What is the average length of the claims?</td>\n",
       "      <td>The average length of the claims is INLINEFORM2</td>\n",
       "      <td>Average claim length is 8.9 tokens.</td>\n",
       "      <td>FLOAT SELECTED: Table 2: A summary of PERSPECT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>What debate topics are included in the dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nPolitics, World, So...</td>\n",
       "      <td>Ethics, Gender, Human rights, Sports, Freedom ...</td>\n",
       "      <td>FLOAT SELECTED: Figure 3: Distribution of clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>By how much, the proposed method improves BiDA...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n2.3% and 1.7% impro...</td>\n",
       "      <td>In terms of F1 score, the Hybrid approach impr...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Effect of Character E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>What are the linguistic differences between ea...</td>\n",
       "      <td>The linguistic differences between each class ...</td>\n",
       "      <td>Each class has different patterns in adjective...</td>\n",
       "      <td>Generic Sarcasm. We first examine the differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>what genres do they songs fall under?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe songs fall unde...</td>\n",
       "      <td>Gospel, Sertanejo, MPB, Forró, Pagode, Rock, S...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The number of songs a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>To what other competitive baselines is this ap...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nV...</td>\n",
       "      <td>LSTMs with and without attention, HRED, VHRED ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Automatic Evaluation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>How is human evaluation performed, what was th...</td>\n",
       "      <td>Human evaluation was performed using pairwise ...</td>\n",
       "      <td>Through Amazon MTurk annotators to determine p...</td>\n",
       "      <td>We thus also conducted human studies on Amazon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>How much better were results of the proposed m...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>on diversity 6.87 and on relevance 4.6 points ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Automatic Evaluation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Which one of the four proposed models performe...</td>\n",
       "      <td>LFT</td>\n",
       "      <td>the hybrid model MinAvgOut + RL</td>\n",
       "      <td>We employ several complementary metrics to cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>How much is proposed model better than baselin...</td>\n",
       "      <td>The proposed model (GDP) is significantly bett...</td>\n",
       "      <td>most of the models have similar performance on...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: The performance of ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>By how much is precission increased?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nPrecision increased...</td>\n",
       "      <td>ROUGE-1 increases by 0.05, ROUGE-2 by 0.06 and...</td>\n",
       "      <td>FLOAT SELECTED: Figure 3: ROUGE Quality of pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>What labels are in the dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nSTRESS, ANXIETY, SO...</td>\n",
       "      <td>binary label of stress or not stress</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: An example of stress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>How are customer satisfaction, customer frustr...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>By annotators on Amazon Mechanical Turk.</td>\n",
       "      <td>Using these filters as pre-processing methods,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>How many improvements on the French-German tra...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n3...</td>\n",
       "      <td>one</td>\n",
       "      <td>While the mixing strategy compensates for most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>How do they prevent the model complexity incre...</td>\n",
       "      <td>By using a state tracking model independent of...</td>\n",
       "      <td>They exclude slot-specific parameters and inco...</td>\n",
       "      <td>To solve this problem, we need a state trackin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>How do they measure model size?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThey measure model ...</td>\n",
       "      <td>By the number of parameters.</td>\n",
       "      <td>Furthermore, as SIM has no slot-specific neura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Which model architecture do they for sentence ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Skip-thought vec...</td>\n",
       "      <td>We select the following training objectives to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Which data sources do they use?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nTable 1</td>\n",
       "      <td>- En-Fr (WMT14)\\n- En-De (WMT15)\\n- Skipthough...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: An approximate number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>How were breast cancer related posts compiled ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>By using  keywords `breast' AND `cancer' in tw...</td>\n",
       "      <td>We collected tweets from two distinct Spritzer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>What machine learning and NLP methods were use...</td>\n",
       "      <td>The answer is:\\n\\nThe machine learning and NLP...</td>\n",
       "      <td>ML  logistic regression classifier combined wi...</td>\n",
       "      <td>Sentence classification combines natural langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>What approach performs better in experiments g...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>PPL: SVT\\nDiversity: GVT\\nEmbeddings Similarit...</td>\n",
       "      <td>Compare to baseline models, the GVT achieves r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Which translation system do they use to transl...</td>\n",
       "      <td>BIBREF6</td>\n",
       "      <td>Attention-based translation model with convolu...</td>\n",
       "      <td>Attention-base translation model We use the sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Which pre-trained English NER model do they use?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nF...</td>\n",
       "      <td>Bidirectional LSTM based NER model of Flair</td>\n",
       "      <td>Pre-trained English NER model We construct the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>How much of the ASR grapheme set is shared bet...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Little overlap except common basic Latin alpha...</td>\n",
       "      <td>The character sets of these 7 languages have l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>What are the languages used to test the model?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Hindi, English and German (German task won)</td>\n",
       "      <td>The dataset at HASOC 2019 were given in three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Which language has the lowest error rate reduc...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>thai</td>\n",
       "      <td>FLOAT SELECTED: Table 9 Character error rates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>How is moral bias measured?</td>\n",
       "      <td>By calculating the cosine similarity between t...</td>\n",
       "      <td>Answer with content missing: (formula 1) bias(...</td>\n",
       "      <td>Analogous to word embeddings, sentence embeddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>What metrics are used for evaluation?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>word error rate</td>\n",
       "      <td>The Density Ratio method consistently outperfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>How much training data is used?</td>\n",
       "      <td>Approximately 3 billion sub-word tokens</td>\n",
       "      <td>163,110,000 utterances</td>\n",
       "      <td>The following data sources were used to train ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>How does their model differ from BERT?</td>\n",
       "      <td>The model used in the experiments is a pre-tra...</td>\n",
       "      <td>Their model does not differ from BERT.</td>\n",
       "      <td>In all our experiments, we used the out-of-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>How does explicit constraint on the KL diverge...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Formula 2) Formu...</td>\n",
       "      <td>Given the above interpretation, we now turn to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>what was the baseline?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>There is no baseline.</td>\n",
       "      <td>This paper experimented with two different mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>How big is dataset used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n10000</td>\n",
       "      <td>553,451 documents</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistics of the dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>How much better does this baseline neural mode...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n10.2% better</td>\n",
       "      <td>The model outperforms at every point in the\\ni...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: PR curve on our impl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>What are the baseline models?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nC...</td>\n",
       "      <td>MC-CNN\\nMVCNN\\nCNN</td>\n",
       "      <td>We compared our proposed approaches to a stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>By how much of MGNC-CNN out perform the baseli...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>In terms of Subj the Average MGNC-CNN is bette...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results mean (min, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>What is increase in percentage of humor contai...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Humor in headlines (TitleStylist vs Multitask ...</td>\n",
       "      <td>The human evaluation is to have a comprehensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>What are the languages they consider in this p...</td>\n",
       "      <td>English, Russian, Arabic, Chinese, German, Spa...</td>\n",
       "      <td>The languages considered were English, Chinese...</td>\n",
       "      <td>To test this hypothesis we first trained UG-WG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Did they experiment with tasks other than word...</td>\n",
       "      <td>No</td>\n",
       "      <td>They experimented with sentiment analysis and ...</td>\n",
       "      <td>To test this hypothesis we first trained UG-WG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>What evaluation metrics are used?</td>\n",
       "      <td>The evaluation metrics used are accuracy and I...</td>\n",
       "      <td>Accuracy on each dataset and the average accur...</td>\n",
       "      <td>Table TABREF34 shows the performances of the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>What kind of Youtube video transcripts did the...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThey used a variety...</td>\n",
       "      <td>youtube video transcripts on news covering dif...</td>\n",
       "      <td>We focused evaluation over a small but diversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>What makes it a more reliable metric?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>It takes into account the agreement between di...</td>\n",
       "      <td>Results form Table TABREF31 may give an idea t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>How much in experiments is performance improve...</td>\n",
       "      <td>Performance is improved by around 10% on avera...</td>\n",
       "      <td>Answer with content missing: (Table 1) The per...</td>\n",
       "      <td>Adversarial training can often improve model r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>How is the delta-softmax calculated?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Answer with content missing: (Formula) Formula...</td>\n",
       "      <td>We reason that, if a token is important for pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Which two datasets does the resource come from?</td>\n",
       "      <td>The resource comes from two datasets, one coll...</td>\n",
       "      <td>two surveys by two groups - school students an...</td>\n",
       "      <td>The resource is composed of data from two diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>What is the size of the second dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n240</td>\n",
       "      <td>1 000 labeled dialogues for training and 240 u...</td>\n",
       "      <td>The two datasets used for the challenge are Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>How large is the first dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe first dataset, ...</td>\n",
       "      <td>1 000 labeled dialogues for training and 240 u...</td>\n",
       "      <td>The two datasets used for the challenge are Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Who was the top-scoring team?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>IDEA</td>\n",
       "      <td>FLOAT SELECTED: Table 6: F-scores for Friends ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Why is big data not appropriate for this task?</td>\n",
       "      <td>Big data is not appropriate for this task beca...</td>\n",
       "      <td>Training embeddings from small-corpora can inc...</td>\n",
       "      <td>Word embeddings have risen in popularity for N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>What is an example of a computational social s...</td>\n",
       "      <td>Analyzing the topic embeddings of State of the...</td>\n",
       "      <td>Visualization of State of the union addresses</td>\n",
       "      <td>I also performed several case studies. I obtai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Which major geographical regions are studied?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nN...</td>\n",
       "      <td>Northeast U.S, South U.S., West U.S. and Midwe...</td>\n",
       "      <td>We examine other features regarding the charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>How strong is the correlation between the prev...</td>\n",
       "      <td>Weak</td>\n",
       "      <td>0.9098 correlation</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Linear regression res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>How are the topics embedded in the #MeToo twee...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Using Latent Dirichlet Allocation on TF-IDF tr...</td>\n",
       "      <td>In order to understand the latent topics of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Which geographical regions correlate to the tr...</td>\n",
       "      <td>The Northeast, West, and South regions correla...</td>\n",
       "      <td>Northeast U.S., West U.S. and South U.S.</td>\n",
       "      <td>Observing the results of the linear regression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>What two components are included in their prop...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>evidence extraction and answer synthesis</td>\n",
       "      <td>In this paper, we present an extraction-then-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Which modifications do they make to well-estab...</td>\n",
       "      <td>They modify the attention mechanism from locat...</td>\n",
       "      <td>Replacing attention mechanism to query-key att...</td>\n",
       "      <td>Traditional text-to-speech (TTS) systems are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>How was speed measured?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nTime</td>\n",
       "      <td>how long it takes the system to lemmatize a se...</td>\n",
       "      <td>In terms of speed, our system was able to lemm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>What were their accuracy results on the task?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n85.11%</td>\n",
       "      <td>97.32%</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Lemmatization accurac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>What two types the Chinese reading comprehensi...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nUser Query Track an...</td>\n",
       "      <td>cloze-style reading comprehension and user que...</td>\n",
       "      <td>Cloze Track: In this track, the participants a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>For which languages most of the existing MRC d...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>English</td>\n",
       "      <td>The previously mentioned datasets are all in E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Which sentiment analysis tasks are addressed?</td>\n",
       "      <td>Binary-class and multi-class cross-domain sent...</td>\n",
       "      <td>12 binary-class classification and multi-class...</td>\n",
       "      <td>We conducted experiments on the Amazon reviews...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Which 3 NLP areas are cited the most?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe answer is:\\n\\n1...</td>\n",
       "      <td>machine translation, statistical machine, sent...</td>\n",
       "      <td>FLOAT SELECTED: Figure 33 The most cited areas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Which journal and conference are cited the mos...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>CL Journal and EMNLP conference</td>\n",
       "      <td>FLOAT SELECTED: Figure 25 Average citations fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Which 5 languages appear most frequently in AA...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nEnglish, Spanish, C...</td>\n",
       "      <td>English, Chinese, French, Japanese and Arabic</td>\n",
       "      <td>FLOAT SELECTED: Figure 11 A treemap of the 122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>How much F1 was improved after adding skip con...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Simple Skip improves F1 from 74.34 to 74.81\\nT...</td>\n",
       "      <td>Table TABREF20 reports the F1 and EM scores ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>How much gain does the model achieve with pret...</td>\n",
       "      <td>The answer is:\\n\\nThe model achieves a gain of...</td>\n",
       "      <td>0.8 points on Binary; 0.7 points on Fine-Grain...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Test set results of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>What is the highest accuracy score achieved?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n0.85</td>\n",
       "      <td>82.0%</td>\n",
       "      <td>FLOAT SELECTED: Table 4: The performance of cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>What are the three datasets used in the paper?</td>\n",
       "      <td>The answer is:\\n\\nThe three datasets used in t...</td>\n",
       "      <td>Data released for APDA shared task contains 3 ...</td>\n",
       "      <td>For the purpose of our experiments, we use dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>What is improvement in accuracy for short Joke...</td>\n",
       "      <td>8% improvement in accuracy for short jokes com...</td>\n",
       "      <td>It had the highest accuracy comparing to all d...</td>\n",
       "      <td>Our experiment with the Short Jokes dataset fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>What baseline did they compare Entity-GCN to?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver...</td>\n",
       "      <td>In this experiment, we compare our Enitity-GCN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>How did they get relations between mentions?</td>\n",
       "      <td>They got relations between mentions using thre...</td>\n",
       "      <td>Assign a value to the relation based on whethe...</td>\n",
       "      <td>To each node $v_i$ , we associate a continuous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>How did they detect entity mentions?</td>\n",
       "      <td>They detected entity mentions by using a simpl...</td>\n",
       "      <td>Exact matches to the entity string and predict...</td>\n",
       "      <td>In an offline step, we organize the content of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>What performance does the Entity-GCN get on WI...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>During testing: 67.6 for single model without ...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Accuracy of different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>What document context was added?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nPreceding and follo...</td>\n",
       "      <td>Preceding and following sentence of each metap...</td>\n",
       "      <td>We extracted 200 sentence pairs from BIBREF3 '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>What were the results of the first experiment?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Best performance achieved is 0.72 F1 score</td>\n",
       "      <td>We also observe that the best combination seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>By how much does their model outperform existi...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Table II) Propos...</td>\n",
       "      <td>We compare our best F1 score with other state-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>What is the performance of their model?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Table II) Propos...</td>\n",
       "      <td>We compare our best F1 score with other state-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>How do they damage different neural modules?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Damage to neural modules is done by randomly i...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results for artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>How long are the datasets?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Travel dataset contains 4100 raw samples, 1129...</td>\n",
       "      <td>We compile three Chinese text corpora from onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>What are the sources of the data?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nOnline user reviews...</td>\n",
       "      <td>User reviews written in Chinese collected onli...</td>\n",
       "      <td>We compile three Chinese text corpora from onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>What is the new labeling strategy?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>They use a two-stage labeling strategy where i...</td>\n",
       "      <td>We address the above issues with a new methodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>How are their changes evaluated?</td>\n",
       "      <td>The changes are evaluated based on the accurac...</td>\n",
       "      <td>The changes are evaluated based on accuracy of...</td>\n",
       "      <td>To evaluate the performance of our approach, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>What are the six target languages?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nE...</td>\n",
       "      <td>Answer with content missing: (3 Experimental S...</td>\n",
       "      <td>Given the initial distributional or specialise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>What is the size of the released dataset?</td>\n",
       "      <td>2247 triples</td>\n",
       "      <td>440 sentences, 2247 triples extracted from tho...</td>\n",
       "      <td>We used two different data sources in our eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Which OpenIE systems were used?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nO...</td>\n",
       "      <td>OpenIE4 and MiniIE</td>\n",
       "      <td>We evaluate two OIE systems (i.e. extractors)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>how are the bidirectional lms obtained?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>They pre-train forward and backward LMs separa...</td>\n",
       "      <td>In our final system, after pre-training the fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>what metrics are used in evaluation?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nm...</td>\n",
       "      <td>micro-averaged F1</td>\n",
       "      <td>We evaluate our approach on two well benchmark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>what results do they achieve?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>91.93% F1 score on CoNLL 2003 NER task and 96....</td>\n",
       "      <td>Our main contribution is to show that the cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>what previous systems were compared to?</td>\n",
       "      <td>Previous systems compared to are those without...</td>\n",
       "      <td>Chiu and Nichols (2016), Lample et al. (2016),...</td>\n",
       "      <td>Tables TABREF15 and TABREF16 compare results f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Are this models usually semi/supervised or uns...</td>\n",
       "      <td>Semi/supervised.\\n\\nThese models are trained o...</td>\n",
       "      <td>Both supervised and unsupervised, depending on...</td>\n",
       "      <td>Machine translation finds use in cheminformati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>When they say \"comparable performance\", how mu...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nA negligible perfor...</td>\n",
       "      <td>Performance was comparable, with the proposed ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results on test data....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>What types of word representations are they ev...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nBoth GloVe and SGNS...</td>\n",
       "      <td>GloVE; SGNS</td>\n",
       "      <td>We trained word embeddings using either GloVe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>What type of recurrent layers does the model use?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>GRU</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: The proposed model w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>What is a word confusion network?</td>\n",
       "      <td>A word confusion network (cnet) is a type of i...</td>\n",
       "      <td>It is a network used to encode speech lattices...</td>\n",
       "      <td>We take a first step towards integrating ASR i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>What evaluation metrics were used in the exper...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>For sentence-level prediction they used tolera...</td>\n",
       "      <td>Metrics. We use tolerance accuracy BIBREF16, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>What kind of instructional videos are in the d...</td>\n",
       "      <td>Screencast tutorial videos</td>\n",
       "      <td>tutorial videos for a photo-editing software</td>\n",
       "      <td>The remainder of this paper is structured as f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>What baseline algorithms were presented?</td>\n",
       "      <td>Baseline1, Baseline2, and Baseline3</td>\n",
       "      <td>a sentence-level prediction algorithm, a segme...</td>\n",
       "      <td>Our video question answering task is novel and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>How does TP-N2F compare to LSTM-based Seq2Seq ...</td>\n",
       "      <td>TP-N2F is faster than LSTM-based Seq2Seq in bo...</td>\n",
       "      <td>Full Testing Set accuracy: 84.02\\nCleaned Test...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results of AlgoLisp d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>What is the performance proposed model achieve...</td>\n",
       "      <td>State-of-the-art performance on both the full ...</td>\n",
       "      <td>Full Testing Set Accuracy: 84.02\\nCleaned Test...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results of AlgoLisp d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>What is the performance proposed model achieve...</td>\n",
       "      <td>The proposed model achieved an execution accur...</td>\n",
       "      <td>Operation accuracy: 71.89\\nExecution accuracy:...</td>\n",
       "      <td>Given a natural-language math problem, we need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>What previous methods is the proposed method c...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>BLSTM+Attention+BLSTM\\nHierarchical BLSTM-CRF\\...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Comparison results wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>What is the baseline model used?</td>\n",
       "      <td>DrQA+CoQA</td>\n",
       "      <td>The baseline models used are DrQA modified to ...</td>\n",
       "      <td>DrQA is a CRC baseline coming with the CoQA da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>What domains are present in the data?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Alarm, Banks, Buses, Calendar, Events, Flights...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: The total number of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>How many texts/datapoints are in the SemEval, ...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe answer is:\\n\\n*...</td>\n",
       "      <td>Total number of annotated data:\\nSemeval'15: 1...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Datasets details from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>In which languages did the approach outperform...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Arabic, German, Portuguese, Russian, Swedish</td>\n",
       "      <td>In BIBREF3 , BIBREF2 , the authors study the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Which is the baseline model?</td>\n",
       "      <td>AG-RNN-LID</td>\n",
       "      <td>The three baseline models are the i-vector mod...</td>\n",
       "      <td>As the first step, we build three baseline LID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>What is the main contribution of the paper?</td>\n",
       "      <td>The main contribution of the paper is the prop...</td>\n",
       "      <td>Proposing an improved RNN model, the phonetic ...</td>\n",
       "      <td>All the present neural LID methods are based o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>How do they get the formal languages?</td>\n",
       "      <td>They get the formal languages from a context-f...</td>\n",
       "      <td>These are well-known formal languages some of ...</td>\n",
       "      <td>BIBREF7 investigated the learning capabilities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>What is a confusion network or lattice?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nA confusion network...</td>\n",
       "      <td>graph-like structures where arcs connect nodes...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 2: Standard ASR outputs A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>How close do clusters match to ground truth to...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>NMI between cluster assignments and ground tru...</td>\n",
       "      <td>To test this hypothesis, we evaluate the model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>what are the evaluation metrics?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nPrecision, Recall, ...</td>\n",
       "      <td>Precision, Recall, F1</td>\n",
       "      <td>FLOAT SELECTED: Table 5: CoNLL 2003 English re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>which datasets were used in evaluation?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nSONAR-1 and Ancora 2.0</td>\n",
       "      <td>CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkar...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Datasets used for tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>what are the baselines?</td>\n",
       "      <td>local features</td>\n",
       "      <td>Perceptron model using the local features.</td>\n",
       "      <td>Our system learns Perceptron models BIBREF37 u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>What monolingual word representations are used?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>AraVec for Arabic, FastText for French, and Wo...</td>\n",
       "      <td>Feature-based models. We used state-of-the-art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Do they build one model per topic or on all to...</td>\n",
       "      <td>They build one model per topic</td>\n",
       "      <td>One model per topic.</td>\n",
       "      <td>The turkers are asked to indicate their prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Do they quantitavely or qualitatively evalute ...</td>\n",
       "      <td>Quantitatively</td>\n",
       "      <td>They evaluate quantitatively.</td>\n",
       "      <td>In this section, we evaluate the proposed meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>How well does their system perform on the deve...</td>\n",
       "      <td>The system achieves a relative improvement of ...</td>\n",
       "      <td>EER 16.04, Cmindet 0.6012, Cdet 0.6107</td>\n",
       "      <td>In this section we present the results obtaine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>Which of the classifiers showed the best perfo...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nRandom Forest</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>FLOAT SELECTED: TABLE II: A comparison of clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>How are the keywords associated with events su...</td>\n",
       "      <td>By using a Bayesian approach to learn which te...</td>\n",
       "      <td>By using a Bayesian approach  and by using wor...</td>\n",
       "      <td>We approached the first and second challenges ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>What is different in BERT-gen from standard BERT?</td>\n",
       "      <td>The use of a left-to-right attention mask to r...</td>\n",
       "      <td>They use a left-to-right attention mask so tha...</td>\n",
       "      <td>As we iteratively concatenate the generated to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>How are multimodal representations combined?</td>\n",
       "      <td>The multimodal representations are combined us...</td>\n",
       "      <td>The image feature vectors are mapped into BERT...</td>\n",
       "      <td>To investigate whether our BERT-based model ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>What is the problem with existing metrics that...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nExisting metrics do...</td>\n",
       "      <td>Answer with content missing: (whole introducti...</td>\n",
       "      <td>Building Extractive CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>How are discourse embeddings analyzed?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>They perform t-SNE clustering to analyze disco...</td>\n",
       "      <td>To further study the information encoded in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>How are discourse features incorporated into t...</td>\n",
       "      <td>Discourse features are incorporated into the m...</td>\n",
       "      <td>They derive entity grid with grammatical relat...</td>\n",
       "      <td>CNN2-PV. This model (Figure FIGREF10 , left+ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>What discourse features are used?</td>\n",
       "      <td>GR and RST discourse features</td>\n",
       "      <td>Entity grid with grammatical relations and RST...</td>\n",
       "      <td>CNN2-PV. This model (Figure FIGREF10 , left+ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>What are proof paths?</td>\n",
       "      <td>Proof paths are the sequences of proof states ...</td>\n",
       "      <td>A sequence of logical statements represented i...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1. A visual depiction o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>What external sources are used?</td>\n",
       "      <td>Raw Text, Automatically Segmented Text, Hetero...</td>\n",
       "      <td>Raw data from Gigaword, Automatically segmente...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Statistics of externa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>How much better peformance is achieved in huma...</td>\n",
       "      <td>The proposed comparative evaluator with skill ...</td>\n",
       "      <td>Pearson correlation to human judgement - propo...</td>\n",
       "      <td>The experimental results are summarized in Tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>How much transcribed data is available for for...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Transcribed data is available for duration of ...</td>\n",
       "      <td>The corpus we have prepared for ASR in this st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>What baseline approaches do they compare against?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>HotspotQA: Yang, Ding, Muppet\\nFever: Hanselow...</td>\n",
       "      <td>We chose the best system based on the dev set,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>how many domains did they experiment with?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>2</td>\n",
       "      <td>We demonstrated the utility of Katecheo by dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>How long is the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>8000</td>\n",
       "      <td>Data set. For the cross-domain polarity classi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>What is a string kernel?</td>\n",
       "      <td>A string kernel is a method for measuring the ...</td>\n",
       "      <td>String kernel is a technique that uses charact...</td>\n",
       "      <td>In recent years, methods based on string kerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>How do they correlate NED with emotional bond ...</td>\n",
       "      <td>They compute the correlation of the proposed N...</td>\n",
       "      <td>They compute Pearson’s correlation between NED...</td>\n",
       "      <td>According to prior work, both from domain theo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>What was their F1 score on the Bengali NER cor...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n5.5 points F1</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Bengali manual annota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>What is the size of the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n3...</td>\n",
       "      <td>300,000 sentences with 1.5 million single-quiz...</td>\n",
       "      <td>Using our platform, we extracted anonymized us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>How many examples do they have in the target d...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n0</td>\n",
       "      <td>Around 388k examples, 194k from tst2013 (in-do...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: German→English: Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>What is the baseline model?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nA...</td>\n",
       "      <td>a RNN-based seq2seq VC model called ATTS2S bas...</td>\n",
       "      <td>Next, we compared our VTN model with an RNN-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Where did they get training data?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nTable 1</td>\n",
       "      <td>AmazonQA and ConciergeQA datasets</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Precision (P), Recall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>What extraction model did they use?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nMulti-Encoder, Cons...</td>\n",
       "      <td>Multi-Encoder, Constrained-Decoder model</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Multi-Encoder, Const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Which datasets did they experiment on?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nTable 1</td>\n",
       "      <td>ConciergeQA and AmazonQA</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Various types of trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>How do slot binary classifiers improve perform...</td>\n",
       "      <td>Slot binary classifiers improve performance by...</td>\n",
       "      <td>by adding extra supervision to generate the sl...</td>\n",
       "      <td>This paper proposes the Flexibly-Structured Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>What baselines have been used in this work?</td>\n",
       "      <td>NDM BIBREF7, LIDM BIBREF9, KVRN BIBREF13, and ...</td>\n",
       "      <td>NDM, LIDM, KVRN, and TSCP/RL</td>\n",
       "      <td>We compare FSDM with four baseline methods and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>what bottlenecks were identified?</td>\n",
       "      <td>Confusion among active words at certain nodes ...</td>\n",
       "      <td>Confusion in recognizing the words that are ac...</td>\n",
       "      <td>In this paper we proposed a methodology to ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>By how much do they outperform BiLSTMs in Sent...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Proposed RCRN outperforms ablative baselines B...</td>\n",
       "      <td>On the 16 review datasets (Table TABREF22 ) fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>what state of the accuracy did they obtain?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n87.5%</td>\n",
       "      <td>51.5</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracies on the Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>what models did they compare to?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nt...</td>\n",
       "      <td>High-order CNN, Tree-LSTM, DRNN, DCNN, CNN-MC,...</td>\n",
       "      <td>The test-set accuracies obtained by different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>which benchmark tasks did they experiment on?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\ns...</td>\n",
       "      <td>They used Stanford Sentiment Treebank benchma...</td>\n",
       "      <td>Experiments on two benchmark data sets, the St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>How is the proficiency score calculated?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>They used 6 indicators for proficiency (same f...</td>\n",
       "      <td>Tables and report some statistics extracted fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>What proficiency indicators are used to the sc...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>6 indicators:\\n- lexical richness\\n- pronuncia...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: List of the indicator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>What accuracy is achieved by the speech recogn...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Accuracy not available: WER results are report...</td>\n",
       "      <td>Table , extracted from BIBREF0, reports WERs o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>How is the speech recognition system evaluated?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Speech recognition system is evaluated using W...</td>\n",
       "      <td>Table , extracted from BIBREF0, reports WERs o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>How many of the utterances are transcribed?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n75.6% of the uttera...</td>\n",
       "      <td>Total number of transcribed utterances includi...</td>\n",
       "      <td>Speakers were assigned either to training or e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>How many utterances are in the corpus?</td>\n",
       "      <td>2000</td>\n",
       "      <td>Total number of utterances available is: 70607...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Spoken data collected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>By how much does their model outperform both t...</td>\n",
       "      <td>Their model outperforms both state-of-the-art ...</td>\n",
       "      <td>w.r.t Rouge-1 their model outperforms by 0.98%...</td>\n",
       "      <td>Evaluation on DUC2004: DUC 2004 ( BIBREF15 ) i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>What is the state-of-the art?</td>\n",
       "      <td>The state-of-the-art is the `Read-Again' encod...</td>\n",
       "      <td>neural attention model with a convolutional en...</td>\n",
       "      <td>Very recently, the success of deep neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>What was the performance on the self-collected...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n🔥 OUTPERFORMED THE ...</td>\n",
       "      <td>F1 scores of 86.16 on slot filling and 94.56 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Results on our CAIS d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>What is the size of their dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n1000</td>\n",
       "      <td>10,001 utterances</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Dataset statistics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>how was the dataset built?</td>\n",
       "      <td>The dataset was built by gathering queries fro...</td>\n",
       "      <td>Questions are gathered from anonymized, aggreg...</td>\n",
       "      <td>Questions are gathered from anonymized, aggreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>what processing was done on the speeches befor...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Remove numbers and interjections</td>\n",
       "      <td>To estimate speakers' position we use Wordscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>What is the performance change of the textual ...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>10 Epochs: pearson-Spearman correlation  drops...</td>\n",
       "      <td>Figure FIGREF12stsa and FIGREF12stsb shows Pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Which sentiment analysis data set has a larger...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nS...</td>\n",
       "      <td>SST-2 dataset</td>\n",
       "      <td>Let us discuss the results from the above ment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>How much is pre-training loss increased in Low...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The increase is linearly from lowest on averag...</td>\n",
       "      <td>We've seen that over-pruning BERT deletes info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>What is the average length of the recordings?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n3...</td>\n",
       "      <td>40 minutes</td>\n",
       "      <td>Each game's video ranges from 30 to 50 minutes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>What were their results?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe results were no...</td>\n",
       "      <td>Best model achieved F-score 74.7 on NALCS and ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Test Results on the N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>What is the prediction accuracy of the model?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n85.6%</td>\n",
       "      <td>mean prediction accuracy 0.99582651\\nS&amp;P 500 A...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Predicted Mean MPA re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>What is the dataset used in the paper?</td>\n",
       "      <td>The dataset used in the paper is a collection ...</td>\n",
       "      <td>historical S&amp;P 500 component stocks\\n 306242 n...</td>\n",
       "      <td>The data for this project are two parts, the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>How does the SCAN dataset evaluate composition...</td>\n",
       "      <td>By systematically holding out the training set...</td>\n",
       "      <td>it systematically holds out inputs in the trai...</td>\n",
       "      <td>A recently published dataset called SCAN BIBRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>How much does this system outperform prior work?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThis system outperf...</td>\n",
       "      <td>The system outperforms by 27.7% the LSTM model...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracy on the ListO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>What are the baseline systems that are compare...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe baseline system...</td>\n",
       "      <td>The system is compared to baseline models: LST...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracy on the ListO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>What systems are tested?</td>\n",
       "      <td>The systems tested are the VoxCeleb-based syst...</td>\n",
       "      <td>BULATS i-vector/PLDA\\nBULATS x-vector/PLDA\\nVo...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. % EER performance of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>What benchmark datasets they use?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nV...</td>\n",
       "      <td>VQA and GeoQA</td>\n",
       "      <td>Our first task is the recently-introduced Visu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>How do they combine MonaLog with BERT?</td>\n",
       "      <td>They hybridize MonaLog with BERT for compositi...</td>\n",
       "      <td>They use Monalog for data-augmentation to fine...</td>\n",
       "      <td>In this work, we introduce a new logical infer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>How do they select monotonicity facts?</td>\n",
       "      <td>MonaLog selects monotonicity facts based on th...</td>\n",
       "      <td>They derive it from Wordnet</td>\n",
       "      <td>MonaLog utilizes two auxiliary sets. First, a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>What are the 12 categories devised?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n12 categories devis...</td>\n",
       "      <td>Economics, Genocide, Geography, History, Human...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistics of the cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>what are the off-the-shelf systems discussed i...</td>\n",
       "      <td>The answer is:\\n\\nThere are several off-the-sh...</td>\n",
       "      <td>Answer with content missing: (Names of many id...</td>\n",
       "      <td>TextCat is the most well-known Perl implementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>How many rules had to be defined?</td>\n",
       "      <td>3 rules</td>\n",
       "      <td>WikiSQL - 2 rules (SELECT, WHERE)\\nSimpleQuest...</td>\n",
       "      <td>We describe our rules for WikiSQL here. We fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>What was performance of classifiers before/aft...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Bi-LSTM: For low resource &lt;17k clean data: Usi...</td>\n",
       "      <td>The experimental results for Yorùbá are given ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>How big are the datasets used?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Evaluation datasets used:\\nCMRC 2018 - 18939 q...</td>\n",
       "      <td>We evaluate our approaches on two public Chine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>What datasets are used for training/testing mo...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Microsoft Research dataset containing movie, t...</td>\n",
       "      <td>The experiment dataset comes from Microsoft Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>How better is gCAS approach compared to other ...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\ngCAS approach is be...</td>\n",
       "      <td>For entity  F1 in the movie, taxi and restaura...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Entity F1 and Success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>What is specific to gCAS cell?</td>\n",
       "      <td>The gCAS cell is specific in that it is compos...</td>\n",
       "      <td>It has three sequentially connected units to o...</td>\n",
       "      <td>In this paper, we introduce a novel policy mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>What is the source of external knowledge?</td>\n",
       "      <td>English Wikipedia</td>\n",
       "      <td>counts of predicate-argument tuples from Engli...</td>\n",
       "      <td>The second type is the selectional preference ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>What were the sizes of the test sets?</td>\n",
       "      <td>The answer is:\\n\\nTest Set 1: 57 drug labels\\n...</td>\n",
       "      <td>Test set 1 contained 57 drug labels and 8208 s...</td>\n",
       "      <td>Each drug label is a collection of sections (e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Which datasets are used?</td>\n",
       "      <td>The answer is:\\n\\nThe datasets used are:\\n\\n* ...</td>\n",
       "      <td>ABSA SemEval 2014-2016 datasets\\nYelp Academic...</td>\n",
       "      <td>Table TABREF7 shows the ABSA datasets from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>How much does it minimally cost to fine-tune s...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>$1,728</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Pretraining costs of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>What models are included in baseline benchmark...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nDistilBERT, BERT, a...</td>\n",
       "      <td>BERT, XLNET RoBERTa, ALBERT, DistilBERT</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Pretraining costs of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>It looks like learning to paraphrase questions...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>using multiple pivot sentences</td>\n",
       "      <td>BIBREF11 revisit bilingual pivoting in the con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>How much more accurate is the model than the b...</td>\n",
       "      <td>NAGM is significantly more accurate than the b...</td>\n",
       "      <td>For the Oshiete-goo dataset, the NAGM model's ...</td>\n",
       "      <td>NAGMWA is much better than the other methods e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>What is new state-of-the-art performance on Co...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>In closed setting 84.22 F1 and in open 87.35 F1.</td>\n",
       "      <td>Table TABREF46 shows that our Open model achie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>What are two strong baseline methods authors r...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nBERT and RoBERTa</td>\n",
       "      <td>Marcheggiani and Titov (2017) and Cai et al. (...</td>\n",
       "      <td>FLOAT SELECTED: Table 7: SRL results on the Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>How many category tags are considered?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n4</td>\n",
       "      <td>14 categories</td>\n",
       "      <td>FLOAT SELECTED: Figure 5. The results are spli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>What domain does the dataset fall into?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nYouTube</td>\n",
       "      <td>YouTube videos</td>\n",
       "      <td>We perform our experiments using ActivityNet C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>How are EAC evaluated?</td>\n",
       "      <td>EACs are evaluated using a combination of qual...</td>\n",
       "      <td>Qualitatively through efficiency, effectivenes...</td>\n",
       "      <td>We characterize the evaluation of Emotionally-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>What is triangulation?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nTriangulation is a ...</td>\n",
       "      <td>Answer with content missing: (Chapter 3) The c...</td>\n",
       "      <td>Conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>What languages do they use?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nEnglish, Spanish, A...</td>\n",
       "      <td>Train languages are: Cantonese, Bengali, Pasht...</td>\n",
       "      <td>In this work, the experiments are conducted us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>How they evaluate their approach?</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>They  evaluate newly proposed models in severa...</td>\n",
       "      <td>Our contributions are as follows: We propose t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>How large is the corpus?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe corpus contains...</td>\n",
       "      <td>It contains 106,350 documents</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistical summary o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>How large is the dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe dataset is quit...</td>\n",
       "      <td>over 104k documents</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistical summary o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>What was their perplexity score?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n3...</td>\n",
       "      <td>Perplexity score 142.84 on dev and 138.91 on test</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Language Modeling Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>What parallel corpus did they use?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Parallel monolingual corpus in English and Man...</td>\n",
       "      <td>In this section, we present the experimental s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>In which setting they achieve the state of the...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>in open-ended task esp. for counting-type ques...</td>\n",
       "      <td>FLOAT SELECTED: Table 4. Evaluation results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>What they formulate the question generation as?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nLASSO optimization ...</td>\n",
       "      <td>LASSO optimization problem</td>\n",
       "      <td>Our idea is the BQ generation for MQ and, at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Was the degree of offensiveness taken as how g...</td>\n",
       "      <td>The degree of offensiveness was based on how p...</td>\n",
       "      <td>Personal thought of the annotator.</td>\n",
       "      <td>The surveys consisted of 20 tweets presented i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Which embeddings do they detect biases in?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>Word embeddings trained on GoogleNews and Word...</td>\n",
       "      <td>For both word2vec BIBREF0 and gensim BIBREF7 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>What are the two PharmaCoNER subtasks?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Entity identification with offset mapping and ...</td>\n",
       "      <td>Although the competition proposes two differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>How do they perform data augmentation?</td>\n",
       "      <td>They perform data augmentation by adding sente...</td>\n",
       "      <td>They randomly sample sentences from Wikipedia ...</td>\n",
       "      <td>We first inspect the frequencies of object and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>What are the characteristics of the city dialect?</td>\n",
       "      <td>The city dialect is characterized by a more un...</td>\n",
       "      <td>Lexicon of the cities tend to use most forms o...</td>\n",
       "      <td>After averaging over all concepts, we lose inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>What are the characteristics of the rural dial...</td>\n",
       "      <td>The rural dialect has more specific words in i...</td>\n",
       "      <td>It uses particular forms of a concept rather t...</td>\n",
       "      <td>After averaging over all concepts, we lose inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>What is the performance of the models on the t...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Overall accuracy per model is: 5-gram (60.5), ...</td>\n",
       "      <td>An LM's overall performance on *X can be measu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>What other non-neural baselines do the authors...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>bag of words, tf-idf, bag-of-means</td>\n",
       "      <td>is the standard word counting method whereby t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>On what dataset is Aristo system trained?</td>\n",
       "      <td>Aristo system is trained on the ARC dataset</td>\n",
       "      <td>Aristo Corpus\\nRegents 4th\\nRegents 8th\\nRegen...</td>\n",
       "      <td>Several methods make use of the Aristo Corpus,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>How many roles are proposed?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n8</td>\n",
       "      <td>12</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Most common syntactic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>What language technologies have been introduce...</td>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>- Font &amp; Keyboard\\n- Speech-to-Text\\n- Text-to...</td>\n",
       "      <td>Often, many state-of-the-art tools cannot be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>How do they define local variance?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nL...</td>\n",
       "      <td>The reciprocal of the variance of the attentio...</td>\n",
       "      <td>As discussed in section SECREF1, the attention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>how do they measure discussion quality?</td>\n",
       "      <td>through the annotation scheme, which captures ...</td>\n",
       "      <td>Measuring three aspects: argumentation, specif...</td>\n",
       "      <td>As a first step towards developing an automate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>what were the baselines?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>2008 Punyakanok et al. \\n2009 Zhao et al. + ME...</td>\n",
       "      <td>Generally, the above work is summarized in Tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Which soft-selection approaches are evaluated?</td>\n",
       "      <td>Soft-selection approaches evaluated are attent...</td>\n",
       "      <td>LSTM and BERT</td>\n",
       "      <td>Previous attention-based methods can be catego...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>How big is slot filing dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Dataset has 1737 train, 497 dev and 559 test s...</td>\n",
       "      <td>In our experiments, we use Onsei Intent Slot d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>How large is the dataset they generate?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe dataset they ge...</td>\n",
       "      <td>4.756 million sentences</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Number of run-on (RO)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>What are the weaknesses of their proposed inte...</td>\n",
       "      <td>Bias due to dataset selection and word coverage</td>\n",
       "      <td>can be biased by dataset used and may generate...</td>\n",
       "      <td>Our interpretability measurements are based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>What advantages does their proposed method of ...</td>\n",
       "      <td>Their proposed method of quantifying interpret...</td>\n",
       "      <td>it is less expensive and quantifies interpreta...</td>\n",
       "      <td>In the word embedding literature, the problem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>How was lexical diversity measured?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nL...</td>\n",
       "      <td>By computing number of unique responses and nu...</td>\n",
       "      <td>To study the lexical and semantic diversities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Which existing models does this approach outpe...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThis approach outpe...</td>\n",
       "      <td>RNN-context, SRB, CopyNet, RNN-distract, DRGD</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Comparisons with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>What human evaluation method is proposed?</td>\n",
       "      <td>Simple human evaluation method</td>\n",
       "      <td>comparing the summary with the text instead of...</td>\n",
       "      <td>More detailed explanation is introduced in Sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>What languages are represented in the dataset?</td>\n",
       "      <td>English and Japanese are the most represented ...</td>\n",
       "      <td>EN, JA, ES, AR, PT, KO, TH, FR, TR, RU, IT, DE...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Twitter corpus distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>How faster is training and decoding compared t...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Proposed vs best baseline:\\nDecoding: 8541 vs ...</td>\n",
       "      <td>In order to verify the time complexity analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>What datasets are used to evaluate the model?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nWN18 and FB15k</td>\n",
       "      <td>WN18 and FB15k</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The knowledge base co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>What is the source of the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Online sites tagged as fake news site by Veraf...</td>\n",
       "      <td>We work with a dataset composed of 3,206 news ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>What were the baselines?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Siamese neural network consisting of an embedd...</td>\n",
       "      <td>We use a siamese neural network, shown to perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>What metadata is included?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe answer is:\\n\\n*...</td>\n",
       "      <td>besides claim, label and claim url, it also in...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: An example of a claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Do the images have multilingual annotations or...</td>\n",
       "      <td>Monolingual annotations</td>\n",
       "      <td>monolingual</td>\n",
       "      <td>We experiment using a dataset derived from Goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>How much important is the visual grounding in ...</td>\n",
       "      <td>Sure! Here's my answer based on the provided c...</td>\n",
       "      <td>performance is significantly degraded without ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Crosslingual semantic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>How is the generative model evaluated?</td>\n",
       "      <td>The generative model is evaluated using BLEU s...</td>\n",
       "      <td>Comparing BLEU score of model with and without...</td>\n",
       "      <td>We train an LSTM with and without attention on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>What is an example of a health-related tweet?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nA health-related tw...</td>\n",
       "      <td>The health benefits of alcohol consumption are...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 1. Proposed representatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>What is the challenge for other language excep...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>not researched as much as English</td>\n",
       "      <td>Given the fact that the research on offensive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>How many categories of offensive language were...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In sub-task C the goal is to classify the targ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Which matching features do they employ?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nM...</td>\n",
       "      <td>Matching features from matching sentences from...</td>\n",
       "      <td>In this paper, we propose the MIMN model for N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>By how much does their method outperform the m...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n1.75x</td>\n",
       "      <td>Their average improvement in Character Error R...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Experimental results.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>How large is the corpus they use?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n100,000 words</td>\n",
       "      <td>449050</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Experimental conditions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>How many shared layers are in the system?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n2</td>\n",
       "      <td>1</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Optimal hyperparamete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>How many additional task-specific layers are i...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n2</td>\n",
       "      <td>2 for the ADE dataset and 3 for the CoNLL04 da...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Optimal hyperparamete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>How many layers of self-attention does the mod...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n3 layers of self-at...</td>\n",
       "      <td>1, 4, 8, 16, 32, 64</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Evaluation of effect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>what are the state of the art methods?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>S2VT, RGB (VGG), RGB (VGG)+Flow (AlexNet), LST...</td>\n",
       "      <td>We also evaluate our Joint-BiLSTM structure by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Which four languages do they experiment with?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nEnglish, Spanish, F...</td>\n",
       "      <td>German, English, Italian, Chinese</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Datasets used for var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Does DCA or GMM-based attention perform better...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nGMM-based attention...</td>\n",
       "      <td>About the same performance</td>\n",
       "      <td>FLOAT SELECTED: Table 3. MOS naturalness resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>What evaluation metric is used?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>F1 and Weighted-F1</td>\n",
       "      <td>FLOAT SELECTED: Table 10: Results of experimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Is any data-to-text generation model trained o...</td>\n",
       "      <td>Yes, the results show that the NLG model train...</td>\n",
       "      <td>Yes, Transformer based seq2seq is evaluated wi...</td>\n",
       "      <td>The NLG model we use to establish a baseline f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>How are the potentially relevant text fragment...</td>\n",
       "      <td>By generating a query based on the claim's ver...</td>\n",
       "      <td>Generate a query out of the claim and queryin...</td>\n",
       "      <td>This step consists of generating a query out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>weibo-100k, Ontonotes, LCQMC and XNLI</td>\n",
       "      <td>Table TABREF14 shows the experiment measuring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>What is the size of the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n2...</td>\n",
       "      <td>3029</td>\n",
       "      <td>We use the publicly available dataset KVRET BI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>What are the 12 AV approaches which are examined?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>MOCC, OCCAV, COAV, AVeer, GLAD, DistAV, Unmask...</td>\n",
       "      <td>As a basis for our experiments, we reimplement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>how was annotation done?</td>\n",
       "      <td>Annotation was done using Amazon Mechanical Tu...</td>\n",
       "      <td>Annotation was done with the help of annotator...</td>\n",
       "      <td>With the gathered comments, we reconstructed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>How do they measure correlation between the pr...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>They look at the performance accuracy of expla...</td>\n",
       "      <td>We would expect that explanation performance s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>What are the results achieved from the introdu...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nImproved accuracy a...</td>\n",
       "      <td>Their model resulted in values of 0.476, 0.672...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>How do they incorporate human advice?</td>\n",
       "      <td>They incorporate human advice by explicitly re...</td>\n",
       "      <td>by converting human advice to first-order logi...</td>\n",
       "      <td>While most relational learning methods restric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>What affective-based features are used?</td>\n",
       "      <td>Emolex, EmoSenticNet, Dictionary of Affect in ...</td>\n",
       "      <td>affective features provided by different emoti...</td>\n",
       "      <td>We used the following affective resources rely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>How big is performance improvement proposed me...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Data augmentation (es)  improved Adv es by 20%...</td>\n",
       "      <td>The performance of the base model described in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>By how much does transfer learning improve per...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n22.6% improvement i...</td>\n",
       "      <td>In task 1 best transfer learning strategy impr...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Transfer learning per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>What baseline is used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nLinear Support Vect...</td>\n",
       "      <td>SVM</td>\n",
       "      <td>The baseline classifier uses a linear Support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>What topic clusters are identified by LDA?</td>\n",
       "      <td>LDA identifies topic clusters such as American...</td>\n",
       "      <td>Clusters of Twitter user ids from accounts of ...</td>\n",
       "      <td>For offensive language detection in Twitter, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>How much do they outperform previous state-of-...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>On subtask 3 best proposed model has F1 score ...</td>\n",
       "      <td>Results on SemEval-2014 are presented in Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>How big is the provided treebank?</td>\n",
       "      <td>The provided treebank consists of 1,448 tweets</td>\n",
       "      <td>1448 sentences more than the dataset from Bhat...</td>\n",
       "      <td>Recently bhat-EtAl:2017:EACLshort provided a C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>what dataset was used?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nADAPT-Microsoft dat...</td>\n",
       "      <td>The dataset from a joint ADAPT-Microsoft project</td>\n",
       "      <td>The data stems from a joint ADAPT-Microsoft pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>What are the citation intent labels in the dat...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe citation intent...</td>\n",
       "      <td>Background, extends, uses, motivation, compare...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Characteristics of Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>How is quality of annotation measured?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Annotators went through various phases to make...</td>\n",
       "      <td>To control the quality, we ensured that a sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>What accuracy score do they obtain?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n85.2%</td>\n",
       "      <td>the best performing model obtained an accuracy...</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Performance evaluatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>What is the 12 class bilingual text?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nBilingual text with...</td>\n",
       "      <td>Appreciation, Satisfied, Peripheral complaint,...</td>\n",
       "      <td>FLOAT SELECTED: Table 1. Description of class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Which are the sequence model architectures thi...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nL...</td>\n",
       "      <td>The sequence model architectures which this me...</td>\n",
       "      <td>The sequence modeling layer models the depende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>What percentage of improvement in inference s...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Across 4 datasets, the best performing propose...</td>\n",
       "      <td>Table TABREF34 shows the inference speed of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>What is the metric that is measures in this pa...</td>\n",
       "      <td>ABX error rate</td>\n",
       "      <td>error rate in a minimal pair ABX discriminatio...</td>\n",
       "      <td>To test if the learned representations can sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Was evaluation metrics and criteria were used ...</td>\n",
       "      <td>Yes, evaluation metrics and criteria were used...</td>\n",
       "      <td>BLEU scores</td>\n",
       "      <td>We train all the models on an Nvidia RTX 2080T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>What are the two decoding functions?</td>\n",
       "      <td>The answer is:\\n\\nThe two decoding functions a...</td>\n",
       "      <td>a linear projection and a bijective function w...</td>\n",
       "      <td>In this case, the decoding function is a linea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>What are the domains covered in the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Alarm\\nBank\\nBus\\nCalendar\\nEvent\\nFlight\\nHom...</td>\n",
       "      <td>The 17 domains (`Alarm' domain not included in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>How are the two different models trained?</td>\n",
       "      <td>BERT-BASE and BERT-LARGE are trained using dif...</td>\n",
       "      <td>They pre-train the models using 600000 article...</td>\n",
       "      <td>We use the additional INLINEFORM0 training art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>How long is the dataset?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n6...</td>\n",
       "      <td>645, 600000</td>\n",
       "      <td>We focus primarily on the smaller data set of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>How big are negative effects of proposed techn...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nNEGLIGIBLE</td>\n",
       "      <td>The negative effects were insignificant.</td>\n",
       "      <td>We have presented adaptive schedules for multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Are this techniques used in training multiling...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nY...</td>\n",
       "      <td>English to French and English to German</td>\n",
       "      <td>We extract data from the WMT'14 English-French...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>What metric is used to measure performance?</td>\n",
       "      <td>Accuracy and F1 scores are used to measure per...</td>\n",
       "      <td>Accuracy and F1 score for supervised tasks, Pe...</td>\n",
       "      <td>We use a standard set of supervised as well as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>How do Zipf and Herdan-Heap's laws differ?</td>\n",
       "      <td>Zipf's law and Herdan-Heap's law differ in the...</td>\n",
       "      <td>Zipf's law describes change of word frequency ...</td>\n",
       "      <td>Statistical characterization of languages has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>How are the synthetic examples generated?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>Random perturbation of Wikipedia sentences usi...</td>\n",
       "      <td>One way to expose Bleurt to a wide variety of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>By how much does the new parser outperform the...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Proposed method achieves 94.5 UAS and 92.4 LAS...</td>\n",
       "      <td>Table TABREF12 compares our novel system with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>What experimental evaluation is used?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nO...</td>\n",
       "      <td>root mean square error between the actual and ...</td>\n",
       "      <td>Once the KryptoOracle engine was bootstrapped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>How is the architecture fault-tolerant?</td>\n",
       "      <td>KryptoOracle's architecture is fault-tolerant ...</td>\n",
       "      <td>By using Apache Spark which stores all executi...</td>\n",
       "      <td>KryptoOracle has been built in the Apache ecos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Which elements of the platform are modular?</td>\n",
       "      <td>The platform's modular elements include its Sp...</td>\n",
       "      <td>handling large volume incoming data, sentiment...</td>\n",
       "      <td>In this paper we provide a novel real-time and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Could you tell me more about the metrics used ...</td>\n",
       "      <td>Sure! The answer is:\\n\\nThe performance evalua...</td>\n",
       "      <td>BLUE utilizes different metrics for each of th...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: BLUE tasks The aim of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>What are the tasks that this method has shown ...</td>\n",
       "      <td>Monolingual and cross-lingual word similarity,...</td>\n",
       "      <td>bilingual dictionary induction, monolingual an...</td>\n",
       "      <td>Our experimental results show that the propose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Why does the model improve in monolingual spac...</td>\n",
       "      <td>The model improves in monolingual spaces becau...</td>\n",
       "      <td>because word pair similarity increases if the ...</td>\n",
       "      <td>As a complement of this analysis we show some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>How is annotation projection done when languag...</td>\n",
       "      <td>The annotation projection is done using word a...</td>\n",
       "      <td>Word alignments are generated for parallel tex...</td>\n",
       "      <td>AMR is not grounded in the input sentence, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>What's the precision of the system?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>0.8320 on semantic typing, 0.7194 on entity ma...</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Overall typing perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Which of the two ensembles yields the best per...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nE-BERT</td>\n",
       "      <td>Answer with content missing: (Table 2) CONCAT ...</td>\n",
       "      <td>Figure FIGREF5 shows that E-BERT performs comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>What is the new initialization method proposed...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nP...</td>\n",
       "      <td>They initialize their word and entity embeddin...</td>\n",
       "      <td>Training our model implicitly embeds the vocab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>How was a quality control performed so that th...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The authors believe that the Wikilinks corpus ...</td>\n",
       "      <td>Wikilinks can be seen as a large-scale, natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Is it a neural model? How is it trained?</td>\n",
       "      <td>No, it is not a neural model. It is a probabil...</td>\n",
       "      <td>No, it is a probabilistic model trained by fin...</td>\n",
       "      <td>Here we describe the components of our probabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>How they evaluate quality of generated output?</td>\n",
       "      <td>$n$-gram based similarity metrics and human ev...</td>\n",
       "      <td>Through human evaluation where they are asked ...</td>\n",
       "      <td>Automatic evaluation of Natural Language Gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>What are the four forums the data comes from?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nB...</td>\n",
       "      <td>Darkode,  Hack Forums, Blackhat and Nulled.</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Test set results at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>How are sentence embeddings incorporated into ...</td>\n",
       "      <td>Sentence embeddings are incorporated into the ...</td>\n",
       "      <td>BERT generates sentence embeddings that repres...</td>\n",
       "      <td>There exist many word/sentence embeddings whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>How different is the dataset size of source an...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe dataset size of...</td>\n",
       "      <td>the training dataset is large while the target...</td>\n",
       "      <td>The procedure of transfer learning in this wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>What type of documents are supported by the an...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nP...</td>\n",
       "      <td>Variety of formats supported (PDF, Word...), u...</td>\n",
       "      <td>All the capabilities described in this paper c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>What are the strong baselines you have?</td>\n",
       "      <td>The answer is:\\n\\nStrong baselines: 256 hidden...</td>\n",
       "      <td>optimize single task with no synthetic data</td>\n",
       "      <td>We optimized our single-task baseline to get a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>What are causal attribution networks?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nCausal attribution ...</td>\n",
       "      <td>networks where nodes represent causes and effe...</td>\n",
       "      <td>In this work we compare causal attribution net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>how did they ask if a tweet was racist?</td>\n",
       "      <td>They used a common sense definition of racist ...</td>\n",
       "      <td>if it includes  negative utterances, negative ...</td>\n",
       "      <td>The classification of racist insults presents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>How does the model compute the likelihood of e...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>By treating logical forms as a latent variable...</td>\n",
       "      <td>Since the training data consists only of utter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>What are state of the art methods authors comp...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nH...</td>\n",
       "      <td>ISOT dataset: LLVM\\nLiar dataset: Hybrid CNN a...</td>\n",
       "      <td>Table TABREF21 shows the performance of non-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>How much improvement do they get?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\n11.2% improvement</td>\n",
       "      <td>Their GTRS approach got an improvement of 3.89...</td>\n",
       "      <td>FLOAT SELECTED: Table 7. Experimental results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>Which languages do they test on?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Answer with content missing: (Applications sec...</td>\n",
       "      <td>Space requirements might still be considerable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>What limitations are mentioned?</td>\n",
       "      <td>Small sample size, sampling bias, low inter-ra...</td>\n",
       "      <td>deciding publisher partisanship, risk annotato...</td>\n",
       "      <td>We identified some limitations during the proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>What are the baselines?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe baselines are t...</td>\n",
       "      <td>CNN, LSTM, BERT</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results of baselines ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>What semantic features help in detecting wheth...</td>\n",
       "      <td>Content accuracy, coherence, and consistency w...</td>\n",
       "      <td>No feature is given, only discussion that sema...</td>\n",
       "      <td>Many practical fake news detection algorithms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Is the assumption that natural language is sta...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>It is not completely valid for natural languag...</td>\n",
       "      <td>Manning and Schütze argue that, even though no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>Which models do they try out?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThey try out linear...</td>\n",
       "      <td>DocQA, SAN, QANet, ASReader, LM, Random Guess</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Performance of variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>What are the competing models?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe competing model...</td>\n",
       "      <td>TEACHER FORCING (TF), SCHEDULED SAMPLING (SS),...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results on EMNLP2017 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>How is the input triple translated to a slot-f...</td>\n",
       "      <td>The input triple is translated to a slot-filli...</td>\n",
       "      <td>The relation R(x,y) is mapped onto a question ...</td>\n",
       "      <td>We show that it is possible to reduce relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>How is module that analyzes behavioral state t...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>pre-trained to identify the presence of behavi...</td>\n",
       "      <td>The behavior model was implemented using an RN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>Can the model add new relations to the knowled...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nN...</td>\n",
       "      <td>The model does not add new relations to the kn...</td>\n",
       "      <td>In ConMask, we use a similar idea to select th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>Do twitter users tend to tweet about the DOS a...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The dataset contains about 590 tweets about DD...</td>\n",
       "      <td>In this subsection we discuss the experiment o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>What is the training and test data used?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Tweets related to a Bank of America DDos attac...</td>\n",
       "      <td>We collected tweets related to five different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>What writing styles are present in the corpus?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nA variety of writin...</td>\n",
       "      <td>current news, historical news, free time, spor...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Stylistic domains and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>What meta-information is being transferred?</td>\n",
       "      <td>Relation meta and gradient meta</td>\n",
       "      <td>high-order representation of a relation, loss ...</td>\n",
       "      <td>The relation-specific meta information is help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>What datasets are used to evaluate the approach?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nN...</td>\n",
       "      <td>NELL-One, Wiki-One</td>\n",
       "      <td>We use two datasets, NELL-One and Wiki-One whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>How much is performance hurt when using too sm...</td>\n",
       "      <td>Performance can be hurt when using too small a...</td>\n",
       "      <td>comparing to the results from reducing the num...</td>\n",
       "      <td>The number of layers ($N_{src}$-$N_{mt}$-$N_{p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>What neural machine translation models can lea...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Multilingual Neural Machine Translation Models</td>\n",
       "      <td>Various multilingual extensions of NMT have al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>How does the semi-automatic construction proce...</td>\n",
       "      <td>The semi-automatic construction process works ...</td>\n",
       "      <td>Automatic transcription of 5000 tokens through...</td>\n",
       "      <td>In order to make the corpus collection easier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>What does \"explicitly leverages their probabil...</td>\n",
       "      <td>The training framework explicitly leverages th...</td>\n",
       "      <td>The framework jointly learns parametrized QA a...</td>\n",
       "      <td>Moreover, QA and QG have probabilistic correla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>What is WNGT 2019 shared task?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>efficiency task aimed  at reducing the number ...</td>\n",
       "      <td>The Transformer network BIBREF3 is a neural se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Was any variation in results observed based on...</td>\n",
       "      <td>No variation in results was observed based on ...</td>\n",
       "      <td>It is observed some variability - but not sign...</td>\n",
       "      <td>On another note, we apply our formalization to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Can the approach be generalized to other techn...</td>\n",
       "      <td>Yes. The approach can be generalized to other ...</td>\n",
       "      <td>There is no reason to think that this approach...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: NMT training after r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>What dataset they use for evaluation?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nG...</td>\n",
       "      <td>The same 2K set from Gigaword used in BIBREF7</td>\n",
       "      <td>We validate our approach on the Gigaword corpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Which regions of the United States do they con...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe lower 48 states</td>\n",
       "      <td>all regions except those that are colored black</td>\n",
       "      <td>FLOAT SELECTED: Fig 5. (A) The average verb re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>How is performance measured?</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nP...</td>\n",
       "      <td>they use ROC curves and cross-validation</td>\n",
       "      <td>To assess the predictive capability of this an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>What is novel in author's approach?</td>\n",
       "      <td>The author's approach is novel in using self-p...</td>\n",
       "      <td>They use self-play learning , optimize the mod...</td>\n",
       "      <td>Our novelties include: Using self-play learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>How large is the Dialog State Tracking Dataset?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nThe Dialog State Tr...</td>\n",
       "      <td>1,618 training dialogs, 500 validation dialogs...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Data used in this pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>What dataset is used for train/test of this me...</td>\n",
       "      <td>The training dataset is a mixture of neutral a...</td>\n",
       "      <td>Training datasets: TTS System dataset and embe...</td>\n",
       "      <td>Experimental Protocol ::: Datasets ::: Trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>How much is the gap between using the proposed...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>The mixed objective improves EM by 2.5% and F1...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Ablation study on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>How many domains of ontologies do they gather ...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\n4...</td>\n",
       "      <td>5 domains: software, stuff, african wildlife, ...</td>\n",
       "      <td>The Software Ontology (SWO) BIBREF5 is include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>what is the practical application for this paper?</td>\n",
       "      <td>Improving natural language processing (NLP) me...</td>\n",
       "      <td>Improve existing NLP methods. Improve linguist...</td>\n",
       "      <td>Morphology deals with the internal structure o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>What's the method used here?</td>\n",
       "      <td>BERT-based encoder-decoder framework with LSTM...</td>\n",
       "      <td>Two neural networks: an extractor based on an ...</td>\n",
       "      <td>Our model consists of two neural network modul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>By how much does their method outperform state...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...</td>\n",
       "      <td>The goal of this paper is to propose a novel O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>What are dilated convolutions?</td>\n",
       "      <td>Dilated convolutions are a type of convolution...</td>\n",
       "      <td>Similar to standard convolutional networks but...</td>\n",
       "      <td>In this work we focus on end-to-end stateless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>what are the three methods presented in the pa...</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nBERT, RoBERTa, and ...</td>\n",
       "      <td>Optimized TF-IDF, iterated TF-IDF, BERT re-ran...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: MAP scoring of new me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>what datasets did the authors use?</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Kaggle\\nSubversive Kaggle\\nWikipedia\\nSubversi...</td>\n",
       "      <td>We trained and tested our neural network with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>How much performance improvements they achieve...</td>\n",
       "      <td>Sure! Here's the answer to your question based...</td>\n",
       "      <td>Compared to baselines SAN (Table 1) shows  imp...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Test performance on S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>What is the baseline?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nA baseline multi-ta...</td>\n",
       "      <td>The baseline is a multi-task architecture insp...</td>\n",
       "      <td>We compare the results of our model to a basel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>What is the network architecture?</td>\n",
       "      <td>A multi-task Bi-Directional Recurrent Neural N...</td>\n",
       "      <td>The network architecture has a multi-task Bi-D...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Our Hierarchical Net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>What does recurrent deep stacking network do?</td>\n",
       "      <td>RDSN stacks and concatenates the outputs of pr...</td>\n",
       "      <td>Stacks and joins outputs of previous frames wi...</td>\n",
       "      <td>As indicated in its name, Recurrent Deep Stack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>What is the reward model for the reinforcement...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nT...</td>\n",
       "      <td>reward 1 for successfully completing the task,...</td>\n",
       "      <td>We defined the reward as being 1 for successfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Does this paper propose a new task that others...</td>\n",
       "      <td>No. The paper does not propose a new task, but...</td>\n",
       "      <td>No, there has been previous work on recognizin...</td>\n",
       "      <td>Interesting prior work on quantifying social n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>How big is their dataset?</td>\n",
       "      <td>2.1 million predicate instances</td>\n",
       "      <td>3 million webpages processed with a CCG parser...</td>\n",
       "      <td>Much recent work on semantic parsing has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>What task do they evaluate on?</td>\n",
       "      <td>Sure! Here's my answer:\\n\\nOpen-domain fill-in...</td>\n",
       "      <td>Fill-in-the-blank natural language questions</td>\n",
       "      <td>We demonstrate our approach on the task of ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>How many feature maps are generated for a give...</td>\n",
       "      <td>Sure! Here's the answer to your question:\\n\\nτ...</td>\n",
       "      <td>3 feature maps for a given tuple</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Process involved in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                    what language pairs are explored?   \n",
       "1              what are the topics pulled from Reddit?   \n",
       "2      What accuracy does the proposed system achieve?   \n",
       "3                 What crowdsourcing platform is used?   \n",
       "4    On how many language pairs do they show that p...   \n",
       "5    Which information about text structure is incl...   \n",
       "6    What experiments are proposed to test that upp...   \n",
       "7    How do they calculate a static embedding for e...   \n",
       "8         What is the performance of BERT on the task?   \n",
       "9                   how is model compactness measured?   \n",
       "10                 Who were the human evaluators used?   \n",
       "11   Which methods are considered to find examples ...   \n",
       "12               What biases are found in the dataset?   \n",
       "13   What discourse relations does it work best/wor...   \n",
       "14   On top of BERT does the RNN layer work better ...   \n",
       "15                        How was this data collected?   \n",
       "16               What is the average length of dialog?   \n",
       "17   How does the IPA label data after interacting ...   \n",
       "18                    How was the audio data gathered?   \n",
       "19                     What is the GhostVLAD approach?   \n",
       "20   Which 7 Indian languages do they experiment with?   \n",
       "21                What is the invertibility condition?   \n",
       "22   Which neural architecture do they use as a bas...   \n",
       "23                 What metric is used for evaluation?   \n",
       "24         Which eight NER tasks did they evaluate on?   \n",
       "25   Do they focus on Reading Comprehension or mult...   \n",
       "26         After how many hops does accuracy decrease?   \n",
       "27                       What languages are evaluated?   \n",
       "28                             What is MSD prediction?   \n",
       "29               What other models do they compare to?   \n",
       "30                 What evaluation metric do they use?   \n",
       "31   What are the results from these proposed strat...   \n",
       "32          How much better than the baseline is LiLi?   \n",
       "33   What are the components of the general knowled...   \n",
       "34               How many labels do the datasets have?   \n",
       "35             What are the source and target domains?   \n",
       "36   How do they deal with unknown distribution sen...   \n",
       "37   What conclusions do the authors draw from thei...   \n",
       "38                         How id Depechemood trained?   \n",
       "39   How are similarities and differences between t...   \n",
       "40   How are prominent topics idenified in Dabiq an...   \n",
       "41                            Which datasets are used?   \n",
       "42         What are previous state of the art results?   \n",
       "43   What source-target language pairs were used in...   \n",
       "44       How large is their MNER SnapCaptions dataset?   \n",
       "45                 What is masked document generation?   \n",
       "46     What useful information does attention capture?   \n",
       "47   In what cases is attention different from alig...   \n",
       "48           Which baselines did they compare against?   \n",
       "49                   What baselines did they consider?   \n",
       "50                      How was the dataset annotated?   \n",
       "51                   What is the size of this dataset?   \n",
       "52                      Where does the data come from?   \n",
       "53    Ngrams of which length are aligned using PARENT?   \n",
       "54   How many people participated in their evaluati...   \n",
       "55   By how much more does PARENT correlate with hu...   \n",
       "56   Which stock market sector achieved the best pe...   \n",
       "57   How do the authors evidence the claim that man...   \n",
       "58                         what datasets did they use?   \n",
       "59   How much does their model outperform existing ...   \n",
       "60                What was the baseline for this task?   \n",
       "61         What is a second order co-ocurrence matrix?   \n",
       "62                       How many humans participated?   \n",
       "63   What word level and character level model base...   \n",
       "64            How were the human judgements assembled?   \n",
       "65   Which other approaches do they compare their m...   \n",
       "66   What results do they achieve using their propo...   \n",
       "67   How do they combine a deep learning model with...   \n",
       "68   What are the models used for the baseline of t...   \n",
       "69       How is non-standard pronunciation identified?   \n",
       "70             What novel PMI variants are introduced?   \n",
       "71   What are the disadvantages to clipping negativ...   \n",
       "72   Why are statistics from finite corpora unrelia...   \n",
       "73   Which two pairs of ERPs from the literature be...   \n",
       "74                             What datasets are used?   \n",
       "75            which datasets did they experiment with?   \n",
       "76   What kind of celebrities do they obtain tweets...   \n",
       "77   How did they extend LAMA evaluation framework ...   \n",
       "78   What summarization algorithms did the authors ...   \n",
       "79   What methods were used for sentence classifica...   \n",
       "80        What modern MRC gold standards are analyzed?   \n",
       "81            What language is explored in this paper?   \n",
       "82             How long of dialog history is captured?   \n",
       "83           What was the score of the proposed model?   \n",
       "84                  What hyperparameters are explored?   \n",
       "85   what aspects of conversation flow do they look...   \n",
       "86                       what is the state of the art?   \n",
       "87           What is the Random Kitchen Sink approach?   \n",
       "88               How do they define similar equations?   \n",
       "89    What are the three steps to feature elimination?   \n",
       "90                       How is the dataset annotated?   \n",
       "91   Which architecture do they use for the encoder...   \n",
       "92               How does their decoder generate text?   \n",
       "93            What dataset is used to train the model?   \n",
       "94   Which race and gender are given higher sentime...   \n",
       "95   What criteria are used to select the 8,640 Eng...   \n",
       "96                            what were the baselines?   \n",
       "97           what competitive results did they obtain?   \n",
       "98   By how much is performance improved with multi...   \n",
       "99            How much is performance improved on NLI?   \n",
       "100                           What is active learning?   \n",
       "101                             what was the baseline?   \n",
       "102             How is segmentation quality evaluated?   \n",
       "103                      How do they compare lexicons?   \n",
       "104  How larger are the training sets of these vers...   \n",
       "105  What is the improvement in performance for Est...   \n",
       "106               what is the state of the art on WSJ?   \n",
       "107         what is the size of the augmented dataset?   \n",
       "108  Why are current ELS's not sufficiently effective?   \n",
       "109       How many sentences does the dataset contain?   \n",
       "110                              What is the baseline?   \n",
       "111                   What is the size of the dataset?   \n",
       "112  How many different types of entities exist in ...   \n",
       "113             How big is the new Nepali NER dataset?   \n",
       "114  What is the performance improvement of the gra...   \n",
       "115  Which variation provides the best results on t...   \n",
       "116  What are the different variations of the atten...   \n",
       "117                What dataset is used for this work?   \n",
       "118         What were the datasets used in this paper?   \n",
       "119            What is the performance of classifiers?   \n",
       "120                What classifiers have been trained?   \n",
       "121         How many layers does the UTCNN model have?   \n",
       "122                            What are the baselines?   \n",
       "123        What transfer learning tasks are evaluated?   \n",
       "124  What other sentence embeddings methods are eva...   \n",
       "125  Which shallow approaches did they experiment w...   \n",
       "126  which non-english language had the best perfor...   \n",
       "127  how did the authors translate the reviews to o...   \n",
       "128  What are the five different binary classificat...   \n",
       "129  How was the spatial aspect of the EEG signal c...   \n",
       "130                Which real-world datasets are used?   \n",
       "131  How are the interpretability merits of the app...   \n",
       "132  How are the accuracy merits of the approach de...   \n",
       "133                      What is a wizard of oz setup?   \n",
       "134                       What baseline model is used?   \n",
       "135  How do they determine the exact section to use...   \n",
       "136  What features are used to represent the novelt...   \n",
       "137  What features are used to represent the salien...   \n",
       "138                      How was annotation performed?   \n",
       "139  What activation function do they use in their ...   \n",
       "140                            How are chunks defined?   \n",
       "141          How big is the dataset used in this work?   \n",
       "142    How is a \"chunk of posts\" defined in this work?   \n",
       "143                 Which evaluation methods are used?   \n",
       "144  How are sentences selected from the summary gr...   \n",
       "145               What is the size of the new dataset?   \n",
       "146      What kinds of offensive content are explored?   \n",
       "147  How long is the dataset for each step of hiera...   \n",
       "148  In the proposed metric, how is content relevan...   \n",
       "149  What different correlations result when using ...   \n",
       "150        how is mitigation of gender bias evaluated?   \n",
       "151                         What tasks were evaluated?   \n",
       "152           What are their results on both datasets?   \n",
       "153               by how much did their model improve?   \n",
       "154               what are the sizes of both datasets?   \n",
       "155  What are the distinctive characteristics of ho...   \n",
       "156             How many annotators tagged each tweet?   \n",
       "157  In what way is the offensive dataset not biase...   \n",
       "158  What are the difficulties in modelling the iro...   \n",
       "159   How did the authors find ironic data on twitter?   \n",
       "160  Who judged the irony accuracy, sentiment prese...   \n",
       "161                     How were the tweets annotated?   \n",
       "162                         What are hashtag features?   \n",
       "163  For how many probe tasks the shallow-syntax-aw...   \n",
       "164                What are the black-box probes used?   \n",
       "165  How does this model overcome the assumption th...   \n",
       "166  What are the industry classes defined in this ...   \n",
       "167        What are the hyperparameters of the bi-GRU?   \n",
       "168  Does the algorithm improve on the state-of-the...   \n",
       "169        What background knowledge do they leverage?   \n",
       "170                   What NLP tasks do they consider?   \n",
       "171          How do they define robustness of a model?   \n",
       "172  Are the annotations automatic or manually crea...   \n",
       "173                How long are the essays on average?   \n",
       "174    What neural models are used to encode the text?   \n",
       "175          What TIMIT datasets are used for testing?   \n",
       "176        What state-of-the-art results are achieved?   \n",
       "177               What baselines do they compare with?   \n",
       "178              What datasets are used in evaluation?   \n",
       "179               What is the tagging scheme employed?   \n",
       "180  How they extract \"structured answer-relevant r...   \n",
       "181              How big are significant improvements?   \n",
       "182                         What dataset did they use?   \n",
       "183                  What was their highest MRR score?   \n",
       "184  How do they measure which words are under-tran...   \n",
       "185  How do their models decide how much improtance...   \n",
       "186  Which data do they use as a starting point for...   \n",
       "187  How do they select instances to their hold-out...   \n",
       "188  How do the authors examine whether a model is ...   \n",
       "189  What type of system does the baseline classifi...   \n",
       "190                What are the user-defined keywords?   \n",
       "191          What are the baselines used in the paper?   \n",
       "192  How better is performance compared to previous...   \n",
       "193  How does Gaussian-masked directional multi-hea...   \n",
       "194    What are strong baselines model is compared to?   \n",
       "195  What additional features and context are propo...   \n",
       "196  What evidence do the authors present that the ...   \n",
       "197                      What are the existing biases?   \n",
       "198              What biases does their model capture?   \n",
       "199         which neural embedding model works better?   \n",
       "200  What is the degree of dimension reduction of t...   \n",
       "201  For which languages do they build word embeddi...   \n",
       "202  What experiments do they use to quantify the e...   \n",
       "203  What is the additive modification to the objec...   \n",
       "204  How do they encourage understanding of literat...   \n",
       "205  Why challenges does word segmentation in Vietn...   \n",
       "206  How successful are the approaches used to solv...   \n",
       "207    Which two news domains are country-independent?   \n",
       "208  How is the political bias of different sources...   \n",
       "209                     How was the dataset collected?   \n",
       "210         How do they verify generalization ability?   \n",
       "211  Do they only use adjacent entity mentions or u...   \n",
       "212     Why is lemmatization not necessary in English?   \n",
       "213      How big was the corpora they trained ELMo on?   \n",
       "214                              What dataset is used?   \n",
       "215       What does the \"sensitivity\" quantity denote?   \n",
       "216                What end tasks do they evaluate on?   \n",
       "217              What is a semicharacter architecture?   \n",
       "218  Why is the adversarial setting appropriate for...   \n",
       "219                How do the backoff strategies work?   \n",
       "220         which algorithm was the highest performer?   \n",
       "221                             what dataset was used?   \n",
       "222  How large are the improvements of the Attentio...   \n",
       "223  Which machine learning methods are used in exp...   \n",
       "224                      how was the speech collected?   \n",
       "225                        what topics did they label?   \n",
       "226  what levels of document preprocessing are look...   \n",
       "227  what keyphrase extraction models were reassessed?   \n",
       "228  How many different phenotypes are present in t...   \n",
       "229   What are 10 other phenotypes that are annotated?   \n",
       "230          What are the network's baseline features?   \n",
       "231                What tasks are used for evaluation?   \n",
       "232  HOw does the method perform compared with base...   \n",
       "233                      What baseline method is used?   \n",
       "234  What details are given about the Twitter dataset?   \n",
       "235  What details are given about the movie domain ...   \n",
       "236         what pretrained word embeddings were used?   \n",
       "237               What evaluation metrics did look at?   \n",
       "238                            What datasets are used?   \n",
       "239  How much improvement is gained from Adversaria...   \n",
       "240     why are their techniques cheaper to implement?   \n",
       "241                              what dataset is used?   \n",
       "242                  what language pairs are explored?   \n",
       "243  What are the organic and inorganic ways to sho...   \n",
       "244  How do profile changes vary for influential le...   \n",
       "245          how small of a dataset did they train on?   \n",
       "246               what was their character error rate?   \n",
       "247           which lstm models did they compare with?   \n",
       "248  Do they use datasets with transcribed text or ...   \n",
       "249                      By how much did they improve?   \n",
       "250                         What dataset did they use?   \n",
       "251  Which natural language(s) are studied in this ...   \n",
       "252              What metrics are used for evaluation?   \n",
       "253  What natural language(s) are the recipes writt...   \n",
       "254  Which multiple datasets did they train on duri...   \n",
       "255  what is the size of the real-world civil case ...   \n",
       "256                  What rouge score do they achieve?   \n",
       "257   What was their performance on emotion detection?   \n",
       "258  What is the benchmark dataset and is its quali...   \n",
       "259                       How do they detect spammers?   \n",
       "260                            What are the baselines?   \n",
       "261                         What datasets do they use?   \n",
       "262            What domains are covered in the corpus?   \n",
       "263  By how much does their best model outperform t...   \n",
       "264          How does their simple voting scheme work?   \n",
       "265  How do they obtain the new context represetation?   \n",
       "266           What is the performance of the baseline?   \n",
       "267     What was the performance of multilingual BERT?   \n",
       "268  What is an unordered text document, do these a...   \n",
       "269          Who were the experts used for annotation?   \n",
       "270  Is this hashtag prediction task an established...   \n",
       "271     What other tasks do they test their method on?   \n",
       "272     What is the state of the art system mentioned?   \n",
       "273                   Do they use large or small BERT?   \n",
       "274          What is their system's absolute accuracy?   \n",
       "275  Which is more useful, visual or textual features?   \n",
       "276                       Which languages do they use?   \n",
       "277                       How large is their data set?   \n",
       "278                what linguistics features are used?   \n",
       "279              what dataset statistics are provided?   \n",
       "280                        how was the data collected?   \n",
       "281  What is best performing model among author's s...   \n",
       "282  What extracted features were most influencial ...   \n",
       "283  Did ensemble schemes help in boosting peforman...   \n",
       "284  Which basic neural architecture perform best b...   \n",
       "285  What participating systems had better results ...   \n",
       "286  What is specific to multi-granularity and mult...   \n",
       "287  How much training data from the non-English la...   \n",
       "288   How is the model transferred to other languages?   \n",
       "289       How was the StackExchange dataset collected?   \n",
       "290     What is the size of the StackExchange dataset?   \n",
       "291                           What were the baselines?   \n",
       "292  What labels for antisocial events are availabl...   \n",
       "293         What are two datasets model is applied to?   \n",
       "294                         What is the McGurk effect?   \n",
       "295  what phenomena do they mention is hard to capt...   \n",
       "296            by how much did the BLEU score improve?   \n",
       "297                                       What is NER?   \n",
       "298  How better does new approach behave than exist...   \n",
       "299  How much is classification performance improve...   \n",
       "300             What subtasks did they participate in?   \n",
       "301                         What dataset did they use?   \n",
       "302                 What are the 12 languages covered?   \n",
       "303  What type of evaluation is proposed for this t...   \n",
       "304                  What baseline system is proposed?   \n",
       "305  How were crowd workers instructed to identify ...   \n",
       "306                  How is pseudo-perplexity defined?   \n",
       "307               What is the model architecture used?   \n",
       "308       How is the data used for training annotated?   \n",
       "309                what quantitative analysis is done?   \n",
       "310               by how much did nus outperform abus?   \n",
       "311          Which dataset has been used in this work?   \n",
       "312                  What can word subspace represent?   \n",
       "313  How big are improvements of small-scale unbala...   \n",
       "314                    How big is dataset for testing?   \n",
       "315  What are the qualitative experiments performed...   \n",
       "316  What were their results on the classification ...   \n",
       "317  Which hyperparameters were varied in the exper...   \n",
       "318                   How were the cluster extracted?    \n",
       "319                  what were the evaluation metrics?   \n",
       "320                   what english datasets were used?   \n",
       "321                  which chinese datasets were used?   \n",
       "322              What were their distribution results?   \n",
       "323           How did they determine fake news tweets?   \n",
       "324    What is their definition of tweets going viral?   \n",
       "325  What are the characteristics of the accounts t...   \n",
       "326  How is the ground truth for fake news establis...   \n",
       "327  Where does the ancient Chinese dataset come from?   \n",
       "328  How big is the difference in performance betwe...   \n",
       "329  In what 8 languages is PolyResponse engine use...   \n",
       "330  How many question types do they find in the da...   \n",
       "331  How do they analyze contextual similaries acro...   \n",
       "332               What were their performance results?   \n",
       "333  What datasets are used to assess the performan...   \n",
       "334            IS the graph representation supervised?   \n",
       "335  Is the G-BERT model useful beyond the task con...   \n",
       "336  Do they introduce errors in the data or does t...   \n",
       "337  What is the difference of the proposed model w...   \n",
       "338  Does the model evaluated on NLG datasets or di...   \n",
       "339      How is the quality of singing voice measured?   \n",
       "340     what previous RNN models do they compare with?   \n",
       "341  What are the languages they use in their exper...   \n",
       "342         How do they match annotators to instances?   \n",
       "343  How much data is needed to train the task-spec...   \n",
       "344                          Who are the crowdworkers?   \n",
       "345  Which sentiment class is the most accurately p...   \n",
       "346                           what were the baselines?   \n",
       "347                         What BERT models are used?   \n",
       "348  What experiments are used to demonstrate the b...   \n",
       "349            Which component is the least impactful?   \n",
       "350  Which component has the greatest impact on per...   \n",
       "351             What is the message passing framework?   \n",
       "352                  What is the best reported system?   \n",
       "353                  What cognitive features are used?   \n",
       "354  What approaches do they use towards text analy...   \n",
       "355                          What is the seed lexicon?   \n",
       "356                              What are the results?   \n",
       "357      How are relations used to propagate polarity?   \n",
       "358                      How big is the Japanese data?   \n",
       "359  How big are improvements of supervszed learnin...   \n",
       "360  How does their model learn using mostly raw data?   \n",
       "361         How big is seed lexicon used for training?   \n",
       "362  How do the various social phenomena examined m...   \n",
       "363  How did the select the 300 Reddit communities ...   \n",
       "364  How is the clinical text structuring task defi...   \n",
       "365  Is all text in this dataset a question, or are...   \n",
       "366             How many questions are in the dataset?   \n",
       "367  What aspects have been compared between variou...   \n",
       "368  How many attention layers are there in their m...   \n",
       "369  What are the three measures of bias which are ...   \n",
       "370                            How big is the dataset?   \n",
       "371      How is the intensity of the PTSD established?   \n",
       "372                           how is quality measured?   \n",
       "373  What is the accuracy reported by state-of-the-...   \n",
       "374  How do the authors define or exemplify 'incorr...   \n",
       "375  By how much do they outperform other models in...   \n",
       "376                    Which experiments are perfomed?   \n",
       "377                      Is ROUGE their only baseline?   \n",
       "378  By how much does their system outperform the l...   \n",
       "379  How are the main international development top...   \n",
       "380  Is the semantic hierarchy representation used ...   \n",
       "381                            Is the model evaluated?   \n",
       "382  How better is accuracy of new model compared t...   \n",
       "383           How does the active learning model work?   \n",
       "384            Did the annotators agreed and how much?   \n",
       "385  What datasets are used to evaluate this approach?   \n",
       "386                     How was the dataset collected?   \n",
       "387  What models other than standalone BERT is new ...   \n",
       "388  How big is the performance difference between ...   \n",
       "389  What approaches without reinforcement learning...   \n",
       "390               Which languages do they validate on?   \n",
       "391          What is the baseline method for the task?   \n",
       "392  what amounts of size were used on german-english?   \n",
       "393                            How big is the dataset?   \n",
       "394                            What MC abbreviate for?   \n",
       "395                What are their correlation results?   \n",
       "396               What simpler models do they look at?   \n",
       "397     What linguistic quality aspects are addressed?   \n",
       "398                          What dataset do they use?   \n",
       "399  What is typical GAN architecture for each text...   \n",
       "400               What language do the agents talk in?   \n",
       "401  How much better is performance of proposed met...   \n",
       "402                       What baseline model is used?   \n",
       "403  What stylistic features are used to detect dru...   \n",
       "404    What is the accuracy of the proposed technique?   \n",
       "405     Which retrieval system was used for baselines?   \n",
       "406  How much better was the BLSTM-CNN-CRF than the...   \n",
       "407  What supplemental tasks are used for multitask...   \n",
       "408  How much performance gap between their approac...   \n",
       "409                            How big is their model?   \n",
       "410                 How many emotions do they look at?   \n",
       "411  What approach did previous models use for mult...   \n",
       "412  What is difference in peformance between propo...   \n",
       "413  What is the performance of proposed model on e...   \n",
       "414  How accurate is the aspect based sentiment cla...   \n",
       "415  What were the non-neural baselines used for th...   \n",
       "416                  What are the models evaluated on?   \n",
       "417  What is the results of multimodal compared to ...   \n",
       "418               What were their performance results?   \n",
       "419  By how much did they outperform the other meth...   \n",
       "420                      What is the state of the art?   \n",
       "421  What difficulties does sentiment analysis on T...   \n",
       "422  How many sentence transformations on average a...   \n",
       "423     What annotations are available in the dataset?   \n",
       "424  How are possible sentence transformations repr...   \n",
       "425  What are all 15 types of modifications ilustra...   \n",
       "426     What were their results on the three datasets?   \n",
       "427                  What semantic rules are proposed?   \n",
       "428              What is the performance of the model?   \n",
       "429  What was the performance of both approaches on...   \n",
       "430                           What genres are covered?   \n",
       "431  Which of the two speech recognition models wor...   \n",
       "432  By how much is performance on CN-Celeb inferio...   \n",
       "433            How do the authors measure performance?   \n",
       "434   What is the latest paper covered by this survey?   \n",
       "435  What learning paradigms do they cover in this ...   \n",
       "436  What are all the input modalities considered i...   \n",
       "437  How do this framework facilitate demographic i...   \n",
       "438                         How is the data annotated?   \n",
       "439  Where does the information on individual-level...   \n",
       "440  What is the source of the user interaction data?    \n",
       "441           What is the source of the textual data?    \n",
       "442            What is the source of the visual data?    \n",
       "443  What result from experiments suggest that natu...   \n",
       "444              Which datasets are used in the paper?   \n",
       "445              How do they quantify moral relevance?   \n",
       "446  How much is proposed model better in perplexit...   \n",
       "447  Do they train a different training method exce...   \n",
       "448  How do they define upward and downward reasoning?   \n",
       "449  Do they annotate their own dataset or use an e...   \n",
       "450  What kind of neural network architecture do th...   \n",
       "451  What web and user-generated NER datasets are u...   \n",
       "452        Which unlabeled data do they pretrain with?   \n",
       "453  How many convolutional layers does their model...   \n",
       "454                          How big are the datasets?   \n",
       "455  What baselines did they compare their model with?   \n",
       "456           What was the performance of their model?   \n",
       "457                  What evaluation metrics are used?   \n",
       "458    How were the navigation instructions collected?   \n",
       "459           What language is the experiment done in?   \n",
       "460  What additional features are proposed for futu...   \n",
       "461       What are their initial results on this task?   \n",
       "462  How is morphology knowledge implemented in the...   \n",
       "463      How is the performance on the task evaluated?   \n",
       "464                           what datasets were used?   \n",
       "465               How do they obtain human judgements?   \n",
       "466  Does this approach perform better in the multi...   \n",
       "467  How many samples did they generate for the art...   \n",
       "468  Why does not the approach from English work on...   \n",
       "469                How do they measure grammaticality?   \n",
       "470  What is the difference in recall score between...   \n",
       "471                 What is their f1 score and recall?   \n",
       "472            How many layers does their system have?   \n",
       "473      What context modelling methods are evaluated?   \n",
       "474  Is the baseline a non-heirarchical model like ...   \n",
       "475  How better are results compared to baseline mo...   \n",
       "476      How big is dataset used for training/testing?   \n",
       "477   What geometric properties do embeddings display?   \n",
       "478  How accurate is model trained on text exclusiv...   \n",
       "479  What was their result on Stance Sentiment Emot...   \n",
       "480  What performance did they obtain on the SemEva...   \n",
       "481             What are the state-of-the-art systems?   \n",
       "482       What is the size of their collected dataset?   \n",
       "483  What kind of features are used by the HMM mode...   \n",
       "484  What kind of information do the HMMs learn tha...   \n",
       "485  How large is the gap in performance between th...   \n",
       "486            what was their system's f1 performance?   \n",
       "487      How much more coverage is in the new dataset?   \n",
       "488                          How was quality measured?   \n",
       "489  What is different in the improved annotation p...   \n",
       "490  What data were they used to train the multilin...   \n",
       "491         From when are many VQA datasets collected?   \n",
       "492               What is task success rate achieved?    \n",
       "493  Does proposed end-to-end approach learn in rei...   \n",
       "494        How is performance of this system measured?   \n",
       "495  How big dataset is used for training this system?   \n",
       "496       How do they obtain word lattices from words?   \n",
       "497  How better is proposed method than baselines p...   \n",
       "498  Who manually annotated the semantic roles for ...   \n",
       "499  How do they obtain region descriptions and obj...   \n",
       "500  Which training dataset allowed for the best ge...   \n",
       "501                        Which models were compared?   \n",
       "502                         What is private dashboard?   \n",
       "503                          What is public dashboard?   \n",
       "504                          What dataset do they use?   \n",
       "505  Do the use word embeddings alone or they repla...   \n",
       "506  How many natural language explanations are hum...   \n",
       "507  What is the dataset used as input to the Word2...   \n",
       "508  What methodology is used to compensate for lim...   \n",
       "509     What are the baseline state of the art models?   \n",
       "510           How do they extract causality from text?   \n",
       "511        What is the source of the \"control\" corpus?   \n",
       "512  What are the selection criteria for \"causal st...   \n",
       "513  Do they use expert annotations, crowdsourcing,...   \n",
       "514         how do they collect the comparable corpus?   \n",
       "515            How do they collect the control corpus?   \n",
       "516               What are resolution model variables?   \n",
       "517  Is the model presented in the paper state of t...   \n",
       "518  What was the result of the highest performing ...   \n",
       "519                What do they mean by answer styles?   \n",
       "520  What are the baselines that Masque is compared...   \n",
       "521   What is the performance achieved on NarrativeQA?   \n",
       "522                         What is an \"answer style\"?   \n",
       "523              How are the EAU text spans annotated?   \n",
       "524  Which Twitter corpus was used to train the wor...   \n",
       "525  How does proposed word embeddings compare to S...   \n",
       "526           How many uniue words are in the dataset?   \n",
       "527                   Which baseline methods are used?   \n",
       "528                        How much is the BLEU score?   \n",
       "529            Which datasets are used in experiments?   \n",
       "530   What are new best results on standard benchmark?   \n",
       "531  How better is performance compared to competit...   \n",
       "532          What 6 language pairs is experimented on?   \n",
       "533  How do they enrich the positional embedding wi...   \n",
       "534  How do they condition the output to a given ta...   \n",
       "535  Is this library implemented into Torch or is f...   \n",
       "536  How does this compare to traditional calibrati...   \n",
       "537  What's the input representation of OpenIE tupl...   \n",
       "538  Is CRWIZ already used for data collection, wha...   \n",
       "539                 What contextual features are used?   \n",
       "540                How is the data in RAFAEL labelled?   \n",
       "541  How is the fluctuation in the sense of the wor...   \n",
       "542  By how much does SPNet outperforms state-of-th...   \n",
       "543  Is it expected to have speaker role, semantic ...   \n",
       "544  How does new evaluation metric considers criti...   \n",
       "545  What are state of the art methods MMM is compa...   \n",
       "546  What are the problems related to ambiguity in ...   \n",
       "547             How is knowledge stored in the memory?   \n",
       "548   How do they measure the diversity of inferences?   \n",
       "549  By how much do they improve the accuracy of in...   \n",
       "550  How does the context-aware variational autoenc...   \n",
       "551  How much improvement does their method get ove...   \n",
       "552  By how much do they outpeform previous results...   \n",
       "553   How many paraphrases are generated per question?   \n",
       "554  How strong was the correlation between exercis...   \n",
       "555  How were topics of interest about DDEO identif...   \n",
       "556               How do their train their embeddings?   \n",
       "557                 How do they model travel behavior?   \n",
       "558           How do their interpret the coefficients?   \n",
       "559  By how much do they outperform previous state-...   \n",
       "560  What is the performance difference between pro...   \n",
       "561                       What benchmarks are created?   \n",
       "562  What percentage fewer errors did professional ...   \n",
       "563  What was the weakness in Hassan et al's evalua...   \n",
       "564  What evidence do they present that the model a...   \n",
       "565             In what way is the input restructured?   \n",
       "566           What language is the Twitter content in?   \n",
       "567  What evaluations did the authors use on their ...   \n",
       "568              What accuracy does CNN model achieve?   \n",
       "569  How many documents are in the Indiscapes dataset?   \n",
       "570             What are simulated datasets collected?   \n",
       "571  What human evaluation metrics were used in the...   \n",
       "572  For the purposes of this paper, how is somethi...   \n",
       "573  What type of model are the ELMo representation...   \n",
       "574  By how much does using phonetic feedback impro...   \n",
       "575                            what are the baselines?   \n",
       "576            What are the results of the experiment?   \n",
       "577                     How was the dataset collected?   \n",
       "578                  How many annotators participated?   \n",
       "579  How do they show their model discovers underly...   \n",
       "580  How do they measure performance of language mo...   \n",
       "581  How are content clusters used to improve the p...   \n",
       "582  What cluster identification method is used in ...   \n",
       "583           Why did they think this was a good idea?   \n",
       "584                          What QA models were used?   \n",
       "585  How do their results compare against other com...   \n",
       "586              On which task does do model do worst?   \n",
       "587               On which task does do model do best?   \n",
       "588  How does counterfactual data augmentation aim ...   \n",
       "589  In the targeted data collection approach, what...   \n",
       "590  How do they determine which words are informat...   \n",
       "591  What improvement does the MOE model make over ...   \n",
       "592  What is the difference in performance between ...   \n",
       "593    Which language-pair had the better performance?   \n",
       "594  Which psycholinguistic and basic linguistic fe...   \n",
       "595  How have the differences in communication styl...   \n",
       "596  What data/studies do the authors provide to su...   \n",
       "597      What datasets are used to evaluate the model?   \n",
       "598      What baseline models do they compare against?   \n",
       "599  What are the differences with previous applica...   \n",
       "600  How much improvement is gained from the propos...   \n",
       "601  Is infinite-length sequence generation a resul...   \n",
       "602             How big is dataset for this challenge?   \n",
       "603  How better is performance of proposed model co...   \n",
       "604                                What DCGs are used?   \n",
       "605  What is the performance difference of using a ...   \n",
       "606          What evaluation metrics did they look at?   \n",
       "607           What are the datasets used for the task?   \n",
       "608  What is the accuracy of the model for the six ...   \n",
       "609  Which models achieve state-of-the-art performa...   \n",
       "610  Which competitive relational classification mo...   \n",
       "611  How do they gather human judgements for simila...   \n",
       "612       What text classification task is considered?   \n",
       "613  What novel class of recurrent-like networks is...   \n",
       "614  How much bigger is Switchboard-2000 than Switc...   \n",
       "615           What domains are detected in this paper?   \n",
       "616  Why do they think this task is hard?  What is ...   \n",
       "617        How do they generate the synthetic dataset?   \n",
       "618          What is the average length of the claims?   \n",
       "619    What debate topics are included in the dataset?   \n",
       "620  By how much, the proposed method improves BiDA...   \n",
       "621  What are the linguistic differences between ea...   \n",
       "622              what genres do they songs fall under?   \n",
       "623  To what other competitive baselines is this ap...   \n",
       "624  How is human evaluation performed, what was th...   \n",
       "625  How much better were results of the proposed m...   \n",
       "626  Which one of the four proposed models performe...   \n",
       "627  How much is proposed model better than baselin...   \n",
       "628               By how much is precission increased?   \n",
       "629                    What labels are in the dataset?   \n",
       "630  How are customer satisfaction, customer frustr...   \n",
       "631  How many improvements on the French-German tra...   \n",
       "632  How do they prevent the model complexity incre...   \n",
       "633                    How do they measure model size?   \n",
       "634  Which model architecture do they for sentence ...   \n",
       "635                    Which data sources do they use?   \n",
       "636  How were breast cancer related posts compiled ...   \n",
       "637  What machine learning and NLP methods were use...   \n",
       "638  What approach performs better in experiments g...   \n",
       "639  Which translation system do they use to transl...   \n",
       "640   Which pre-trained English NER model do they use?   \n",
       "641  How much of the ASR grapheme set is shared bet...   \n",
       "642     What are the languages used to test the model?   \n",
       "643  Which language has the lowest error rate reduc...   \n",
       "644                        How is moral bias measured?   \n",
       "645              What metrics are used for evaluation?   \n",
       "646                    How much training data is used?   \n",
       "647             How does their model differ from BERT?   \n",
       "648  How does explicit constraint on the KL diverge...   \n",
       "649                             what was the baseline?   \n",
       "650                           How big is dataset used?   \n",
       "651  How much better does this baseline neural mode...   \n",
       "652                      What are the baseline models?   \n",
       "653  By how much of MGNC-CNN out perform the baseli...   \n",
       "654  What is increase in percentage of humor contai...   \n",
       "655  What are the languages they consider in this p...   \n",
       "656  Did they experiment with tasks other than word...   \n",
       "657                  What evaluation metrics are used?   \n",
       "658  What kind of Youtube video transcripts did the...   \n",
       "659              What makes it a more reliable metric?   \n",
       "660  How much in experiments is performance improve...   \n",
       "661               How is the delta-softmax calculated?   \n",
       "662    Which two datasets does the resource come from?   \n",
       "663            What is the size of the second dataset?   \n",
       "664                    How large is the first dataset?   \n",
       "665                      Who was the top-scoring team?   \n",
       "666     Why is big data not appropriate for this task?   \n",
       "667  What is an example of a computational social s...   \n",
       "668      Which major geographical regions are studied?   \n",
       "669  How strong is the correlation between the prev...   \n",
       "670  How are the topics embedded in the #MeToo twee...   \n",
       "671  Which geographical regions correlate to the tr...   \n",
       "672  What two components are included in their prop...   \n",
       "673  Which modifications do they make to well-estab...   \n",
       "674                            How was speed measured?   \n",
       "675      What were their accuracy results on the task?   \n",
       "676  What two types the Chinese reading comprehensi...   \n",
       "677  For which languages most of the existing MRC d...   \n",
       "678      Which sentiment analysis tasks are addressed?   \n",
       "679              Which 3 NLP areas are cited the most?   \n",
       "680  Which journal and conference are cited the mos...   \n",
       "681  Which 5 languages appear most frequently in AA...   \n",
       "682  How much F1 was improved after adding skip con...   \n",
       "683  How much gain does the model achieve with pret...   \n",
       "684       What is the highest accuracy score achieved?   \n",
       "685     What are the three datasets used in the paper?   \n",
       "686  What is improvement in accuracy for short Joke...   \n",
       "687      What baseline did they compare Entity-GCN to?   \n",
       "688       How did they get relations between mentions?   \n",
       "689               How did they detect entity mentions?   \n",
       "690  What performance does the Entity-GCN get on WI...   \n",
       "691                   What document context was added?   \n",
       "692     What were the results of the first experiment?   \n",
       "693  By how much does their model outperform existi...   \n",
       "694            What is the performance of their model?   \n",
       "695       How do they damage different neural modules?   \n",
       "696                         How long are the datasets?   \n",
       "697                  What are the sources of the data?   \n",
       "698                 What is the new labeling strategy?   \n",
       "699                   How are their changes evaluated?   \n",
       "700                 What are the six target languages?   \n",
       "701          What is the size of the released dataset?   \n",
       "702                    Which OpenIE systems were used?   \n",
       "703            how are the bidirectional lms obtained?   \n",
       "704               what metrics are used in evaluation?   \n",
       "705                      what results do they achieve?   \n",
       "706            what previous systems were compared to?   \n",
       "707  Are this models usually semi/supervised or uns...   \n",
       "708  When they say \"comparable performance\", how mu...   \n",
       "709  What types of word representations are they ev...   \n",
       "710  What type of recurrent layers does the model use?   \n",
       "711                  What is a word confusion network?   \n",
       "712  What evaluation metrics were used in the exper...   \n",
       "713  What kind of instructional videos are in the d...   \n",
       "714           What baseline algorithms were presented?   \n",
       "715  How does TP-N2F compare to LSTM-based Seq2Seq ...   \n",
       "716  What is the performance proposed model achieve...   \n",
       "717  What is the performance proposed model achieve...   \n",
       "718  What previous methods is the proposed method c...   \n",
       "719                   What is the baseline model used?   \n",
       "720              What domains are present in the data?   \n",
       "721  How many texts/datapoints are in the SemEval, ...   \n",
       "722  In which languages did the approach outperform...   \n",
       "723                       Which is the baseline model?   \n",
       "724       What is the main contribution of the paper?    \n",
       "725              How do they get the formal languages?   \n",
       "726            What is a confusion network or lattice?   \n",
       "727  How close do clusters match to ground truth to...   \n",
       "728                   what are the evaluation metrics?   \n",
       "729            which datasets were used in evaluation?   \n",
       "730                            what are the baselines?   \n",
       "731    What monolingual word representations are used?   \n",
       "732  Do they build one model per topic or on all to...   \n",
       "733  Do they quantitavely or qualitatively evalute ...   \n",
       "734  How well does their system perform on the deve...   \n",
       "735  Which of the classifiers showed the best perfo...   \n",
       "736  How are the keywords associated with events su...   \n",
       "737  What is different in BERT-gen from standard BERT?   \n",
       "738       How are multimodal representations combined?   \n",
       "739  What is the problem with existing metrics that...   \n",
       "740             How are discourse embeddings analyzed?   \n",
       "741  How are discourse features incorporated into t...   \n",
       "742                  What discourse features are used?   \n",
       "743                              What are proof paths?   \n",
       "744                    What external sources are used?   \n",
       "745  How much better peformance is achieved in huma...   \n",
       "746  How much transcribed data is available for for...   \n",
       "747  What baseline approaches do they compare against?   \n",
       "748         how many domains did they experiment with?   \n",
       "749                           How long is the dataset?   \n",
       "750                           What is a string kernel?   \n",
       "751  How do they correlate NED with emotional bond ...   \n",
       "752  What was their F1 score on the Bengali NER cor...   \n",
       "753                   What is the size of the dataset?   \n",
       "754  How many examples do they have in the target d...   \n",
       "755                        What is the baseline model?   \n",
       "756                  Where did they get training data?   \n",
       "757                What extraction model did they use?   \n",
       "758             Which datasets did they experiment on?   \n",
       "759  How do slot binary classifiers improve perform...   \n",
       "760        What baselines have been used in this work?   \n",
       "761                  what bottlenecks were identified?   \n",
       "762  By how much do they outperform BiLSTMs in Sent...   \n",
       "763        what state of the accuracy did they obtain?   \n",
       "764                   what models did they compare to?   \n",
       "765      which benchmark tasks did they experiment on?   \n",
       "766           How is the proficiency score calculated?   \n",
       "767  What proficiency indicators are used to the sc...   \n",
       "768  What accuracy is achieved by the speech recogn...   \n",
       "769    How is the speech recognition system evaluated?   \n",
       "770        How many of the utterances are transcribed?   \n",
       "771             How many utterances are in the corpus?   \n",
       "772  By how much does their model outperform both t...   \n",
       "773                      What is the state-of-the art?   \n",
       "774  What was the performance on the self-collected...   \n",
       "775                 What is the size of their dataset?   \n",
       "776                         how was the dataset built?   \n",
       "777  what processing was done on the speeches befor...   \n",
       "778  What is the performance change of the textual ...   \n",
       "779  Which sentiment analysis data set has a larger...   \n",
       "780  How much is pre-training loss increased in Low...   \n",
       "781      What is the average length of the recordings?   \n",
       "782                           What were their results?   \n",
       "783      What is the prediction accuracy of the model?   \n",
       "784             What is the dataset used in the paper?   \n",
       "785  How does the SCAN dataset evaluate composition...   \n",
       "786   How much does this system outperform prior work?   \n",
       "787  What are the baseline systems that are compare...   \n",
       "788                           What systems are tested?   \n",
       "789                  What benchmark datasets they use?   \n",
       "790             How do they combine MonaLog with BERT?   \n",
       "791             How do they select monotonicity facts?   \n",
       "792                What are the 12 categories devised?   \n",
       "793  what are the off-the-shelf systems discussed i...   \n",
       "794                  How many rules had to be defined?   \n",
       "795  What was performance of classifiers before/aft...   \n",
       "796                     How big are the datasets used?   \n",
       "797  What datasets are used for training/testing mo...   \n",
       "798  How better is gCAS approach compared to other ...   \n",
       "799                     What is specific to gCAS cell?   \n",
       "800          What is the source of external knowledge?   \n",
       "801              What were the sizes of the test sets?   \n",
       "802                           Which datasets are used?   \n",
       "803  How much does it minimally cost to fine-tune s...   \n",
       "804  What models are included in baseline benchmark...   \n",
       "805  It looks like learning to paraphrase questions...   \n",
       "806  How much more accurate is the model than the b...   \n",
       "807  What is new state-of-the-art performance on Co...   \n",
       "808  What are two strong baseline methods authors r...   \n",
       "809             How many category tags are considered?   \n",
       "810            What domain does the dataset fall into?   \n",
       "811                             How are EAC evaluated?   \n",
       "812                             What is triangulation?   \n",
       "813                        What languages do they use?   \n",
       "814                  How they evaluate their approach?   \n",
       "815                           How large is the corpus?   \n",
       "816                          How large is the dataset?   \n",
       "817                   What was their perplexity score?   \n",
       "818                 What parallel corpus did they use?   \n",
       "819  In which setting they achieve the state of the...   \n",
       "820    What they formulate the question generation as?   \n",
       "821  Was the degree of offensiveness taken as how g...   \n",
       "822         Which embeddings do they detect biases in?   \n",
       "823             What are the two PharmaCoNER subtasks?   \n",
       "824             How do they perform data augmentation?   \n",
       "825  What are the characteristics of the city dialect?   \n",
       "826  What are the characteristics of the rural dial...   \n",
       "827  What is the performance of the models on the t...   \n",
       "828  What other non-neural baselines do the authors...   \n",
       "829          On what dataset is Aristo system trained?   \n",
       "830                       How many roles are proposed?   \n",
       "831  What language technologies have been introduce...   \n",
       "832                 How do they define local variance?   \n",
       "833            how do they measure discussion quality?   \n",
       "834                           what were the baselines?   \n",
       "835     Which soft-selection approaches are evaluated?   \n",
       "836                    How big is slot filing dataset?   \n",
       "837            How large is the dataset they generate?   \n",
       "838  What are the weaknesses of their proposed inte...   \n",
       "839  What advantages does their proposed method of ...   \n",
       "840                How was lexical diversity measured?   \n",
       "841  Which existing models does this approach outpe...   \n",
       "842          What human evaluation method is proposed?   \n",
       "843     What languages are represented in the dataset?   \n",
       "844  How faster is training and decoding compared t...   \n",
       "845      What datasets are used to evaluate the model?   \n",
       "846                 What is the source of the dataset?   \n",
       "847                           What were the baselines?   \n",
       "848                         What metadata is included?   \n",
       "849  Do the images have multilingual annotations or...   \n",
       "850  How much important is the visual grounding in ...   \n",
       "851             How is the generative model evaluated?   \n",
       "852      What is an example of a health-related tweet?   \n",
       "853  What is the challenge for other language excep...   \n",
       "854  How many categories of offensive language were...   \n",
       "855            Which matching features do they employ?   \n",
       "856  By how much does their method outperform the m...   \n",
       "857                  How large is the corpus they use?   \n",
       "858          How many shared layers are in the system?   \n",
       "859  How many additional task-specific layers are i...   \n",
       "860  How many layers of self-attention does the mod...   \n",
       "861             what are the state of the art methods?   \n",
       "862      Which four languages do they experiment with?   \n",
       "863  Does DCA or GMM-based attention perform better...   \n",
       "864                    What evaluation metric is used?   \n",
       "865  Is any data-to-text generation model trained o...   \n",
       "866  How are the potentially relevant text fragment...   \n",
       "867                         What dataset did they use?   \n",
       "868                   What is the size of the dataset?   \n",
       "869  What are the 12 AV approaches which are examined?   \n",
       "870                           how was annotation done?   \n",
       "871  How do they measure correlation between the pr...   \n",
       "872  What are the results achieved from the introdu...   \n",
       "873              How do they incorporate human advice?   \n",
       "874            What affective-based features are used?   \n",
       "875  How big is performance improvement proposed me...   \n",
       "876  By how much does transfer learning improve per...   \n",
       "877                             What baseline is used?   \n",
       "878         What topic clusters are identified by LDA?   \n",
       "879  How much do they outperform previous state-of-...   \n",
       "880                  How big is the provided treebank?   \n",
       "881                             what dataset was used?   \n",
       "882  What are the citation intent labels in the dat...   \n",
       "883             How is quality of annotation measured?   \n",
       "884                What accuracy score do they obtain?   \n",
       "885               What is the 12 class bilingual text?   \n",
       "886  Which are the sequence model architectures thi...   \n",
       "887   What percentage of improvement in inference s...   \n",
       "888  What is the metric that is measures in this pa...   \n",
       "889  Was evaluation metrics and criteria were used ...   \n",
       "890               What are the two decoding functions?   \n",
       "891       What are the domains covered in the dataset?   \n",
       "892          How are the two different models trained?   \n",
       "893                           How long is the dataset?   \n",
       "894  How big are negative effects of proposed techn...   \n",
       "895  Are this techniques used in training multiling...   \n",
       "896        What metric is used to measure performance?   \n",
       "897         How do Zipf and Herdan-Heap's laws differ?   \n",
       "898          How are the synthetic examples generated?   \n",
       "899  By how much does the new parser outperform the...   \n",
       "900              What experimental evaluation is used?   \n",
       "901            How is the architecture fault-tolerant?   \n",
       "902        Which elements of the platform are modular?   \n",
       "903  Could you tell me more about the metrics used ...   \n",
       "904  What are the tasks that this method has shown ...   \n",
       "905  Why does the model improve in monolingual spac...   \n",
       "906  How is annotation projection done when languag...   \n",
       "907                What's the precision of the system?   \n",
       "908  Which of the two ensembles yields the best per...   \n",
       "909  What is the new initialization method proposed...   \n",
       "910  How was a quality control performed so that th...   \n",
       "911           Is it a neural model? How is it trained?   \n",
       "912     How they evaluate quality of generated output?   \n",
       "913      What are the four forums the data comes from?   \n",
       "914  How are sentence embeddings incorporated into ...   \n",
       "915  How different is the dataset size of source an...   \n",
       "916  What type of documents are supported by the an...   \n",
       "917            What are the strong baselines you have?   \n",
       "918              What are causal attribution networks?   \n",
       "919            how did they ask if a tweet was racist?   \n",
       "920  How does the model compute the likelihood of e...   \n",
       "921  What are state of the art methods authors comp...   \n",
       "922                  How much improvement do they get?   \n",
       "923                   Which languages do they test on?   \n",
       "924                    What limitations are mentioned?   \n",
       "925                            What are the baselines?   \n",
       "926  What semantic features help in detecting wheth...   \n",
       "927  Is the assumption that natural language is sta...   \n",
       "928                      Which models do they try out?   \n",
       "929                     What are the competing models?   \n",
       "930  How is the input triple translated to a slot-f...   \n",
       "931  How is module that analyzes behavioral state t...   \n",
       "932  Can the model add new relations to the knowled...   \n",
       "933  Do twitter users tend to tweet about the DOS a...   \n",
       "934           What is the training and test data used?   \n",
       "935     What writing styles are present in the corpus?   \n",
       "936        What meta-information is being transferred?   \n",
       "937   What datasets are used to evaluate the approach?   \n",
       "938  How much is performance hurt when using too sm...   \n",
       "939  What neural machine translation models can lea...   \n",
       "940  How does the semi-automatic construction proce...   \n",
       "941  What does \"explicitly leverages their probabil...   \n",
       "942                     What is WNGT 2019 shared task?   \n",
       "943  Was any variation in results observed based on...   \n",
       "944  Can the approach be generalized to other techn...   \n",
       "945              What dataset they use for evaluation?   \n",
       "946  Which regions of the United States do they con...   \n",
       "947                       How is performance measured?   \n",
       "948                What is novel in author's approach?   \n",
       "949    How large is the Dialog State Tracking Dataset?   \n",
       "950  What dataset is used for train/test of this me...   \n",
       "951  How much is the gap between using the proposed...   \n",
       "952  How many domains of ontologies do they gather ...   \n",
       "953  what is the practical application for this paper?   \n",
       "954                       What's the method used here?   \n",
       "955  By how much does their method outperform state...   \n",
       "956                     What are dilated convolutions?   \n",
       "957  what are the three methods presented in the pa...   \n",
       "958                 what datasets did the authors use?   \n",
       "959  How much performance improvements they achieve...   \n",
       "960                              What is the baseline?   \n",
       "961                  What is the network architecture?   \n",
       "962      What does recurrent deep stacking network do?   \n",
       "963  What is the reward model for the reinforcement...   \n",
       "964  Does this paper propose a new task that others...   \n",
       "965                          How big is their dataset?   \n",
       "966                     What task do they evaluate on?   \n",
       "967  How many feature maps are generated for a give...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    English (En), Arabic (Ar), Spanish (Es), and R...   \n",
       "1           politics, business, science, and AskReddit   \n",
       "2    Sure! Here's the answer to your question based...   \n",
       "3    Sure! Here's my answer:\\n\\nAmazon Mechanical T...   \n",
       "4    Sure! Here's the answer to your question based...   \n",
       "5    Text structure information included in the cor...   \n",
       "6    The experiments proposed to test that upper la...   \n",
       "7    Sure! Here's the answer to your question:\\n\\nT...   \n",
       "8    BERT outperforms all other systems in terms of...   \n",
       "9    Sure! Here's my answer:\\n\\nModel compactness i...   \n",
       "10   20 evaluators were recruited from the institution   \n",
       "11   The answer is:\\n\\n1. Tagging descriptions with...   \n",
       "12   The dataset appears to have biases in the way ...   \n",
       "13   The model works best for the Temporal discours...   \n",
       "14   The Transformer layer works better than the RN...   \n",
       "15   Through crowdsourcing on the platform CrowdFlo...   \n",
       "16                Sure! Here's my answer:\\n\\n3.5 turns   \n",
       "17   The IPA labels data after interacting with use...   \n",
       "18   The audio data was gathered from the All India...   \n",
       "19   GhostVLAD is an extension of the NetVLAD appro...   \n",
       "20   Kannada, Hindi, Telugu, Malayalam, Bengali, an...   \n",
       "21   The invertibility condition is that INLINEFORM...   \n",
       "22   Sure! Here's the answer to your question based...   \n",
       "23                                            F1 score   \n",
       "24   Sure! Here's the answer to your question:\\n\\nT...   \n",
       "25                  Multiple choice question answering   \n",
       "26                                              2 hops   \n",
       "27       Sure! Here's my answer:\\n\\nEnglish and German   \n",
       "28   MSD prediction is predicting the morphosyntact...   \n",
       "29   They compare to R.M.-Reader + Verifier, a more...   \n",
       "30   Sure! Here's the answer to your question:\\n\\nR...   \n",
       "31   Sure! Here's the answer to your question based...   \n",
       "32   LiLi outperforms the baseline by a significant...   \n",
       "33   The components of the general knowledge learni...   \n",
       "34   Sure! Here's the answer to your question:\\n\\nT...   \n",
       "35   The answer is:\\n\\nSource domain: Book (BK), El...   \n",
       "36   By modifying a naïve Bayesian classifier to re...   \n",
       "37   The authors conclude that both ISIS and Cathol...   \n",
       "38   Depechemood was trained using a lexicon-based ...   \n",
       "39   Similarities and differences between the texts...   \n",
       "40   Non-negative matrix factorization (NMF) was us...   \n",
       "41                              ShapeWorldICE datasets   \n",
       "42   The previous state-of-the-art results are show...   \n",
       "43   En-XX, Zh-XX, Jp-XX, Kr-XX (source-target lang...   \n",
       "44                                              10,000   \n",
       "45   Masked Document Generation (MDG) is a task tha...   \n",
       "46   Attention captures information beyond alignmen...   \n",
       "47   Attention differs from alignment for VERB and ...   \n",
       "48   They compared against previous treestructured ...   \n",
       "49   Sure! Here's the answer to your question based...   \n",
       "50   The dataset was annotated manually by grouping...   \n",
       "51   Sure! Here's the answer to your question:\\n\\n2...   \n",
       "52   The data comes from crowdsourcing tasks, inclu...   \n",
       "53   Sure! Here's the answer to your question based...   \n",
       "54   Sure! Here's the answer to your question based...   \n",
       "55   PARENT correlates significantly better with hu...   \n",
       "56   Sure! Here's the answer to your question:\\n\\nT...   \n",
       "57   The authors evidence the claim by surveying en...   \n",
       "58   The dataset used was a collection of 3500 ques...   \n",
       "59   The neural extractive models outperform existi...   \n",
       "60   A very simple logistic regression classifier w...   \n",
       "61   A second-order co-occurrence matrix is a matri...   \n",
       "62            9 medical coders and 4 medical residents   \n",
       "63   The word level and character level model basel...   \n",
       "64   The human judgements were assembled by a group...   \n",
       "65   Sure! Here's the answer to your question:\\n\\nE...   \n",
       "66   The proposed approach achieves F-1 scores betw...   \n",
       "67   By using a redirection list and a disambiguati...   \n",
       "68   The baseline models used for the three NLP tas...   \n",
       "69   Non-standard pronunciation is identified throu...   \n",
       "70                  The answer is:\\n\\nNPMI and NNEGPMI   \n",
       "71   Sure! Here's the answer to the question at the...   \n",
       "72   The statistics from finite corpora are unrelia...   \n",
       "73                    N400 and P600, and N400 and N200   \n",
       "74   The datasets used are ERP data and eye-trackin...   \n",
       "75   Sure! Here's the answer to your question:\\n\\nU...   \n",
       "76      Sure! Here's my answer:\\n\\nTwitter celebrities   \n",
       "77   They introduced the negated LAMA dataset by si...   \n",
       "78   The authors experimented with a few summarizat...   \n",
       "79   The answer is:\\n\\nFor sentence classification,...   \n",
       "80           BIBREF15, BIBREF28, BIBREF7, and TABREF19   \n",
       "81                  Sure! Here's my answer:\\n\\nENGLISH   \n",
       "82                                      2 dialog turns   \n",
       "83   Sure! Here's the answer to your question:\\n\\nT...   \n",
       "84   The hyperparameters explored are the choice of...   \n",
       "85   Conversational flow features such as self-cove...   \n",
       "86   Sure! Here's my answer:\\n\\nThe answer is:\\n\\nF...   \n",
       "87   The Random Kitchen Sink (RKS) approach is a me...   \n",
       "88   They define similar equations using Euclidean ...   \n",
       "89   The answer is:\\n\\nThe three steps to feature e...   \n",
       "90   The dataset is annotated with depression-relat...   \n",
       "91   The encoder uses a combination of convolutiona...   \n",
       "92   The decoder generates text by predicting the t...   \n",
       "93   The dataset used to train the model is the col...   \n",
       "94                         Female and African American   \n",
       "95   The 8,640 English sentences were selected base...   \n",
       "96   Sure! Here's the answer to your question:\\n\\nT...   \n",
       "97   Competitive results were obtained on both WSJ ...   \n",
       "98   Performance is improved by approximately 0.02 ...   \n",
       "99      4% absolute gain over BERTBase on the NLI task   \n",
       "100  Sure! Here's my answer:\\n\\nActive learning is ...   \n",
       "101               The baseline was a strong NMT system   \n",
       "102  Segmentation quality is evaluated based on the...   \n",
       "103  The experts and crowd contributors have simila...   \n",
       "104  The training sets of these versions of ELMo ar...   \n",
       "105  Sure! Here's the answer to your question based...   \n",
       "106                                    INLINEFORM2 WER   \n",
       "107   The size of the augmented dataset is 500 samples   \n",
       "108  Low precision rates and design challenges in t...   \n",
       "109  Sure! Here's the answer to your question:\\n\\n6946   \n",
       "110  Sure! Here's the answer to your question based...   \n",
       "111          The size of the dataset is 1000 sentences   \n",
       "112     Sure! Here's the answer to your question:\\n\\n3   \n",
       "113  Sure! Here's the answer to your question based...   \n",
       "114  Sure! Here's the answer to your question based...   \n",
       "115  Sure! Here's the answer to your question based...   \n",
       "116  Four variations of the attention-based approac...   \n",
       "117  The dataset used for this work is the SociaL M...   \n",
       "118  The dataset used in this paper is a Twitter da...   \n",
       "119  Sure! Here's the answer to your question based...   \n",
       "120  Sure! Here's the answer to your question:\\n\\nK...   \n",
       "121                                           4 layers   \n",
       "122  SVM with unigram, bigram, and trigram features...   \n",
       "123  The seven SentEval transfer tasks evaluated ar...   \n",
       "124       InferSent and the Universal Sentence Encoder   \n",
       "125  Sure! Here's the answer to your question based...   \n",
       "126                                              Dutch   \n",
       "127  The authors used machine translation to transl...   \n",
       "128  The answer is:\\n\\nThe five different binary cl...   \n",
       "129  The spatial aspect of the EEG signal was compu...   \n",
       "130                    CyberAttack and PoliticianDeath   \n",
       "131  By providing human-understandable explanations...   \n",
       "132  The approach demonstrates significant improvem...   \n",
       "133  A Wizard of Oz setup is a simulated informatio...   \n",
       "134  B1. The first baseline uses only the salience-...   \n",
       "135  They use a multi-class classification problem ...   \n",
       "136  The novelty of news articles is represented by...   \n",
       "137  Baseline features, such as positional features...   \n",
       "138  Annotation was performed using WebAnno BIBREF7...   \n",
       "139                                             $relu$   \n",
       "140  Chunks are defined as sorted sequences of twee...   \n",
       "141  The dataset used in this work consists of 212 ...   \n",
       "142  A \"chunk of posts\" is defined as a sorted sequ...   \n",
       "143                      ROGUE-1, ROGUE-2, and ROGUE-L   \n",
       "144  The sentences are selected from the summary gr...   \n",
       "145          The size of the new dataset is 300 tweets   \n",
       "146  Targeted and untargeted insults and threats, a...   \n",
       "147  The answer is:\\n\\nThe dataset size for each st...   \n",
       "148  Content relevance is measured using informatio...   \n",
       "149  Different correlations result when using diffe...   \n",
       "150  The mitigation of gender bias is evaluated usi...   \n",
       "151  The 8 tasks evaluated in ReviewQA are:\\n\\n1. A...   \n",
       "152  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "153  The answer is:\\n\\nTheir model improved by 2.11...   \n",
       "154  The answer is:\\n\\nWikiSmall: 89,042 sentence p...   \n",
       "155  The answer is:\\n\\nArabic speakers use offensiv...   \n",
       "156  Sure! Here's the answer to your question:\\n\\nO...   \n",
       "157  The offensive dataset is not biased by topic, ...   \n",
       "158  The difficulties in modelling the ironic patte...   \n",
       "159  The authors crawled over 2M tweets from Twitte...   \n",
       "160  Four annotators who are proficient in English ...   \n",
       "161  The tweets were annotated with stance informat...   \n",
       "162  Sure! Here's the answer to your question:\\n\\nH...   \n",
       "163  Sure! Here's the answer to your question based...   \n",
       "164  Sure! Here's the answer to your question based...   \n",
       "165  The Adversarial-neural Event Model (AEM) overc...   \n",
       "166  Sure! Here's my answer:\\n\\nThe industry classe...   \n",
       "167  The hyperparameters of the bi-GRU are:\\n\\n* Ba...   \n",
       "168  Sure! Here's the answer to your question based...   \n",
       "169                Labeled features as prior knowledge   \n",
       "170  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "171  The authors define robustness of a model as it...   \n",
       "172                                   Manually created   \n",
       "173  The average length of the essays is approximat...   \n",
       "174  Sure! Here's the answer to your question:\\n\\nN...   \n",
       "175                                               D, H   \n",
       "176  Sure! Here's my answer:\\n\\nThe state-of-the-ar...   \n",
       "177  Sure! Here's my answer:\\n\\nThey compare with t...   \n",
       "178                                            BIBREF9   \n",
       "179                                        INLINEFORM0   \n",
       "180  They extract \"structured answer-relevant relat...   \n",
       "181  Sure! Here's the answer to your question based...   \n",
       "182                      They used the Phase B dataset   \n",
       "183                                             0.6103   \n",
       "184  By using estimated word importance to detect u...   \n",
       "185  By using integrated gradients to calculate the...   \n",
       "186  Nurse-initiated telephone conversations for co...   \n",
       "187  They select instances for their hold-out test ...   \n",
       "188  By using adversarial sets, specifically AddSen...   \n",
       "189  Sure! Here's the answer to your question based...   \n",
       "190                $\\lbrace subway, manhattan\\rbrace $   \n",
       "191  Sure! Here's my answer:\\n\\nThe baselines used ...   \n",
       "192  Sure! Here's the answer to your question based...   \n",
       "193  Sure! Here's the answer to your question:\\n\\nG...   \n",
       "194  Sure! Here's the answer to your question based...   \n",
       "195  Context tweets are proposed as additional feat...   \n",
       "196  The authors present evidence that the model ca...   \n",
       "197  Existing biases in hate speech detection datas...   \n",
       "198  The model captures biases from data collection...   \n",
       "199  Sure! Here's the answer to your question based...   \n",
       "200                       Sure! Here's my answer:\\n\\n3   \n",
       "201                 Sure! Here's my answer:\\n\\nENGLISH   \n",
       "202  Word intrusion test and semantic category-base...   \n",
       "203  The additive modification to the objective fun...   \n",
       "204  By categorizing each model based on the optimi...   \n",
       "205  Word segmentation in Vietnamese poses challeng...   \n",
       "206  Sure! Here's the answer to your question based...   \n",
       "207  Mainstream and disinformation news domains are...   \n",
       "208  The political bias of different sources is inc...   \n",
       "209  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "210  They verify generalization ability by evaluati...   \n",
       "211  They use more than just adjacent entity mentio...   \n",
       "212  It is not entirely true that lemmatization is ...   \n",
       "213  The corpora they trained ELMo on were approxim...   \n",
       "214                            English WIKIBIO dataset   \n",
       "215  The sensitivity quantity denotes the expected ...   \n",
       "216  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "217                      A semi-character architecture   \n",
       "218  Adversarial misspellings are appropriate for m...   \n",
       "219  The backoff strategies work by either passing ...   \n",
       "220  Sure! Here's the answer to your question:\\n\\nI...   \n",
       "221                Amazon search terms and editor tags   \n",
       "222  Sure! Here's the answer to your question based...   \n",
       "223  Sure! Here's the answer to your question:\\n\\nS...   \n",
       "224  The speech was collected using an Android appl...   \n",
       "225  The topics labeled in the HPI notes include de...   \n",
       "226  The answer is:\\n\\nThree incremental levels of ...   \n",
       "227  Sure! Here's my answer:\\n\\nThe keyphrase extra...   \n",
       "228    Sure! Here's the answer to your question:\\n\\n13   \n",
       "229  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "230  Sure! Here's the answer to your question:\\n\\n1...   \n",
       "231                          Machine translation tasks   \n",
       "232  The method performs similarly or slightly bett...   \n",
       "233  Sure! Here's the answer to your question:\\n\\nS...   \n",
       "234  The Twitter dataset has 1,716 tweets, with 973...   \n",
       "235  The answer is:\\n\\nThe movie domain dataset has...   \n",
       "236   GloVe BIBREF13 and Edinburgh embeddings BIBREF14   \n",
       "237  Sure! Here's the answer to your question based...   \n",
       "238  The dataset used is a collection of 124 questi...   \n",
       "239  Sure! Here's the answer to your question based...   \n",
       "240  Because they do not require the availability o...   \n",
       "241                            Europarl corpus BIBREF5   \n",
       "242                  English-German and English-French   \n",
       "243  The answer is:\\n\\nOrganic ways to show politic...   \n",
       "244  Influential leads are more likely to make chan...   \n",
       "245                                         1000 hours   \n",
       "246  The answer is:\\n\\nThe character error rate (CE...   \n",
       "247  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "248  They use both datasets with transcribed text a...   \n",
       "249  They improved by 2.5% absolute improvement in ...   \n",
       "250  The dataset used was the fine-grained sentimen...   \n",
       "251                                            English   \n",
       "252  The metrics used for evaluation are:\\n\\n* BPE ...   \n",
       "253                                            ENGLISH   \n",
       "254  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "255  The size of the real-world civil case dataset ...   \n",
       "256  The answer is:\\n\\nTheir Rouge scores on the CN...   \n",
       "257  Sure! Here's my answer:\\n\\nThe model achieved ...   \n",
       "258  The benchmark dataset is the Social Honeypot d...   \n",
       "259  Sure! Here's the answer to your question based...   \n",
       "260  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "261  They use three datasets: imdb400, yelp50, and ...   \n",
       "262  Sure! Here's my answer:\\n\\nThe corpus covers a...   \n",
       "263  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "264  The simple voting scheme works by applying mul...   \n",
       "265  They propose a new context representation call...   \n",
       "266                   Sure! Here's my answer:\\n\\n82.6%   \n",
       "267  Sure! Here's the answer to your question based...   \n",
       "268  Sure! Here's the answer to your question:\\n\\nA...   \n",
       "269  Seven experts with legal training were used fo...   \n",
       "270                                        Established   \n",
       "271  Sure! Here's the answer to your question based...   \n",
       "272  Sure! Here's the answer to your question:\\n\\nO...   \n",
       "273                    Small BERT (BERT$_\\text{BASE}$)   \n",
       "274  Sure! Here's the answer to your question based...   \n",
       "275  Both visual and textual features are useful fo...   \n",
       "276                                            English   \n",
       "277          Their dataset consists of 29,794 articles   \n",
       "278  The answer is:\\n\\nSegmentation, POS tagging, s...   \n",
       "279  The answer is:\\n\\n* 87% of questions had a cle...   \n",
       "280  Sure! Here's the answer to your question based...   \n",
       "281  Sure! Here's my answer:\\n\\nThe author's best-p...   \n",
       "282  The pre-trained embeddings (FastText or BERT) ...   \n",
       "283  Yes, ensemble schemes helped in boosting perfo...   \n",
       "284  Sure! Here's my answer based on the given cont...   \n",
       "285  Sure! Here's my answer:\\n\\nOnly one system (Sy...   \n",
       "286  Multi-granularity and multi-tasking neural arc...   \n",
       "287  Sure! Here's the answer to your question based...   \n",
       "288  The model is transferred to other languages by...   \n",
       "289  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "290                  Sure! Here's my answer:\\n\\n10,000   \n",
       "291  The baselines were four non-neural extractive ...   \n",
       "292               Personal attacks and rule violations   \n",
       "293  The two datasets the model is applied to are t...   \n",
       "294  The McGurk effect is a phenomenon where the pe...   \n",
       "295  Sure! Here's the answer to your question based...   \n",
       "296  Sure! Here's the answer to your question:\\n\\n0...   \n",
       "297  Named Entity Recognition (NER) in the Biomedic...   \n",
       "298  New approach performs significantly better tha...   \n",
       "299  The answer is:\\n\\nIn experiments for low data ...   \n",
       "300  Sure! Here's the answer to your question:\\n\\nE...   \n",
       "301  They used the Affect in Tweets Distant Supervi...   \n",
       "302  The answer is:\\n\\n12 languages covered in Mult...   \n",
       "303       Sure! Here's my answer:\\n\\nManual evaluation   \n",
       "304      The proposed baseline system is not specified   \n",
       "305  Crowd workers were instructed to identify impo...   \n",
       "306  Sure! Here's the answer to your question based...   \n",
       "307  A VQA deep learning architecture that combines...   \n",
       "308  The data used for training is annotated with a...   \n",
       "309  Sure! Here's my answer:\\n\\nDescriptive statist...   \n",
       "310  NUS outperformed ABUS by approximately 5.5% (9...   \n",
       "311                                  Reuters-8 dataset   \n",
       "312  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "313  Improvements of small-scale unbalanced dataset...   \n",
       "314  The testing dataset contains approximately 15 ...   \n",
       "315  Qualitative experiments were performed on benc...   \n",
       "316  The answer is:\\n\\nOn the classification task, ...   \n",
       "317  The answer is:\\n\\nThe hyperparameters varied i...   \n",
       "318  Sure! Here's the answer to your question based...   \n",
       "319  The evaluation metrics used in the study were ...   \n",
       "320  Sure! Here's my answer:\\n\\nThe dataset used wa...   \n",
       "321       Sure! Here's my answer:\\n\\nCUHK03 and CUHK07   \n",
       "322  The distribution results for viral tweets cont...   \n",
       "323  Sure! Here's the answer to your question based...   \n",
       "324  According to the context, the definition of tw...   \n",
       "325  Accounts spreading fake news have a higher cha...   \n",
       "326                         Manually, with limitations   \n",
       "327  Ancient Chinese history records and articles w...   \n",
       "328  Sure! Here's the answer to your question based...   \n",
       "329  English, German, Spanish, Mandarin, Polish, Ru...   \n",
       "330  Sure! Here's the answer to your question based...   \n",
       "331  They do not analyze contextual similarities ac...   \n",
       "332  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "333  The system's performance is assessed using the...   \n",
       "334                                                 NO   \n",
       "335                                                Yes   \n",
       "336  Sure! Here's the answer to your question based...   \n",
       "337  The proposed model with a Refinement Adjustmen...   \n",
       "338  Sure! Here's the answer to your question:\\n\\nN...   \n",
       "339  The quality of singing voice is measured using...   \n",
       "340  Sure! Here's my answer:\\n\\nstate-of-the-art me...   \n",
       "341                      English, Spanish, and Finnish   \n",
       "342  Sure! Here's the answer to your question based...   \n",
       "343                                   57,505 sentences   \n",
       "344  Crowdworkers are individuals located in the US...   \n",
       "345                                           NEGATIVE   \n",
       "346  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "347  Sure! Here's my answer:\\n\\nBERT-base and BERT-...   \n",
       "348  The experiments used to demonstrate the benefi...   \n",
       "349  The number of message passing iterations (n) h...   \n",
       "350           The number of message passing iterations   \n",
       "351  The message passing framework is a method for ...   \n",
       "352                                The MILR classifier   \n",
       "353  Sure! Here's my answer:\\n\\nMemory, Attention, ...   \n",
       "354  They use a combination of quantitative and qua...   \n",
       "355  The seed lexicon is a set of positive and nega...   \n",
       "356  Sure! Here's the answer to your question based...   \n",
       "357  Relations are used to propagate polarity throu...   \n",
       "358  The Japanese data consists of approximately 10...   \n",
       "359  Sure! Here's my answer:\\n\\nImprovements of sup...   \n",
       "360  By exploiting discourse relations to efficient...   \n",
       "361  Sure! Here's the answer to your question:\\n\\n1...   \n",
       "362  Dynamic and distinctive communities have highe...   \n",
       "363  The 300 Reddit communities were selected based...   \n",
       "364  The clinical text structuring task is defined ...   \n",
       "365  No, not all text in this dataset is a question...   \n",
       "366  Sure! Here's the answer to your question based...   \n",
       "367  Sure! Here's the answer to your question based...   \n",
       "368     Sure! Here's the answer to your question:\\n\\n1   \n",
       "369                  RIPA, WEAT, and Neighborhood bias   \n",
       "370  The dataset consists of 471,319 references fro...   \n",
       "371  The intensity of PTSD is established based on ...   \n",
       "372  Sure! Here's the answer to your question based...   \n",
       "373  Sure! Here's the answer to your question based...   \n",
       "374  Incorrect words are defined as missing or misp...   \n",
       "375  Sure! Here's the answer to your question based...   \n",
       "376  The experiments performed are on the WNC datas...   \n",
       "377                                                 No   \n",
       "378  The proposed model outperforms the lexicon-bas...   \n",
       "379  Based on the analysis of exclusive and semanti...   \n",
       "380   Sure! Here's the answer to your question:\\n\\nYes   \n",
       "381  Sure! Here's the answer to your question:\\n\\nY...   \n",
       "382  Sure! Here's the answer to your question based...   \n",
       "383  Sure! Here's the answer to the question based ...   \n",
       "384  The annotators agreed moderately to substantia...   \n",
       "385                                  WN18 and YAGO3-10   \n",
       "386  The dataset was collected through a combinatio...   \n",
       "387  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "388  Sure! Here's my answer:\\n\\nThe performance dif...   \n",
       "389  Neural Network Regressor (NNR) and Neural Netw...   \n",
       "390    All 31 languages with both UD and UniMorph data   \n",
       "391  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "392  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "393                                      7934 messages   \n",
       "394  Sure! Here's my answer:\\n\\nMC abbreviates for ...   \n",
       "395  Sure! Here's the answer to your question based...   \n",
       "396  They look at simpler models such as ROUGE, Lan...   \n",
       "397  Sure! Here's my answer:\\n\\nFIVE LINGUISTIC QUA...   \n",
       "398  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "399  The answer is:\\n\\n* Semantic Enhancement GANs:...   \n",
       "400                                            ENGLISH   \n",
       "401  Sure! Here's the answer to your question based...   \n",
       "402        Sure! Here's my answer:\\n\\nHUMAN EVALUATORS   \n",
       "403  Sure! Here's my answer:\\n\\nSentiment analysis,...   \n",
       "404                   Sure! Here's my answer:\\n\\n90.1%   \n",
       "405  Sure! Here's the answer to your question based...   \n",
       "406  Sure! Here's my answer:\\n\\nThe BLSTM-CNN-CRF o...   \n",
       "407  Task C, which involves predicting the relation...   \n",
       "408   Sure! Here's my answer:\\n\\n10.5% performance gap   \n",
       "409  Sure! Here's the answer to your question based...   \n",
       "410                       Sure! Here's my answer:\\n\\n9   \n",
       "411  Sure! Here's the answer to your question:\\n\\nP...   \n",
       "412  Sure! Here's my answer:\\n\\nThe proposed model ...   \n",
       "413  Sure! Here's the answer to your question based...   \n",
       "414  Sure! Here's the answer to your question based...   \n",
       "415  Sure! Here's the answer to your question based...   \n",
       "416  The models are evaluated on both question answ...   \n",
       "417  Sure! Here's the answer to your question based...   \n",
       "418  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "419  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "420  Sure! Here's the answer to your question based...   \n",
       "421  The answer is:\\n\\nTwitter sentiment analysis f...   \n",
       "422  Sure! Here's the answer to your question based...   \n",
       "423  Sure! Here's my answer:\\n\\nThe answer is:\\n\\n*...   \n",
       "424  Sure! Here's my answer:\\n\\nThe possible senten...   \n",
       "425  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "426  Sure! Here's my answer:\\n\\nThe authors achieve...   \n",
       "427  The proposed semantic rules are displayed in T...   \n",
       "428  The model achieves a test accuracy of around 0...   \n",
       "429  Sure! Here's my answer:\\n\\nBoth approaches ach...   \n",
       "430              Sure! Here's my answer:\\n\\nALL GENRES   \n",
       "431  Sure! Here's my answer:\\n\\nThe x-vector system...   \n",
       "432  Sure! Here's my answer:\\n\\n12.3%\\n\\nBased on t...   \n",
       "433  Sure! Here's my answer:\\n\\nThe authors measure...   \n",
       "434  Sure! Here's the answer to your question:\\n\\n\"...   \n",
       "435  Both traditional and neural learning paradigms...   \n",
       "436  Sure! Here's the answer to your question:\\n\\nt...   \n",
       "437  This framework facilitates demographic inferen...   \n",
       "438  The data is annotated with depression symptoms...   \n",
       "439  The information on individual-level demographi...   \n",
       "440  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "441  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "442              The visual data is from posted images   \n",
       "443  The NLP representation outperforms other metho...   \n",
       "444  The answer is:\\n\\n* BIBREF27: Moral Foundation...   \n",
       "445  Sure! Here's the answer to your question based...   \n",
       "446  Sure! Here's the answer to your question based...   \n",
       "447  Sure! Here's the answer to your question based...   \n",
       "448  The answer is:\\n\\nUpward reasoning is defined ...   \n",
       "449  Sure! Here's the answer to your question based...   \n",
       "450  A Siamese Neural Network Architecture with two...   \n",
       "451  Sure! Here's the answer to your question:\\n\\nW...   \n",
       "452  Sure! Here's the answer to your question:\\n\\nW...   \n",
       "453  Sure! Based on the context you provided, the a...   \n",
       "454  The in-house dataset has 15,250 documents, whi...   \n",
       "455  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "456  Sure! Here's my answer:\\n\\nTheir model achieve...   \n",
       "457  Sure! Here's the answer to your question:\\n\\nE...   \n",
       "458  The navigation instructions were collected thr...   \n",
       "459  Sure! Here's the answer to your question:\\n\\nE...   \n",
       "460  The answer is:\\n\\n* Clinical sentiment analysi...   \n",
       "461  Sure! Here's my answer:\\n\\nThe initial results...   \n",
       "462  By using a morphologically motivated segmentat...   \n",
       "463  The performance on the task is evaluated based...   \n",
       "464  Sure! Here's my answer:\\n\\nIWSLT14 German-Engl...   \n",
       "465  Sure! Here's the answer to your question:\\n\\nC...   \n",
       "466  Sure! Here's the answer to your question based...   \n",
       "467  Sure! Here's the answer to your question:\\n\\n3...   \n",
       "468  Because other languages, like Spanish, have gr...   \n",
       "469  Sure! Here's my answer:\\n\\nThey measure gramma...   \n",
       "470  Sure! Here's my answer:\\n\\nThe system using Wi...   \n",
       "471  Sure! Here's the answer to your question based...   \n",
       "472                Sure! Here's my answer:\\n\\n3 layers   \n",
       "473  13 different context modeling methods are eval...   \n",
       "474  No. The baseline is a hierarchical transformer...   \n",
       "475  Sure! Here's the answer to your question based...   \n",
       "476  The dataset used for training/testing consists...   \n",
       "477  The embeddings display clustering properties, ...   \n",
       "478  The model trained on text exclusively achieves...   \n",
       "479  The proposed system outperformed the state-of-...   \n",
       "480  The proposed system obtained an F1-score of 85...   \n",
       "481  The answer is:\\n\\nThe state-of-the-art systems...   \n",
       "482                                    3347 utterances   \n",
       "483  The HMM models in the hybrid approach use feat...   \n",
       "484  The HMMs learn information related to spaces a...   \n",
       "485  Sure! Here's my answer:\\n\\nThe gap in performa...   \n",
       "486  Sure! Here's the answer to your question:\\n\\n1...   \n",
       "487  Sure! Here's the answer to your question based...   \n",
       "488  Quality was measured using F1 score with 5 gen...   \n",
       "489  The improved annotation protocol uses trained ...   \n",
       "490  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "491  Sure! Here's the answer to your question:\\n\\nL...   \n",
       "492  Sure! Here's the answer to your question:\\n\\n9...   \n",
       "493                                Supervised learning   \n",
       "494  Sure! Here's the answer to your question based...   \n",
       "495  The system is trained on a dataset of 15,000 i...   \n",
       "496  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "497  Sure! Here's the answer to your question based...   \n",
       "498  The authors of the paper manually annotated th...   \n",
       "499  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "500  Sure! Here's the answer to your question based...   \n",
       "501  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "502  Sure! Here's the answer to your question based...   \n",
       "503  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "504  VLSP 2016 Sentiment Analysis, VLSP 2018 Sentim...   \n",
       "505  The use of word embeddings in the proposed mod...   \n",
       "506  Sure! Here's the answer to your question:\\n\\n1...   \n",
       "507  The dataset used as input to the Word2Vec algo...   \n",
       "508  Use of influential tweeters to label tweets in...   \n",
       "509  Sure! Here's my answer:\\n\\nThe baseline state ...   \n",
       "510  They extract causality from text by selecting ...   \n",
       "511  Temporally matched Twitter posts that do not c...   \n",
       "512  The answer is:\\n\\nThe selection criteria for \"...   \n",
       "513  Sure! Here's the answer to your question based...   \n",
       "514  They collected the comparable corpus by select...   \n",
       "515           Control documents were selected randomly   \n",
       "516  Resolution model variables are $\\Pi = \\lbrace ...   \n",
       "517  Sure! Here's the answer to your question based...   \n",
       "518  The highest performing system in Task 1 was \"S...   \n",
       "519  The answer styles refer to the two types of an...   \n",
       "520  Sure! Here's the answer to your question based...   \n",
       "521  Sure! Here's the answer to your question based...   \n",
       "522  Sure! Here's the answer to your question based...   \n",
       "523  Sure! Here's the answer to your question based...   \n",
       "524  The Twitter corpus used to train the word vect...   \n",
       "525  Proposed word embeddings outperform Sindhi fas...   \n",
       "526  Sure! Here's the answer to your question:\\n\\n2...   \n",
       "527  The baseline methods used are the standard par...   \n",
       "528                    Sure! Here's my answer:\\n\\n27.4   \n",
       "529  The datasets used in experiments are the Seque...   \n",
       "530  Sure! Here's the answer to your question based...   \n",
       "531  Sure! Here's the answer to your question based...   \n",
       "532  Sure! Here's the answer to your question:\\n\\nE...   \n",
       "533  They enrich the positional embedding with leng...   \n",
       "534  They condition the output to a given target-so...   \n",
       "535  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "536  This method differs from traditional calibrati...   \n",
       "537  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "538  CRWIZ has been used for data collection, and t...   \n",
       "539                       download, malware, malicious   \n",
       "540  The data in RAFAEL is labelled with morphosynt...   \n",
       "541  Surrounding Uniformity (SU) measures the fluct...   \n",
       "542  Sure! Here's the answer to your question based...   \n",
       "543  Sure! Here's the answer to your question based...   \n",
       "544  CIC considers critical informative entities by...   \n",
       "545  Sure! Here's my answer:\\n\\nState-of-the-art me...   \n",
       "546  Ambiguity in PICO sentence prediction tasks ca...   \n",
       "547  Sure! Here's the answer to your question based...   \n",
       "548  Sure! Here's the answer to your question based...   \n",
       "549  Sure! Here's the answer to your question based...   \n",
       "550  By learning a context-aware latent variable in...   \n",
       "551       Sure! Here's my answer:\\n\\n2.3 BLEU-4 points   \n",
       "552  Sure! Here's the answer to your question based...   \n",
       "553  Sure! Here's the answer to your question:\\n\\n1...   \n",
       "554  Sure! Here's the answer to your question based...   \n",
       "555  Topics of interest about DDEO were identified ...   \n",
       "556  Sure! Here's the answer to your question based...   \n",
       "557  Sure! Here's the answer to the question based ...   \n",
       "558  Sure! Here's my answer:\\n\\nThe coefficients fr...   \n",
       "559  The answer is:\\n\\nORNN outperforms previous st...   \n",
       "560  Sure! Here's the answer to your question based...   \n",
       "561  Sure! Here's the answer to your question based...   \n",
       "562  Professional translations made 35% fewer error...   \n",
       "563  The weakness in Hassan et al.'s evaluation des...   \n",
       "564  Sure! Here's the answer to the question based ...   \n",
       "565  The input is restructured to begin with a [STA...   \n",
       "566                                            English   \n",
       "567  Sure! Here's the answer to your question based...   \n",
       "568                    Sure! Here's my answer:\\n\\n0.75   \n",
       "569           Sure! Here's my answer:\\n\\n100 documents   \n",
       "570           Simulated datasets of document revisions   \n",
       "571  Sure! Here's the answer to your question:\\n\\nF...   \n",
       "572  Sure! Here's the answer to your question based...   \n",
       "573  Bidirectional Long Short-Term Memory (BiLSTM) ...   \n",
       "574  Using phonetic feedback improves state-of-the-...   \n",
       "575  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "576  Sure! Here's the answer to your question based...   \n",
       "577  Sure! Here's my answer:\\n\\nThe dataset was col...   \n",
       "578     Sure! Here's the answer to your question:\\n\\n1   \n",
       "579  Sure! Here's the answer to your question based...   \n",
       "580  Sure! Here's the answer to your question based...   \n",
       "581  Sure! Here's the answer to your question based...   \n",
       "582                   Markov Stability (MS) clustering   \n",
       "583  To leverage the knowledge and experience of TC...   \n",
       "584  The QA models used are GloVe BIBREF40, CharCNN...   \n",
       "585  Sure! Here's the answer to your question based...   \n",
       "586         Sure! Here's my answer:\\n\\nThe gender task   \n",
       "587          Sure! Here's my answer:\\n\\nThe joint task   \n",
       "588  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "589  Sure! Here's my answer:\\n\\nReferring nouns or ...   \n",
       "590  They determine which words are informative bas...   \n",
       "591  The MOE model achieves a lower test perplexity...   \n",
       "592  Sure! Here's the answer to your question based...   \n",
       "593  Sure! Here's my answer:\\n\\nThe English-French ...   \n",
       "594  Sure! Here's the answer to your question based...   \n",
       "595  The differences in communication styles betwee...   \n",
       "596  The authors do not provide any specific data o...   \n",
       "597  Sure! Here's the answer to your question:\\n\\nW...   \n",
       "598  Sure! Here's my answer:\\n\\nAgainst a set of st...   \n",
       "599  Sure! Here's the answer to your question based...   \n",
       "600  The proposed approaches result in a non-termin...   \n",
       "601                                                 No   \n",
       "602          Sure! Here's my answer:\\n\\n123,287 images   \n",
       "603  Sure! Here's my answer:\\n\\nThe proposed model ...   \n",
       "604  DCGs used are Lexicon and 1st/3rd step convers...   \n",
       "605  Using a generated summary vs. a user-written o...   \n",
       "606  Sure! Here's my answer:\\n\\nThey looked at norm...   \n",
       "607          CELEX, IIT-Guwahat, and Festival datasets   \n",
       "608  Sure! Here's the answer to your question based...   \n",
       "609  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "610  Sure! Here's the answer to your question based...   \n",
       "611  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "612  Text classification task is considered as clas...   \n",
       "613  Recurrent-like neural networks with nested int...   \n",
       "614  Switchboard-2000 is approximately 6 times bigg...   \n",
       "615  Sure! Here's my answer:\\n\\nNeural activity in ...   \n",
       "616  Sure! Here's my answer:\\n\\nThe task is hard be...   \n",
       "617  They generate the synthetic dataset by samplin...   \n",
       "618    The average length of the claims is INLINEFORM2   \n",
       "619  Sure! Here's my answer:\\n\\nPolitics, World, So...   \n",
       "620  Sure! Here's my answer:\\n\\n2.3% and 1.7% impro...   \n",
       "621  The linguistic differences between each class ...   \n",
       "622  Sure! Here's my answer:\\n\\nThe songs fall unde...   \n",
       "623  Sure! Here's the answer to your question:\\n\\nV...   \n",
       "624  Human evaluation was performed using pairwise ...   \n",
       "625  Sure! Here's the answer to your question based...   \n",
       "626                                                LFT   \n",
       "627  The proposed model (GDP) is significantly bett...   \n",
       "628  Sure! Here's my answer:\\n\\nPrecision increased...   \n",
       "629  Sure! Here's my answer:\\n\\nSTRESS, ANXIETY, SO...   \n",
       "630  Sure! Here's the answer to your question based...   \n",
       "631  Sure! Here's the answer to your question:\\n\\n3...   \n",
       "632  By using a state tracking model independent of...   \n",
       "633  Sure! Here's my answer:\\n\\nThey measure model ...   \n",
       "634  Sure! Here's the answer to your question based...   \n",
       "635                 Sure! Here's my answer:\\n\\nTable 1   \n",
       "636  Sure! Here's the answer to your question based...   \n",
       "637  The answer is:\\n\\nThe machine learning and NLP...   \n",
       "638  Sure! Here's the answer to your question based...   \n",
       "639                                            BIBREF6   \n",
       "640  Sure! Here's the answer to your question:\\n\\nF...   \n",
       "641  Sure! Here's the answer to your question based...   \n",
       "642  Sure! Here's the answer to your question based...   \n",
       "643  Sure! Here's the answer to your question based...   \n",
       "644  By calculating the cosine similarity between t...   \n",
       "645  Sure! Here's the answer to your question based...   \n",
       "646            Approximately 3 billion sub-word tokens   \n",
       "647  The model used in the experiments is a pre-tra...   \n",
       "648  Sure! Here's the answer to your question based...   \n",
       "649  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "650                   Sure! Here's my answer:\\n\\n10000   \n",
       "651            Sure! Here's my answer:\\n\\n10.2% better   \n",
       "652  Sure! Here's the answer to your question:\\n\\nC...   \n",
       "653  Sure! Here's the answer to your question based...   \n",
       "654  Sure! Here's the answer to your question based...   \n",
       "655  English, Russian, Arabic, Chinese, German, Spa...   \n",
       "656                                                 No   \n",
       "657  The evaluation metrics used are accuracy and I...   \n",
       "658  Sure! Here's my answer:\\n\\nThey used a variety...   \n",
       "659  Sure! Here's the answer to your question based...   \n",
       "660  Performance is improved by around 10% on avera...   \n",
       "661  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "662  The resource comes from two datasets, one coll...   \n",
       "663                     Sure! Here's my answer:\\n\\n240   \n",
       "664  Sure! Here's my answer:\\n\\nThe first dataset, ...   \n",
       "665  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "666  Big data is not appropriate for this task beca...   \n",
       "667  Analyzing the topic embeddings of State of the...   \n",
       "668  Sure! Here's the answer to your question:\\n\\nN...   \n",
       "669                                               Weak   \n",
       "670  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "671  The Northeast, West, and South regions correla...   \n",
       "672  Sure! Here's the answer to your question:\\n\\nE...   \n",
       "673  They modify the attention mechanism from locat...   \n",
       "674  Sure! Here's the answer to your question:\\n\\nTime   \n",
       "675                  Sure! Here's my answer:\\n\\n85.11%   \n",
       "676  Sure! Here's my answer:\\n\\nUser Query Track an...   \n",
       "677  Sure! Here's the answer to your question:\\n\\nE...   \n",
       "678  Binary-class and multi-class cross-domain sent...   \n",
       "679  Sure! Here's my answer:\\n\\nThe answer is:\\n\\n1...   \n",
       "680  Sure! Here's the answer to your question based...   \n",
       "681  Sure! Here's my answer:\\n\\nEnglish, Spanish, C...   \n",
       "682  Sure! Here's the answer to your question based...   \n",
       "683  The answer is:\\n\\nThe model achieves a gain of...   \n",
       "684                    Sure! Here's my answer:\\n\\n0.85   \n",
       "685  The answer is:\\n\\nThe three datasets used in t...   \n",
       "686  8% improvement in accuracy for short jokes com...   \n",
       "687  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "688  They got relations between mentions using thre...   \n",
       "689  They detected entity mentions by using a simpl...   \n",
       "690  Sure! Here's the answer to your question based...   \n",
       "691  Sure! Here's my answer:\\n\\nPreceding and follo...   \n",
       "692  Sure! Here's the answer to your question based...   \n",
       "693  Sure! Here's the answer to your question based...   \n",
       "694  Sure! Here's the answer to your question based...   \n",
       "695  Sure! Here's the answer to your question based...   \n",
       "696  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "697  Sure! Here's my answer:\\n\\nOnline user reviews...   \n",
       "698  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "699  The changes are evaluated based on the accurac...   \n",
       "700  Sure! Here's the answer to your question:\\n\\nE...   \n",
       "701                                       2247 triples   \n",
       "702  Sure! Here's the answer to your question:\\n\\nO...   \n",
       "703  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "704  Sure! Here's the answer to your question:\\n\\nm...   \n",
       "705  Sure! Here's the answer to your question based...   \n",
       "706  Previous systems compared to are those without...   \n",
       "707  Semi/supervised.\\n\\nThese models are trained o...   \n",
       "708  Sure! Here's my answer:\\n\\nA negligible perfor...   \n",
       "709  Sure! Here's my answer:\\n\\nBoth GloVe and SGNS...   \n",
       "710  Sure! Here's the answer to your question based...   \n",
       "711  A word confusion network (cnet) is a type of i...   \n",
       "712  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "713                         Screencast tutorial videos   \n",
       "714                Baseline1, Baseline2, and Baseline3   \n",
       "715  TP-N2F is faster than LSTM-based Seq2Seq in bo...   \n",
       "716  State-of-the-art performance on both the full ...   \n",
       "717  The proposed model achieved an execution accur...   \n",
       "718  Sure! Here's the answer to your question based...   \n",
       "719                                          DrQA+CoQA   \n",
       "720  Sure! Here's the answer to your question based...   \n",
       "721  Sure! Here's my answer:\\n\\nThe answer is:\\n\\n*...   \n",
       "722  Sure! Here's the answer to your question based...   \n",
       "723                                         AG-RNN-LID   \n",
       "724  The main contribution of the paper is the prop...   \n",
       "725  They get the formal languages from a context-f...   \n",
       "726  Sure! Here's my answer:\\n\\nA confusion network...   \n",
       "727  Sure! Here's the answer to your question based...   \n",
       "728  Sure! Here's my answer:\\n\\nPrecision, Recall, ...   \n",
       "729  Sure! Here's my answer:\\n\\nSONAR-1 and Ancora 2.0   \n",
       "730                                     local features   \n",
       "731  Sure! Here's the answer to your question based...   \n",
       "732                     They build one model per topic   \n",
       "733                                     Quantitatively   \n",
       "734  The system achieves a relative improvement of ...   \n",
       "735           Sure! Here's my answer:\\n\\nRandom Forest   \n",
       "736  By using a Bayesian approach to learn which te...   \n",
       "737  The use of a left-to-right attention mask to r...   \n",
       "738  The multimodal representations are combined us...   \n",
       "739  Sure! Here's my answer:\\n\\nExisting metrics do...   \n",
       "740  Sure! Here's the answer to your question based...   \n",
       "741  Discourse features are incorporated into the m...   \n",
       "742                      GR and RST discourse features   \n",
       "743  Proof paths are the sequences of proof states ...   \n",
       "744  Raw Text, Automatically Segmented Text, Hetero...   \n",
       "745  The proposed comparative evaluator with skill ...   \n",
       "746  Sure! Here's the answer to your question based...   \n",
       "747  Sure! Here's the answer to your question based...   \n",
       "748  Sure! Here's the answer to your question based...   \n",
       "749  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "750  A string kernel is a method for measuring the ...   \n",
       "751  They compute the correlation of the proposed N...   \n",
       "752           Sure! Here's my answer:\\n\\n5.5 points F1   \n",
       "753  Sure! Here's the answer to your question:\\n\\n3...   \n",
       "754                       Sure! Here's my answer:\\n\\n0   \n",
       "755  Sure! Here's the answer to your question:\\n\\nA...   \n",
       "756                 Sure! Here's my answer:\\n\\nTable 1   \n",
       "757  Sure! Here's my answer:\\n\\nMulti-Encoder, Cons...   \n",
       "758                 Sure! Here's my answer:\\n\\nTable 1   \n",
       "759  Slot binary classifiers improve performance by...   \n",
       "760  NDM BIBREF7, LIDM BIBREF9, KVRN BIBREF13, and ...   \n",
       "761  Confusion among active words at certain nodes ...   \n",
       "762  Sure! Here's the answer to your question based...   \n",
       "763                   Sure! Here's my answer:\\n\\n87.5%   \n",
       "764  Sure! Here's the answer to your question:\\n\\nt...   \n",
       "765  Sure! Here's the answer to your question:\\n\\ns...   \n",
       "766  Sure! Here's the answer to your question based...   \n",
       "767  Sure! Here's the answer to your question based...   \n",
       "768  Sure! Here's the answer to your question based...   \n",
       "769  Sure! Here's the answer to your question based...   \n",
       "770  Sure! Here's my answer:\\n\\n75.6% of the uttera...   \n",
       "771                                               2000   \n",
       "772  Their model outperforms both state-of-the-art ...   \n",
       "773  The state-of-the-art is the `Read-Again' encod...   \n",
       "774  Sure! Here's my answer:\\n\\n🔥 OUTPERFORMED THE ...   \n",
       "775                    Sure! Here's my answer:\\n\\n1000   \n",
       "776  The dataset was built by gathering queries fro...   \n",
       "777  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "778  Sure! Here's the answer to your question based...   \n",
       "779  Sure! Here's the answer to your question:\\n\\nS...   \n",
       "780  Sure! Here's the answer to your question based...   \n",
       "781  Sure! Here's the answer to your question:\\n\\n3...   \n",
       "782  Sure! Here's my answer:\\n\\nThe results were no...   \n",
       "783                   Sure! Here's my answer:\\n\\n85.6%   \n",
       "784  The dataset used in the paper is a collection ...   \n",
       "785  By systematically holding out the training set...   \n",
       "786  Sure! Here's my answer:\\n\\nThis system outperf...   \n",
       "787  Sure! Here's my answer:\\n\\nThe baseline system...   \n",
       "788  The systems tested are the VoxCeleb-based syst...   \n",
       "789  Sure! Here's the answer to your question:\\n\\nV...   \n",
       "790  They hybridize MonaLog with BERT for compositi...   \n",
       "791  MonaLog selects monotonicity facts based on th...   \n",
       "792  Sure! Here's my answer:\\n\\n12 categories devis...   \n",
       "793  The answer is:\\n\\nThere are several off-the-sh...   \n",
       "794                                            3 rules   \n",
       "795  Sure! Here's the answer to your question based...   \n",
       "796  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "797  Sure! Here's the answer to your question based...   \n",
       "798  Sure! Here's my answer:\\n\\ngCAS approach is be...   \n",
       "799  The gCAS cell is specific in that it is compos...   \n",
       "800                                  English Wikipedia   \n",
       "801  The answer is:\\n\\nTest Set 1: 57 drug labels\\n...   \n",
       "802  The answer is:\\n\\nThe datasets used are:\\n\\n* ...   \n",
       "803  Sure! Here's the answer to your question based...   \n",
       "804  Sure! Here's my answer:\\n\\nDistilBERT, BERT, a...   \n",
       "805  Sure! Here's the answer to your question based...   \n",
       "806  NAGM is significantly more accurate than the b...   \n",
       "807  Sure! Here's the answer to your question based...   \n",
       "808        Sure! Here's my answer:\\n\\nBERT and RoBERTa   \n",
       "809                       Sure! Here's my answer:\\n\\n4   \n",
       "810                 Sure! Here's my answer:\\n\\nYouTube   \n",
       "811  EACs are evaluated using a combination of qual...   \n",
       "812  Sure! Here's my answer:\\n\\nTriangulation is a ...   \n",
       "813  Sure! Here's my answer:\\n\\nEnglish, Spanish, A...   \n",
       "814  Sure! Here's the answer to the question based ...   \n",
       "815  Sure! Here's my answer:\\n\\nThe corpus contains...   \n",
       "816  Sure! Here's my answer:\\n\\nThe dataset is quit...   \n",
       "817  Sure! Here's the answer to your question:\\n\\n3...   \n",
       "818  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "819  Sure! Here's the answer to your question based...   \n",
       "820  Sure! Here's my answer:\\n\\nLASSO optimization ...   \n",
       "821  The degree of offensiveness was based on how p...   \n",
       "822  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "823  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "824  They perform data augmentation by adding sente...   \n",
       "825  The city dialect is characterized by a more un...   \n",
       "826  The rural dialect has more specific words in i...   \n",
       "827  Sure! Here's the answer to your question based...   \n",
       "828  Sure! Here's the answer to your question based...   \n",
       "829        Aristo system is trained on the ARC dataset   \n",
       "830                       Sure! Here's my answer:\\n\\n8   \n",
       "831                                Machine Translation   \n",
       "832  Sure! Here's the answer to your question:\\n\\nL...   \n",
       "833  through the annotation scheme, which captures ...   \n",
       "834  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "835  Soft-selection approaches evaluated are attent...   \n",
       "836  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "837  Sure! Here's my answer:\\n\\nThe dataset they ge...   \n",
       "838    Bias due to dataset selection and word coverage   \n",
       "839  Their proposed method of quantifying interpret...   \n",
       "840  Sure! Here's the answer to your question:\\n\\nL...   \n",
       "841  Sure! Here's my answer:\\n\\nThis approach outpe...   \n",
       "842                     Simple human evaluation method   \n",
       "843  English and Japanese are the most represented ...   \n",
       "844  Sure! Here's the answer to your question based...   \n",
       "845          Sure! Here's my answer:\\n\\nWN18 and FB15k   \n",
       "846  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "847  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "848  Sure! Here's my answer:\\n\\nThe answer is:\\n\\n*...   \n",
       "849                            Monolingual annotations   \n",
       "850  Sure! Here's my answer based on the provided c...   \n",
       "851  The generative model is evaluated using BLEU s...   \n",
       "852  Sure! Here's my answer:\\n\\nA health-related tw...   \n",
       "853  Sure! Here's the answer to your question based...   \n",
       "854                                                  3   \n",
       "855  Sure! Here's the answer to your question:\\n\\nM...   \n",
       "856                   Sure! Here's my answer:\\n\\n1.75x   \n",
       "857           Sure! Here's my answer:\\n\\n100,000 words   \n",
       "858                       Sure! Here's my answer:\\n\\n2   \n",
       "859                       Sure! Here's my answer:\\n\\n2   \n",
       "860  Sure! Here's my answer:\\n\\n3 layers of self-at...   \n",
       "861  Sure! Here's the answer to your question based...   \n",
       "862  Sure! Here's my answer:\\n\\nEnglish, Spanish, F...   \n",
       "863  Sure! Here's my answer:\\n\\nGMM-based attention...   \n",
       "864  Sure! Here's the answer to your question based...   \n",
       "865  Yes, the results show that the NLG model train...   \n",
       "866  By generating a query based on the claim's ver...   \n",
       "867  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "868  Sure! Here's the answer to your question:\\n\\n2...   \n",
       "869  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "870  Annotation was done using Amazon Mechanical Tu...   \n",
       "871  Sure! Here's the answer to your question based...   \n",
       "872  Sure! Here's my answer:\\n\\nImproved accuracy a...   \n",
       "873  They incorporate human advice by explicitly re...   \n",
       "874  Emolex, EmoSenticNet, Dictionary of Affect in ...   \n",
       "875  Sure! Here's the answer to your question based...   \n",
       "876  Sure! Here's my answer:\\n\\n22.6% improvement i...   \n",
       "877  Sure! Here's my answer:\\n\\nLinear Support Vect...   \n",
       "878  LDA identifies topic clusters such as American...   \n",
       "879  Sure! Here's the answer to your question based...   \n",
       "880     The provided treebank consists of 1,448 tweets   \n",
       "881  Sure! Here's my answer:\\n\\nADAPT-Microsoft dat...   \n",
       "882  Sure! Here's my answer:\\n\\nThe citation intent...   \n",
       "883  Sure! Here's the answer to your question based...   \n",
       "884                   Sure! Here's my answer:\\n\\n85.2%   \n",
       "885  Sure! Here's my answer:\\n\\nBilingual text with...   \n",
       "886  Sure! Here's the answer to your question:\\n\\nL...   \n",
       "887  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "888                                     ABX error rate   \n",
       "889  Yes, evaluation metrics and criteria were used...   \n",
       "890  The answer is:\\n\\nThe two decoding functions a...   \n",
       "891  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "892  BERT-BASE and BERT-LARGE are trained using dif...   \n",
       "893  Sure! Here's the answer to your question:\\n\\n6...   \n",
       "894              Sure! Here's my answer:\\n\\nNEGLIGIBLE   \n",
       "895  Sure! Here's the answer to your question:\\n\\nY...   \n",
       "896  Accuracy and F1 scores are used to measure per...   \n",
       "897  Zipf's law and Herdan-Heap's law differ in the...   \n",
       "898  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "899  Sure! Here's the answer to your question based...   \n",
       "900  Sure! Here's the answer to your question:\\n\\nO...   \n",
       "901  KryptoOracle's architecture is fault-tolerant ...   \n",
       "902  The platform's modular elements include its Sp...   \n",
       "903  Sure! The answer is:\\n\\nThe performance evalua...   \n",
       "904  Monolingual and cross-lingual word similarity,...   \n",
       "905  The model improves in monolingual spaces becau...   \n",
       "906  The annotation projection is done using word a...   \n",
       "907  Sure! Here's the answer to your question based...   \n",
       "908                  Sure! Here's my answer:\\n\\nE-BERT   \n",
       "909  Sure! Here's the answer to your question:\\n\\nP...   \n",
       "910  Sure! Here's the answer to your question based...   \n",
       "911  No, it is not a neural model. It is a probabil...   \n",
       "912  $n$-gram based similarity metrics and human ev...   \n",
       "913  Sure! Here's the answer to your question:\\n\\nB...   \n",
       "914  Sentence embeddings are incorporated into the ...   \n",
       "915  Sure! Here's my answer:\\n\\nThe dataset size of...   \n",
       "916  Sure! Here's the answer to your question:\\n\\nP...   \n",
       "917  The answer is:\\n\\nStrong baselines: 256 hidden...   \n",
       "918  Sure! Here's my answer:\\n\\nCausal attribution ...   \n",
       "919  They used a common sense definition of racist ...   \n",
       "920  Sure! Here's the answer to your question based...   \n",
       "921  Sure! Here's the answer to your question:\\n\\nH...   \n",
       "922       Sure! Here's my answer:\\n\\n11.2% improvement   \n",
       "923  Sure! Here's the answer to your question based...   \n",
       "924  Small sample size, sampling bias, low inter-ra...   \n",
       "925  Sure! Here's my answer:\\n\\nThe baselines are t...   \n",
       "926  Content accuracy, coherence, and consistency w...   \n",
       "927  Sure! Here's the answer to your question based...   \n",
       "928  Sure! Here's my answer:\\n\\nThey try out linear...   \n",
       "929  Sure! Here's my answer:\\n\\nThe competing model...   \n",
       "930  The input triple is translated to a slot-filli...   \n",
       "931  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "932  Sure! Here's the answer to your question:\\n\\nN...   \n",
       "933  Sure! Here's the answer to your question based...   \n",
       "934  Sure! Here's the answer to your question based...   \n",
       "935  Sure! Here's my answer:\\n\\nA variety of writin...   \n",
       "936                    Relation meta and gradient meta   \n",
       "937  Sure! Here's the answer to your question:\\n\\nN...   \n",
       "938  Performance can be hurt when using too small a...   \n",
       "939  Sure! Here's the answer to your question based...   \n",
       "940  The semi-automatic construction process works ...   \n",
       "941  The training framework explicitly leverages th...   \n",
       "942  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "943  No variation in results was observed based on ...   \n",
       "944  Yes. The approach can be generalized to other ...   \n",
       "945  Sure! Here's the answer to your question:\\n\\nG...   \n",
       "946     Sure! Here's my answer:\\n\\nThe lower 48 states   \n",
       "947  Sure! Here's the answer to your question:\\n\\nP...   \n",
       "948  The author's approach is novel in using self-p...   \n",
       "949  Sure! Here's my answer:\\n\\nThe Dialog State Tr...   \n",
       "950  The training dataset is a mixture of neutral a...   \n",
       "951  Sure! Here's the answer to your question based...   \n",
       "952  Sure! Here's the answer to your question:\\n\\n4...   \n",
       "953  Improving natural language processing (NLP) me...   \n",
       "954  BERT-based encoder-decoder framework with LSTM...   \n",
       "955  Sure! Here's the answer to your question based...   \n",
       "956  Dilated convolutions are a type of convolution...   \n",
       "957  Sure! Here's my answer:\\n\\nBERT, RoBERTa, and ...   \n",
       "958  Sure! Here's the answer to your question based...   \n",
       "959  Sure! Here's the answer to your question based...   \n",
       "960  Sure! Here's my answer:\\n\\nA baseline multi-ta...   \n",
       "961  A multi-task Bi-Directional Recurrent Neural N...   \n",
       "962  RDSN stacks and concatenates the outputs of pr...   \n",
       "963  Sure! Here's the answer to your question:\\n\\nT...   \n",
       "964  No. The paper does not propose a new task, but...   \n",
       "965                    2.1 million predicate instances   \n",
       "966  Sure! Here's my answer:\\n\\nOpen-domain fill-in...   \n",
       "967  Sure! Here's the answer to your question:\\n\\nτ...   \n",
       "\n",
       "                                        correct_answer  \\\n",
       "0    De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...   \n",
       "1     training data has posts from politics, busine...   \n",
       "2    F1 scores of 85.99 on the DL-PS data,  75.15 o...   \n",
       "3     They did not use any platform, instead they h...   \n",
       "4                                                   5    \n",
       "5     paragraph, lines, textspan element (paragraph...   \n",
       "6    They measure self-similarity, intra-sentence s...   \n",
       "7    They use the first principal component of a wo...   \n",
       "8    F1 scores are:\\nHUBES-PHI: Detection(0.965), C...   \n",
       "9                             Using file size on disk    \n",
       "10              20 annotatos from author's institution   \n",
       "11    Looking for adjectives marking the noun \"baby...   \n",
       "12                                        Ethnic bias    \n",
       "13    Best: Expansion (Exp). Worst: Comparison (Comp).   \n",
       "14                               The transformer layer   \n",
       "15    The crowdsourcing platform CrowdFlower was us...   \n",
       "16   4.49 turns 4.5 turns per dialog (8533 turns / ...   \n",
       "17   It defined a sequence labeling task to extract...   \n",
       "18   Through the All India Radio new channel where ...   \n",
       "19    An extension of NetVLAD which replaces hard a...   \n",
       "20   Hindi, English, Kannada, Telugu, Assamese, Ben...   \n",
       "21           The neural projector must be invertible.    \n",
       "22   GRU-based encoder, interaction block, and clas...   \n",
       "23   F1, precision, recall, accuracy Precision, rec...   \n",
       "24   BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4...   \n",
       "25                 MULTIPLE CHOICE QUESTION ANSWERING    \n",
       "26                                  one additional hop   \n",
       "27   German, English, Spanish, Finnish, French, Rus...   \n",
       "28   The task of predicting MSD tags: V, PST, V.PCT...   \n",
       "29   SAN Baseline, BNA, DocQA, R.M-Reader, R.M-Read...   \n",
       "30                                           Accuracy    \n",
       "31   Reward of 11.8 for the A2C-chained model, 41.8...   \n",
       "32   In case of Freebase knowledge base, LiLi model...   \n",
       "33   Answer with content missing: (list)\\nLiLi shou...   \n",
       "34   719313 Book, Electronics, Beauty and Music eac...   \n",
       "35   Book, electronics, beauty, music, IMDB, Yelp, ...   \n",
       "36   The Näive-Bayes classifier is corrected so it ...   \n",
       "37    By comparing scores for each word calculated ...   \n",
       "38   By multiplying crowd-annotated document-emotio...   \n",
       "39   By using topic modeling and unsupervised emoti...   \n",
       "40    Using NMF based topic modeling and their cohe...   \n",
       "41   Existential (OneShape, MultiShapes), Spacial (...   \n",
       "42   Overall F1 score:\\n- He and Sun (2017) 58.23\\n...   \n",
       "43   En-Fr, En-Zh, En-Jp, En-Kr, Zh-En, Zh-Fr, Zh-J...   \n",
       "44                                               10000   \n",
       "45   A task for seq2seq model pra-training that rec...   \n",
       "46                   Alignment points of the POS tags.   \n",
       "47             For certain POS tags, e.g. VERB, PRON.    \n",
       "48   Various tree structured neural networks includ...   \n",
       "49              Linear SVM, RBF SVM, and Random Forest   \n",
       "50   intents are annotated manually with guidance f...   \n",
       "51     23,700 queries, including 22,500 in-scope qu...   \n",
       "52   crowsourcing platform For ins scope data colle...   \n",
       "53    Answer with content missing: (Parent subsecti...   \n",
       "54                                          about 500    \n",
       "55   Best proposed metric has average correlation w...   \n",
       "56                Energy with accuracy of 0.538 Energy   \n",
       "57             By conducting a survey among engineers    \n",
       "58   Dataset of total 3500 questions from the Inter...   \n",
       "59   Best proposed model result vs best previous re...   \n",
       "60   The baseline system for the SLC task is a very...   \n",
       "61    The matrix containing co-occurrences of the w...   \n",
       "62                                                  16   \n",
       "63   None Word-level Memory Neural Networks (MemNNs...   \n",
       "64   50 human annotators ranked a random sample of ...   \n",
       "65   Akbik et al. (2018), Link et al. (2012) They c...   \n",
       "66   F-1 score on the OntoNotes is 88%, and it is 5...   \n",
       "67   Entities from a deep learning model are linked...   \n",
       "68    For speech synthesis, they build a speech clu...   \n",
       "69    Original transcription was labeled with addit...   \n",
       "70                               clipped PMI; NNEGPMI    \n",
       "71   It may lead to poor rare word representations ...   \n",
       "72    A finite corpora may entirely omit rare word ...   \n",
       "73   Answer with content missing: (Whole Method and...   \n",
       "74   Answer with content missing: (Whole Method and...   \n",
       "75   Universal Dependencies v1.2 treebanks for the ...   \n",
       "76   Amitabh Bachchan, Ariana Grande, Barack Obama,...   \n",
       "77    Create the negated LAMA dataset and  query th...   \n",
       "78   LSA, TextRank, LexRank and ILP-based summary. ...   \n",
       "79   Logistic Regression, Multinomial Naive Bayes, ...   \n",
       "80    MSMARCO,  HOTPOTQA, RECORD,  MULTIRC, NEWSQA,...   \n",
       "81                                    English language   \n",
       "82                                 two previous turns    \n",
       "83   Best results authors obtain is EM 51.10 and F1...   \n",
       "84   Dimension size, window size, architecture, alg...   \n",
       "85   The time devoted to self-coverage, opponent-co...   \n",
       "86   Babelfy, DBpedia Spotlight, Entityclassifier.e...   \n",
       "87   Random Kitchen Sink method uses a kernel funct...   \n",
       "88   By using Euclidean distance computed between t...   \n",
       "89    reduced the dataset by eliminating features, ...   \n",
       "90    The annotations are based on evidence of depr...   \n",
       "91    In encoder they use convolutional, NIN and bi...   \n",
       "92    Decoder predicts the sequence of phoneme or g...   \n",
       "93    Collected tweets and opening and closing stoc...   \n",
       "94   Females are given higher sentiment intensity w...   \n",
       "95   Sentences involving at least one race- or gend...   \n",
       "96    LF-MMI Attention\\nSeq2Seq \\nRNN-T \\nChar E2E ...   \n",
       "97   In case of read speech datasets,  their best m...   \n",
       "98   by 2.3-6.8 points in f1 score for intent recog...   \n",
       "99    The average score improved by 1.4 points over...   \n",
       "100  A process of training a model when selected un...   \n",
       "101                                    M2M Transformer   \n",
       "102  Segmentation quality is evaluated by calculati...   \n",
       "103  Human evaluators were asked to evaluate on a s...   \n",
       "104               By 14 times. up to 1.95 times larger   \n",
       "105                          5 percent points. 0.05 F1   \n",
       "106                                 CNN-DNN-BLSTM-HMM    \n",
       "107                                                609   \n",
       "108    Linked entities may be ambiguous or too common    \n",
       "109                                              3606    \n",
       "110   Bam et al. SVM, Ma and Hovy w/glove, Lample e...   \n",
       "111  Dataset contains 3606 total sentences and 7908...   \n",
       "112  OurNepali contains 3 different types of entiti...   \n",
       "113  3606 sentences Dataset contains 3606 total sen...   \n",
       "114  On OurNepali test dataset Grapheme-level repre...   \n",
       "115  the model with multi-attention mechanism and a...   \n",
       "116  classic RNN model, avgRNN model, attentionRNN ...   \n",
       "117  Twitter dataset provided by the organizers The...   \n",
       "118  The dataset from the SociaL Media And Harassme...   \n",
       "119   Using F1 Micro measure, the KNN classifier pe...   \n",
       "120                                 KNN\\nRF\\nSVM\\nMLP    \n",
       "121                                       eight layers   \n",
       "122   SVM with unigram, bigram, trigram features, w...   \n",
       "123    Semantic Textual Similarity, sentiment predi...   \n",
       "124  GloVe, BERT, Universal Sentence Encoder, TF-ID...   \n",
       "125   SVM with linear kernel using bag-of-words fea...   \n",
       "126                                           Russsian   \n",
       "127                     Using Google translation API.    \n",
       "128   presence/absence of consonants, presence/abse...   \n",
       "129   They use four-layered 2D CNN and two fully co...   \n",
       "130  Tweets related to CyberAttack and tweets relat...   \n",
       "131  By involving humans for post-hoc evaluation of...   \n",
       "132   By evaluating the performance of the approach...   \n",
       "133   a setup where the seeker interacts with a rea...   \n",
       "134  For Article-Entity placement, they consider tw...   \n",
       "135  They use a multi-class classifier to determine...   \n",
       "136  KL-divergences of language models for the news...   \n",
       "137  Salience features positional features, occurre...   \n",
       "138  Experienced medical doctors used a linguistic ...   \n",
       "139   Activation function is hyperparameter. Possib...   \n",
       "140  Chunks is group of tweets from single account ...   \n",
       "141  Total dataset size: 171 account (522967 tweets...   \n",
       "142                             sequence of $s$ tweets   \n",
       "143  Quantitative evaluation methods using ROUGE, R...   \n",
       "144    Two methods: first is to simply pick initial...   \n",
       "145   14,100 tweets Dataset contains total of 14100...   \n",
       "146  non-targeted profanity and swearing, targeted ...   \n",
       "147  Level A: 14100 Tweets\\nLevel B: 4640 Tweets\\nL...   \n",
       "148  The content relevance between the candidate su...   \n",
       "149   Using Pearson corelation measure,  for exampl...   \n",
       "150                 Using INLINEFORM0 and INLINEFORM1    \n",
       "151   Detection of an aspect in a review, Predictio...   \n",
       "152  Combining  pattern based and Machine translati...   \n",
       "153  For the WikiLarge dataset, the improvement ove...   \n",
       "154   WikiSmall  89 142 sentence pair and  WikiLarg...   \n",
       "155  Frequent use of direct animal name calling, us...   \n",
       "156    One One experienced annotator tagged all tweets   \n",
       "157  It does not use a seed list to gather tweets s...   \n",
       "158   ironies are often obscure and hard to understand   \n",
       "159  They developed a classifier to find ironic sen...   \n",
       "160  Irony accuracy is judged only by human ; senri...   \n",
       "161  tweets are annotated with only Favor or Agains...   \n",
       "162  hashtag features contain whether there is any ...   \n",
       "163                                                  3   \n",
       "164  CCG Supertagging CCGBank , PTB part-of-speech ...   \n",
       "165   by learning a projection function between the...   \n",
       "166  technology, religion, fashion, publishing, spo...   \n",
       "167  They use the embedding layer with a size 35 an...   \n",
       "168   From all reported results proposed method (NB...   \n",
       "169   labelled features, which are words whose pres...   \n",
       "170  text classification for themes including senti...   \n",
       "171  ability to accurately classify texts even when...   \n",
       "172                                         Automatic    \n",
       "173                                        204 tokens    \n",
       "174                        NBOW, LSTM, attentive LSTM    \n",
       "175  Once split into 8 subsets (A-H), the test set ...   \n",
       "176  F1 score of 92.19 on homographic pun detection...   \n",
       "177  They compare with the following models: by Ped...   \n",
       "178   A homographic and heterographic benchmark dat...   \n",
       "179  A new tagging scheme that tags the words befor...   \n",
       "180  Using the OpenIE toolbox and applying heuristi...   \n",
       "181  Metrics show better results on all metrics com...   \n",
       "182  BioASQ  dataset A dataset provided by BioASQ c...   \n",
       "183                                            0.5115    \n",
       "184  They measured the under-translated words with ...   \n",
       "185   They compute the gradient of the output at ea...   \n",
       "186  A sample from nurse-initiated telephone conver...   \n",
       "187  1264 instances from simulated data, 1280 insta...   \n",
       "188  By evaluating their model on adversarial sets ...   \n",
       "189   Classification system use n-grams, bag-of-wor...   \n",
       "190  Words that a user wants them to appear in the ...   \n",
       "191  GloVe vectors trained on Wikipedia Corpus with...   \n",
       "192  F1 score of 97.5 on MSR and 95.7 on AS MSR: 97...   \n",
       "193  pays attentions to adjacent characters and cas...   \n",
       "194  Baseline models are:\\n- Chen et al., 2015a\\n- ...   \n",
       "195  using tweets that one has replied or quoted to...   \n",
       "196  The authors showed few tweets where neither an...   \n",
       "197   sampling tweets from specific keywords create...   \n",
       "198  Data annotation biases where tweet containing ...   \n",
       "199                                     the CRX model    \n",
       "200  The number of dimensions can be reduced by up ...   \n",
       "201                                            English   \n",
       "202  Human evaluation for interpretability using th...   \n",
       "203  The cost function for any one of the words of ...   \n",
       "204  They group the existing works in terms of the ...   \n",
       "205  Acquire very large Vietnamese corpus and build...   \n",
       "206  Their accuracy in word segmentation is about 9...   \n",
       "207                mainstream news and disinformation    \n",
       "208  By assigning a political bias label to each ne...   \n",
       "209  from 3rd to 9th grade science questions collec...   \n",
       "210  By calculating Macro F1 metric at the document...   \n",
       "211  NCEL considers only adjacent mentions. More th...   \n",
       "212  Advanced neural architectures and contextualiz...   \n",
       "213  2174000000, 989000000 2174 million tokens for ...   \n",
       "214  English WIKIBIO, French WIKIBIO , German WIKIB...   \n",
       "215   The expected number of unique outputs a word ...   \n",
       "216  Sentiment analysis and paraphrase detection un...   \n",
       "217  A semi-character based RNN (ScRNN) treats the ...   \n",
       "218  Adversarial misspellings are a real-world problem   \n",
       "219  In pass-through, the recognizer passes on the ...   \n",
       "220  A hybrid model consisting of best performing p...   \n",
       "221    E-book annotation data: editor tags, Amazon ...   \n",
       "222   Answer with content missing: (Table 2) Accura...   \n",
       "223                 Structural Support Vector Machine    \n",
       "224  The speech was collected from respondents usin...   \n",
       "225  Demographics Age, DiagnosisHistory, Medication...   \n",
       "226                      Level 1, Level 2 and Level 3.   \n",
       "227  Answer with content missing: (LVL1, LVL2, LVL3...   \n",
       "228   Thirteen different phenotypes are present in ...   \n",
       "229  Adv. Heart Disease, Adv. Lung Disease, Alcohol...   \n",
       "230                   The features extracted from CNN.   \n",
       "231  four machine translation tasks: German -> Engl...   \n",
       "232  On the datasets DE-EN, JA-EN, RO-EN, and EN-DE...   \n",
       "233  using word2vec to create features that are use...   \n",
       "234   one of the Twitter datasets is about Turkish ...   \n",
       "235  there are 20,244 reviews divided into positive...   \n",
       "236         Pretrained word embeddings  were not used    \n",
       "237  precision, recall, F1 and accuracy Response ti...   \n",
       "238  Custom dataset with user questions; set of doc...   \n",
       "239  ARAM has achieved improvement over all baselin...   \n",
       "240  They use a slightly modified copy of the targe...   \n",
       "241   Europarl tests from 2006, 2007, 2008; WMT new...   \n",
       "242  English-German, English-French. English-German...   \n",
       "243  Organic: mention of political parties names in...   \n",
       "244  Influential leaders are more likely to change ...   \n",
       "245                                23085 hours of data   \n",
       "246  2.49% for  layer-wise training, 2.63% for dist...   \n",
       "247  Unidirectional LSTM networks with 2, 6, 7, 8, ...   \n",
       "248                  They use text transcription. both   \n",
       "249                          They decrease MAE in 0.34   \n",
       "250   high-quality datasets  from SemEval-2016 “Sen...   \n",
       "251                                            English   \n",
       "252  Byte-Pair Encoding perplexity  (BPE PPL),\\nBLE...   \n",
       "253                                   English English    \n",
       "254   BioScope Abstracts, SFU, and BioScope Full Pa...   \n",
       "255                                 100 000 documents    \n",
       "256  Best results on unigram:\\nCNN/Daily Mail: Rogu...   \n",
       "257  Answer with content missing: (Table 3) Best au...   \n",
       "258  Social Honeypot dataset (public) and Weibo dat...   \n",
       "259  Extract features from the LDA model and use th...   \n",
       "260   Answer with content missing: (Experimental Se...   \n",
       "261                 1 IMDB dataset and 2 Yelp datasets   \n",
       "262       No specific domain is covered in the corpus.   \n",
       "263  0.8% F1 better than the best state-of-the-art ...   \n",
       "264   Among all the classes predicted by several mo...   \n",
       "265  They use two independent convolutional and max...   \n",
       "266  M-Bert had 76.6 F1 macro score. 75.1% and 75.6...   \n",
       "267  BERT had 76.6 F1 macro score on x-stance dataset.   \n",
       "268  A unordered text document is one where sentenc...   \n",
       "269                   Individuals with legal training    \n",
       "270                                  established task    \n",
       "271                                               None   \n",
       "272  Two knowledge-based systems,\\ntwo traditional ...   \n",
       "273                              small BERT small BERT   \n",
       "274  59.4% on wikipedia dataset, 93.4% on peer-revi...   \n",
       "275  It depends on the dataset. Experimental result...   \n",
       "276                                            English   \n",
       "277  a sample of  29,794 wikipedia articles and 2,7...   \n",
       "278                    POS, gender/number and stem POS   \n",
       "279  More than 2,100 texts were paired with 15 ques...   \n",
       "280  The data was collected using 3 components: des...   \n",
       "281  For SLC task, the \"ltuorp\" team  has the best ...   \n",
       "282                                        Linguistic    \n",
       "283  The best ensemble topped the best single model...   \n",
       "284                                               BERT   \n",
       "285  For SLC task : Ituorp, ProperGander and YMJA  ...   \n",
       "286  An output layer for each task Multi-tasking is...   \n",
       "287                 No data. Pretrained model is used.   \n",
       "288  Build a bilingual language model,   learn the ...   \n",
       "289  they obtained computer science related topics ...   \n",
       "290                              around 332k questions   \n",
       "291  CopyRNN (Meng et al., 2017), Multi-Task (Ye an...   \n",
       "292  The Conversations Gone Awry dataset is labelle...   \n",
       "293   An expanded version of the existing 'Conversa...   \n",
       "294  a perceptual illusion, where listening to a sp...   \n",
       "295  Four discourse phenomena - deixis, lexical coh...   \n",
       "296                                   On average 0.64    \n",
       "297   Named Entity Recognition, including entities ...   \n",
       "298   On Coin Collector, proposed model finds short...   \n",
       "299  Low data: SST-5, TREC, IMDB around 1-2 accurac...   \n",
       "300  Answer with content missing: (Subscript 1: \"We...   \n",
       "301   Selection of tweets with for each tweet a lab...   \n",
       "302  Chinese Mandarin, Welsh, English, Estonian, Fi...   \n",
       "303  Answer with content missing: (Evaluation Metri...   \n",
       "304  Answer with content missing: (Baseline Method ...   \n",
       "305   They break down the task of importance annota...   \n",
       "306  Answer with content missing: (formulas in sele...   \n",
       "307  LSTM to encode the question, VGG16 to extract ...   \n",
       "308  The number of redundant answers to collect fro...   \n",
       "309  Answer with content missing: (Evaluation secti...   \n",
       "310  Average success rate is higher by 2.6 percent ...   \n",
       "311    The Reuters-8 dataset (with stop words removed)   \n",
       "312  Word vectors, usually in the context of others...   \n",
       "313   it has 0.024 improvement in accuracy comparin...   \n",
       "314  30 terms, each term-sanse pair has around 15 s...   \n",
       "315  Spearman correlation values of GM_KL model eva...   \n",
       "316                          F1 score result of 0.8099   \n",
       "317  number of clusters, seed value in clustering, ...   \n",
       "318  Word clusters are extracted using k-means on w...   \n",
       "319   Unlabeled sentence-level F1, perplexity, gram...   \n",
       "320  Answer with content missing: (Data section) Pe...   \n",
       "321  Answer with content missing: (Data section) Ch...   \n",
       "322  Distributions of Followers, Friends and URLs a...   \n",
       "323  an expert annotator determined if the tweet fe...   \n",
       "324  Viral tweets are the ones that are retweeted m...   \n",
       "325  Accounts that spread fake news are mostly unve...   \n",
       "326       Ground truth is not established in the paper   \n",
       "327   Ancient Chinese history records in several dy...   \n",
       "328  Metric difference between Aloha and best basel...   \n",
       "329  English, German, Spanish, Mandarin, Polish, Ru...   \n",
       "330                                                  7   \n",
       "331  They compare the tasks that the datasets are s...   \n",
       "332  best model achieves 0.94 F1 score for Wikipedi...   \n",
       "333    LORELEI datasets of Uzbek, Mandarin and Turkish   \n",
       "334  The graph representation appears to be semi-su...   \n",
       "335  There is nothing specific about the approach t...   \n",
       "336                        Data already contain errors   \n",
       "337  Introduce a \"Refinement Adjustment LSTM-based ...   \n",
       "338                          NLG datasets NLG datasets   \n",
       "339   Automatic: Normalized cross correlation (NCC)...   \n",
       "340  Variational LSTM, CharCNN, Pointer Sentinel-LS...   \n",
       "341  English\\nFrench\\nSpanish\\nGerman\\nGreek\\nBulga...   \n",
       "342  Annotations from experts are used if they have...   \n",
       "343                  57,505 sentences 57,505 sentences   \n",
       "344  people in the US that use Amazon Mechanical Turk    \n",
       "345                                  neutral sentiment   \n",
       "346      BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN    \n",
       "347    BERT-base, BERT-large, BERT-uncased, BERT-cased   \n",
       "348   Calculate test log-likelihood on the three co...   \n",
       "349  Based on table results provided changing direc...   \n",
       "350  Increasing number of message passing iteration...   \n",
       "351  It is a framework used to describe algorithms ...   \n",
       "352  Gaze Sarcasm using Multi Instance Logistic Reg...   \n",
       "353  Readability (RED),  Number of Words (LEN), Avg...   \n",
       "354   Modeling considerations:  the variables (both...   \n",
       "355  a vocabulary of positive and negative predicat...   \n",
       "356  Using all data to train: AL -- BiGRU achieved ...   \n",
       "357  based on the relation between events, the sugg...   \n",
       "358  7000000 pairs of events were extracted from th...   \n",
       "359                                                 3%   \n",
       "360  by exploiting discourse relations to propagate...   \n",
       "361                                           30 words   \n",
       "362  Dynamic communities have substantially higher ...   \n",
       "363  They selected all the subreddits from January ...   \n",
       "364   CTS is extracting structural data from medica...   \n",
       "365  the dataset consists of pathology reports incl...   \n",
       "366                                             2,714    \n",
       "367  Quality measures using perplexity and recall, ...   \n",
       "368                                                one   \n",
       "369                    RIPA, Neighborhood Metric, WEAT   \n",
       "370                                  903019 references   \n",
       "371  Given we have four intensity, No PTSD, Low Ris...   \n",
       "372  Accuracy and the macro-F1 (averaged F1 over po...   \n",
       "373  Answer with content missing: (Table 1)\\nPrevio...   \n",
       "374          typos in spellings or ungrammatical words   \n",
       "375  In the sentiment classification task by 6% to ...   \n",
       "376  They used BERT-based models to detect subjecti...   \n",
       "377   No, other baseline metrics they use besides R...   \n",
       "378  Under the retrieval evaluation setting, their ...   \n",
       "379   They focus on exclusivity and semantic cohere...   \n",
       "380                                      Yes, Open IE    \n",
       "381  the English version is evaluated. The German v...   \n",
       "382  Average accuracy of proposed model vs best pre...   \n",
       "383  Active learning methods has a learning engine ...   \n",
       "384  For event types and participant types, there w...   \n",
       "385   Kinship and Nations knowledge graphs, YAGO3-1...   \n",
       "386   They crawled travel information from the Web ...   \n",
       "387  Only Bert base and Bert large are compared to ...   \n",
       "388  Comparing with the highest performing baseline...   \n",
       "389        classification, regression, neural methods    \n",
       "390  Ar, Bg, Ca, Cs, Da, De, En, Es, Eu, Fa, Fi, Fr...   \n",
       "391  For the emotion recognition from text they use...   \n",
       "392  Training data with 159000, 80000, 40000, 20000...   \n",
       "393   Resulting dataset was 7934 messages for train...   \n",
       "394                              machine comprehension   \n",
       "395  High correlation results range from 0.472 to 0...   \n",
       "396   BiGRUs with attention, ROUGE, Language model,...   \n",
       "397  Grammaticality, non-redundancy, referential cl...   \n",
       "398  A parallel corpus where the source is an Engli...   \n",
       "399  Semantic Enhancement GANs: DC-GANs, MC-GAN\\nRe...   \n",
       "400                                            English   \n",
       "401  Accuracy of best proposed method KANE (LSTM+Co...   \n",
       "402                                   Human evaluators   \n",
       "403  LDA unigrams (Presence/Count), POS Ratio, #Nam...   \n",
       "404  51.7 and 51.6 on 4th and 8th grade question se...   \n",
       "405  The dataset comes with a ranked set of relevan...   \n",
       "406  Best BLSTM-CNN-CRF had F1 score 86.87 vs 86.69...   \n",
       "407  Multitask learning is used for the task of pre...   \n",
       "408  0.007 MAP on Task A, 0.032 MAP on Task B, 0.05...   \n",
       "409  Proposed model has 1.16 million parameters and...   \n",
       "410                                                  9   \n",
       "411  Only MTMSM specifically tried to tackle the mu...   \n",
       "412  For single-span questions, the proposed LARGE-...   \n",
       "413  The proposed model achieves  EM 77,63 and F1 8...   \n",
       "414  BiLSTM-XR-Dev Estimation accuracy is 83.31 for...   \n",
       "415                      The Lemming model in BIBREF17   \n",
       "416  They evaluate F1 score and agent's test perfor...   \n",
       "417  Unimodal LSTM vs Best Multimodal (FCM)\\n- F sc...   \n",
       "418  On SearchSnippets dataset ACC 77.01%, NMI 62.9...   \n",
       "419  on SearchSnippets dataset by 6.72% in ACC, by ...   \n",
       "420  POS and DP task: CONLL 2018\\nNER task: (no ext...   \n",
       "421  Tweets noisy nature, use of creative spelling ...   \n",
       "422  27.41 transformation on average of single seed...   \n",
       "423  For each source sentence, transformation sente...   \n",
       "424                             Yes, as new sentences.   \n",
       "425  - paraphrase 1\\n- paraphrase 2\\n- different me...   \n",
       "426  accuracy of 86.63 on STS, 85.14 on Sanders and...   \n",
       "427  rules that compute polarity of words after POS...   \n",
       "428  Experiment 1: ACC around 0.5 with 50% noise ra...   \n",
       "429  ERR of 19.05 with i-vectors and 15.52 with x-v...   \n",
       "430  genre, entertainment, interview, singing, play...   \n",
       "431                                           x-vector   \n",
       "432  For i-vector system, performances are 11.75% i...   \n",
       "433                       Accuracy across six datasets   \n",
       "434                                  Kim et al. (2019)   \n",
       "435  Considering \"What\" and \"How\" separately versus...   \n",
       "436       Textual inputs, knowledge bases, and images.   \n",
       "437  Demographic information is predicted using wei...   \n",
       "438  The data are self-reported by Twitter users an...   \n",
       "439    From Twitter profile descriptions of the users.   \n",
       "440            Sociability from ego-network on Twitter   \n",
       "441                                      Users' tweets   \n",
       "442  Profile pictures from the Twitter users' profi...   \n",
       "443  Average reward across 5 seeds show that NLP re...   \n",
       "444  Google N-grams\\nCOHA\\nMoral Foundations Dictio...   \n",
       "445  By complementing morally relevant seed words w...   \n",
       "446  Perplexity of the best model is 65.58 compared...   \n",
       "447  Answer with content missing: (list missing) \\n...   \n",
       "448  Upward reasoning is defined as going from one ...   \n",
       "449                                Use an existing one   \n",
       "450                                                CNN   \n",
       "451      MUC, CoNLL, ACE, OntoNotes, MSM, Ritter, UMBC   \n",
       "452                       1000 hours of WSJ audio data   \n",
       "453                wav2vec has 12 convolutional layers   \n",
       "454  In-house dataset consists of  3716 documents \\...   \n",
       "455  the baseline where path generation uses a stan...   \n",
       "456  For test-repeated set, EM score of 61.17, F1 o...   \n",
       "457  exact match, f1 score, edit distance and goal ...   \n",
       "458  using Amazon Mechanical Turk using simulated e...   \n",
       "459                                   english language   \n",
       "460  distinguishing between clinically positive and...   \n",
       "461  Achieved the highest per-domain scores on Subs...   \n",
       "462  A BPE model is applied to the stem after morph...   \n",
       "463  Comparison of test accuracies of neural networ...   \n",
       "464  IWSLT14 German-English, IWSLT14 Turkish-Englis...   \n",
       "465                               Using crowdsourcing    \n",
       "466                              single-domain setting   \n",
       "467                                             70,000   \n",
       "468  Because, unlike other languages, English does ...   \n",
       "469  by calculating log ratio of grammatical phrase...   \n",
       "470  Between the model and Stanford, Spacy and Flai...   \n",
       "471  F1 score and Recall are 68.66, 80.08 with Trad...   \n",
       "472                                           4 layers   \n",
       "473  Concat\\nTurn\\nGate\\nAction Copy\\nTree Copy\\nSQ...   \n",
       "474  There were hierarchical and non-hierarchical b...   \n",
       "475  F1 score of best authors' model is 55.98 compa...   \n",
       "476        4,261  days for France and 4,748 for the UK   \n",
       "477  Winter and summer words formed two separate cl...   \n",
       "478                     Relative error is less than 5%   \n",
       "479                                 F1 score of 66.66%   \n",
       "480                                 F1 score of 82.10%   \n",
       "481  For sentiment analysis UWB, INF-UFRGS-OPINION-...   \n",
       "482                            3347 unique utterances    \n",
       "483  A continuous emission HMM uses the hidden stat...   \n",
       "484  The HMM can identify punctuation or pick up on...   \n",
       "485  With similar number of parameters, the log lik...   \n",
       "486  Proposed model achieves 0.86, 0.924, 0.71 F1 s...   \n",
       "487                               278 more annotations   \n",
       "488  Inter-annotator agreement, comparison against ...   \n",
       "489  a trained worker consolidates existing annotat...   \n",
       "490                     WMT 2014 En-Fr parallel corpus   \n",
       "491                                          late 2014   \n",
       "492  96-97.6% using the objects color or shape and ...   \n",
       "493                                supervised learning   \n",
       "494  using the BLEU score as a quantitative metric ...   \n",
       "495  For the question generation model 15,000 image...   \n",
       "496  By considering words as vertices and generatin...   \n",
       "497  Perplexity of proposed MEED model is 19.795 vs...   \n",
       "498                                            Authors   \n",
       "499    they are available in the Visual Genome dataset   \n",
       "500                                           MultiNLI   \n",
       "501  BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and ...   \n",
       "502  Private dashboard is leaderboard where competi...   \n",
       "503  Public dashboard where competitors can see the...   \n",
       "504  They used Wiki Vietnamese language and Vietnam...   \n",
       "505  They use it as addition to previous model - th...   \n",
       "506  Totally 6980 validation and test image-sentenc...   \n",
       "507  Italian Wikipedia and Google News extraction p...   \n",
       "508  Influential tweeters ( who they define as indi...   \n",
       "509  Stanford NER, BiLSTM+CRF, LSTM+CNN+CRF, T-NER ...   \n",
       "510  They identify documents that contain the unigr...   \n",
       "511  Randomly selected from a Twitter dump, tempora...   \n",
       "512  Presence of only the exact unigrams 'caused', ...   \n",
       "513                             Only automatic methods   \n",
       "514                       Randomly from a Twitter dump   \n",
       "515                              Randomly from Twitter   \n",
       "516  Variables in the set {str, prec, attr} indicat...   \n",
       "517  No, supervised models perform better for this ...   \n",
       "518  For task 1 best F1 score was 0.9391 on closed ...   \n",
       "519           well-formed sentences vs concise answers   \n",
       "520  BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Mult...   \n",
       "521  Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, R...   \n",
       "522           well-formed sentences vs concise answers   \n",
       "523  Answer with content missing: (Data and pre-pro...   \n",
       "524  They collected tweets in Russian language usin...   \n",
       "525  Proposed SG model vs SINDHI FASTTEXT:\\nAverage...   \n",
       "526  908456 unique words are available in collected...   \n",
       "527  standard parametrized attention and a non-atte...   \n",
       "528  Ranges from 44.22 to 100.00 depending on K and...   \n",
       "529                      Sequence Copy Task and WMT'17   \n",
       "530  New best results of accuracy (P@1) on Vecmap:\\...   \n",
       "531  Proposed method vs best baseline result on Vec...   \n",
       "532  EN<->ES\\nEN<->DE\\nEN<->IT\\nEN<->EO\\nEN<->MS\\nE...   \n",
       "533  They introduce new trigonometric encoding whic...   \n",
       "534  They use three groups short/normal/long transl...   \n",
       "535          It uses deep learning framework (pytorch)   \n",
       "536  No reliability diagrams are provided and no ex...   \n",
       "537                                    word embeddings   \n",
       "538  Yes, CRWIZ has been used for data collection a...   \n",
       "539  The words that can indicate the characteristic...   \n",
       "540  Using a set of annotation tools such as Morfeu...   \n",
       "541  Our method performs a statistical test to dete...   \n",
       "542  SPNet vs best baseline:\\nROUGE-1: 90.97 vs 90....   \n",
       "543  Not at the moment, but summaries can be additi...   \n",
       "544  Answer with content missing: (formula for CIC)...   \n",
       "545                          FTLM++, BERT-large, XLNet   \n",
       "546  Some sentences are associated to ambiguous dim...   \n",
       "547               entity memory and relational memory.   \n",
       "548                      by number of distinct n-grams   \n",
       "549  ON Event2Mind, the accuracy of proposed method...   \n",
       "550   CWVAE is trained on an auxiliary dataset to l...   \n",
       "551  0.08 points on the 2011 test set, 0.44 points ...   \n",
       "552  Their best average precision tops previous bes...   \n",
       "553  10*n paraphrases, where n depends on the numbe...   \n",
       "554              weak correlation with p-value of 0.08   \n",
       "555  using topic modeling model Latent Dirichlet Al...   \n",
       "556  The embeddings are learned several times using...   \n",
       "557  The data from collected travel surveys is used...   \n",
       "558  The coefficients are projected back to the dum...   \n",
       "559  Proposed ORNN has 0.769, 1.238, 0.818, 0.772 c...   \n",
       "560  Difference is around 1 BLEU score lower on ave...   \n",
       "561  Answer with content missing: (formula) The acc...   \n",
       "562                                                36%   \n",
       "563  MT developers to which crowd workers were comp...   \n",
       "564  Using model gradients with respect to input fe...   \n",
       "565  In four entity-centric ways - entity-first, en...   \n",
       "566                                            English   \n",
       "567  BLEU scores, exact matches of words in both tr...   \n",
       "568  Combined per-pixel accuracy for character line...   \n",
       "569                                                508   \n",
       "570  There are 6 simulated datasets collected which...   \n",
       "571  rating questions on a scale of 1-5 based on fl...   \n",
       "572  reviews under distinct product categories are ...   \n",
       "573            A bi-LSTM with max-pooling on top of it   \n",
       "574      Improved AECNN-T by 2.1 and AECNN-T-SM BY 0.9   \n",
       "575                   AS Reader, GA Reader, CAS Reader   \n",
       "576  They were able to create a language model from...   \n",
       "577  extracted text from Sorani Kurdish books of pr...   \n",
       "578                                                  1   \n",
       "579  By visualizing syntactic distance estimated by...   \n",
       "580                                    BPC, Perplexity   \n",
       "581  they are used as additional features in a supe...   \n",
       "582  A combination of Minimum spanning trees, K-Nea...   \n",
       "583  They think it will help human TCM practitioner...   \n",
       "584  A pointer network decodes the answer from a bi...   \n",
       "585  They achieved best result in the PAN 2017 shar...   \n",
       "586                             Gender prediction task   \n",
       "587                            Variety prediction task   \n",
       "588  The training dataset is augmented by swapping ...   \n",
       "589                 Gendered characters in the dataset   \n",
       "590  Informative are those that will not be suppres...   \n",
       "591           Perpexity is improved from 34.7 to 28.0.   \n",
       "592  Accuracy of best interpretible system was 0.39...   \n",
       "593                                     French-English   \n",
       "594  Emotion Sensor Feature, Part of Speech, Punctu...   \n",
       "595  Systems do not perform well both in Facebook a...   \n",
       "596                                               None   \n",
       "597                                        WN18, FB15k   \n",
       "598  SLQA, Rusalka, HMA Model (single), TriAN (sing...   \n",
       "599             This approach considers related images   \n",
       "600  It eliminates non-termination in some models f...   \n",
       "601  There are is a strong conjecture that it might...   \n",
       "602                                     133,287 images   \n",
       "603  Proposed model achive 66+-22 win rate, baselin...   \n",
       "604   Author's own DCG rules are defined from scratch.   \n",
       "605                                2.7 accuracy points   \n",
       "606                   accuracy with standard deviation   \n",
       "607  Datasets used are Celex (English, Dutch), Fest...   \n",
       "608  Authors report their best models have followin...   \n",
       "609  CELEX (Dutch and English) - SVM-HMM\\nFestival,...   \n",
       "610  For relation prediction they test TransE and f...   \n",
       "611  By assessing similarity of 360 pairs of relati...   \n",
       "612  To classify a text as belonging to one of the ...   \n",
       "613  A network, whose learned functions satisfy a c...   \n",
       "614  Switchboard-2000 contains 1700 more hours of s...   \n",
       "615  Answer with content missing: (Experimental set...   \n",
       "616  1. there may be situations where more than one...   \n",
       "617                           using generative process   \n",
       "618                Average claim length is 8.9 tokens.   \n",
       "619  Ethics, Gender, Human rights, Sports, Freedom ...   \n",
       "620  In terms of F1 score, the Hybrid approach impr...   \n",
       "621  Each class has different patterns in adjective...   \n",
       "622  Gospel, Sertanejo, MPB, Forró, Pagode, Rock, S...   \n",
       "623  LSTMs with and without attention, HRED, VHRED ...   \n",
       "624  Through Amazon MTurk annotators to determine p...   \n",
       "625  on diversity 6.87 and on relevance 4.6 points ...   \n",
       "626                    the hybrid model MinAvgOut + RL   \n",
       "627  most of the models have similar performance on...   \n",
       "628  ROUGE-1 increases by 0.05, ROUGE-2 by 0.06 and...   \n",
       "629               binary label of stress or not stress   \n",
       "630           By annotators on Amazon Mechanical Turk.   \n",
       "631                                                one   \n",
       "632  They exclude slot-specific parameters and inco...   \n",
       "633                       By the number of parameters.   \n",
       "634  Answer with content missing: (Skip-thought vec...   \n",
       "635  - En-Fr (WMT14)\\n- En-De (WMT15)\\n- Skipthough...   \n",
       "636  By using  keywords `breast' AND `cancer' in tw...   \n",
       "637  ML  logistic regression classifier combined wi...   \n",
       "638  PPL: SVT\\nDiversity: GVT\\nEmbeddings Similarit...   \n",
       "639  Attention-based translation model with convolu...   \n",
       "640        Bidirectional LSTM based NER model of Flair   \n",
       "641  Little overlap except common basic Latin alpha...   \n",
       "642        Hindi, English and German (German task won)   \n",
       "643                                               thai   \n",
       "644  Answer with content missing: (formula 1) bias(...   \n",
       "645                                    word error rate   \n",
       "646                             163,110,000 utterances   \n",
       "647             Their model does not differ from BERT.   \n",
       "648  Answer with content missing: (Formula 2) Formu...   \n",
       "649                              There is no baseline.   \n",
       "650                                  553,451 documents   \n",
       "651  The model outperforms at every point in the\\ni...   \n",
       "652                                 MC-CNN\\nMVCNN\\nCNN   \n",
       "653  In terms of Subj the Average MGNC-CNN is bette...   \n",
       "654  Humor in headlines (TitleStylist vs Multitask ...   \n",
       "655  The languages considered were English, Chinese...   \n",
       "656  They experimented with sentiment analysis and ...   \n",
       "657  Accuracy on each dataset and the average accur...   \n",
       "658  youtube video transcripts on news covering dif...   \n",
       "659  It takes into account the agreement between di...   \n",
       "660  Answer with content missing: (Table 1) The per...   \n",
       "661  Answer with content missing: (Formula) Formula...   \n",
       "662  two surveys by two groups - school students an...   \n",
       "663  1 000 labeled dialogues for training and 240 u...   \n",
       "664  1 000 labeled dialogues for training and 240 u...   \n",
       "665                                               IDEA   \n",
       "666  Training embeddings from small-corpora can inc...   \n",
       "667      Visualization of State of the union addresses   \n",
       "668  Northeast U.S, South U.S., West U.S. and Midwe...   \n",
       "669                                 0.9098 correlation   \n",
       "670  Using Latent Dirichlet Allocation on TF-IDF tr...   \n",
       "671           Northeast U.S., West U.S. and South U.S.   \n",
       "672           evidence extraction and answer synthesis   \n",
       "673  Replacing attention mechanism to query-key att...   \n",
       "674  how long it takes the system to lemmatize a se...   \n",
       "675                                             97.32%   \n",
       "676  cloze-style reading comprehension and user que...   \n",
       "677                                            English   \n",
       "678  12 binary-class classification and multi-class...   \n",
       "679  machine translation, statistical machine, sent...   \n",
       "680                    CL Journal and EMNLP conference   \n",
       "681      English, Chinese, French, Japanese and Arabic   \n",
       "682  Simple Skip improves F1 from 74.34 to 74.81\\nT...   \n",
       "683  0.8 points on Binary; 0.7 points on Fine-Grain...   \n",
       "684                                              82.0%   \n",
       "685  Data released for APDA shared task contains 3 ...   \n",
       "686  It had the highest accuracy comparing to all d...   \n",
       "687  Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver...   \n",
       "688  Assign a value to the relation based on whethe...   \n",
       "689  Exact matches to the entity string and predict...   \n",
       "690  During testing: 67.6 for single model without ...   \n",
       "691  Preceding and following sentence of each metap...   \n",
       "692         Best performance achieved is 0.72 F1 score   \n",
       "693  Answer with content missing: (Table II) Propos...   \n",
       "694  Answer with content missing: (Table II) Propos...   \n",
       "695  Damage to neural modules is done by randomly i...   \n",
       "696  Travel dataset contains 4100 raw samples, 1129...   \n",
       "697  User reviews written in Chinese collected onli...   \n",
       "698  They use a two-stage labeling strategy where i...   \n",
       "699  The changes are evaluated based on accuracy of...   \n",
       "700  Answer with content missing: (3 Experimental S...   \n",
       "701  440 sentences, 2247 triples extracted from tho...   \n",
       "702                                 OpenIE4 and MiniIE   \n",
       "703  They pre-train forward and backward LMs separa...   \n",
       "704                                  micro-averaged F1   \n",
       "705  91.93% F1 score on CoNLL 2003 NER task and 96....   \n",
       "706  Chiu and Nichols (2016), Lample et al. (2016),...   \n",
       "707  Both supervised and unsupervised, depending on...   \n",
       "708  Performance was comparable, with the proposed ...   \n",
       "709                                        GloVE; SGNS   \n",
       "710                                                GRU   \n",
       "711  It is a network used to encode speech lattices...   \n",
       "712  For sentence-level prediction they used tolera...   \n",
       "713       tutorial videos for a photo-editing software   \n",
       "714  a sentence-level prediction algorithm, a segme...   \n",
       "715  Full Testing Set accuracy: 84.02\\nCleaned Test...   \n",
       "716  Full Testing Set Accuracy: 84.02\\nCleaned Test...   \n",
       "717  Operation accuracy: 71.89\\nExecution accuracy:...   \n",
       "718  BLSTM+Attention+BLSTM\\nHierarchical BLSTM-CRF\\...   \n",
       "719  The baseline models used are DrQA modified to ...   \n",
       "720  Alarm, Banks, Buses, Calendar, Events, Flights...   \n",
       "721  Total number of annotated data:\\nSemeval'15: 1...   \n",
       "722       Arabic, German, Portuguese, Russian, Swedish   \n",
       "723  The three baseline models are the i-vector mod...   \n",
       "724  Proposing an improved RNN model, the phonetic ...   \n",
       "725  These are well-known formal languages some of ...   \n",
       "726  graph-like structures where arcs connect nodes...   \n",
       "727  NMI between cluster assignments and ground tru...   \n",
       "728                              Precision, Recall, F1   \n",
       "729  CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkar...   \n",
       "730         Perceptron model using the local features.   \n",
       "731  AraVec for Arabic, FastText for French, and Wo...   \n",
       "732                               One model per topic.   \n",
       "733                      They evaluate quantitatively.   \n",
       "734             EER 16.04, Cmindet 0.6012, Cdet 0.6107   \n",
       "735                                Logistic regression   \n",
       "736  By using a Bayesian approach  and by using wor...   \n",
       "737  They use a left-to-right attention mask so tha...   \n",
       "738  The image feature vectors are mapped into BERT...   \n",
       "739  Answer with content missing: (whole introducti...   \n",
       "740  They perform t-SNE clustering to analyze disco...   \n",
       "741  They derive entity grid with grammatical relat...   \n",
       "742  Entity grid with grammatical relations and RST...   \n",
       "743  A sequence of logical statements represented i...   \n",
       "744  Raw data from Gigaword, Automatically segmente...   \n",
       "745  Pearson correlation to human judgement - propo...   \n",
       "746  Transcribed data is available for duration of ...   \n",
       "747  HotspotQA: Yang, Ding, Muppet\\nFever: Hanselow...   \n",
       "748                                                  2   \n",
       "749                                               8000   \n",
       "750  String kernel is a technique that uses charact...   \n",
       "751  They compute Pearson’s correlation between NED...   \n",
       "752                                              52.0%   \n",
       "753  300,000 sentences with 1.5 million single-quiz...   \n",
       "754  Around 388k examples, 194k from tst2013 (in-do...   \n",
       "755  a RNN-based seq2seq VC model called ATTS2S bas...   \n",
       "756                  AmazonQA and ConciergeQA datasets   \n",
       "757           Multi-Encoder, Constrained-Decoder model   \n",
       "758                           ConciergeQA and AmazonQA   \n",
       "759  by adding extra supervision to generate the sl...   \n",
       "760                       NDM, LIDM, KVRN, and TSCP/RL   \n",
       "761  Confusion in recognizing the words that are ac...   \n",
       "762  Proposed RCRN outperforms ablative baselines B...   \n",
       "763                                               51.5   \n",
       "764  High-order CNN, Tree-LSTM, DRNN, DCNN, CNN-MC,...   \n",
       "765   They used Stanford Sentiment Treebank benchma...   \n",
       "766  They used 6 indicators for proficiency (same f...   \n",
       "767  6 indicators:\\n- lexical richness\\n- pronuncia...   \n",
       "768  Accuracy not available: WER results are report...   \n",
       "769  Speech recognition system is evaluated using W...   \n",
       "770  Total number of transcribed utterances includi...   \n",
       "771  Total number of utterances available is: 70607...   \n",
       "772  w.r.t Rouge-1 their model outperforms by 0.98%...   \n",
       "773  neural attention model with a convolutional en...   \n",
       "774  F1 scores of 86.16 on slot filling and 94.56 o...   \n",
       "775                                  10,001 utterances   \n",
       "776  Questions are gathered from anonymized, aggreg...   \n",
       "777                   Remove numbers and interjections   \n",
       "778  10 Epochs: pearson-Spearman correlation  drops...   \n",
       "779                                      SST-2 dataset   \n",
       "780  The increase is linearly from lowest on averag...   \n",
       "781                                         40 minutes   \n",
       "782  Best model achieved F-score 74.7 on NALCS and ...   \n",
       "783  mean prediction accuracy 0.99582651\\nS&P 500 A...   \n",
       "784  historical S&P 500 component stocks\\n 306242 n...   \n",
       "785  it systematically holds out inputs in the trai...   \n",
       "786  The system outperforms by 27.7% the LSTM model...   \n",
       "787  The system is compared to baseline models: LST...   \n",
       "788  BULATS i-vector/PLDA\\nBULATS x-vector/PLDA\\nVo...   \n",
       "789                                      VQA and GeoQA   \n",
       "790  They use Monalog for data-augmentation to fine...   \n",
       "791                        They derive it from Wordnet   \n",
       "792  Economics, Genocide, Geography, History, Human...   \n",
       "793  Answer with content missing: (Names of many id...   \n",
       "794  WikiSQL - 2 rules (SELECT, WHERE)\\nSimpleQuest...   \n",
       "795  Bi-LSTM: For low resource <17k clean data: Usi...   \n",
       "796  Evaluation datasets used:\\nCMRC 2018 - 18939 q...   \n",
       "797  Microsoft Research dataset containing movie, t...   \n",
       "798  For entity  F1 in the movie, taxi and restaura...   \n",
       "799  It has three sequentially connected units to o...   \n",
       "800  counts of predicate-argument tuples from Engli...   \n",
       "801  Test set 1 contained 57 drug labels and 8208 s...   \n",
       "802  ABSA SemEval 2014-2016 datasets\\nYelp Academic...   \n",
       "803                                             $1,728   \n",
       "804            BERT, XLNET RoBERTa, ALBERT, DistilBERT   \n",
       "805                     using multiple pivot sentences   \n",
       "806  For the Oshiete-goo dataset, the NAGM model's ...   \n",
       "807   In closed setting 84.22 F1 and in open 87.35 F1.   \n",
       "808  Marcheggiani and Titov (2017) and Cai et al. (...   \n",
       "809                                      14 categories   \n",
       "810                                     YouTube videos   \n",
       "811  Qualitatively through efficiency, effectivenes...   \n",
       "812  Answer with content missing: (Chapter 3) The c...   \n",
       "813  Train languages are: Cantonese, Bengali, Pasht...   \n",
       "814  They  evaluate newly proposed models in severa...   \n",
       "815                      It contains 106,350 documents   \n",
       "816                                over 104k documents   \n",
       "817  Perplexity score 142.84 on dev and 138.91 on test   \n",
       "818  Parallel monolingual corpus in English and Man...   \n",
       "819  in open-ended task esp. for counting-type ques...   \n",
       "820                         LASSO optimization problem   \n",
       "821                 Personal thought of the annotator.   \n",
       "822  Word embeddings trained on GoogleNews and Word...   \n",
       "823  Entity identification with offset mapping and ...   \n",
       "824  They randomly sample sentences from Wikipedia ...   \n",
       "825  Lexicon of the cities tend to use most forms o...   \n",
       "826  It uses particular forms of a concept rather t...   \n",
       "827  Overall accuracy per model is: 5-gram (60.5), ...   \n",
       "828                 bag of words, tf-idf, bag-of-means   \n",
       "829  Aristo Corpus\\nRegents 4th\\nRegents 8th\\nRegen...   \n",
       "830                                                 12   \n",
       "831  - Font & Keyboard\\n- Speech-to-Text\\n- Text-to...   \n",
       "832  The reciprocal of the variance of the attentio...   \n",
       "833  Measuring three aspects: argumentation, specif...   \n",
       "834  2008 Punyakanok et al. \\n2009 Zhao et al. + ME...   \n",
       "835                                     LSTM and BERT    \n",
       "836  Dataset has 1737 train, 497 dev and 559 test s...   \n",
       "837                            4.756 million sentences   \n",
       "838  can be biased by dataset used and may generate...   \n",
       "839  it is less expensive and quantifies interpreta...   \n",
       "840  By computing number of unique responses and nu...   \n",
       "841      RNN-context, SRB, CopyNet, RNN-distract, DRGD   \n",
       "842  comparing the summary with the text instead of...   \n",
       "843  EN, JA, ES, AR, PT, KO, TH, FR, TR, RU, IT, DE...   \n",
       "844  Proposed vs best baseline:\\nDecoding: 8541 vs ...   \n",
       "845                                     WN18 and FB15k   \n",
       "846  Online sites tagged as fake news site by Veraf...   \n",
       "847  Siamese neural network consisting of an embedd...   \n",
       "848  besides claim, label and claim url, it also in...   \n",
       "849                                        monolingual   \n",
       "850  performance is significantly degraded without ...   \n",
       "851  Comparing BLEU score of model with and without...   \n",
       "852  The health benefits of alcohol consumption are...   \n",
       "853                  not researched as much as English   \n",
       "854                                                  3   \n",
       "855  Matching features from matching sentences from...   \n",
       "856  Their average improvement in Character Error R...   \n",
       "857                                             449050   \n",
       "858                                                  1   \n",
       "859  2 for the ADE dataset and 3 for the CoNLL04 da...   \n",
       "860                                1, 4, 8, 16, 32, 64   \n",
       "861  S2VT, RGB (VGG), RGB (VGG)+Flow (AlexNet), LST...   \n",
       "862                  German, English, Italian, Chinese   \n",
       "863                         About the same performance   \n",
       "864                                 F1 and Weighted-F1   \n",
       "865  Yes, Transformer based seq2seq is evaluated wi...   \n",
       "866   Generate a query out of the claim and queryin...   \n",
       "867              weibo-100k, Ontonotes, LCQMC and XNLI   \n",
       "868                                               3029   \n",
       "869  MOCC, OCCAV, COAV, AVeer, GLAD, DistAV, Unmask...   \n",
       "870  Annotation was done with the help of annotator...   \n",
       "871  They look at the performance accuracy of expla...   \n",
       "872  Their model resulted in values of 0.476, 0.672...   \n",
       "873  by converting human advice to first-order logi...   \n",
       "874  affective features provided by different emoti...   \n",
       "875  Data augmentation (es)  improved Adv es by 20%...   \n",
       "876  In task 1 best transfer learning strategy impr...   \n",
       "877                                                SVM   \n",
       "878  Clusters of Twitter user ids from accounts of ...   \n",
       "879  On subtask 3 best proposed model has F1 score ...   \n",
       "880  1448 sentences more than the dataset from Bhat...   \n",
       "881   The dataset from a joint ADAPT-Microsoft project   \n",
       "882  Background, extends, uses, motivation, compare...   \n",
       "883  Annotators went through various phases to make...   \n",
       "884  the best performing model obtained an accuracy...   \n",
       "885  Appreciation, Satisfied, Peripheral complaint,...   \n",
       "886  The sequence model architectures which this me...   \n",
       "887  Across 4 datasets, the best performing propose...   \n",
       "888  error rate in a minimal pair ABX discriminatio...   \n",
       "889                                        BLEU scores   \n",
       "890  a linear projection and a bijective function w...   \n",
       "891  Alarm\\nBank\\nBus\\nCalendar\\nEvent\\nFlight\\nHom...   \n",
       "892  They pre-train the models using 600000 article...   \n",
       "893                                        645, 600000   \n",
       "894           The negative effects were insignificant.   \n",
       "895            English to French and English to German   \n",
       "896  Accuracy and F1 score for supervised tasks, Pe...   \n",
       "897  Zipf's law describes change of word frequency ...   \n",
       "898  Random perturbation of Wikipedia sentences usi...   \n",
       "899  Proposed method achieves 94.5 UAS and 92.4 LAS...   \n",
       "900  root mean square error between the actual and ...   \n",
       "901  By using Apache Spark which stores all executi...   \n",
       "902  handling large volume incoming data, sentiment...   \n",
       "903  BLUE utilizes different metrics for each of th...   \n",
       "904  bilingual dictionary induction, monolingual an...   \n",
       "905  because word pair similarity increases if the ...   \n",
       "906  Word alignments are generated for parallel tex...   \n",
       "907  0.8320 on semantic typing, 0.7194 on entity ma...   \n",
       "908  Answer with content missing: (Table 2) CONCAT ...   \n",
       "909  They initialize their word and entity embeddin...   \n",
       "910  The authors believe that the Wikilinks corpus ...   \n",
       "911  No, it is a probabilistic model trained by fin...   \n",
       "912  Through human evaluation where they are asked ...   \n",
       "913        Darkode,  Hack Forums, Blackhat and Nulled.   \n",
       "914  BERT generates sentence embeddings that repres...   \n",
       "915  the training dataset is large while the target...   \n",
       "916  Variety of formats supported (PDF, Word...), u...   \n",
       "917        optimize single task with no synthetic data   \n",
       "918  networks where nodes represent causes and effe...   \n",
       "919  if it includes  negative utterances, negative ...   \n",
       "920  By treating logical forms as a latent variable...   \n",
       "921  ISOT dataset: LLVM\\nLiar dataset: Hybrid CNN a...   \n",
       "922  Their GTRS approach got an improvement of 3.89...   \n",
       "923  Answer with content missing: (Applications sec...   \n",
       "924  deciding publisher partisanship, risk annotato...   \n",
       "925                                    CNN, LSTM, BERT   \n",
       "926  No feature is given, only discussion that sema...   \n",
       "927  It is not completely valid for natural languag...   \n",
       "928      DocQA, SAN, QANet, ASReader, LM, Random Guess   \n",
       "929  TEACHER FORCING (TF), SCHEDULED SAMPLING (SS),...   \n",
       "930  The relation R(x,y) is mapped onto a question ...   \n",
       "931  pre-trained to identify the presence of behavi...   \n",
       "932  The model does not add new relations to the kn...   \n",
       "933  The dataset contains about 590 tweets about DD...   \n",
       "934  Tweets related to a Bank of America DDos attac...   \n",
       "935  current news, historical news, free time, spor...   \n",
       "936  high-order representation of a relation, loss ...   \n",
       "937                                 NELL-One, Wiki-One   \n",
       "938  comparing to the results from reducing the num...   \n",
       "939     Multilingual Neural Machine Translation Models   \n",
       "940  Automatic transcription of 5000 tokens through...   \n",
       "941  The framework jointly learns parametrized QA a...   \n",
       "942  efficiency task aimed  at reducing the number ...   \n",
       "943  It is observed some variability - but not sign...   \n",
       "944  There is no reason to think that this approach...   \n",
       "945      The same 2K set from Gigaword used in BIBREF7   \n",
       "946    all regions except those that are colored black   \n",
       "947           they use ROC curves and cross-validation   \n",
       "948  They use self-play learning , optimize the mod...   \n",
       "949  1,618 training dialogs, 500 validation dialogs...   \n",
       "950  Training datasets: TTS System dataset and embe...   \n",
       "951  The mixed objective improves EM by 2.5% and F1...   \n",
       "952  5 domains: software, stuff, african wildlife, ...   \n",
       "953  Improve existing NLP methods. Improve linguist...   \n",
       "954  Two neural networks: an extractor based on an ...   \n",
       "955  AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...   \n",
       "956  Similar to standard convolutional networks but...   \n",
       "957  Optimized TF-IDF, iterated TF-IDF, BERT re-ran...   \n",
       "958  Kaggle\\nSubversive Kaggle\\nWikipedia\\nSubversi...   \n",
       "959  Compared to baselines SAN (Table 1) shows  imp...   \n",
       "960  The baseline is a multi-task architecture insp...   \n",
       "961  The network architecture has a multi-task Bi-D...   \n",
       "962  Stacks and joins outputs of previous frames wi...   \n",
       "963  reward 1 for successfully completing the task,...   \n",
       "964  No, there has been previous work on recognizin...   \n",
       "965  3 million webpages processed with a CCG parser...   \n",
       "966       Fill-in-the-blank natural language questions   \n",
       "967                   3 feature maps for a given tuple   \n",
       "\n",
       "                                               context  \n",
       "0    For MultiUN corpus, we use four languages: Eng...  \n",
       "1    Data collection. Subreddits are sub-communitie...  \n",
       "2    FLOAT SELECTED: Table 2: Main results on the D...  \n",
       "3    With the purpose of obtaining evaluation datas...  \n",
       "4    We experimented with English INLINEFORM0 Hindi...  \n",
       "5    The paper at hand introduces a corpus develope...  \n",
       "6    We measure how contextual a word representatio...  \n",
       "7    FLOAT SELECTED: Table 1: The performance of va...  \n",
       "8    To finish with this experiment set, Table also...  \n",
       "9    Even if LangID-High does not present a more ac...  \n",
       "10   Human Evaluation Results. While automated eval...  \n",
       "11   It may be difficult to spot patterns by just l...  \n",
       "12   Ethnicity/race One interesting pattern is that...  \n",
       "13   The second row shows the performance of our ba...  \n",
       "14   In this paper, we propose a method that builds...  \n",
       "15   However, getting access to systems with real u...  \n",
       "16   We collected the dataset with 1900 dialogs and...  \n",
       "17   Named Entity Recognition: We defined a sequenc...  \n",
       "18   In this paper, we explore multiple pooling str...  \n",
       "19   GhostVLAD is an extension of the NetVLAD appro...  \n",
       "20   FLOAT SELECTED: Table 1: Dataset In this secti...  \n",
       "21   In this section, we introduce an invertibility...  \n",
       "22   We create two models both of which constitutes...  \n",
       "23   FLOAT SELECTED: Table 2: Clustering results on...  \n",
       "24   FLOAT SELECTED: Table 2: Top: Examples of with...  \n",
       "25   Automatically answering questions, especially ...  \n",
       "26   Our comprehensive assessment reveals several i...  \n",
       "27   FLOAT SELECTED: Table 2: Official shared task ...  \n",
       "28   FLOAT SELECTED: Table 1: Example input sentenc...  \n",
       "29   Table TABREF21 reports comparison results in l...  \n",
       "30   To test all the possible combinations of param...  \n",
       "31   FLOAT SELECTED: Figure 2: Ablation results on ...  \n",
       "32   Baselines. As none of the existing KBC methods...  \n",
       "33   We solve the OKBC problem by mimicking how hum...  \n",
       "34   FLOAT SELECTED: Table 1: Summary of datasets. ...  \n",
       "35   FLOAT SELECTED: Table 1: Summary of datasets. ...  \n",
       "36   Monosemous relatives have been employed multip...  \n",
       "37   Comparing these topics with those that appeare...  \n",
       "38   Depechemood is a lexicon-based emotion detecti...  \n",
       "39   What similarities and/or differences do these ...  \n",
       "40   Topic modeling methods are the more powerful t...  \n",
       "41   We develop a variety of ShapeWorldICE datasets...  \n",
       "42   FLOAT SELECTED: Table 1: The results of two pr...  \n",
       "43   FLOAT SELECTED: Table 2: EM/F1 score of multi-...  \n",
       "44   The SnapCaptions dataset is composed of 10K us...  \n",
       "45   Based on the above observations, we propose St...  \n",
       "46   Our analysis shows that attention models tradi...  \n",
       "47   To better understand how attention accuracy af...  \n",
       "48   FLOAT SELECTED: Table 1: The comparison of var...  \n",
       "49   We first use state-of-the-art PDTB taggers for...  \n",
       "50   We defined the intents with guidance from quer...  \n",
       "51   This paper fills this gap by analyzing intent ...  \n",
       "52   We introduce a new crowdsourced dataset of 23,...  \n",
       "53   We show that existing automatic metrics, inclu...  \n",
       "54   The data collection was performed separately f...  \n",
       "55   We use bootstrap sampling (500 iterations) ove...  \n",
       "56   FLOAT SELECTED: Table 8: Sector-level performa...  \n",
       "57   The above challenges often hinder the producti...  \n",
       "58   Though Bengali is the seventh most spoken lang...  \n",
       "59   The performance of all models on arXiv and Pub...  \n",
       "60   The baseline system for the SLC task is a very...  \n",
       "61   However, despite these successes distributiona...  \n",
       "62   MiniMayoSRS: The MayoSRS, developed by Pakhomo...  \n",
       "63   In our experiments, the Memory Neural Networks...  \n",
       "64   To ensure that the increase in BLEU score corr...  \n",
       "65   FLOAT SELECTED: Table 3: Comparison with exist...  \n",
       "66   The results for each class type are shown in T...  \n",
       "67   While these knowledge bases provide semantical...  \n",
       "68   Baseline Results ::: Speech Synthesis In our p...  \n",
       "69   In addition, the transcription includes annota...  \n",
       "70   where * denotes summation over the correspondi...  \n",
       "71   Why incorporate -PMI? $\\mathit {\\texttt {+}PPM...  \n",
       "72   Unfortunately, $\\mathit {PMI}(w,c)$ goes to ne...  \n",
       "73   This work is most closely related to the paper...  \n",
       "74   This work is most closely related to the paper...  \n",
       "75   We carried out our experiments on the Universa...  \n",
       "76   FLOAT SELECTED: Table 1: Twitter celebrities i...  \n",
       "77   This work analyzes the understanding of pretra...  \n",
       "78   We considered a dataset of 100 employees, wher...  \n",
       "79   We randomly selected 2000 sentences from the s...  \n",
       "80   We select contemporary MRC benchmarks to repre...  \n",
       "81   Figure FIGREF4 pictorially represents our meth...  \n",
       "82   The previously proposed contextual language mo...  \n",
       "83   To better demonstrate the effectiveness of the...  \n",
       "84   FLOAT SELECTED: Table 1: Hyper-parameter choic...  \n",
       "85   The flow of talking points . A side can either...  \n",
       "86   FLOAT SELECTED: Table 2: Comparison of annotat...  \n",
       "87   RKS approach proposed in BIBREF21, BIBREF22, e...  \n",
       "88   In addition to words, EqEmb models can capture...  \n",
       "89   Feature elimination strategies are often taken...  \n",
       "90   Specifically, we conducted a feature ablation ...  \n",
       "91   In this work, we use the raw waveform as the i...  \n",
       "92   where INLINEFORM0 , INLINEFORM1 is the number ...  \n",
       "93   A total of 2,50,000 tweets over a period of Au...  \n",
       "94   When predicting anger, joy, or valence, the nu...  \n",
       "95   We decided to use sentences involving at least...  \n",
       "96   We also evaluate the Jasper model's performanc...  \n",
       "97   We trained a smaller Jasper 10x3 model with SG...  \n",
       "98   FLOAT SELECTED: Table 1: Speech Embeddings Exp...  \n",
       "99   Table TABREF21 illustrates the experimental re...  \n",
       "100  Active learning sharply increases the performa...  \n",
       "101  We began with evaluating standard MT paradigms...  \n",
       "102  Two batch of tests were performed. The first o...  \n",
       "103  We perform a direct comparison of expert and c...  \n",
       "104  Recently, ELMoForManyLangs BIBREF6 project rel...  \n",
       "105  FLOAT SELECTED: Table 4: The results of NER ev...  \n",
       "106  Table TABREF11 shows Word Error Rates (WER) on...  \n",
       "107  FLOAT SELECTED: Table 1: Speech datasets used....  \n",
       "108  Despite its usefulness, linked entities extrac...  \n",
       "109  FLOAT SELECTED: Table 1: Dataset statistics In...  \n",
       "110  Similar approaches has been applied to many So...  \n",
       "111  After much time, we received the dataset from ...  \n",
       "112  FLOAT SELECTED: Table 1: Dataset statistics Ta...  \n",
       "113  FLOAT SELECTED: Table 1: Dataset statistics Af...  \n",
       "114  FLOAT SELECTED: Table 5: Comparison of differe...  \n",
       "115  We have evaluated our models considering the F...  \n",
       "116  We compare eight different models in our exper...  \n",
       "117  In this paper we present our work, which is a ...  \n",
       "118  In this paper we present our work, which is a ...  \n",
       "119  In order to evaluate our classifiers, we perfo...  \n",
       "120  FLOAT SELECTED: Table 2: Evaluation metrics fo...  \n",
       "121  Figure FIGREF10 illustrates the UTCNN model. A...  \n",
       "122  We pit our model against the following baselin...  \n",
       "123  We compare the SBERT sentence embeddings to ot...  \n",
       "124  FLOAT SELECTED: Table 1: Spearman rank correla...  \n",
       "125  As a first baseline we use Bag-of-Words, a wel...  \n",
       "126  Considering the improvements over the majority...  \n",
       "127  In order to eliminate the need to find data an...  \n",
       "128  We evaluate our model on a publicly available ...  \n",
       "129  In order to decode spatial connections between...  \n",
       "130  Datasets. We perform our experiments with two ...  \n",
       "131  Human-in-the-Loop Approaches. Our work extends...  \n",
       "132  Our approach improves LR by 5.17% (Accuracy) a...  \n",
       "133  Macaw also supports Wizard of Oz studies or in...  \n",
       "134  Here we introduce the evaluation setup and ana...  \n",
       "135  We model the ASP placement task as a successor...  \n",
       "136  An important feature when suggesting an articl...  \n",
       "137  Baseline Features. As discussed in Section SEC...  \n",
       "138  We asked medical doctors experienced in extrac...  \n",
       "139  Experimental Setup. We apply a 5 cross-validat...  \n",
       "140  Given a news Twitter account, we read its twee...  \n",
       "141  Data. We build a dataset of Twitter accounts b...  \n",
       "142  The main obstacle for detecting suspicious Twi...  \n",
       "143  For the evaluation of summaries we use the sta...  \n",
       "144  After parsing (Step 1) we have the AMR graphs ...  \n",
       "145  FLOAT SELECTED: Table 3: Distribution of label...  \n",
       "146  Level B categorizes the type of offense and tw...  \n",
       "147  The data included in OLID has been collected f...  \n",
       "148  Our proposed metric is based on analysis of th...  \n",
       "149  Table TABREF23 shows the Pearson, Spearman and...  \n",
       "150  Results for the experiments are listed in Tabl...  \n",
       "151  Table TABREF19 displays the performance of the...  \n",
       "152  The error detection results can be seen in Tab...  \n",
       "153  Results. Table 1 shows the results of all mode...  \n",
       "154  Dataset. We use two simplification datasets (W...  \n",
       "155  Next, we analyzed all tweets labeled as offens...  \n",
       "156  We developed the annotation guidelines jointly...  \n",
       "157  Disclaimer: Due to the nature of the paper, so...  \n",
       "158  Although some previous studies focus on irony ...  \n",
       "159  As neural networks are proved effective in iro...  \n",
       "160  In order to evaluate sentiment preservation, w...  \n",
       "161  We have decided to consider tweets about popul...  \n",
       "162  With an intention to exploit the contribution ...  \n",
       "163  Results in Table TABREF13 show ten probes. Aga...  \n",
       "164  Recent work has probed the knowledge encoded i...  \n",
       "165  To deal with these limitations, in this paper,...  \n",
       "166  FLOAT SELECTED: Table 1: Industry categories a...  \n",
       "167  Minimal pre-processing was done by converting ...  \n",
       "168  FLOAT SELECTED: Table 2: LID Accuracy Results....  \n",
       "169  We address the robustness problem on top of GE...  \n",
       "170  In this section, we first justify the approach...  \n",
       "171  GE-FL reduces the heavy load of instance annot...  \n",
       "172  We annotated the dataset at two levels: Part o...  \n",
       "173  FLOAT SELECTED: Figure 2: Histogram of documen...  \n",
       "174  In this paper, we use three encoders (NBOW, LS...  \n",
       "175  In order to achieve these configuration the TI...  \n",
       "176  FLOAT SELECTED: Table 1: Comparison results on...  \n",
       "177  FLOAT SELECTED: Table 1: Comparison results on...  \n",
       "178  We evaluate our model on two benchmark dataset...  \n",
       "179  The contexts have the characteristic that each...  \n",
       "180  To address this issue, we extract the structur...  \n",
       "181  Table TABREF30 shows automatic evaluation resu...  \n",
       "182  BioASQ organizers provide the training and tes...  \n",
       "183  FLOAT SELECTED: Table 1: Factoid Questions. In...  \n",
       "184  In this experiment, we propose to use the esti...  \n",
       "185  Following the formula, we can calculate the co...  \n",
       "186  We used recordings of nurse-initiated telephon...  \n",
       "187  To evaluate the effectiveness of our linguisti...  \n",
       "188  MRC Dataset. The MRC dataset used in this pape...  \n",
       "189  We experimented with four different classifier...  \n",
       "190  Nonetheless, GANs have continued to show their...  \n",
       "191       FLOAT SELECTED: Table 1: Results of RNN/LSTM  \n",
       "192  FLOAT SELECTED: Table 5: Results on PKU and MS...  \n",
       "193  Different from scaled dot-product attention, G...  \n",
       "194  Tables TABREF25 and TABREF26 reports the perfo...  \n",
       "195  While manually analyzing the raw dataset, we n...  \n",
       "196  By examining more samples and with respect to ...  \n",
       "197  As one of the first attempts in neural network...  \n",
       "198  By examining more samples and with respect to ...  \n",
       "199  FLOAT SELECTED: Table 5 Accuracy of concept ca...  \n",
       "200  FLOAT SELECTED: Table 8 Evaluation results of ...  \n",
       "201  FLOAT SELECTED: Table 2: We generate vectors f...  \n",
       "202  One of the main goals of this study is to impr...  \n",
       "203  Especially after the introduction of the word2...  \n",
       "204  Despite this, there is a lack of prior work wh...  \n",
       "205  There are several challenges on supervised lea...  \n",
       "206  There are several studies about the Vietnamese...  \n",
       "207  We collected tweets associated to a dozen US m...  \n",
       "208  As it is reported that conservatives and liber...  \n",
       "209  Questions: We make use of the 7,787 science ex...  \n",
       "210  Training We collect 50,000 Wikipedia articles ...  \n",
       "211  Complexity Analysis Compared with local method...  \n",
       "212  A long-standing tradition if the field of appl...  \n",
       "213  FLOAT SELECTED: Table 1: Training corpora For ...  \n",
       "214  FLOAT SELECTED: Table 1: Comparison of differe...  \n",
       "215  In NLP, we often get such invariance for free,...  \n",
       "216  For sentiment classification, we systematicall...  \n",
       "217  Inspired by the psycholinguistic studies BIBRE...  \n",
       "218  For all the interest in adversarial computer v...  \n",
       "219  While BIBREF7 demonstrate strong word recognit...  \n",
       "220  Hybrid approaches. Figure FIGREF11 shows the a...  \n",
       "221  Data used to generate recommendations. We empl...  \n",
       "222  If we take the best psr ensemble trained on CB...  \n",
       "223  We chose SVMhmm BIBREF111 implementation of St...  \n",
       "224  DeepMine is publicly available for everybody w...  \n",
       "225  FLOAT SELECTED: Table 1. HPI Categories and An...  \n",
       "226  While previous work clearly states that effici...  \n",
       "227  In this study, we concentrate our effort on re...  \n",
       "228  We have created a dataset of discharge summari...  \n",
       "229  Table defines each of the considered clinical ...  \n",
       "230  CNN can also be employed on the sarcasm datase...  \n",
       "231  We apply our adaptively sparse Transformers on...  \n",
       "232  FLOAT SELECTED: Table 1: Machine translation t...  \n",
       "233  In a recent work on sentiment analysis in Turk...  \n",
       "234  The second Turkish dataset is the Twitter corp...  \n",
       "235  For Turkish, as the first dataset, we utilised...  \n",
       "236  Word Vectors: We focus primarily on the word v...  \n",
       "237  FLOAT SELECTED: Table 15: Evaluation of differ...  \n",
       "238  Given that there is no public dataset availabl...  \n",
       "239  FLOAT SELECTED: Table 4: Automatic evaluation ...  \n",
       "240  In this paper, we have analyzed various ways t...  \n",
       "241  We are mostly interested with the following tr...  \n",
       "242  We are mostly interested with the following tr...  \n",
       "243  In this section, we first describe the phenome...  \n",
       "244  INSIGHT 1: Political handles are more likely t...  \n",
       "245  In this paper, we explore a entire deep LSTM R...  \n",
       "246  FLOAT SELECTED: Table 3. The CER and RTF of 9-...  \n",
       "247  There is a high real time requirement in real ...  \n",
       "248  We assume that speech transcripts can be extra...  \n",
       "249  Concerning the neural network architecture, we...  \n",
       "250  Ternary and fine-grained sentiment classificat...  \n",
       "251  The Propaganda Techniques Corpus (PTC) dataset...  \n",
       "252  FLOAT SELECTED: Table 2: Metrics on generated ...  \n",
       "253  FLOAT SELECTED: Figure 1: Sample data flow thr...  \n",
       "254  We use a default train-validation-test split o...  \n",
       "255  For experiments, we train and evaluate our mod...  \n",
       "256  We evaluated summarization quality automatical...  \n",
       "257  In Table TABREF26 we report the results of our...  \n",
       "258  We use one public dataset Social Honeypot data...  \n",
       "259  Using the LDA model, each person in the datase...  \n",
       "260  Experimental Setup In this section we present ...  \n",
       "261  We construct three datasets based on IMDB revi...  \n",
       "262  Common Voice BIBREF10 is a crowdsourcing speec...  \n",
       "263  Table TABREF16 shows the results of our models...  \n",
       "264  Finally, we combine our CNN and RNN models usi...  \n",
       "265  (1) We propose extended middle context, a new ...  \n",
       "266  FLOAT SELECTED: Table 6: Performance of BERT-l...  \n",
       "267  To put the supervised score into context we li...  \n",
       "268  To structure an unordered document is an essen...  \n",
       "269  To identify legally sound answers, we recruit ...  \n",
       "270  Hashtag prediction for social media has been a...  \n",
       "271  We test the character and word-level variants ...  \n",
       "272  FLOAT SELECTED: Table 3: F1-score (%) for fine...  \n",
       "273  We use the pre-trained uncased BERT$_\\mathrm {...  \n",
       "274  FLOAT SELECTED: Table 1: Experimental results....  \n",
       "275  We proposed to use visual renderings of docume...  \n",
       "276  The Wikipedia dataset consists of articles fro...  \n",
       "277  We randomly sampled 5,000 articles from each q...  \n",
       "278  Table TABREF17 lists the features that we used...  \n",
       "279  More than 2,100 texts were paired with 15 ques...  \n",
       "280  Machine comprehension datasets consist of thre...  \n",
       "281  FLOAT SELECTED: Table 2: Comparison of our sys...  \n",
       "282  FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...  \n",
       "283  FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...  \n",
       "284  FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...  \n",
       "285  FLOAT SELECTED: Table 2: Comparison of our sys...  \n",
       "286  Shared Task: This work addresses the two tasks...  \n",
       "287  Do multilingual models always need to be train...  \n",
       "288  Do multilingual models always need to be train...  \n",
       "289  Inspired by the StackLite tag recommendation t...  \n",
       "290  FLOAT SELECTED: Table 1: Statistics of dataset...  \n",
       "291  We report our model's performance on the prese...  \n",
       "292  We consider two datasets, representing related...  \n",
       "293  To test the effectiveness of this new architec...  \n",
       "294  For the McGurk effect, we attempt an illusion ...  \n",
       "295  We analyze which discourse phenomena are hard ...  \n",
       "296  The BLEU scores are provided in Table TABREF24...  \n",
       "297  Named Entity Recognition (NER) in the Biomedic...  \n",
       "298  Results ::: CoinCollector In this setting, we ...  \n",
       "299  FLOAT SELECTED: Table 1: Accuracy of Data Mani...  \n",
       "300  Our submissions ranked second (EI-Reg), second...  \n",
       "301  For each task, the training data that was made...  \n",
       "302  Language Selection. Multi-SimLex comprises ele...  \n",
       "303  Baseline Experiments In this section, we brief...  \n",
       "304  Baseline Experiments In this section, we brief...  \n",
       "305  We break down the task of importance annotatio...  \n",
       "306  The goal of an language model is to assign mea...  \n",
       "307  We next adapt a VQA deep learning architecture...  \n",
       "308  FLOAT SELECTED: Fig. 6: We propose a novel app...  \n",
       "309                               Results and Analysis  \n",
       "310  Table TABREF18 shows the results of the cross-...  \n",
       "311  In this section we describe the experiments pe...  \n",
       "312  To tackle this problem, we introduce the novel...  \n",
       "313  The last group contains the results of our pro...  \n",
       "314  Our testing dataset takes MIMIC-III BIBREF18 a...  \n",
       "315  Table TABREF18 shows the Spearman correlation ...  \n",
       "316  Table TABREF29 gives three results from our su...  \n",
       "317  We cluster the embeddings with INLINEFORM0 -Me...  \n",
       "318  We cluster the embeddings with INLINEFORM0 -Me...  \n",
       "319  Table TABREF23 shows the unlabeled INLINEFORM0...  \n",
       "320                                 Experimental Setup  \n",
       "321                                 Experimental Setup  \n",
       "322  FLOAT SELECTED: Table 1: For each one of the s...  \n",
       "323  For our study, we used the number of retweets ...  \n",
       "324  One straightforward way of sharing information...  \n",
       "325  We found that 82 users within our sample were ...  \n",
       "326  The 1327 `viral' tweets were manually annotate...  \n",
       "327  Data Collection. To build the large ancient-mo...  \n",
       "328  Table TABREF44 shows average results of our au...  \n",
       "329  The PolyResponse restaurant search is currentl...  \n",
       "330  Fig. FIGREF4 shows the distributions of seven ...  \n",
       "331  All corpora provide datasets/splits for answer...  \n",
       "332  DNN based models coupled with transfer learnin...  \n",
       "333  For our single-label topic classification expe...  \n",
       "334  FLOAT SELECTED: Figure 2: The framework of G-B...  \n",
       "335  FLOAT SELECTED: Figure 2: The framework of G-B...  \n",
       "336  We use three languages in our experiments: Eng...  \n",
       "337  While the RNN-based generators with DA gating-...  \n",
       "338  We assessed the proposed models on four differ...  \n",
       "339  To compare the conversions between USVC and Pi...  \n",
       "340  Table TABREF23 compares the performance of the...  \n",
       "341  FLOAT SELECTED: Table 1: XNLI dev results (acc...  \n",
       "342  So far a system was trained on one type of dat...  \n",
       "343  Our contributions in this work are summarized ...  \n",
       "344  We used the 1,000-tweet dataset by BIBREF2 tha...  \n",
       "345  FLOAT SELECTED: Table 1: Average Correct Class...  \n",
       "346  The experiment results of validation on Friend...  \n",
       "347  FLOAT SELECTED: Table 6: Validation Results (F...  \n",
       "348  In this section, we describe the experimental ...  \n",
       "349  Results and ablations ::: Ablation studies To ...  \n",
       "350  Results and ablations ::: Ablation studies To ...  \n",
       "351  The MP framework is based on the core idea of ...  \n",
       "352  FLOAT SELECTED: Table 3: Classification result...  \n",
       "353  FLOAT SELECTED: Table 2: The complete set of f...  \n",
       "354  This contrasts with much of the work in comput...  \n",
       "355  The seed lexicon consists of positive and nega...  \n",
       "356  FLOAT SELECTED: Table 3: Performance of variou...  \n",
       "357  In this paper, we propose a simple and effecti...  \n",
       "358  As a raw corpus, we used a Japanese web corpus...  \n",
       "359  FLOAT SELECTED: Table 4: Results for small lab...  \n",
       "360  In this paper, we propose a simple and effecti...  \n",
       "361  We constructed our seed lexicon consisting of ...  \n",
       "362  We find that dynamic communities, such as Seah...  \n",
       "363  Our full dataset consists of all subreddits on...  \n",
       "364  FLOAT SELECTED: Fig. 1. An illustrative exampl...  \n",
       "365  Our dataset is annotated based on Chinese path...  \n",
       "366  Our dataset is annotated based on Chinese path...  \n",
       "367  For each model, we examined word-level perplex...  \n",
       "368  The baseline model is a deep sequence-to-seque...  \n",
       "369  Geometric bias mitigation uses the cosine dist...  \n",
       "370  Overall, through the process described in Sect...  \n",
       "371  To provide an initial results, we take 50% of ...  \n",
       "372  FLOAT SELECTED: Table 1: Comparison of manuall...  \n",
       "373  In Table TABREF1, we summarize the quantitativ...  \n",
       "374  Understanding a user's intent and sentiment is...  \n",
       "375  Experimental results for the Twitter Sentiment...  \n",
       "376  In natural language, subjectivity refers to th...  \n",
       "377  Our first baseline is ROUGE-L BIBREF1 , since ...  \n",
       "378  NVDM (Lexical, Neural) is a VAE-based approach...  \n",
       "379  We assess the optimal number of topics that ne...  \n",
       "380  An extrinsic evaluation was carried out on the...  \n",
       "381  For the English version, we performed both a t...  \n",
       "382  Table TABREF29 presents the quantitative resul...  \n",
       "383  Active learning methods can generally be descr...  \n",
       "384  FLOAT SELECTED: Figure 4: Inter-annotator agre...  \n",
       "385  FLOAT SELECTED: Table 2: Data Statistics of th...  \n",
       "386  Database Construction: we crawled travel infor...  \n",
       "387  Results on WNLaMPro rare and medium are shown ...  \n",
       "388  FLOAT SELECTED: Table 3: Compare our model wit...  \n",
       "389  We conducted cross-validation experiments usin...  \n",
       "390  FLOAT SELECTED: Table 3: Token-level recall wh...  \n",
       "391  For the emotion recognition from text, we manu...  \n",
       "392  We use the TED data from the IWSLT 2014 German...  \n",
       "393  Dataset: Based on some earlier work, only avai...  \n",
       "394  Enabling computers to understand given documen...  \n",
       "395  FLOAT SELECTED: Table 1: Spearman’s ρ, Kendall...  \n",
       "396  Methods ::: Baselines ::: BiGRU s with attenti...  \n",
       "397  FLOAT SELECTED: Figure 1: SUM-QE rates summari...  \n",
       "398  SMT techniques require a parallel corpus in th...  \n",
       "399  In this section, we propose a taxonomy to summ...  \n",
       "400  Tourist: I can't go straight any further. Guid...  \n",
       "401  Experimental results of entity classification ...  \n",
       "402  FLOAT SELECTED: Table 5: Performance of human ...  \n",
       "403  FLOAT SELECTED: Table 1: Our Feature Set for D...  \n",
       "404  FLOAT SELECTED: Table 2: TUPLEINF is significa...  \n",
       "405  Each dataset consists of a collection of recor...  \n",
       "406  Table 2 shows our experiments on two models wi...  \n",
       "407  Automation of cQA forums can be divided into t...  \n",
       "408  FLOAT SELECTED: Table 4: Compared with other s...  \n",
       "409  To figure out whether the proposed AEN-GloVe i...  \n",
       "410  The final annotation categories for the datase...  \n",
       "411  MTMSN BIBREF4 is the first, and only model so ...  \n",
       "412  FLOAT SELECTED: Table 2. Performance of differ...  \n",
       "413  Table TABREF25 shows the results on DROP's tes...  \n",
       "414  FLOAT SELECTED: Table 1: Average accuracies an...  \n",
       "415  BIBREF17: The Lemming model is a log-linear mo...  \n",
       "416  We build the iSQuAD and iNewsQA datasets based...  \n",
       "417  Table TABREF31 shows the F-score, the Area Und...  \n",
       "418  FLOAT SELECTED: Table 6: Comparison of ACC of ...  \n",
       "419  FLOAT SELECTED: Table 6: Comparison of ACC of ...  \n",
       "420  We will compare to the more recent cross-lingu...  \n",
       "421  Pre-processing. Tweets are subject to standard...  \n",
       "422  In the second round, we collected 293 annotati...  \n",
       "423  We asked for two distinct paraphrases of each ...  \n",
       "424  In the second round, we collected 293 annotati...  \n",
       "425  We selected 15 modifications types to collect ...  \n",
       "426  FLOAT SELECTED: Table IV ACCURACY OF DIFFERENT...  \n",
       "427  In Twitter social networking, people express t...  \n",
       "428  The test accuracy curves with the noise rates ...  \n",
       "429  FLOAT SELECTED: Table 4. EER(%) results of the...  \n",
       "430  FLOAT SELECTED: Table 1. The distribution over...  \n",
       "431  FLOAT SELECTED: Table 4. EER(%) results of the...  \n",
       "432  FLOAT SELECTED: Table 4. EER(%) results of the...  \n",
       "433  FLOAT SELECTED: Table 2: Accuracies of differe...  \n",
       "434  FLOAT SELECTED: Table 2: Existing NQG models w...  \n",
       "435  Past research took a reductionist approach, se...  \n",
       "436  Question generation is an NLG task for which t...  \n",
       "437  We employ BIBREF73 's weighted lexicon of term...  \n",
       "438  Self-disclosure clues have been extensively ut...  \n",
       "439  Age Enabled Ground-truth Dataset: We extract u...  \n",
       "440  The recent advancements in deep neural network...  \n",
       "441  The recent advancements in deep neural network...  \n",
       "442  The recent advancements in deep neural network...  \n",
       "443  Results of the DQN-based agent are presented i...  \n",
       "444  To ground moral sentiment in text, we leverage...  \n",
       "445  To implement the first tier of our framework a...  \n",
       "446  As illustrated in Table TABREF12 (ID 1). Given...  \n",
       "447  Since the official test set has not been relea...  \n",
       "448  A context is upward entailing (shown by [... $...  \n",
       "449  For our experiments, we select a dataset whose...  \n",
       "450  We adopt the approach in BIBREF4 , modifying i...  \n",
       "451  Since the goal of this study is to compare NER...  \n",
       "452  We consider pre-training on the audio data (wi...  \n",
       "453  Given raw audio samples INLINEFORM0 , we apply...  \n",
       "454  FLOAT SELECTED: Table 2: Number of documents i...  \n",
       "455  The baseline approach is based on BIBREF20 . I...  \n",
       "456  FLOAT SELECTED: Table 3: Performance of differ...  \n",
       "457  We compare the performance of translation appr...  \n",
       "458  This work also contributes a new dataset of IN...  \n",
       "459  While the dataset was collected with simulated...  \n",
       "460  Our current feature set for training a machine...  \n",
       "461  FLOAT SELECTED: Table 5: Overall and domain-sp...  \n",
       "462  The problem with morpheme segmentation is that...  \n",
       "463  Neural network models, and specifically sequen...  \n",
       "464  We use three datasets for our experiments: IWS...  \n",
       "465  As the book is too small to train any models, ...  \n",
       "466  FLOAT SELECTED: Table 3: The joint goal accura...  \n",
       "467  In a new experiment, we train the models on pa...  \n",
       "468  To date, the NLP community has focused primari...  \n",
       "469  Because our approach is specifically intended ...  \n",
       "470  FLOAT SELECTED: Table 2. Comparison with Tradi...  \n",
       "471  FLOAT SELECTED: Table 2. Comparison with Tradi...  \n",
       "472  FLOAT SELECTED: Figure 1. BERT + Bi-GRU + CRF,...  \n",
       "473  To conduct a thorough comparison, we evaluate ...  \n",
       "474  FLOAT SELECTED: Table 1: Results of various mo...  \n",
       "475  We see that parent quality is a simple yet eff...  \n",
       "476  Our work aims at predicting time series using ...  \n",
       "477  The initial analyses of the embedding matrices...  \n",
       "478  The main contribution of our paper is to sugge...  \n",
       "479  FLOAT SELECTED: TABLE II F-SCORE OF VARIOUS MO...  \n",
       "480  We implement our model in Python using Tensorf...  \n",
       "481  FLOAT SELECTED: TABLE III COMPARISON WITH THE ...  \n",
       "482  Our AV in-cabin data-set includes 30 hours of ...  \n",
       "483  We compare a hybrid HMM-LSTM approach with a c...  \n",
       "484  We interpret the HMM and LSTM states in the hy...  \n",
       "485  FLOAT SELECTED: Table 1: Predictive loglikelih...  \n",
       "486  FLOAT SELECTED: Table 2: F1 Results3 The appro...  \n",
       "487  The measured precision with respect to PropBan...  \n",
       "488  Dataset Quality Analysis ::: Inter-Annotator A...  \n",
       "489  We adopt the annotation machinery of BIBREF5 i...  \n",
       "490  For the MT task, we use the WMT 2014 En $\\left...  \n",
       "491  VQA research began in earnest in late 2014 whe...  \n",
       "492  To test our model, we generated 500 new scenar...  \n",
       "493  To train our model, we generated a dataset of ...  \n",
       "494  We use the BLEU BIBREF30 metric on the validat...  \n",
       "495  We use MS COCO, Bing and Flickr datasets from ...  \n",
       "496  Word Lattice As shown in Figure FIGREF4 , a wo...  \n",
       "497  Table TABREF34 gives the perplexity scores obt...  \n",
       "498  In this paper, we manually annotate the predic...  \n",
       "499  In this work, we introduce a methodology that ...  \n",
       "500  FLOAT SELECTED: Table 4: Test accuracies (%). ...  \n",
       "501  For sentence encoding models, we chose a simpl...  \n",
       "502  For each model having the best fit on the dev ...  \n",
       "503  For each model having the best fit on the dev ...  \n",
       "504  The fundamental idea of this system is how to ...  \n",
       "505  While the co-occurrence representation yields ...  \n",
       "506  e-SNLI-VE-2.0 is the combination of SNLI-VE-2....  \n",
       "507  The dataset needed to train the W2V was obtain...  \n",
       "508  The first data batch consists of tweets releva...  \n",
       "509  FLOAT SELECTED: Table 3: Evaluation results of...  \n",
       "510  Causal documents were chosen to contain one oc...  \n",
       "511  Data was collected from a 10% uniform sample o...  \n",
       "512  Causal documents were chosen to contain one oc...  \n",
       "513  The rest of this paper is organized as follows...  \n",
       "514  Data was collected from a 10% uniform sample o...  \n",
       "515  Data was collected from a 10% uniform sample o...  \n",
       "516  According to previous work BIBREF17 , BIBREF18...  \n",
       "517  To make a thorough empirical comparison with p...  \n",
       "518  There are 74 participants who are signing up t...  \n",
       "519  We conducted experiments on the two tasks of M...  \n",
       "520  FLOAT SELECTED: Table 2: Performance of our an...  \n",
       "521  FLOAT SELECTED: Table 5: Performance of our an...  \n",
       "522  We conducted experiments on the two tasks of M...  \n",
       "523  Tree-based sentiment annotations are sentiment...  \n",
       "524  Twitter provides well-documented API, which al...  \n",
       "525  Generally, closer words are considered more im...  \n",
       "526  The large corpus acquired from multiple resour...  \n",
       "527  Table 1 shows the BLEU scores of our model on ...  \n",
       "528  FLOAT SELECTED: Table 1: BLEU scores and compu...  \n",
       "529  Due to the reduction of computational time com...  \n",
       "530  Table TABREF15 shows the final results on Vecm...  \n",
       "531  FLOAT SELECTED: Table 4: Accuracy (P@1) on Vec...  \n",
       "532  Table TABREF13 shows the inconsistency rates o...  \n",
       "533  Methods ::: Length Encoding Method Inspired by...  \n",
       "534  Methods ::: Length Token Method Our first appr...  \n",
       "535  With this challenge in mind, we introduce Torc...  \n",
       "536  Compared to using external models for confiden...  \n",
       "537  Our training method in sec:ours could potentia...  \n",
       "538  For the intitial data collection using the CRW...  \n",
       "539  IOCs in cybersecurity articles are often descr...  \n",
       "540  Secondly, texts go through a cascade of annota...  \n",
       "541  Distributed representation of word sense provi...  \n",
       "542  We show all the models' results in Table TABRE...  \n",
       "543  Moreover, we can easily extend SPNet to other ...  \n",
       "544  In this case, the summary has a high ROUGE sco...  \n",
       "545  FLOAT SELECTED: Table 3: Accuracy on the DREAM...  \n",
       "546  Sentences 1 and 2 are labelled incorrectly, an...  \n",
       "547  There are three main components to the model: ...  \n",
       "548  We first compare the perplexity of CWVAE with ...  \n",
       "549  We first compare the perplexity of CWVAE with ...  \n",
       "550  In addition to the traditional VAE structure, ...  \n",
       "551  FLOAT SELECTED: Table 1: Domain adaptation res...  \n",
       "552  FLOAT SELECTED: Table 1: Final test set result...  \n",
       "553  For WebQuestions, we use 8 handcrafted part-of...  \n",
       "554  The main DDEO topics showed some level of inte...  \n",
       "555  To discover topics from the collected tweets, ...  \n",
       "556  For each variable in encoding set, learn the n...  \n",
       "557  Differently to textual data, our goal in this ...  \n",
       "558  We will apply the methodology to the well-know...  \n",
       "559  All models are trained and evaluated using the...  \n",
       "560  Table TABREF40 illustrates the BLEU scores of ...  \n",
       "561  In HotpotQA, on average we can find 6 candidat...  \n",
       "562  FLOAT SELECTED: Table 5: Classification of err...  \n",
       "563  The human evaluation of MT output in research ...  \n",
       "564  One way to analyze the model is to compute mod...  \n",
       "565  Our approach consists of structuring input to ...  \n",
       "566  In this work, we analyze a set of tweets relat...  \n",
       "567  FLOAT SELECTED: Table 1: Experiment results on...  \n",
       "568  FLOAT SELECTED: TABLE IV: Class-wise average I...  \n",
       "569  FLOAT SELECTED: TABLE III: Scripts in the INDI...  \n",
       "570  The generation process of the simulated data s...  \n",
       "571  For the human evaluation, we follow the standa...  \n",
       "572  Amazon Reviews Dataset BIBREF24 is a large dat...  \n",
       "573  The usage of a purely character-based input wo...  \n",
       "574  In addition to the setting without any paralle...  \n",
       "575  Table TABREF17 shows our results on CMRC-2017 ...  \n",
       "576  The BD-4SK-ASR Dataset ::: The Language Model ...  \n",
       "577  To develop the dataset, we extracted 200 sente...  \n",
       "578  Two thousand narration files were created. We ...  \n",
       "579  In Figure FIGREF32 , we visualize the syntacti...  \n",
       "580  In Table TABREF39 , our results are comparable...  \n",
       "581  As a further application of our work, we have ...  \n",
       "582  The trained Doc2Vec model is subsequently used...  \n",
       "583  During the long history of TCM, there has been...  \n",
       "584  The input of our model are the words in the in...  \n",
       "585  FLOAT SELECTED: Table 8. Results (accuracy) on...  \n",
       "586  N-GrAM ranked first in all cases except for th...  \n",
       "587  N-GrAM ranked first in all cases except for th...  \n",
       "588  One of the solutions that has been proposed fo...  \n",
       "589  There are a larger number of male-gendered cha...  \n",
       "590  Data dependent regularization. As explained in...  \n",
       "591  The two models achieved test perplexity of INL...  \n",
       "592  The experimental results are presented in Tabl...  \n",
       "593  FLOAT SELECTED: Table 5: Results obtained for ...  \n",
       "594  Exploiting psycho-linguistic features with bas...  \n",
       "595  Most of the above-discussed systems either sho...  \n",
       "596  The informal setting/environment of social med...  \n",
       "597  As we show below, STransE performs better than...  \n",
       "598  FLOAT SELECTED: Table 2: Experimental Results ...  \n",
       "599  One common point in all the approaches yet has...  \n",
       "600  Table TABREF44 shows that consistent nucleus a...  \n",
       "601  We extended the notion of consistency of a rec...  \n",
       "602  We use the VisDial v1.0 BIBREF0 dataset to tra...  \n",
       "603  FLOAT SELECTED: Table 1: Final win rate on sim...  \n",
       "604  convertible.pl: implementing DCG rules for 1st...  \n",
       "605  Table TABREF34 and Table TABREF35 show the fin...  \n",
       "606  Los resultados de la evaluación se presentan e...  \n",
       "607  FLOAT SELECTED: TABLE I DATASETS AND LANGUAGES...  \n",
       "608  We tested three model versions against all dat...  \n",
       "609  FLOAT SELECTED: TABLE II REPORTED ACCURACIES O...  \n",
       "610  In this section, we consider two kinds of rela...  \n",
       "611  Human Judgments Following BIBREF11 , BIBREF12 ...  \n",
       "612  We trained word embeddings and a uni-direction...  \n",
       "613  First, we propose a class of recurrent-like ne...  \n",
       "614  This study focuses on Switchboard-300, a stand...  \n",
       "615                                 Experimental Setup  \n",
       "616  Although not done in this work, an alternative...  \n",
       "617  We performed experiments on synthetically gene...  \n",
       "618  FLOAT SELECTED: Table 2: A summary of PERSPECT...  \n",
       "619  FLOAT SELECTED: Figure 3: Distribution of clai...  \n",
       "620  FLOAT SELECTED: Table 1: Effect of Character E...  \n",
       "621  Generic Sarcasm. We first examine the differen...  \n",
       "622  FLOAT SELECTED: Table 1: The number of songs a...  \n",
       "623  FLOAT SELECTED: Table 1: Automatic Evaluation ...  \n",
       "624  We thus also conducted human studies on Amazon...  \n",
       "625  FLOAT SELECTED: Table 1: Automatic Evaluation ...  \n",
       "626  We employ several complementary metrics to cap...  \n",
       "627  FLOAT SELECTED: Table 2: The performance of ba...  \n",
       "628  FLOAT SELECTED: Figure 3: ROUGE Quality of pro...  \n",
       "629  FLOAT SELECTED: Figure 1: An example of stress...  \n",
       "630  Using these filters as pre-processing methods,...  \n",
       "631  While the mixing strategy compensates for most...  \n",
       "632  To solve this problem, we need a state trackin...  \n",
       "633  Furthermore, as SIM has no slot-specific neura...  \n",
       "634  We select the following training objectives to...  \n",
       "635  FLOAT SELECTED: Table 1: An approximate number...  \n",
       "636  We collected tweets from two distinct Spritzer...  \n",
       "637  Sentence classification combines natural langu...  \n",
       "638  Compare to baseline models, the GVT achieves r...  \n",
       "639  Attention-base translation model We use the sy...  \n",
       "640  Pre-trained English NER model We construct the...  \n",
       "641  The character sets of these 7 languages have l...  \n",
       "642  The dataset at HASOC 2019 were given in three ...  \n",
       "643  FLOAT SELECTED: Table 9 Character error rates ...  \n",
       "644  Analogous to word embeddings, sentence embeddi...  \n",
       "645  The Density Ratio method consistently outperfo...  \n",
       "646  The following data sources were used to train ...  \n",
       "647  In all our experiments, we used the out-of-the...  \n",
       "648  Given the above interpretation, we now turn to...  \n",
       "649  This paper experimented with two different mod...  \n",
       "650  FLOAT SELECTED: Table 1: Statistics of the dat...  \n",
       "651  FLOAT SELECTED: Figure 2: PR curve on our impl...  \n",
       "652  We compared our proposed approaches to a stand...  \n",
       "653  FLOAT SELECTED: Table 1: Results mean (min, ma...  \n",
       "654  The human evaluation is to have a comprehensiv...  \n",
       "655  To test this hypothesis we first trained UG-WG...  \n",
       "656  To test this hypothesis we first trained UG-WG...  \n",
       "657  Table TABREF34 shows the performances of the d...  \n",
       "658  We focused evaluation over a small but diversi...  \n",
       "659  Results form Table TABREF31 may give an idea t...  \n",
       "660  Adversarial training can often improve model r...  \n",
       "661  We reason that, if a token is important for pr...  \n",
       "662  The resource is composed of data from two diff...  \n",
       "663  The two datasets used for the challenge are Fr...  \n",
       "664  The two datasets used for the challenge are Fr...  \n",
       "665  FLOAT SELECTED: Table 6: F-scores for Friends ...  \n",
       "666  Word embeddings have risen in popularity for N...  \n",
       "667  I also performed several case studies. I obtai...  \n",
       "668  We examine other features regarding the charac...  \n",
       "669  FLOAT SELECTED: Table 2: Linear regression res...  \n",
       "670  In order to understand the latent topics of th...  \n",
       "671  Observing the results of the linear regression...  \n",
       "672  In this paper, we present an extraction-then-s...  \n",
       "673  Traditional text-to-speech (TTS) systems are c...  \n",
       "674  In terms of speed, our system was able to lemm...  \n",
       "675  FLOAT SELECTED: Table 3: Lemmatization accurac...  \n",
       "676  Cloze Track: In this track, the participants a...  \n",
       "677  The previously mentioned datasets are all in E...  \n",
       "678  We conducted experiments on the Amazon reviews...  \n",
       "679  FLOAT SELECTED: Figure 33 The most cited areas...  \n",
       "680  FLOAT SELECTED: Figure 25 Average citations fo...  \n",
       "681  FLOAT SELECTED: Figure 11 A treemap of the 122...  \n",
       "682  Table TABREF20 reports the F1 and EM scores ob...  \n",
       "683  FLOAT SELECTED: Table 3: Test set results of o...  \n",
       "684  FLOAT SELECTED: Table 4: The performance of cl...  \n",
       "685  For the purpose of our experiments, we use dat...  \n",
       "686  Our experiment with the Short Jokes dataset fo...  \n",
       "687  In this experiment, we compare our Enitity-GCN...  \n",
       "688  To each node $v_i$ , we associate a continuous...  \n",
       "689  In an offline step, we organize the content of...  \n",
       "690  FLOAT SELECTED: Table 2: Accuracy of different...  \n",
       "691  We extracted 200 sentence pairs from BIBREF3 '...  \n",
       "692  We also observe that the best combination seem...  \n",
       "693  We compare our best F1 score with other state-...  \n",
       "694  We compare our best F1 score with other state-...  \n",
       "695  FLOAT SELECTED: Table 2: Results for artificia...  \n",
       "696  We compile three Chinese text corpora from onl...  \n",
       "697  We compile three Chinese text corpora from onl...  \n",
       "698  We address the above issues with a new methodo...  \n",
       "699  To evaluate the performance of our approach, w...  \n",
       "700  Given the initial distributional or specialise...  \n",
       "701  We used two different data sources in our eval...  \n",
       "702  We evaluate two OIE systems (i.e. extractors)....  \n",
       "703  In our final system, after pre-training the fo...  \n",
       "704  We evaluate our approach on two well benchmark...  \n",
       "705  Our main contribution is to show that the cont...  \n",
       "706  Tables TABREF15 and TABREF16 compare results f...  \n",
       "707  Machine translation finds use in cheminformati...  \n",
       "708  FLOAT SELECTED: Table 1: Results on test data....  \n",
       "709  We trained word embeddings using either GloVe ...  \n",
       "710  FLOAT SELECTED: Figure 1: The proposed model w...  \n",
       "711  We take a first step towards integrating ASR i...  \n",
       "712  Metrics. We use tolerance accuracy BIBREF16, w...  \n",
       "713  The remainder of this paper is structured as f...  \n",
       "714  Our video question answering task is novel and...  \n",
       "715  FLOAT SELECTED: Table 2: Results of AlgoLisp d...  \n",
       "716  FLOAT SELECTED: Table 2: Results of AlgoLisp d...  \n",
       "717  Given a natural-language math problem, we need...  \n",
       "718  FLOAT SELECTED: Table 4: Comparison results wi...  \n",
       "719  DrQA is a CRC baseline coming with the CoQA da...  \n",
       "720  FLOAT SELECTED: Table 2: The total number of i...  \n",
       "721  FLOAT SELECTED: Table 3: Datasets details from...  \n",
       "722  In BIBREF3 , BIBREF2 , the authors study the e...  \n",
       "723  As the first step, we build three baseline LID...  \n",
       "724  All the present neural LID methods are based o...  \n",
       "725  BIBREF7 investigated the learning capabilities...  \n",
       "726  FLOAT SELECTED: Fig. 2: Standard ASR outputs A...  \n",
       "727  To test this hypothesis, we evaluate the model...  \n",
       "728  FLOAT SELECTED: Table 5: CoNLL 2003 English re...  \n",
       "729  FLOAT SELECTED: Table 1: Datasets used for tra...  \n",
       "730  Our system learns Perceptron models BIBREF37 u...  \n",
       "731  Feature-based models. We used state-of-the-art...  \n",
       "732  The turkers are asked to indicate their prefer...  \n",
       "733  In this section, we evaluate the proposed meth...  \n",
       "734  In this section we present the results obtaine...  \n",
       "735  FLOAT SELECTED: TABLE II: A comparison of clas...  \n",
       "736  We approached the first and second challenges ...  \n",
       "737  As we iteratively concatenate the generated to...  \n",
       "738  To investigate whether our BERT-based model ca...  \n",
       "739                 Building Extractive CNN/Daily Mail  \n",
       "740  To further study the information encoded in th...  \n",
       "741  CNN2-PV. This model (Figure FIGREF10 , left+ce...  \n",
       "742  CNN2-PV. This model (Figure FIGREF10 , left+ce...  \n",
       "743  FLOAT SELECTED: Figure 1. A visual depiction o...  \n",
       "744  FLOAT SELECTED: Table 3: Statistics of externa...  \n",
       "745  The experimental results are summarized in Tab...  \n",
       "746  The corpus we have prepared for ASR in this st...  \n",
       "747  We chose the best system based on the dev set,...  \n",
       "748  We demonstrated the utility of Katecheo by dep...  \n",
       "749  Data set. For the cross-domain polarity classi...  \n",
       "750  In recent years, methods based on string kerne...  \n",
       "751  According to prior work, both from domain theo...  \n",
       "752  FLOAT SELECTED: Table 5: Bengali manual annota...  \n",
       "753  Using our platform, we extracted anonymized us...  \n",
       "754  FLOAT SELECTED: Figure 1: German→English: Lear...  \n",
       "755  Next, we compared our VTN model with an RNN-ba...  \n",
       "756  FLOAT SELECTED: Table 3: Precision (P), Recall...  \n",
       "757  FLOAT SELECTED: Figure 1: Multi-Encoder, Const...  \n",
       "758  FLOAT SELECTED: Table 1: Various types of trai...  \n",
       "759  This paper proposes the Flexibly-Structured Di...  \n",
       "760  We compare FSDM with four baseline methods and...  \n",
       "761  In this paper we proposed a methodology to ide...  \n",
       "762  On the 16 review datasets (Table TABREF22 ) fr...  \n",
       "763  FLOAT SELECTED: Table 1: Accuracies on the Sta...  \n",
       "764  The test-set accuracies obtained by different ...  \n",
       "765  Experiments on two benchmark data sets, the St...  \n",
       "766  Tables and report some statistics extracted fr...  \n",
       "767  FLOAT SELECTED: Table 4: List of the indicator...  \n",
       "768  Table , extracted from BIBREF0, reports WERs o...  \n",
       "769  Table , extracted from BIBREF0, reports WERs o...  \n",
       "770  Speakers were assigned either to training or e...  \n",
       "771  FLOAT SELECTED: Table 3: Spoken data collected...  \n",
       "772  Evaluation on DUC2004: DUC 2004 ( BIBREF15 ) i...  \n",
       "773  Very recently, the success of deep neural netw...  \n",
       "774  FLOAT SELECTED: Table 6: Results on our CAIS d...  \n",
       "775       FLOAT SELECTED: Table 2: Dataset statistics.  \n",
       "776  Questions are gathered from anonymized, aggreg...  \n",
       "777  To estimate speakers' position we use Wordscor...  \n",
       "778  Figure FIGREF12stsa and FIGREF12stsb shows Pea...  \n",
       "779  Let us discuss the results from the above ment...  \n",
       "780  We've seen that over-pruning BERT deletes info...  \n",
       "781  Each game's video ranges from 30 to 50 minutes...  \n",
       "782  FLOAT SELECTED: Table 3: Test Results on the N...  \n",
       "783  FLOAT SELECTED: Table 1: Predicted Mean MPA re...  \n",
       "784  The data for this project are two parts, the f...  \n",
       "785  A recently published dataset called SCAN BIBRE...  \n",
       "786  FLOAT SELECTED: Table 1: Accuracy on the ListO...  \n",
       "787  FLOAT SELECTED: Table 1: Accuracy on the ListO...  \n",
       "788  FLOAT SELECTED: Table 2. % EER performance of ...  \n",
       "789  Our first task is the recently-introduced Visu...  \n",
       "790  In this work, we introduce a new logical infer...  \n",
       "791  MonaLog utilizes two auxiliary sets. First, a ...  \n",
       "792  FLOAT SELECTED: Table 1: Statistics of the cor...  \n",
       "793  TextCat is the most well-known Perl implementa...  \n",
       "794  We describe our rules for WikiSQL here. We fir...  \n",
       "795  The experimental results for Yorùbá are given ...  \n",
       "796  We evaluate our approaches on two public Chine...  \n",
       "797  The experiment dataset comes from Microsoft Re...  \n",
       "798  FLOAT SELECTED: Table 5: Entity F1 and Success...  \n",
       "799  In this paper, we introduce a novel policy mod...  \n",
       "800  The second type is the selectional preference ...  \n",
       "801  Each drug label is a collection of sections (e...  \n",
       "802  Table TABREF7 shows the ABSA datasets from the...  \n",
       "803  FLOAT SELECTED: Table 1: Pretraining costs of ...  \n",
       "804  FLOAT SELECTED: Table 1: Pretraining costs of ...  \n",
       "805  BIBREF11 revisit bilingual pivoting in the con...  \n",
       "806  NAGMWA is much better than the other methods e...  \n",
       "807  Table TABREF46 shows that our Open model achie...  \n",
       "808  FLOAT SELECTED: Table 7: SRL results on the Ch...  \n",
       "809  FLOAT SELECTED: Figure 5. The results are spli...  \n",
       "810  We perform our experiments using ActivityNet C...  \n",
       "811  We characterize the evaluation of Emotionally-...  \n",
       "812                                         Conclusion  \n",
       "813  In this work, the experiments are conducted us...  \n",
       "814  Our contributions are as follows: We propose t...  \n",
       "815  FLOAT SELECTED: Table 1: Statistical summary o...  \n",
       "816  FLOAT SELECTED: Table 1: Statistical summary o...  \n",
       "817  FLOAT SELECTED: Table 3. Language Modeling Res...  \n",
       "818  In this section, we present the experimental s...  \n",
       "819  FLOAT SELECTED: Table 4. Evaluation results on...  \n",
       "820  Our idea is the BQ generation for MQ and, at t...  \n",
       "821  The surveys consisted of 20 tweets presented i...  \n",
       "822  For both word2vec BIBREF0 and gensim BIBREF7 w...  \n",
       "823  Although the competition proposes two differen...  \n",
       "824  We first inspect the frequencies of object and...  \n",
       "825  After averaging over all concepts, we lose inf...  \n",
       "826  After averaging over all concepts, we lose inf...  \n",
       "827  An LM's overall performance on *X can be measu...  \n",
       "828  is the standard word counting method whereby t...  \n",
       "829  Several methods make use of the Aristo Corpus,...  \n",
       "830  FLOAT SELECTED: Table 2: Most common syntactic...  \n",
       "831  Often, many state-of-the-art tools cannot be a...  \n",
       "832  As discussed in section SECREF1, the attention...  \n",
       "833  As a first step towards developing an automate...  \n",
       "834  Generally, the above work is summarized in Tab...  \n",
       "835  Previous attention-based methods can be catego...  \n",
       "836  In our experiments, we use Onsei Intent Slot d...  \n",
       "837  FLOAT SELECTED: Table 3: Number of run-on (RO)...  \n",
       "838  Our interpretability measurements are based on...  \n",
       "839  In the word embedding literature, the problem ...  \n",
       "840  To study the lexical and semantic diversities ...  \n",
       "841  FLOAT SELECTED: Table 3. Comparisons with the ...  \n",
       "842  More detailed explanation is introduced in Sec...  \n",
       "843  FLOAT SELECTED: Table 2. Twitter corpus distri...  \n",
       "844  In order to verify the time complexity analysi...  \n",
       "845  FLOAT SELECTED: Table 1: The knowledge base co...  \n",
       "846  We work with a dataset composed of 3,206 news ...  \n",
       "847  We use a siamese neural network, shown to perf...  \n",
       "848  FLOAT SELECTED: Table 1: An example of a claim...  \n",
       "849  We experiment using a dataset derived from Goo...  \n",
       "850  FLOAT SELECTED: Table 1: Crosslingual semantic...  \n",
       "851  We train an LSTM with and without attention on...  \n",
       "852  FLOAT SELECTED: Fig. 1. Proposed representatio...  \n",
       "853  Given the fact that the research on offensive ...  \n",
       "854  In sub-task C the goal is to classify the targ...  \n",
       "855  In this paper, we propose the MIMN model for N...  \n",
       "856     FLOAT SELECTED: Table 2: Experimental results.  \n",
       "857  FLOAT SELECTED: Table 1: Experimental conditions.  \n",
       "858  FLOAT SELECTED: Table 1: Optimal hyperparamete...  \n",
       "859  FLOAT SELECTED: Table 1: Optimal hyperparamete...  \n",
       "860  FLOAT SELECTED: Table 6: Evaluation of effect ...  \n",
       "861  We also evaluate our Joint-BiLSTM structure by...  \n",
       "862  FLOAT SELECTED: Table 1: Datasets used for var...  \n",
       "863  FLOAT SELECTED: Table 3. MOS naturalness resul...  \n",
       "864  FLOAT SELECTED: Table 10: Results of experimen...  \n",
       "865  The NLG model we use to establish a baseline f...  \n",
       "866  This step consists of generating a query out o...  \n",
       "867  Table TABREF14 shows the experiment measuring ...  \n",
       "868  We use the publicly available dataset KVRET BI...  \n",
       "869  As a basis for our experiments, we reimplement...  \n",
       "870  With the gathered comments, we reconstructed t...  \n",
       "871  We would expect that explanation performance s...  \n",
       "872  FLOAT SELECTED: Table 1: Comparison of differe...  \n",
       "873  While most relational learning methods restric...  \n",
       "874  We used the following affective resources rely...  \n",
       "875  The performance of the base model described in...  \n",
       "876  FLOAT SELECTED: Table 2: Transfer learning per...  \n",
       "877  The baseline classifier uses a linear Support ...  \n",
       "878  For offensive language detection in Twitter, u...  \n",
       "879  Results on SemEval-2014 are presented in Table...  \n",
       "880  Recently bhat-EtAl:2017:EACLshort provided a C...  \n",
       "881  The data stems from a joint ADAPT-Microsoft pr...  \n",
       "882  FLOAT SELECTED: Table 2: Characteristics of Sc...  \n",
       "883  To control the quality, we ensured that a sing...  \n",
       "884  FLOAT SELECTED: Table 3. Performance evaluatio...  \n",
       "885  FLOAT SELECTED: Table 1. Description of class ...  \n",
       "886  The sequence modeling layer models the depende...  \n",
       "887  Table TABREF34 shows the inference speed of ou...  \n",
       "888  To test if the learned representations can sep...  \n",
       "889  We train all the models on an Nvidia RTX 2080T...  \n",
       "890  In this case, the decoding function is a linea...  \n",
       "891  The 17 domains (`Alarm' domain not included in...  \n",
       "892  We use the additional INLINEFORM0 training art...  \n",
       "893  We focus primarily on the smaller data set of ...  \n",
       "894  We have presented adaptive schedules for multi...  \n",
       "895  We extract data from the WMT'14 English-French...  \n",
       "896  We use a standard set of supervised as well as...  \n",
       "897  Statistical characterization of languages has ...  \n",
       "898  One way to expose Bleurt to a wide variety of ...  \n",
       "899  Table TABREF12 compares our novel system with ...  \n",
       "900  Once the KryptoOracle engine was bootstrapped ...  \n",
       "901  KryptoOracle has been built in the Apache ecos...  \n",
       "902  In this paper we provide a novel real-time and...  \n",
       "903  FLOAT SELECTED: Table 1: BLUE tasks The aim of...  \n",
       "904  Our experimental results show that the propose...  \n",
       "905  As a complement of this analysis we show some ...  \n",
       "906  AMR is not grounded in the input sentence, the...  \n",
       "907  FLOAT SELECTED: Table 3. Overall typing perfor...  \n",
       "908  Figure FIGREF5 shows that E-BERT performs comp...  \n",
       "909  Training our model implicitly embeds the vocab...  \n",
       "910  Wikilinks can be seen as a large-scale, natura...  \n",
       "911  Here we describe the components of our probabi...  \n",
       "912  Automatic evaluation of Natural Language Gener...  \n",
       "913  FLOAT SELECTED: Table 3: Test set results at t...  \n",
       "914  There exist many word/sentence embeddings whic...  \n",
       "915  The procedure of transfer learning in this wor...  \n",
       "916  All the capabilities described in this paper c...  \n",
       "917  We optimized our single-task baseline to get a...  \n",
       "918  In this work we compare causal attribution net...  \n",
       "919  The classification of racist insults presents ...  \n",
       "920  Since the training data consists only of utter...  \n",
       "921  Table TABREF21 shows the performance of non-st...  \n",
       "922      FLOAT SELECTED: Table 7. Experimental results  \n",
       "923  Space requirements might still be considerable...  \n",
       "924  We identified some limitations during the proc...  \n",
       "925  FLOAT SELECTED: Table 2: Results of baselines ...  \n",
       "926  Many practical fake news detection algorithms ...  \n",
       "927  Manning and Schütze argue that, even though no...  \n",
       "928  FLOAT SELECTED: Table 4: Performance of variou...  \n",
       "929  FLOAT SELECTED: Table 2: Results on EMNLP2017 ...  \n",
       "930  We show that it is possible to reduce relation...  \n",
       "931  The behavior model was implemented using an RN...  \n",
       "932  In ConMask, we use a similar idea to select th...  \n",
       "933  In this subsection we discuss the experiment o...  \n",
       "934  We collected tweets related to five different ...  \n",
       "935  FLOAT SELECTED: Table 1: Stylistic domains and...  \n",
       "936  The relation-specific meta information is help...  \n",
       "937  We use two datasets, NELL-One and Wiki-One whi...  \n",
       "938  The number of layers ($N_{src}$-$N_{mt}$-$N_{p...  \n",
       "939  Various multilingual extensions of NMT have al...  \n",
       "940  In order to make the corpus collection easier ...  \n",
       "941  Moreover, QA and QG have probabilistic correla...  \n",
       "942  The Transformer network BIBREF3 is a neural se...  \n",
       "943  On another note, we apply our formalization to...  \n",
       "944  FLOAT SELECTED: Figure 2: NMT training after r...  \n",
       "945  We validate our approach on the Gigaword corpu...  \n",
       "946  FLOAT SELECTED: Fig 5. (A) The average verb re...  \n",
       "947  To assess the predictive capability of this an...  \n",
       "948  Our novelties include: Using self-play learnin...  \n",
       "949  FLOAT SELECTED: Table 1: Data used in this pap...  \n",
       "950  Experimental Protocol ::: Datasets ::: Trainin...  \n",
       "951  FLOAT SELECTED: Table 2: Ablation study on the...  \n",
       "952  The Software Ontology (SWO) BIBREF5 is include...  \n",
       "953  Morphology deals with the internal structure o...  \n",
       "954  Our model consists of two neural network modul...  \n",
       "955  The goal of this paper is to propose a novel O...  \n",
       "956  In this work we focus on end-to-end stateless ...  \n",
       "957  FLOAT SELECTED: Table 2: MAP scoring of new me...  \n",
       "958  We trained and tested our neural network with ...  \n",
       "959  FLOAT SELECTED: Table 2: Test performance on S...  \n",
       "960  We compare the results of our model to a basel...  \n",
       "961  FLOAT SELECTED: Figure 1: Our Hierarchical Net...  \n",
       "962  As indicated in its name, Recurrent Deep Stack...  \n",
       "963  We defined the reward as being 1 for successfu...  \n",
       "964  Interesting prior work on quantifying social n...  \n",
       "965  Much recent work on semantic parsing has been ...  \n",
       "966  We demonstrate our approach on the task of ans...  \n",
       "967  FLOAT SELECTED: Figure 1: Process involved in ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_1 = r\"Sure! Here's the answer to your question:\\n\\n\"\n",
    "prefix_2 = r\"Sure! Here's the answer to your question based on the given context:\\n\\n\"\n",
    "prefix_3 = r\"The answer is:\\n\\n\"\n",
    "prefix_4 = r\"Sure! Here's my answer:\\n\\n\"\n",
    "prefix_5 = r\"Sure! Here's the answer to your question based on the provided context:\\n\\n\"\n",
    "prefix_6 = r\"Sure! Here's the answer to your question based\"\n",
    "\n",
    "df['answer'] = df['answer'].str.replace(prefix_1, '', regex=True)\n",
    "df['answer'] = df['answer'].str.replace(prefix_2, '', regex=True)\n",
    "df['answer'] = df['answer'].str.replace(prefix_3, '', regex=True)\n",
    "df['answer'] = df['answer'].str.replace(prefix_4, '', regex=True)\n",
    "df['answer'] = df['answer'].str.replace(prefix_5, '', regex=True)\n",
    "df['answer'] = df['answer'].str.replace(prefix_6, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what language pairs are explored?</td>\n",
       "      <td>English (En), Arabic (Ar), Spanish (Es), and R...</td>\n",
       "      <td>De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...</td>\n",
       "      <td>For MultiUN corpus, we use four languages: Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what are the topics pulled from Reddit?</td>\n",
       "      <td>politics, business, science, and AskReddit</td>\n",
       "      <td>training data has posts from politics, busine...</td>\n",
       "      <td>Data collection. Subreddits are sub-communitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What accuracy does the proposed system achieve?</td>\n",
       "      <td>The proposed system achieves an accuracy of [i...</td>\n",
       "      <td>F1 scores of 85.99 on the DL-PS data,  75.15 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Main results on the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What crowdsourcing platform is used?</td>\n",
       "      <td>Amazon Mechanical Turk (MTurk)</td>\n",
       "      <td>They did not use any platform, instead they h...</td>\n",
       "      <td>With the purpose of obtaining evaluation datas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On how many language pairs do they show that p...</td>\n",
       "      <td>5.\\n\\nIn the experiment, preordering the assis...</td>\n",
       "      <td>5</td>\n",
       "      <td>We experimented with English INLINEFORM0 Hindi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Which information about text structure is incl...</td>\n",
       "      <td>Text structure information included in the cor...</td>\n",
       "      <td>paragraph, lines, textspan element (paragraph...</td>\n",
       "      <td>The paper at hand introduces a corpus develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What experiments are proposed to test that upp...</td>\n",
       "      <td>The experiments proposed to test that upper la...</td>\n",
       "      <td>They measure self-similarity, intra-sentence s...</td>\n",
       "      <td>We measure how contextual a word representatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How do they calculate a static embedding for e...</td>\n",
       "      <td>They calculate a static embedding for each wor...</td>\n",
       "      <td>They use the first principal component of a wo...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The performance of va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the performance of BERT on the task?</td>\n",
       "      <td>BERT outperforms all other systems in terms of...</td>\n",
       "      <td>F1 scores are:\\nHUBES-PHI: Detection(0.965), C...</td>\n",
       "      <td>To finish with this experiment set, Table also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how is model compactness measured?</td>\n",
       "      <td>Model compactness is measured in terms of its ...</td>\n",
       "      <td>Using file size on disk</td>\n",
       "      <td>Even if LangID-High does not present a more ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Who were the human evaluators used?</td>\n",
       "      <td>20 evaluators were recruited from the institution</td>\n",
       "      <td>20 annotatos from author's institution</td>\n",
       "      <td>Human Evaluation Results. While automated eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Which methods are considered to find examples ...</td>\n",
       "      <td>1. Tagging descriptions with part-of-speech in...</td>\n",
       "      <td>Looking for adjectives marking the noun \"baby...</td>\n",
       "      <td>It may be difficult to spot patterns by just l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What biases are found in the dataset?</td>\n",
       "      <td>The dataset appears to have biases in the way ...</td>\n",
       "      <td>Ethnic bias</td>\n",
       "      <td>Ethnicity/race One interesting pattern is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What discourse relations does it work best/wor...</td>\n",
       "      <td>The model works best for the Temporal discours...</td>\n",
       "      <td>Best: Expansion (Exp). Worst: Comparison (Comp).</td>\n",
       "      <td>The second row shows the performance of our ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>On top of BERT does the RNN layer work better ...</td>\n",
       "      <td>The Transformer layer works better than the RN...</td>\n",
       "      <td>The transformer layer</td>\n",
       "      <td>In this paper, we propose a method that builds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How was this data collected?</td>\n",
       "      <td>Through crowdsourcing on the platform CrowdFlo...</td>\n",
       "      <td>The crowdsourcing platform CrowdFlower was us...</td>\n",
       "      <td>However, getting access to systems with real u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What is the average length of dialog?</td>\n",
       "      <td>3.5 turns</td>\n",
       "      <td>4.49 turns 4.5 turns per dialog (8533 turns / ...</td>\n",
       "      <td>We collected the dataset with 1900 dialogs and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How does the IPA label data after interacting ...</td>\n",
       "      <td>The IPA labels data after interacting with use...</td>\n",
       "      <td>It defined a sequence labeling task to extract...</td>\n",
       "      <td>Named Entity Recognition: We defined a sequenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How was the audio data gathered?</td>\n",
       "      <td>The audio data was gathered from the All India...</td>\n",
       "      <td>Through the All India Radio new channel where ...</td>\n",
       "      <td>In this paper, we explore multiple pooling str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What is the GhostVLAD approach?</td>\n",
       "      <td>GhostVLAD is an extension of the NetVLAD appro...</td>\n",
       "      <td>An extension of NetVLAD which replaces hard a...</td>\n",
       "      <td>GhostVLAD is an extension of the NetVLAD appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Which 7 Indian languages do they experiment with?</td>\n",
       "      <td>Kannada, Hindi, Telugu, Malayalam, Bengali, an...</td>\n",
       "      <td>Hindi, English, Kannada, Telugu, Assamese, Ben...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset In this secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is the invertibility condition?</td>\n",
       "      <td>The invertibility condition is that INLINEFORM...</td>\n",
       "      <td>The neural projector must be invertible.</td>\n",
       "      <td>In this section, we introduce an invertibility...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Which neural architecture do they use as a bas...</td>\n",
       "      <td>Attention mechanism</td>\n",
       "      <td>GRU-based encoder, interaction block, and clas...</td>\n",
       "      <td>We create two models both of which constitutes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What metric is used for evaluation?</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>F1, precision, recall, accuracy Precision, rec...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Clustering results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Which eight NER tasks did they evaluate on?</td>\n",
       "      <td>They evaluated on eight NER tasks</td>\n",
       "      <td>BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Top: Examples of with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Do they focus on Reading Comprehension or mult...</td>\n",
       "      <td>Multiple choice question answering</td>\n",
       "      <td>MULTIPLE CHOICE QUESTION ANSWERING</td>\n",
       "      <td>Automatically answering questions, especially ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>After how many hops does accuracy decrease?</td>\n",
       "      <td>2 hops</td>\n",
       "      <td>one additional hop</td>\n",
       "      <td>Our comprehensive assessment reveals several i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What languages are evaluated?</td>\n",
       "      <td>English and German</td>\n",
       "      <td>German, English, Spanish, Finnish, French, Rus...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Official shared task ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is MSD prediction?</td>\n",
       "      <td>MSD prediction is predicting the morphosyntact...</td>\n",
       "      <td>The task of predicting MSD tags: V, PST, V.PCT...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Example input sentenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What other models do they compare to?</td>\n",
       "      <td>They compare to R.M.-Reader + Verifier, a more...</td>\n",
       "      <td>SAN Baseline, BNA, DocQA, R.M-Reader, R.M-Read...</td>\n",
       "      <td>Table TABREF21 reports comparison results in l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What evaluation metric do they use?</td>\n",
       "      <td>Ratio of correct translations (matches)</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>To test all the possible combinations of param...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What are the results from these proposed strat...</td>\n",
       "      <td>The proposed strategies of using knowledge-gra...</td>\n",
       "      <td>Reward of 11.8 for the A2C-chained model, 41.8...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: Ablation results on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>How much better than the baseline is LiLi?</td>\n",
       "      <td>LiLi outperforms the baseline by a significant...</td>\n",
       "      <td>In case of Freebase knowledge base, LiLi model...</td>\n",
       "      <td>Baselines. As none of the existing KBC methods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What are the components of the general knowled...</td>\n",
       "      <td>The components of the general knowledge learni...</td>\n",
       "      <td>Answer with content missing: (list)\\nLiLi shou...</td>\n",
       "      <td>We solve the OKBC problem by mimicking how hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>How many labels do the datasets have?</td>\n",
       "      <td>The datasets have 4 labels in total</td>\n",
       "      <td>719313 Book, Electronics, Beauty and Music eac...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Summary of datasets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>What are the source and target domains?</td>\n",
       "      <td>Source domain: Book (BK), Electronics (E), Bea...</td>\n",
       "      <td>Book, electronics, beauty, music, IMDB, Yelp, ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Summary of datasets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>How do they deal with unknown distribution sen...</td>\n",
       "      <td>By modifying a naïve Bayesian classifier to re...</td>\n",
       "      <td>The Näive-Bayes classifier is corrected so it ...</td>\n",
       "      <td>Monosemous relatives have been employed multip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What conclusions do the authors draw from thei...</td>\n",
       "      <td>The authors conclude that both ISIS and Cathol...</td>\n",
       "      <td>By comparing scores for each word calculated ...</td>\n",
       "      <td>Comparing these topics with those that appeare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>How id Depechemood trained?</td>\n",
       "      <td>Depechemood was trained using a lexicon-based ...</td>\n",
       "      <td>By multiplying crowd-annotated document-emotio...</td>\n",
       "      <td>Depechemood is a lexicon-based emotion detecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>How are similarities and differences between t...</td>\n",
       "      <td>Similarities and differences between the texts...</td>\n",
       "      <td>By using topic modeling and unsupervised emoti...</td>\n",
       "      <td>What similarities and/or differences do these ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>How are prominent topics idenified in Dabiq an...</td>\n",
       "      <td>Non-negative matrix factorization (NMF) was us...</td>\n",
       "      <td>Using NMF based topic modeling and their cohe...</td>\n",
       "      <td>Topic modeling methods are the more powerful t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Which datasets are used?</td>\n",
       "      <td>ShapeWorldICE datasets</td>\n",
       "      <td>Existential (OneShape, MultiShapes), Spacial (...</td>\n",
       "      <td>We develop a variety of ShapeWorldICE datasets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>What are previous state of the art results?</td>\n",
       "      <td>The previous state-of-the-art results are show...</td>\n",
       "      <td>Overall F1 score:\\n- He and Sun (2017) 58.23\\n...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The results of two pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What source-target language pairs were used in...</td>\n",
       "      <td>En-XX, Zh-XX, Jp-XX, Kr-XX (source-target lang...</td>\n",
       "      <td>En-Fr, En-Zh, En-Jp, En-Kr, Zh-En, Zh-Fr, Zh-J...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: EM/F1 score of multi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>How large is their MNER SnapCaptions dataset?</td>\n",
       "      <td>10,000</td>\n",
       "      <td>10000</td>\n",
       "      <td>The SnapCaptions dataset is composed of 10K us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What is masked document generation?</td>\n",
       "      <td>Masked Document Generation (MDG) is a task tha...</td>\n",
       "      <td>A task for seq2seq model pra-training that rec...</td>\n",
       "      <td>Based on the above observations, we propose St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What useful information does attention capture?</td>\n",
       "      <td>Attention captures information beyond alignmen...</td>\n",
       "      <td>Alignment points of the POS tags.</td>\n",
       "      <td>Our analysis shows that attention models tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>In what cases is attention different from alig...</td>\n",
       "      <td>Attention differs from alignment for VERB and ...</td>\n",
       "      <td>For certain POS tags, e.g. VERB, PRON.</td>\n",
       "      <td>To better understand how attention accuracy af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Which baselines did they compare against?</td>\n",
       "      <td>They compared against previous treestructured ...</td>\n",
       "      <td>Various tree structured neural networks includ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The comparison of var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>What baselines did they consider?</td>\n",
       "      <td>BIBREF13 and BIBREF12</td>\n",
       "      <td>Linear SVM, RBF SVM, and Random Forest</td>\n",
       "      <td>We first use state-of-the-art PDTB taggers for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>How was the dataset annotated?</td>\n",
       "      <td>The dataset was annotated manually by grouping...</td>\n",
       "      <td>intents are annotated manually with guidance f...</td>\n",
       "      <td>We defined the intents with guidance from quer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>What is the size of this dataset?</td>\n",
       "      <td>23,700 queries</td>\n",
       "      <td>23,700 queries, including 22,500 in-scope qu...</td>\n",
       "      <td>This paper fills this gap by analyzing intent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Where does the data come from?</td>\n",
       "      <td>The data comes from crowdsourcing tasks, inclu...</td>\n",
       "      <td>crowsourcing platform For ins scope data colle...</td>\n",
       "      <td>We introduce a new crowdsourced dataset of 23,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Ngrams of which length are aligned using PARENT?</td>\n",
       "      <td>N-grams of length 3</td>\n",
       "      <td>Answer with content missing: (Parent subsecti...</td>\n",
       "      <td>We show that existing automatic metrics, inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>How many people participated in their evaluati...</td>\n",
       "      <td>500 people</td>\n",
       "      <td>about 500</td>\n",
       "      <td>The data collection was performed separately f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>By how much more does PARENT correlate with hu...</td>\n",
       "      <td>PARENT correlates significantly better with hu...</td>\n",
       "      <td>Best proposed metric has average correlation w...</td>\n",
       "      <td>We use bootstrap sampling (500 iterations) ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Which stock market sector achieved the best pe...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Energy with accuracy of 0.538 Energy</td>\n",
       "      <td>FLOAT SELECTED: Table 8: Sector-level performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>How do the authors evidence the claim that man...</td>\n",
       "      <td>The authors evidence the claim by surveying en...</td>\n",
       "      <td>By conducting a survey among engineers</td>\n",
       "      <td>The above challenges often hinder the producti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>what datasets did they use?</td>\n",
       "      <td>The dataset used was a collection of 3500 ques...</td>\n",
       "      <td>Dataset of total 3500 questions from the Inter...</td>\n",
       "      <td>Though Bengali is the seventh most spoken lang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>How much does their model outperform existing ...</td>\n",
       "      <td>The neural extractive models outperform existi...</td>\n",
       "      <td>Best proposed model result vs best previous re...</td>\n",
       "      <td>The performance of all models on arXiv and Pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>What was the baseline for this task?</td>\n",
       "      <td>A very simple logistic regression classifier w...</td>\n",
       "      <td>The baseline system for the SLC task is a very...</td>\n",
       "      <td>The baseline system for the SLC task is a very...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>What is a second order co-ocurrence matrix?</td>\n",
       "      <td>A second-order co-occurrence matrix is a matri...</td>\n",
       "      <td>The matrix containing co-occurrences of the w...</td>\n",
       "      <td>However, despite these successes distributiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>How many humans participated?</td>\n",
       "      <td>9 medical coders and 4 medical residents</td>\n",
       "      <td>16</td>\n",
       "      <td>MiniMayoSRS: The MayoSRS, developed by Pakhomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>What word level and character level model base...</td>\n",
       "      <td>The word level and character level model basel...</td>\n",
       "      <td>None Word-level Memory Neural Networks (MemNNs...</td>\n",
       "      <td>In our experiments, the Memory Neural Networks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>How were the human judgements assembled?</td>\n",
       "      <td>The human judgements were assembled by a group...</td>\n",
       "      <td>50 human annotators ranked a random sample of ...</td>\n",
       "      <td>To ensure that the increase in BLEU score corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Which other approaches do they compare their m...</td>\n",
       "      <td>Existing systems</td>\n",
       "      <td>Akbik et al. (2018), Link et al. (2012) They c...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Comparison with exist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>What results do they achieve using their propo...</td>\n",
       "      <td>The proposed approach achieves F-1 scores betw...</td>\n",
       "      <td>F-1 score on the OntoNotes is 88%, and it is 5...</td>\n",
       "      <td>The results for each class type are shown in T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>How do they combine a deep learning model with...</td>\n",
       "      <td>By using a redirection list and a disambiguati...</td>\n",
       "      <td>Entities from a deep learning model are linked...</td>\n",
       "      <td>While these knowledge bases provide semantical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>What are the models used for the baseline of t...</td>\n",
       "      <td>The baseline models used for the three NLP tas...</td>\n",
       "      <td>For speech synthesis, they build a speech clu...</td>\n",
       "      <td>Baseline Results ::: Speech Synthesis In our p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>How is non-standard pronunciation identified?</td>\n",
       "      <td>Non-standard pronunciation is identified throu...</td>\n",
       "      <td>Original transcription was labeled with addit...</td>\n",
       "      <td>In addition, the transcription includes annota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>What novel PMI variants are introduced?</td>\n",
       "      <td>NPMI and NNEGPMI</td>\n",
       "      <td>clipped PMI; NNEGPMI</td>\n",
       "      <td>where * denotes summation over the correspondi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>What are the disadvantages to clipping negativ...</td>\n",
       "      <td>Sure! Here's the answer to the question at the...</td>\n",
       "      <td>It may lead to poor rare word representations ...</td>\n",
       "      <td>Why incorporate -PMI? $\\mathit {\\texttt {+}PPM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Why are statistics from finite corpora unrelia...</td>\n",
       "      <td>The statistics from finite corpora are unrelia...</td>\n",
       "      <td>A finite corpora may entirely omit rare word ...</td>\n",
       "      <td>Unfortunately, $\\mathit {PMI}(w,c)$ goes to ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Which two pairs of ERPs from the literature be...</td>\n",
       "      <td>N400 and P600, and N400 and N200</td>\n",
       "      <td>Answer with content missing: (Whole Method and...</td>\n",
       "      <td>This work is most closely related to the paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>What datasets are used?</td>\n",
       "      <td>The datasets used are ERP data and eye-trackin...</td>\n",
       "      <td>Answer with content missing: (Whole Method and...</td>\n",
       "      <td>This work is most closely related to the paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>which datasets did they experiment with?</td>\n",
       "      <td>UD1.2 treebanks for 16 languages: Bulgarian, C...</td>\n",
       "      <td>Universal Dependencies v1.2 treebanks for the ...</td>\n",
       "      <td>We carried out our experiments on the Universa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>What kind of celebrities do they obtain tweets...</td>\n",
       "      <td>Twitter celebrities</td>\n",
       "      <td>Amitabh Bachchan, Ariana Grande, Barack Obama,...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Twitter celebrities i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>How did they extend LAMA evaluation framework ...</td>\n",
       "      <td>They introduced the negated LAMA dataset by si...</td>\n",
       "      <td>Create the negated LAMA dataset and  query th...</td>\n",
       "      <td>This work analyzes the understanding of pretra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>What summarization algorithms did the authors ...</td>\n",
       "      <td>The authors experimented with a few summarizat...</td>\n",
       "      <td>LSA, TextRank, LexRank and ILP-based summary. ...</td>\n",
       "      <td>We considered a dataset of 100 employees, wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>What methods were used for sentence classifica...</td>\n",
       "      <td>For sentence classification, the following met...</td>\n",
       "      <td>Logistic Regression, Multinomial Naive Bayes, ...</td>\n",
       "      <td>We randomly selected 2000 sentences from the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>What modern MRC gold standards are analyzed?</td>\n",
       "      <td>BIBREF15, BIBREF28, BIBREF7, and TABREF19</td>\n",
       "      <td>MSMARCO,  HOTPOTQA, RECORD,  MULTIRC, NEWSQA,...</td>\n",
       "      <td>We select contemporary MRC benchmarks to repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>What language is explored in this paper?</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>English language</td>\n",
       "      <td>Figure FIGREF4 pictorially represents our meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>How long of dialog history is captured?</td>\n",
       "      <td>2 dialog turns</td>\n",
       "      <td>two previous turns</td>\n",
       "      <td>The previously proposed contextual language mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>What was the score of the proposed model?</td>\n",
       "      <td>The proposed model achieved an EM/F1 score of ...</td>\n",
       "      <td>Best results authors obtain is EM 51.10 and F1...</td>\n",
       "      <td>To better demonstrate the effectiveness of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>What hyperparameters are explored?</td>\n",
       "      <td>The hyperparameters explored are the choice of...</td>\n",
       "      <td>Dimension size, window size, architecture, alg...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Hyper-parameter choic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>what aspects of conversation flow do they look...</td>\n",
       "      <td>Conversational flow features such as self-cove...</td>\n",
       "      <td>The time devoted to self-coverage, opponent-co...</td>\n",
       "      <td>The flow of talking points . A side can either...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>what is the state of the art?</td>\n",
       "      <td>For NER-style F1, the state of the art is ACE2...</td>\n",
       "      <td>Babelfy, DBpedia Spotlight, Entityclassifier.e...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Comparison of annotat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>What is the Random Kitchen Sink approach?</td>\n",
       "      <td>The Random Kitchen Sink (RKS) approach is a me...</td>\n",
       "      <td>Random Kitchen Sink method uses a kernel funct...</td>\n",
       "      <td>RKS approach proposed in BIBREF21, BIBREF22, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>How do they define similar equations?</td>\n",
       "      <td>They define similar equations using Euclidean ...</td>\n",
       "      <td>By using Euclidean distance computed between t...</td>\n",
       "      <td>In addition to words, EqEmb models can capture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>What are the three steps to feature elimination?</td>\n",
       "      <td>The three steps to feature elimination are:\\n\\...</td>\n",
       "      <td>reduced the dataset by eliminating features, ...</td>\n",
       "      <td>Feature elimination strategies are often taken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>How is the dataset annotated?</td>\n",
       "      <td>The dataset is annotated with depression-relat...</td>\n",
       "      <td>The annotations are based on evidence of depr...</td>\n",
       "      <td>Specifically, we conducted a feature ablation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Which architecture do they use for the encoder...</td>\n",
       "      <td>The encoder uses a combination of convolutiona...</td>\n",
       "      <td>In encoder they use convolutional, NIN and bi...</td>\n",
       "      <td>In this work, we use the raw waveform as the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>How does their decoder generate text?</td>\n",
       "      <td>The decoder generates text by predicting the t...</td>\n",
       "      <td>Decoder predicts the sequence of phoneme or g...</td>\n",
       "      <td>where INLINEFORM0 , INLINEFORM1 is the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>What dataset is used to train the model?</td>\n",
       "      <td>The dataset used to train the model is the col...</td>\n",
       "      <td>Collected tweets and opening and closing stoc...</td>\n",
       "      <td>A total of 2,50,000 tweets over a period of Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Which race and gender are given higher sentime...</td>\n",
       "      <td>Female and African American</td>\n",
       "      <td>Females are given higher sentiment intensity w...</td>\n",
       "      <td>When predicting anger, joy, or valence, the nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>What criteria are used to select the 8,640 Eng...</td>\n",
       "      <td>The 8,640 English sentences were selected base...</td>\n",
       "      <td>Sentences involving at least one race- or gend...</td>\n",
       "      <td>We decided to use sentences involving at least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>what were the baselines?</td>\n",
       "      <td>The baselines were the other models trained us...</td>\n",
       "      <td>LF-MMI Attention\\nSeq2Seq \\nRNN-T \\nChar E2E ...</td>\n",
       "      <td>We also evaluate the Jasper model's performanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>what competitive results did they obtain?</td>\n",
       "      <td>Competitive results were obtained on both WSJ ...</td>\n",
       "      <td>In case of read speech datasets,  their best m...</td>\n",
       "      <td>We trained a smaller Jasper 10x3 model with SG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>By how much is performance improved with multi...</td>\n",
       "      <td>Performance is improved by approximately 0.02 ...</td>\n",
       "      <td>by 2.3-6.8 points in f1 score for intent recog...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Speech Embeddings Exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How much is performance improved on NLI?</td>\n",
       "      <td>4% absolute gain over BERTBase on the NLI task</td>\n",
       "      <td>The average score improved by 1.4 points over...</td>\n",
       "      <td>Table TABREF21 illustrates the experimental re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>What is active learning?</td>\n",
       "      <td>Active learning is a technique for selectively...</td>\n",
       "      <td>A process of training a model when selected un...</td>\n",
       "      <td>Active learning sharply increases the performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>what was the baseline?</td>\n",
       "      <td>The baseline was a strong NMT system</td>\n",
       "      <td>M2M Transformer</td>\n",
       "      <td>We began with evaluating standard MT paradigms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>How is segmentation quality evaluated?</td>\n",
       "      <td>Segmentation quality is evaluated based on the...</td>\n",
       "      <td>Segmentation quality is evaluated by calculati...</td>\n",
       "      <td>Two batch of tests were performed. The first o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>How do they compare lexicons?</td>\n",
       "      <td>The experts and crowd contributors have simila...</td>\n",
       "      <td>Human evaluators were asked to evaluate on a s...</td>\n",
       "      <td>We perform a direct comparison of expert and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>How larger are the training sets of these vers...</td>\n",
       "      <td>The training sets of these versions of ELMo ar...</td>\n",
       "      <td>By 14 times. up to 1.95 times larger</td>\n",
       "      <td>Recently, ELMoForManyLangs BIBREF6 project rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>What is the improvement in performance for Est...</td>\n",
       "      <td>2.42% improvement in performance for Estonian ...</td>\n",
       "      <td>5 percent points. 0.05 F1</td>\n",
       "      <td>FLOAT SELECTED: Table 4: The results of NER ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>what is the state of the art on WSJ?</td>\n",
       "      <td>INLINEFORM2 WER</td>\n",
       "      <td>CNN-DNN-BLSTM-HMM</td>\n",
       "      <td>Table TABREF11 shows Word Error Rates (WER) on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>what is the size of the augmented dataset?</td>\n",
       "      <td>The size of the augmented dataset is 500 samples</td>\n",
       "      <td>609</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Speech datasets used....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Why are current ELS's not sufficiently effective?</td>\n",
       "      <td>Low precision rates and design challenges in t...</td>\n",
       "      <td>Linked entities may be ambiguous or too common</td>\n",
       "      <td>Despite its usefulness, linked entities extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>How many sentences does the dataset contain?</td>\n",
       "      <td>6946</td>\n",
       "      <td>3606</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset statistics In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>What is the baseline?</td>\n",
       "      <td>The baseline is the Stanford CRF model (BIBREF21)</td>\n",
       "      <td>Bam et al. SVM, Ma and Hovy w/glove, Lample e...</td>\n",
       "      <td>Similar approaches has been applied to many So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>What is the size of the dataset?</td>\n",
       "      <td>The size of the dataset is 1000 sentences</td>\n",
       "      <td>Dataset contains 3606 total sentences and 7908...</td>\n",
       "      <td>After much time, we received the dataset from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>How many different types of entities exist in ...</td>\n",
       "      <td>3</td>\n",
       "      <td>OurNepali contains 3 different types of entiti...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset statistics Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>How big is the new Nepali NER dataset?</td>\n",
       "      <td>The new Nepali NER dataset has a size of 23,33...</td>\n",
       "      <td>3606 sentences Dataset contains 3606 total sen...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Dataset statistics Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>What is the performance improvement of the gra...</td>\n",
       "      <td>The grapheme-level representation model outper...</td>\n",
       "      <td>On OurNepali test dataset Grapheme-level repre...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Comparison of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Which variation provides the best results on t...</td>\n",
       "      <td>The variation with the Projected Layer provide...</td>\n",
       "      <td>the model with multi-attention mechanism and a...</td>\n",
       "      <td>We have evaluated our models considering the F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>What are the different variations of the atten...</td>\n",
       "      <td>Four variations of the attention-based approac...</td>\n",
       "      <td>classic RNN model, avgRNN model, attentionRNN ...</td>\n",
       "      <td>We compare eight different models in our exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>What dataset is used for this work?</td>\n",
       "      <td>The dataset used for this work is the SociaL M...</td>\n",
       "      <td>Twitter dataset provided by the organizers The...</td>\n",
       "      <td>In this paper we present our work, which is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>What were the datasets used in this paper?</td>\n",
       "      <td>The dataset used in this paper is a Twitter da...</td>\n",
       "      <td>The dataset from the SociaL Media And Harassme...</td>\n",
       "      <td>In this paper we present our work, which is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>What is the performance of classifiers?</td>\n",
       "      <td>The performance of the classifiers is good, wi...</td>\n",
       "      <td>Using F1 Micro measure, the KNN classifier pe...</td>\n",
       "      <td>In order to evaluate our classifiers, we perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>What classifiers have been trained?</td>\n",
       "      <td>KNN, RF, SVM, and MLP</td>\n",
       "      <td>KNN\\nRF\\nSVM\\nMLP</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Evaluation metrics fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>How many layers does the UTCNN model have?</td>\n",
       "      <td>4 layers</td>\n",
       "      <td>eight layers</td>\n",
       "      <td>Figure FIGREF10 illustrates the UTCNN model. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>What are the baselines?</td>\n",
       "      <td>SVM with unigram, bigram, and trigram features...</td>\n",
       "      <td>SVM with unigram, bigram, trigram features, w...</td>\n",
       "      <td>We pit our model against the following baselin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>What transfer learning tasks are evaluated?</td>\n",
       "      <td>The seven SentEval transfer tasks evaluated ar...</td>\n",
       "      <td>Semantic Textual Similarity, sentiment predi...</td>\n",
       "      <td>We compare the SBERT sentence embeddings to ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>What other sentence embeddings methods are eva...</td>\n",
       "      <td>InferSent and the Universal Sentence Encoder</td>\n",
       "      <td>GloVe, BERT, Universal Sentence Encoder, TF-ID...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Spearman rank correla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Which shallow approaches did they experiment w...</td>\n",
       "      <td>Bag-of-Words and Support Vector Machine with l...</td>\n",
       "      <td>SVM with linear kernel using bag-of-words fea...</td>\n",
       "      <td>As a first baseline we use Bag-of-Words, a wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>which non-english language had the best perfor...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Russsian</td>\n",
       "      <td>Considering the improvements over the majority...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>how did the authors translate the reviews to o...</td>\n",
       "      <td>The authors used machine translation to transl...</td>\n",
       "      <td>Using Google translation API.</td>\n",
       "      <td>In order to eliminate the need to find data an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>What are the five different binary classificat...</td>\n",
       "      <td>The five different binary classification tasks...</td>\n",
       "      <td>presence/absence of consonants, presence/abse...</td>\n",
       "      <td>We evaluate our model on a publicly available ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>How was the spatial aspect of the EEG signal c...</td>\n",
       "      <td>The spatial aspect of the EEG signal was compu...</td>\n",
       "      <td>They use four-layered 2D CNN and two fully co...</td>\n",
       "      <td>In order to decode spatial connections between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Which real-world datasets are used?</td>\n",
       "      <td>CyberAttack and PoliticianDeath</td>\n",
       "      <td>Tweets related to CyberAttack and tweets relat...</td>\n",
       "      <td>Datasets. We perform our experiments with two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>How are the interpretability merits of the app...</td>\n",
       "      <td>By providing human-understandable explanations...</td>\n",
       "      <td>By involving humans for post-hoc evaluation of...</td>\n",
       "      <td>Human-in-the-Loop Approaches. Our work extends...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>How are the accuracy merits of the approach de...</td>\n",
       "      <td>The approach demonstrates significant improvem...</td>\n",
       "      <td>By evaluating the performance of the approach...</td>\n",
       "      <td>Our approach improves LR by 5.17% (Accuracy) a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>What is a wizard of oz setup?</td>\n",
       "      <td>A Wizard of Oz setup is a simulated informatio...</td>\n",
       "      <td>a setup where the seeker interacts with a rea...</td>\n",
       "      <td>Macaw also supports Wizard of Oz studies or in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>What baseline model is used?</td>\n",
       "      <td>B1. The first baseline uses only the salience-...</td>\n",
       "      <td>For Article-Entity placement, they consider tw...</td>\n",
       "      <td>Here we introduce the evaluation setup and ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>How do they determine the exact section to use...</td>\n",
       "      <td>They use a multi-class classification problem ...</td>\n",
       "      <td>They use a multi-class classifier to determine...</td>\n",
       "      <td>We model the ASP placement task as a successor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>What features are used to represent the novelt...</td>\n",
       "      <td>The novelty of news articles is represented by...</td>\n",
       "      <td>KL-divergences of language models for the news...</td>\n",
       "      <td>An important feature when suggesting an articl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>What features are used to represent the salien...</td>\n",
       "      <td>Baseline features, such as positional features...</td>\n",
       "      <td>Salience features positional features, occurre...</td>\n",
       "      <td>Baseline Features. As discussed in Section SEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>How was annotation performed?</td>\n",
       "      <td>Annotation was performed using WebAnno BIBREF7...</td>\n",
       "      <td>Experienced medical doctors used a linguistic ...</td>\n",
       "      <td>We asked medical doctors experienced in extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>What activation function do they use in their ...</td>\n",
       "      <td>$relu$</td>\n",
       "      <td>Activation function is hyperparameter. Possib...</td>\n",
       "      <td>Experimental Setup. We apply a 5 cross-validat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>How are chunks defined?</td>\n",
       "      <td>Chunks are defined as sorted sequences of twee...</td>\n",
       "      <td>Chunks is group of tweets from single account ...</td>\n",
       "      <td>Given a news Twitter account, we read its twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>How big is the dataset used in this work?</td>\n",
       "      <td>The dataset used in this work consists of 212 ...</td>\n",
       "      <td>Total dataset size: 171 account (522967 tweets...</td>\n",
       "      <td>Data. We build a dataset of Twitter accounts b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>How is a \"chunk of posts\" defined in this work?</td>\n",
       "      <td>A \"chunk of posts\" is defined as a sorted sequ...</td>\n",
       "      <td>sequence of $s$ tweets</td>\n",
       "      <td>The main obstacle for detecting suspicious Twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Which evaluation methods are used?</td>\n",
       "      <td>ROGUE-1, ROGUE-2, and ROGUE-L</td>\n",
       "      <td>Quantitative evaluation methods using ROUGE, R...</td>\n",
       "      <td>For the evaluation of summaries we use the sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>How are sentences selected from the summary gr...</td>\n",
       "      <td>The sentences are selected from the summary gr...</td>\n",
       "      <td>Two methods: first is to simply pick initial...</td>\n",
       "      <td>After parsing (Step 1) we have the AMR graphs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>What is the size of the new dataset?</td>\n",
       "      <td>The size of the new dataset is 300 tweets</td>\n",
       "      <td>14,100 tweets Dataset contains total of 14100...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Distribution of label...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>What kinds of offensive content are explored?</td>\n",
       "      <td>Targeted and untargeted insults and threats, a...</td>\n",
       "      <td>non-targeted profanity and swearing, targeted ...</td>\n",
       "      <td>Level B categorizes the type of offense and tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>How long is the dataset for each step of hiera...</td>\n",
       "      <td>The dataset size for each step of the hierarch...</td>\n",
       "      <td>Level A: 14100 Tweets\\nLevel B: 4640 Tweets\\nL...</td>\n",
       "      <td>The data included in OLID has been collected f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>In the proposed metric, how is content relevan...</td>\n",
       "      <td>Content relevance is measured using informatio...</td>\n",
       "      <td>The content relevance between the candidate su...</td>\n",
       "      <td>Our proposed metric is based on analysis of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>What different correlations result when using ...</td>\n",
       "      <td>Different correlations result when using diffe...</td>\n",
       "      <td>Using Pearson corelation measure,  for exampl...</td>\n",
       "      <td>Table TABREF23 shows the Pearson, Spearman and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>how is mitigation of gender bias evaluated?</td>\n",
       "      <td>The mitigation of gender bias is evaluated usi...</td>\n",
       "      <td>Using INLINEFORM0 and INLINEFORM1</td>\n",
       "      <td>Results for the experiments are listed in Tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>What tasks were evaluated?</td>\n",
       "      <td>The 8 tasks evaluated in ReviewQA are:\\n\\n1. A...</td>\n",
       "      <td>Detection of an aspect in a review, Predictio...</td>\n",
       "      <td>Table TABREF19 displays the performance of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>What are their results on both datasets?</td>\n",
       "      <td>On both datasets, the combination of the patte...</td>\n",
       "      <td>Combining  pattern based and Machine translati...</td>\n",
       "      <td>The error detection results can be seen in Tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>by how much did their model improve?</td>\n",
       "      <td>Their model improved by 2.11 BLEU, 1.7 FKGL, a...</td>\n",
       "      <td>For the WikiLarge dataset, the improvement ove...</td>\n",
       "      <td>Results. Table 1 shows the results of all mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>what are the sizes of both datasets?</td>\n",
       "      <td>WikiSmall: 89,042 sentence pairs (training) + ...</td>\n",
       "      <td>WikiSmall  89 142 sentence pair and  WikiLarg...</td>\n",
       "      <td>Dataset. We use two simplification datasets (W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>What are the distinctive characteristics of ho...</td>\n",
       "      <td>Arabic speakers use offensive language in a va...</td>\n",
       "      <td>Frequent use of direct animal name calling, us...</td>\n",
       "      <td>Next, we analyzed all tweets labeled as offens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>How many annotators tagged each tweet?</td>\n",
       "      <td>One annotator tagged each tweet</td>\n",
       "      <td>One One experienced annotator tagged all tweets</td>\n",
       "      <td>We developed the annotation guidelines jointly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>In what way is the offensive dataset not biase...</td>\n",
       "      <td>The offensive dataset is not biased by topic, ...</td>\n",
       "      <td>It does not use a seed list to gather tweets s...</td>\n",
       "      <td>Disclaimer: Due to the nature of the paper, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>What are the difficulties in modelling the iro...</td>\n",
       "      <td>The difficulties in modelling the ironic patte...</td>\n",
       "      <td>ironies are often obscure and hard to understand</td>\n",
       "      <td>Although some previous studies focus on irony ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>How did the authors find ironic data on twitter?</td>\n",
       "      <td>The authors crawled over 2M tweets from Twitte...</td>\n",
       "      <td>They developed a classifier to find ironic sen...</td>\n",
       "      <td>As neural networks are proved effective in iro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Who judged the irony accuracy, sentiment prese...</td>\n",
       "      <td>Four annotators who are proficient in English ...</td>\n",
       "      <td>Irony accuracy is judged only by human ; senri...</td>\n",
       "      <td>In order to evaluate sentiment preservation, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>How were the tweets annotated?</td>\n",
       "      <td>The tweets were annotated with stance informat...</td>\n",
       "      <td>tweets are annotated with only Favor or Agains...</td>\n",
       "      <td>We have decided to consider tweets about popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>What are hashtag features?</td>\n",
       "      <td>Hashtag features refer to the presence or abse...</td>\n",
       "      <td>hashtag features contain whether there is any ...</td>\n",
       "      <td>With an intention to exploit the contribution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>For how many probe tasks the shallow-syntax-aw...</td>\n",
       "      <td>1.\\n\\nOut of the 9 tasks in the table, mSynC p...</td>\n",
       "      <td>3</td>\n",
       "      <td>Results in Table TABREF13 show ten probes. Aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>What are the black-box probes used?</td>\n",
       "      <td>BIBREF1</td>\n",
       "      <td>CCG Supertagging CCGBank , PTB part-of-speech ...</td>\n",
       "      <td>Recent work has probed the knowledge encoded i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>How does this model overcome the assumption th...</td>\n",
       "      <td>The Adversarial-neural Event Model (AEM) overc...</td>\n",
       "      <td>by learning a projection function between the...</td>\n",
       "      <td>To deal with these limitations, in this paper,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>What are the industry classes defined in this ...</td>\n",
       "      <td>The industry classes defined in this paper are...</td>\n",
       "      <td>technology, religion, fashion, publishing, spo...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Industry categories a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>What are the hyperparameters of the bi-GRU?</td>\n",
       "      <td>The hyperparameters of the bi-GRU are:\\n\\n* Ba...</td>\n",
       "      <td>They use the embedding layer with a size 35 an...</td>\n",
       "      <td>Minimal pre-processing was done by converting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Does the algorithm improve on the state-of-the...</td>\n",
       "      <td>YES</td>\n",
       "      <td>From all reported results proposed method (NB...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: LID Accuracy Results....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>What background knowledge do they leverage?</td>\n",
       "      <td>Labeled features as prior knowledge</td>\n",
       "      <td>labelled features, which are words whose pres...</td>\n",
       "      <td>We address the robustness problem on top of GE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>What NLP tasks do they consider?</td>\n",
       "      <td>Text classification</td>\n",
       "      <td>text classification for themes including senti...</td>\n",
       "      <td>In this section, we first justify the approach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>How do they define robustness of a model?</td>\n",
       "      <td>The authors define robustness of a model as it...</td>\n",
       "      <td>ability to accurately classify texts even when...</td>\n",
       "      <td>GE-FL reduces the heavy load of instance annot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Are the annotations automatic or manually crea...</td>\n",
       "      <td>Manually created</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>We annotated the dataset at two levels: Part o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>How long are the essays on average?</td>\n",
       "      <td>The average length of the essays is approximat...</td>\n",
       "      <td>204 tokens</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: Histogram of documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>What neural models are used to encode the text?</td>\n",
       "      <td>NBOW, LSTM, and attentive LSTM</td>\n",
       "      <td>NBOW, LSTM, attentive LSTM</td>\n",
       "      <td>In this paper, we use three encoders (NBOW, LS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>What TIMIT datasets are used for testing?</td>\n",
       "      <td>D, H</td>\n",
       "      <td>Once split into 8 subsets (A-H), the test set ...</td>\n",
       "      <td>In order to achieve these configuration the TI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>What state-of-the-art results are achieved?</td>\n",
       "      <td>The state-of-the-art results achieved are Prec...</td>\n",
       "      <td>F1 score of 92.19 on homographic pun detection...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>What baselines do they compare with?</td>\n",
       "      <td>They compare with three baselines: Random, Wor...</td>\n",
       "      <td>They compare with the following models: by Ped...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>What datasets are used in evaluation?</td>\n",
       "      <td>BIBREF9</td>\n",
       "      <td>A homographic and heterographic benchmark dat...</td>\n",
       "      <td>We evaluate our model on two benchmark dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>What is the tagging scheme employed?</td>\n",
       "      <td>INLINEFORM0</td>\n",
       "      <td>A new tagging scheme that tags the words befor...</td>\n",
       "      <td>The contexts have the characteristic that each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>How they extract \"structured answer-relevant r...</td>\n",
       "      <td>They extract \"structured answer-relevant relat...</td>\n",
       "      <td>Using the OpenIE toolbox and applying heuristi...</td>\n",
       "      <td>To address this issue, we extract the structur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>How big are significant improvements?</td>\n",
       "      <td>The improvements are significant, with our pro...</td>\n",
       "      <td>Metrics show better results on all metrics com...</td>\n",
       "      <td>Table TABREF30 shows automatic evaluation resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>They used the Phase B dataset</td>\n",
       "      <td>BioASQ  dataset A dataset provided by BioASQ c...</td>\n",
       "      <td>BioASQ organizers provide the training and tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>What was their highest MRR score?</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.5115</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Factoid Questions. In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>How do they measure which words are under-tran...</td>\n",
       "      <td>By using estimated word importance to detect u...</td>\n",
       "      <td>They measured the under-translated words with ...</td>\n",
       "      <td>In this experiment, we propose to use the esti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>How do their models decide how much improtance...</td>\n",
       "      <td>By using integrated gradients to calculate the...</td>\n",
       "      <td>They compute the gradient of the output at ea...</td>\n",
       "      <td>Following the formula, we can calculate the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Which data do they use as a starting point for...</td>\n",
       "      <td>Nurse-initiated telephone conversations for co...</td>\n",
       "      <td>A sample from nurse-initiated telephone conver...</td>\n",
       "      <td>We used recordings of nurse-initiated telephon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>How do they select instances to their hold-out...</td>\n",
       "      <td>They select instances for their hold-out test ...</td>\n",
       "      <td>1264 instances from simulated data, 1280 insta...</td>\n",
       "      <td>To evaluate the effectiveness of our linguisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>How do the authors examine whether a model is ...</td>\n",
       "      <td>By using adversarial sets, specifically AddSen...</td>\n",
       "      <td>By evaluating their model on adversarial sets ...</td>\n",
       "      <td>MRC Dataset. The MRC dataset used in this pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>What type of system does the baseline classifi...</td>\n",
       "      <td>Naive Bayes classifier</td>\n",
       "      <td>Classification system use n-grams, bag-of-wor...</td>\n",
       "      <td>We experimented with four different classifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>What are the user-defined keywords?</td>\n",
       "      <td>$\\lbrace subway, manhattan\\rbrace $</td>\n",
       "      <td>Words that a user wants them to appear in the ...</td>\n",
       "      <td>Nonetheless, GANs have continued to show their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>What are the baselines used in the paper?</td>\n",
       "      <td>The baselines used in the paper are Random For...</td>\n",
       "      <td>GloVe vectors trained on Wikipedia Corpus with...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results of RNN/LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>How better is performance compared to previous...</td>\n",
       "      <td>Our model achieves new state-of-the-art result...</td>\n",
       "      <td>F1 score of 97.5 on MSR and 95.7 on AS MSR: 97...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Results on PKU and MS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>How does Gaussian-masked directional multi-hea...</td>\n",
       "      <td>Gaussian-masked directional multi-head attenti...</td>\n",
       "      <td>pays attentions to adjacent characters and cas...</td>\n",
       "      <td>Different from scaled dot-product attention, G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>What are strong baselines model is compared to?</td>\n",
       "      <td>All the other models in the comparison, except...</td>\n",
       "      <td>Baseline models are:\\n- Chen et al., 2015a\\n- ...</td>\n",
       "      <td>Tables TABREF25 and TABREF26 reports the perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>What additional features and context are propo...</td>\n",
       "      <td>Context tweets are proposed as additional feat...</td>\n",
       "      <td>using tweets that one has replied or quoted to...</td>\n",
       "      <td>While manually analyzing the raw dataset, we n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>What evidence do the authors present that the ...</td>\n",
       "      <td>The authors present evidence that the model ca...</td>\n",
       "      <td>The authors showed few tweets where neither an...</td>\n",
       "      <td>By examining more samples and with respect to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>What are the existing biases?</td>\n",
       "      <td>Existing biases in hate speech detection datas...</td>\n",
       "      <td>sampling tweets from specific keywords create...</td>\n",
       "      <td>As one of the first attempts in neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>What biases does their model capture?</td>\n",
       "      <td>The model captures biases from data collection...</td>\n",
       "      <td>Data annotation biases where tweet containing ...</td>\n",
       "      <td>By examining more samples and with respect to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>which neural embedding model works better?</td>\n",
       "      <td>The CRC model embeddings work better</td>\n",
       "      <td>the CRX model</td>\n",
       "      <td>FLOAT SELECTED: Table 5 Accuracy of concept ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>What is the degree of dimension reduction of t...</td>\n",
       "      <td>3</td>\n",
       "      <td>The number of dimensions can be reduced by up ...</td>\n",
       "      <td>FLOAT SELECTED: Table 8 Evaluation results of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>For which languages do they build word embeddi...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>English</td>\n",
       "      <td>FLOAT SELECTED: Table 2: We generate vectors f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>What experiments do they use to quantify the e...</td>\n",
       "      <td>Word intrusion test and semantic category-base...</td>\n",
       "      <td>Human evaluation for interpretability using th...</td>\n",
       "      <td>One of the main goals of this study is to impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>What is the additive modification to the objec...</td>\n",
       "      <td>The additive modification to the objective fun...</td>\n",
       "      <td>The cost function for any one of the words of ...</td>\n",
       "      <td>Especially after the introduction of the word2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>How do they encourage understanding of literat...</td>\n",
       "      <td>By categorizing each model based on the optimi...</td>\n",
       "      <td>They group the existing works in terms of the ...</td>\n",
       "      <td>Despite this, there is a lack of prior work wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Why challenges does word segmentation in Vietn...</td>\n",
       "      <td>Word segmentation in Vietnamese poses challeng...</td>\n",
       "      <td>Acquire very large Vietnamese corpus and build...</td>\n",
       "      <td>There are several challenges on supervised lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>How successful are the approaches used to solv...</td>\n",
       "      <td>The approaches used to solve word segmentation...</td>\n",
       "      <td>Their accuracy in word segmentation is about 9...</td>\n",
       "      <td>There are several studies about the Vietnamese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Which two news domains are country-independent?</td>\n",
       "      <td>Mainstream and disinformation news domains are...</td>\n",
       "      <td>mainstream news and disinformation</td>\n",
       "      <td>We collected tweets associated to a dozen US m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>How is the political bias of different sources...</td>\n",
       "      <td>The political bias of different sources is inc...</td>\n",
       "      <td>By assigning a political bias label to each ne...</td>\n",
       "      <td>As it is reported that conservatives and liber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>How was the dataset collected?</td>\n",
       "      <td>The dataset was collected from standardized sc...</td>\n",
       "      <td>from 3rd to 9th grade science questions collec...</td>\n",
       "      <td>Questions: We make use of the 7,787 science ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>How do they verify generalization ability?</td>\n",
       "      <td>They verify generalization ability by evaluati...</td>\n",
       "      <td>By calculating Macro F1 metric at the document...</td>\n",
       "      <td>Training We collect 50,000 Wikipedia articles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Do they only use adjacent entity mentions or u...</td>\n",
       "      <td>They use more than just adjacent entity mentio...</td>\n",
       "      <td>NCEL considers only adjacent mentions. More th...</td>\n",
       "      <td>Complexity Analysis Compared with local method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Why is lemmatization not necessary in English?</td>\n",
       "      <td>It is not entirely true that lemmatization is ...</td>\n",
       "      <td>Advanced neural architectures and contextualiz...</td>\n",
       "      <td>A long-standing tradition if the field of appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>How big was the corpora they trained ELMo on?</td>\n",
       "      <td>The corpora they trained ELMo on were approxim...</td>\n",
       "      <td>2174000000, 989000000 2174 million tokens for ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Training corpora For ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>What dataset is used?</td>\n",
       "      <td>English WIKIBIO dataset</td>\n",
       "      <td>English WIKIBIO, French WIKIBIO , German WIKIB...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>What does the \"sensitivity\" quantity denote?</td>\n",
       "      <td>The sensitivity quantity denotes the expected ...</td>\n",
       "      <td>The expected number of unique outputs a word ...</td>\n",
       "      <td>In NLP, we often get such invariance for free,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>What end tasks do they evaluate on?</td>\n",
       "      <td>They evaluate on sentiment classification and ...</td>\n",
       "      <td>Sentiment analysis and paraphrase detection un...</td>\n",
       "      <td>For sentiment classification, we systematicall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>What is a semicharacter architecture?</td>\n",
       "      <td>A semi-character architecture</td>\n",
       "      <td>A semi-character based RNN (ScRNN) treats the ...</td>\n",
       "      <td>Inspired by the psycholinguistic studies BIBRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Why is the adversarial setting appropriate for...</td>\n",
       "      <td>Adversarial misspellings are appropriate for m...</td>\n",
       "      <td>Adversarial misspellings are a real-world problem</td>\n",
       "      <td>For all the interest in adversarial computer v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>How do the backoff strategies work?</td>\n",
       "      <td>The backoff strategies work by either passing ...</td>\n",
       "      <td>In pass-through, the recognizer passes on the ...</td>\n",
       "      <td>While BIBREF7 demonstrate strong word recognit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>which algorithm was the highest performer?</td>\n",
       "      <td>INLINEFORM7</td>\n",
       "      <td>A hybrid model consisting of best performing p...</td>\n",
       "      <td>Hybrid approaches. Figure FIGREF11 shows the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>what dataset was used?</td>\n",
       "      <td>Amazon search terms and editor tags</td>\n",
       "      <td>E-book annotation data: editor tags, Amazon ...</td>\n",
       "      <td>Data used to generate recommendations. We empl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>How large are the improvements of the Attentio...</td>\n",
       "      <td>The Attention-Sum Reader model improves by 2.3...</td>\n",
       "      <td>Answer with content missing: (Table 2) Accura...</td>\n",
       "      <td>If we take the best psr ensemble trained on CB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Which machine learning methods are used in exp...</td>\n",
       "      <td>SVMhmm BIBREF111 implementation of Structural ...</td>\n",
       "      <td>Structural Support Vector Machine</td>\n",
       "      <td>We chose SVMhmm BIBREF111 implementation of St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>how was the speech collected?</td>\n",
       "      <td>The speech was collected using an Android appl...</td>\n",
       "      <td>The speech was collected from respondents usin...</td>\n",
       "      <td>DeepMine is publicly available for everybody w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>what topics did they label?</td>\n",
       "      <td>The topics labeled in the HPI notes include de...</td>\n",
       "      <td>Demographics Age, DiagnosisHistory, Medication...</td>\n",
       "      <td>FLOAT SELECTED: Table 1. HPI Categories and An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>what levels of document preprocessing are look...</td>\n",
       "      <td>Three incremental levels of document preproces...</td>\n",
       "      <td>Level 1, Level 2 and Level 3.</td>\n",
       "      <td>While previous work clearly states that effici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>what keyphrase extraction models were reassessed?</td>\n",
       "      <td>The keyphrase extraction models were reassessed</td>\n",
       "      <td>Answer with content missing: (LVL1, LVL2, LVL3...</td>\n",
       "      <td>In this study, we concentrate our effort on re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>How many different phenotypes are present in t...</td>\n",
       "      <td>13</td>\n",
       "      <td>Thirteen different phenotypes are present in ...</td>\n",
       "      <td>We have created a dataset of discharge summari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>What are 10 other phenotypes that are annotated?</td>\n",
       "      <td>10 other phenotypes that are annotated are:\\n\\...</td>\n",
       "      <td>Adv. Heart Disease, Adv. Lung Disease, Alcohol...</td>\n",
       "      <td>Table defines each of the considered clinical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>What are the network's baseline features?</td>\n",
       "      <td>100 baseline features</td>\n",
       "      <td>The features extracted from CNN.</td>\n",
       "      <td>CNN can also be employed on the sarcasm datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>What tasks are used for evaluation?</td>\n",
       "      <td>Machine translation tasks</td>\n",
       "      <td>four machine translation tasks: German -&gt; Engl...</td>\n",
       "      <td>We apply our adaptively sparse Transformers on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>HOw does the method perform compared with base...</td>\n",
       "      <td>The method performs similarly or slightly bett...</td>\n",
       "      <td>On the datasets DE-EN, JA-EN, RO-EN, and EN-DE...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Machine translation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>What baseline method is used?</td>\n",
       "      <td>SVM approach using unsupervised hand-crafted f...</td>\n",
       "      <td>using word2vec to create features that are use...</td>\n",
       "      <td>In a recent work on sentiment analysis in Turk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>What details are given about the Twitter dataset?</td>\n",
       "      <td>The Twitter dataset has 1,716 tweets, with 973...</td>\n",
       "      <td>one of the Twitter datasets is about Turkish ...</td>\n",
       "      <td>The second Turkish dataset is the Twitter corp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>What details are given about the movie domain ...</td>\n",
       "      <td>The movie domain dataset has 20,244 reviews wi...</td>\n",
       "      <td>there are 20,244 reviews divided into positive...</td>\n",
       "      <td>For Turkish, as the first dataset, we utilised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>what pretrained word embeddings were used?</td>\n",
       "      <td>GloVe BIBREF13 and Edinburgh embeddings BIBREF14</td>\n",
       "      <td>Pretrained word embeddings  were not used</td>\n",
       "      <td>Word Vectors: We focus primarily on the word v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>What evaluation metrics did look at?</td>\n",
       "      <td>The evaluation metrics looked at were time tak...</td>\n",
       "      <td>precision, recall, F1 and accuracy Response ti...</td>\n",
       "      <td>FLOAT SELECTED: Table 15: Evaluation of differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>What datasets are used?</td>\n",
       "      <td>The dataset used is a collection of 124 questi...</td>\n",
       "      <td>Custom dataset with user questions; set of doc...</td>\n",
       "      <td>Given that there is no public dataset availabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>How much improvement is gained from Adversaria...</td>\n",
       "      <td>ARAML achieves a significant improvement of 10...</td>\n",
       "      <td>ARAM has achieved improvement over all baselin...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Automatic evaluation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>why are their techniques cheaper to implement?</td>\n",
       "      <td>Because they do not require the availability o...</td>\n",
       "      <td>They use a slightly modified copy of the targe...</td>\n",
       "      <td>In this paper, we have analyzed various ways t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>what dataset is used?</td>\n",
       "      <td>Europarl corpus BIBREF5</td>\n",
       "      <td>Europarl tests from 2006, 2007, 2008; WMT new...</td>\n",
       "      <td>We are mostly interested with the following tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>what language pairs are explored?</td>\n",
       "      <td>English-German and English-French</td>\n",
       "      <td>English-German, English-French. English-German...</td>\n",
       "      <td>We are mostly interested with the following tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>What are the organic and inorganic ways to sho...</td>\n",
       "      <td>Organic ways to show political affiliation thr...</td>\n",
       "      <td>Organic: mention of political parties names in...</td>\n",
       "      <td>In this section, we first describe the phenome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>How do profile changes vary for influential le...</td>\n",
       "      <td>Influential leads are more likely to make chan...</td>\n",
       "      <td>Influential leaders are more likely to change ...</td>\n",
       "      <td>INSIGHT 1: Political handles are more likely t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>how small of a dataset did they train on?</td>\n",
       "      <td>1000 hours</td>\n",
       "      <td>23085 hours of data</td>\n",
       "      <td>In this paper, we explore a entire deep LSTM R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>what was their character error rate?</td>\n",
       "      <td>The character error rate (CER) of the 9-layer ...</td>\n",
       "      <td>2.49% for  layer-wise training, 2.63% for dist...</td>\n",
       "      <td>FLOAT SELECTED: Table 3. The CER and RTF of 9-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>which lstm models did they compare with?</td>\n",
       "      <td>They compared 6-9 layer LSTM models trained wi...</td>\n",
       "      <td>Unidirectional LSTM networks with 2, 6, 7, 8, ...</td>\n",
       "      <td>There is a high real time requirement in real ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Do they use datasets with transcribed text or ...</td>\n",
       "      <td>They use both datasets with transcribed text a...</td>\n",
       "      <td>They use text transcription. both</td>\n",
       "      <td>We assume that speech transcripts can be extra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>By how much did they improve?</td>\n",
       "      <td>They improved by 2.5% absolute improvement in ...</td>\n",
       "      <td>They decrease MAE in 0.34</td>\n",
       "      <td>Concerning the neural network architecture, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>The dataset used was the fine-grained sentimen...</td>\n",
       "      <td>high-quality datasets  from SemEval-2016 “Sen...</td>\n",
       "      <td>Ternary and fine-grained sentiment classificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Which natural language(s) are studied in this ...</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>The Propaganda Techniques Corpus (PTC) dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>What metrics are used for evaluation?</td>\n",
       "      <td>The metrics used for evaluation are:\\n\\n* BPE ...</td>\n",
       "      <td>Byte-Pair Encoding perplexity  (BPE PPL),\\nBLE...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Metrics on generated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>What natural language(s) are the recipes writt...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>English English</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Sample data flow thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Which multiple datasets did they train on duri...</td>\n",
       "      <td>BF, BA, SFU, and Sherlock</td>\n",
       "      <td>BioScope Abstracts, SFU, and BioScope Full Pa...</td>\n",
       "      <td>We use a default train-validation-test split o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>what is the size of the real-world civil case ...</td>\n",
       "      <td>The size of the real-world civil case dataset ...</td>\n",
       "      <td>100 000 documents</td>\n",
       "      <td>For experiments, we train and evaluate our mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>What rouge score do they achieve?</td>\n",
       "      <td>Their Rouge scores on the CNN/DailyMail test s...</td>\n",
       "      <td>Best results on unigram:\\nCNN/Daily Mail: Rogu...</td>\n",
       "      <td>We evaluated summarization quality automatical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>What was their performance on emotion detection?</td>\n",
       "      <td>The model achieved an accuracy of 85.6% on the...</td>\n",
       "      <td>Answer with content missing: (Table 3) Best au...</td>\n",
       "      <td>In Table TABREF26 we report the results of our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>What is the benchmark dataset and is its quali...</td>\n",
       "      <td>The benchmark dataset is the Social Honeypot d...</td>\n",
       "      <td>Social Honeypot dataset (public) and Weibo dat...</td>\n",
       "      <td>We use one public dataset Social Honeypot data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>How do they detect spammers?</td>\n",
       "      <td>They detect spammers using a combination of Lo...</td>\n",
       "      <td>Extract features from the LDA model and use th...</td>\n",
       "      <td>Using the LDA model, each person in the datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>What are the baselines?</td>\n",
       "      <td>The baselines used in this study are:\\n\\n1. Ex...</td>\n",
       "      <td>Answer with content missing: (Experimental Se...</td>\n",
       "      <td>Experimental Setup In this section we present ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>What datasets do they use?</td>\n",
       "      <td>They use three datasets: imdb400, yelp50, and ...</td>\n",
       "      <td>1 IMDB dataset and 2 Yelp datasets</td>\n",
       "      <td>We construct three datasets based on IMDB revi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>What domains are covered in the corpus?</td>\n",
       "      <td>The corpus covers a wide range of domains, inc...</td>\n",
       "      <td>No specific domain is covered in the corpus.</td>\n",
       "      <td>Common Voice BIBREF10 is a crowdsourcing speec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>By how much does their best model outperform t...</td>\n",
       "      <td>Their best model outperforms the state-of-the-...</td>\n",
       "      <td>0.8% F1 better than the best state-of-the-art ...</td>\n",
       "      <td>Table TABREF16 shows the results of our models...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>How does their simple voting scheme work?</td>\n",
       "      <td>The simple voting scheme works by applying mul...</td>\n",
       "      <td>Among all the classes predicted by several mo...</td>\n",
       "      <td>Finally, we combine our CNN and RNN models usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>How do they obtain the new context represetation?</td>\n",
       "      <td>They propose a new context representation call...</td>\n",
       "      <td>They use two independent convolutional and max...</td>\n",
       "      <td>(1) We propose extended middle context, a new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>What is the performance of the baseline?</td>\n",
       "      <td>82.6%</td>\n",
       "      <td>M-Bert had 76.6 F1 macro score. 75.1% and 75.6...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Performance of BERT-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>What was the performance of multilingual BERT?</td>\n",
       "      <td>Multilingual BERT achieved a performance of 85...</td>\n",
       "      <td>BERT had 76.6 F1 macro score on x-stance dataset.</td>\n",
       "      <td>To put the supervised score into context we li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>What is an unordered text document, do these a...</td>\n",
       "      <td>An unordered text document is a document that ...</td>\n",
       "      <td>A unordered text document is one where sentenc...</td>\n",
       "      <td>To structure an unordered document is an essen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Who were the experts used for annotation?</td>\n",
       "      <td>Seven experts with legal training were used fo...</td>\n",
       "      <td>Individuals with legal training</td>\n",
       "      <td>To identify legally sound answers, we recruit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Is this hashtag prediction task an established...</td>\n",
       "      <td>Established</td>\n",
       "      <td>established task</td>\n",
       "      <td>Hashtag prediction for social media has been a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>What other tasks do they test their method on?</td>\n",
       "      <td>They also test their method on task of predict...</td>\n",
       "      <td>None</td>\n",
       "      <td>We test the character and word-level variants ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>What is the state of the art system mentioned?</td>\n",
       "      <td>Our system</td>\n",
       "      <td>Two knowledge-based systems,\\ntwo traditional ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: F1-score (%) for fine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Do they use large or small BERT?</td>\n",
       "      <td>Small BERT (BERT$_\\text{BASE}$)</td>\n",
       "      <td>small BERT small BERT</td>\n",
       "      <td>We use the pre-trained uncased BERT$_\\mathrm {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>What is their system's absolute accuracy?</td>\n",
       "      <td>The absolute accuracy of their system is not p...</td>\n",
       "      <td>59.4% on wikipedia dataset, 93.4% on peer-revi...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Experimental results....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Which is more useful, visual or textual features?</td>\n",
       "      <td>Both visual and textual features are useful fo...</td>\n",
       "      <td>It depends on the dataset. Experimental result...</td>\n",
       "      <td>We proposed to use visual renderings of docume...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Which languages do they use?</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>The Wikipedia dataset consists of articles fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>How large is their data set?</td>\n",
       "      <td>Their dataset consists of 29,794 articles</td>\n",
       "      <td>a sample of  29,794 wikipedia articles and 2,7...</td>\n",
       "      <td>We randomly sampled 5,000 articles from each q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>what linguistics features are used?</td>\n",
       "      <td>Segmentation, POS tagging, stem templates, aff...</td>\n",
       "      <td>POS, gender/number and stem POS</td>\n",
       "      <td>Table TABREF17 lists the features that we used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>what dataset statistics are provided?</td>\n",
       "      <td>* 87% of questions had a clear category label\\...</td>\n",
       "      <td>More than 2,100 texts were paired with 15 ques...</td>\n",
       "      <td>More than 2,100 texts were paired with 15 ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>how was the data collected?</td>\n",
       "      <td>via crowdsourcing on Amazon Mechanical Turk (M...</td>\n",
       "      <td>The data was collected using 3 components: des...</td>\n",
       "      <td>Machine comprehension datasets consist of thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>What is best performing model among author's s...</td>\n",
       "      <td>The author's best-performing model on the Test...</td>\n",
       "      <td>For SLC task, the \"ltuorp\" team  has the best ...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Comparison of our sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>What extracted features were most influencial ...</td>\n",
       "      <td>The pre-trained embeddings (FastText or BERT) ...</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Did ensemble schemes help in boosting peforman...</td>\n",
       "      <td>Yes, ensemble schemes helped in boosting perfo...</td>\n",
       "      <td>The best ensemble topped the best single model...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Which basic neural architecture perform best b...</td>\n",
       "      <td>Sure! Here's my answer based on the given cont...</td>\n",
       "      <td>BERT</td>\n",
       "      <td>FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>What participating systems had better results ...</td>\n",
       "      <td>Only one system (System 4) had better results ...</td>\n",
       "      <td>For SLC task : Ituorp, ProperGander and YMJA  ...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Comparison of our sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>What is specific to multi-granularity and mult...</td>\n",
       "      <td>Multi-granularity and multi-tasking neural arc...</td>\n",
       "      <td>An output layer for each task Multi-tasking is...</td>\n",
       "      <td>Shared Task: This work addresses the two tasks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>How much training data from the non-English la...</td>\n",
       "      <td>A small amount of training data from the non-E...</td>\n",
       "      <td>No data. Pretrained model is used.</td>\n",
       "      <td>Do multilingual models always need to be train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>How is the model transferred to other languages?</td>\n",
       "      <td>The model is transferred to other languages by...</td>\n",
       "      <td>Build a bilingual language model,   learn the ...</td>\n",
       "      <td>Do multilingual models always need to be train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>How was the StackExchange dataset collected?</td>\n",
       "      <td>The StackExchange dataset was collected by usi...</td>\n",
       "      <td>they obtained computer science related topics ...</td>\n",
       "      <td>Inspired by the StackLite tag recommendation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>What is the size of the StackExchange dataset?</td>\n",
       "      <td>10,000</td>\n",
       "      <td>around 332k questions</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistics of dataset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>What were the baselines?</td>\n",
       "      <td>The baselines were four non-neural extractive ...</td>\n",
       "      <td>CopyRNN (Meng et al., 2017), Multi-Task (Ye an...</td>\n",
       "      <td>We report our model's performance on the prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>What labels for antisocial events are availabl...</td>\n",
       "      <td>Personal attacks and rule violations</td>\n",
       "      <td>The Conversations Gone Awry dataset is labelle...</td>\n",
       "      <td>We consider two datasets, representing related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>What are two datasets model is applied to?</td>\n",
       "      <td>The two datasets the model is applied to are t...</td>\n",
       "      <td>An expanded version of the existing 'Conversa...</td>\n",
       "      <td>To test the effectiveness of this new architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>What is the McGurk effect?</td>\n",
       "      <td>The McGurk effect is a phenomenon where the pe...</td>\n",
       "      <td>a perceptual illusion, where listening to a sp...</td>\n",
       "      <td>For the McGurk effect, we attempt an illusion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>what phenomena do they mention is hard to capt...</td>\n",
       "      <td>VP ellipsis</td>\n",
       "      <td>Four discourse phenomena - deixis, lexical coh...</td>\n",
       "      <td>We analyze which discourse phenomena are hard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>by how much did the BLEU score improve?</td>\n",
       "      <td>0.7 BLEU</td>\n",
       "      <td>On average 0.64</td>\n",
       "      <td>The BLEU scores are provided in Table TABREF24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>What is NER?</td>\n",
       "      <td>Named Entity Recognition (NER) in the Biomedic...</td>\n",
       "      <td>Named Entity Recognition, including entities ...</td>\n",
       "      <td>Named Entity Recognition (NER) in the Biomedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>How better does new approach behave than exist...</td>\n",
       "      <td>New approach performs significantly better tha...</td>\n",
       "      <td>On Coin Collector, proposed model finds short...</td>\n",
       "      <td>Results ::: CoinCollector In this setting, we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>How much is classification performance improve...</td>\n",
       "      <td>In experiments for low data regime and class-i...</td>\n",
       "      <td>Low data: SST-5, TREC, IMDB around 1-2 accurac...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracy of Data Mani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>What subtasks did they participate in?</td>\n",
       "      <td>EI-Reg, EI-Oc, V-Reg, and V-Oc</td>\n",
       "      <td>Answer with content missing: (Subscript 1: \"We...</td>\n",
       "      <td>Our submissions ranked second (EI-Reg), second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>They used the Affect in Tweets Distant Supervi...</td>\n",
       "      <td>Selection of tweets with for each tweet a lab...</td>\n",
       "      <td>For each task, the training data that was made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>What are the 12 languages covered?</td>\n",
       "      <td>12 languages covered in Multi-SimLex:\\n\\n1. Ch...</td>\n",
       "      <td>Chinese Mandarin, Welsh, English, Estonian, Fi...</td>\n",
       "      <td>Language Selection. Multi-SimLex comprises ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>What type of evaluation is proposed for this t...</td>\n",
       "      <td>Manual evaluation</td>\n",
       "      <td>Answer with content missing: (Evaluation Metri...</td>\n",
       "      <td>Baseline Experiments In this section, we brief...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>What baseline system is proposed?</td>\n",
       "      <td>The proposed baseline system is not specified</td>\n",
       "      <td>Answer with content missing: (Baseline Method ...</td>\n",
       "      <td>Baseline Experiments In this section, we brief...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>How were crowd workers instructed to identify ...</td>\n",
       "      <td>Crowd workers were instructed to identify impo...</td>\n",
       "      <td>They break down the task of importance annota...</td>\n",
       "      <td>We break down the task of importance annotatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>How is pseudo-perplexity defined?</td>\n",
       "      <td>Pseudo-perplexity is defined as the inverse of...</td>\n",
       "      <td>Answer with content missing: (formulas in sele...</td>\n",
       "      <td>The goal of an language model is to assign mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>What is the model architecture used?</td>\n",
       "      <td>A VQA deep learning architecture that combines...</td>\n",
       "      <td>LSTM to encode the question, VGG16 to extract ...</td>\n",
       "      <td>We next adapt a VQA deep learning architecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>How is the data used for training annotated?</td>\n",
       "      <td>The data used for training is annotated with a...</td>\n",
       "      <td>The number of redundant answers to collect fro...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 6: We propose a novel app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>what quantitative analysis is done?</td>\n",
       "      <td>Descriptive statistics and visualizations</td>\n",
       "      <td>Answer with content missing: (Evaluation secti...</td>\n",
       "      <td>Results and Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>by how much did nus outperform abus?</td>\n",
       "      <td>NUS outperformed ABUS by approximately 5.5% (9...</td>\n",
       "      <td>Average success rate is higher by 2.6 percent ...</td>\n",
       "      <td>Table TABREF18 shows the results of the cross-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Which dataset has been used in this work?</td>\n",
       "      <td>Reuters-8 dataset</td>\n",
       "      <td>The Reuters-8 dataset (with stop words removed)</td>\n",
       "      <td>In this section we describe the experiments pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>What can word subspace represent?</td>\n",
       "      <td>The context of a text</td>\n",
       "      <td>Word vectors, usually in the context of others...</td>\n",
       "      <td>To tackle this problem, we introduce the novel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>How big are improvements of small-scale unbala...</td>\n",
       "      <td>Improvements of small-scale unbalanced dataset...</td>\n",
       "      <td>it has 0.024 improvement in accuracy comparin...</td>\n",
       "      <td>The last group contains the results of our pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>How big is dataset for testing?</td>\n",
       "      <td>The testing dataset contains approximately 15 ...</td>\n",
       "      <td>30 terms, each term-sanse pair has around 15 s...</td>\n",
       "      <td>Our testing dataset takes MIMIC-III BIBREF18 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>What are the qualitative experiments performed...</td>\n",
       "      <td>Qualitative experiments were performed on benc...</td>\n",
       "      <td>Spearman correlation values of GM_KL model eva...</td>\n",
       "      <td>Table TABREF18 shows the Spearman correlation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>What were their results on the classification ...</td>\n",
       "      <td>On the classification task, their best model a...</td>\n",
       "      <td>F1 score result of 0.8099</td>\n",
       "      <td>Table TABREF29 gives three results from our su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Which hyperparameters were varied in the exper...</td>\n",
       "      <td>The hyperparameters varied in the experiments ...</td>\n",
       "      <td>number of clusters, seed value in clustering, ...</td>\n",
       "      <td>We cluster the embeddings with INLINEFORM0 -Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>How were the cluster extracted?</td>\n",
       "      <td>K-means++ with INLINEFORM0-Means</td>\n",
       "      <td>Word clusters are extracted using k-means on w...</td>\n",
       "      <td>We cluster the embeddings with INLINEFORM0 -Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>what were the evaluation metrics?</td>\n",
       "      <td>The evaluation metrics used in the study were ...</td>\n",
       "      <td>Unlabeled sentence-level F1, perplexity, gram...</td>\n",
       "      <td>Table TABREF23 shows the unlabeled INLINEFORM0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>what english datasets were used?</td>\n",
       "      <td>The dataset used was the Penn Treebank Corpus</td>\n",
       "      <td>Answer with content missing: (Data section) Pe...</td>\n",
       "      <td>Experimental Setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>which chinese datasets were used?</td>\n",
       "      <td>CUHK03 and CUHK07</td>\n",
       "      <td>Answer with content missing: (Data section) Ch...</td>\n",
       "      <td>Experimental Setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>What were their distribution results?</td>\n",
       "      <td>The distribution results for viral tweets cont...</td>\n",
       "      <td>Distributions of Followers, Friends and URLs a...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: For each one of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>How did they determine fake news tweets?</td>\n",
       "      <td>They used the number of retweets to single out...</td>\n",
       "      <td>an expert annotator determined if the tweet fe...</td>\n",
       "      <td>For our study, we used the number of retweets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>What is their definition of tweets going viral?</td>\n",
       "      <td>According to the context, the definition of tw...</td>\n",
       "      <td>Viral tweets are the ones that are retweeted m...</td>\n",
       "      <td>One straightforward way of sharing information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>What are the characteristics of the accounts t...</td>\n",
       "      <td>Accounts spreading fake news have a higher cha...</td>\n",
       "      <td>Accounts that spread fake news are mostly unve...</td>\n",
       "      <td>We found that 82 users within our sample were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>How is the ground truth for fake news establis...</td>\n",
       "      <td>Manually, with limitations</td>\n",
       "      <td>Ground truth is not established in the paper</td>\n",
       "      <td>The 1327 `viral' tweets were manually annotate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Where does the ancient Chinese dataset come from?</td>\n",
       "      <td>Ancient Chinese history records and articles w...</td>\n",
       "      <td>Ancient Chinese history records in several dy...</td>\n",
       "      <td>Data Collection. To build the large ancient-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>How big is the difference in performance betwe...</td>\n",
       "      <td>The proposed model (ALOHA with HLA-OG during t...</td>\n",
       "      <td>Metric difference between Aloha and best basel...</td>\n",
       "      <td>Table TABREF44 shows average results of our au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>In what 8 languages is PolyResponse engine use...</td>\n",
       "      <td>English, German, Spanish, Mandarin, Polish, Ru...</td>\n",
       "      <td>English, German, Spanish, Mandarin, Polish, Ru...</td>\n",
       "      <td>The PolyResponse restaurant search is currentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>How many question types do they find in the da...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Fig. FIGREF4 shows the distributions of seven ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>How do they analyze contextual similaries acro...</td>\n",
       "      <td>They do not analyze contextual similarities ac...</td>\n",
       "      <td>They compare the tasks that the datasets are s...</td>\n",
       "      <td>All corpora provide datasets/splits for answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>What were their performance results?</td>\n",
       "      <td>* For Wikipedia BIBREF4 and Twitter BIBREF8 da...</td>\n",
       "      <td>best model achieves 0.94 F1 score for Wikipedi...</td>\n",
       "      <td>DNN based models coupled with transfer learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>What datasets are used to assess the performan...</td>\n",
       "      <td>The system's performance is assessed using the...</td>\n",
       "      <td>LORELEI datasets of Uzbek, Mandarin and Turkish</td>\n",
       "      <td>For our single-label topic classification expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>IS the graph representation supervised?</td>\n",
       "      <td>NO</td>\n",
       "      <td>The graph representation appears to be semi-su...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: The framework of G-B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Is the G-BERT model useful beyond the task con...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>There is nothing specific about the approach t...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: The framework of G-B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Do they introduce errors in the data or does t...</td>\n",
       "      <td>The data already contains errors.\\n\\nIn the co...</td>\n",
       "      <td>Data already contain errors</td>\n",
       "      <td>We use three languages in our experiments: Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>What is the difference of the proposed model w...</td>\n",
       "      <td>The proposed model with a Refinement Adjustmen...</td>\n",
       "      <td>Introduce a \"Refinement Adjustment LSTM-based ...</td>\n",
       "      <td>While the RNN-based generators with DA gating-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Does the model evaluated on NLG datasets or di...</td>\n",
       "      <td>NLG datasets</td>\n",
       "      <td>NLG datasets NLG datasets</td>\n",
       "      <td>We assessed the proposed models on four differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>How is the quality of singing voice measured?</td>\n",
       "      <td>The quality of singing voice is measured using...</td>\n",
       "      <td>Automatic: Normalized cross correlation (NCC)...</td>\n",
       "      <td>To compare the conversions between USVC and Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>what previous RNN models do they compare with?</td>\n",
       "      <td>state-of-the-art methods</td>\n",
       "      <td>Variational LSTM, CharCNN, Pointer Sentinel-LS...</td>\n",
       "      <td>Table TABREF23 compares the performance of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>What are the languages they use in their exper...</td>\n",
       "      <td>English, Spanish, and Finnish</td>\n",
       "      <td>English\\nFrench\\nSpanish\\nGerman\\nGreek\\nBulga...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: XNLI dev results (acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>How do they match annotators to instances?</td>\n",
       "      <td>They match annotators to instances based on th...</td>\n",
       "      <td>Annotations from experts are used if they have...</td>\n",
       "      <td>So far a system was trained on one type of dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>How much data is needed to train the task-spec...</td>\n",
       "      <td>57,505 sentences</td>\n",
       "      <td>57,505 sentences 57,505 sentences</td>\n",
       "      <td>Our contributions in this work are summarized ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Who are the crowdworkers?</td>\n",
       "      <td>Crowdworkers are individuals located in the US...</td>\n",
       "      <td>people in the US that use Amazon Mechanical Turk</td>\n",
       "      <td>We used the 1,000-tweet dataset by BIBREF2 tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Which sentiment class is the most accurately p...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>neutral sentiment</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Average Correct Class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>what were the baselines?</td>\n",
       "      <td>The baselines used in the experiment were bag-...</td>\n",
       "      <td>BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN</td>\n",
       "      <td>The experiment results of validation on Friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>What BERT models are used?</td>\n",
       "      <td>BERT-base and BERT-large</td>\n",
       "      <td>BERT-base, BERT-large, BERT-uncased, BERT-cased</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Validation Results (F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>What experiments are used to demonstrate the b...</td>\n",
       "      <td>The experiments used to demonstrate the benefi...</td>\n",
       "      <td>Calculate test log-likelihood on the three co...</td>\n",
       "      <td>In this section, we describe the experimental ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Which component is the least impactful?</td>\n",
       "      <td>The number of message passing iterations (n) h...</td>\n",
       "      <td>Based on table results provided changing direc...</td>\n",
       "      <td>Results and ablations ::: Ablation studies To ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Which component has the greatest impact on per...</td>\n",
       "      <td>The number of message passing iterations</td>\n",
       "      <td>Increasing number of message passing iteration...</td>\n",
       "      <td>Results and ablations ::: Ablation studies To ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>What is the message passing framework?</td>\n",
       "      <td>The message passing framework is a method for ...</td>\n",
       "      <td>It is a framework used to describe algorithms ...</td>\n",
       "      <td>The MP framework is based on the core idea of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>What is the best reported system?</td>\n",
       "      <td>The MILR classifier</td>\n",
       "      <td>Gaze Sarcasm using Multi Instance Logistic Reg...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Classification result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>What cognitive features are used?</td>\n",
       "      <td>Memory, Attention, Perception, and Processing ...</td>\n",
       "      <td>Readability (RED),  Number of Words (LEN), Avg...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: The complete set of f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>What approaches do they use towards text analy...</td>\n",
       "      <td>They use a combination of quantitative and qua...</td>\n",
       "      <td>Modeling considerations:  the variables (both...</td>\n",
       "      <td>This contrasts with much of the work in comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>What is the seed lexicon?</td>\n",
       "      <td>The seed lexicon is a set of positive and nega...</td>\n",
       "      <td>a vocabulary of positive and negative predicat...</td>\n",
       "      <td>The seed lexicon consists of positive and nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>What are the results?</td>\n",
       "      <td>The results show that BERT trained only with t...</td>\n",
       "      <td>Using all data to train: AL -- BiGRU achieved ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>How are relations used to propagate polarity?</td>\n",
       "      <td>Relations are used to propagate polarity throu...</td>\n",
       "      <td>based on the relation between events, the sugg...</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>How big is the Japanese data?</td>\n",
       "      <td>The Japanese data consists of approximately 10...</td>\n",
       "      <td>7000000 pairs of events were extracted from th...</td>\n",
       "      <td>As a raw corpus, we used a Japanese web corpus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>How big are improvements of supervszed learnin...</td>\n",
       "      <td>Improvements of supervised learning results tr...</td>\n",
       "      <td>3%</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Results for small lab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>How does their model learn using mostly raw data?</td>\n",
       "      <td>By exploiting discourse relations to efficient...</td>\n",
       "      <td>by exploiting discourse relations to propagate...</td>\n",
       "      <td>In this paper, we propose a simple and effecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>How big is seed lexicon used for training?</td>\n",
       "      <td>15 positive words and 15 negative words</td>\n",
       "      <td>30 words</td>\n",
       "      <td>We constructed our seed lexicon consisting of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>How do the various social phenomena examined m...</td>\n",
       "      <td>Dynamic and distinctive communities have highe...</td>\n",
       "      <td>Dynamic communities have substantially higher ...</td>\n",
       "      <td>We find that dynamic communities, such as Seah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>How did the select the 300 Reddit communities ...</td>\n",
       "      <td>The 300 Reddit communities were selected based...</td>\n",
       "      <td>They selected all the subreddits from January ...</td>\n",
       "      <td>Our full dataset consists of all subreddits on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>How is the clinical text structuring task defi...</td>\n",
       "      <td>The clinical text structuring task is defined ...</td>\n",
       "      <td>CTS is extracting structural data from medica...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 1. An illustrative exampl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Is all text in this dataset a question, or are...</td>\n",
       "      <td>No, not all text in this dataset is a question...</td>\n",
       "      <td>the dataset consists of pathology reports incl...</td>\n",
       "      <td>Our dataset is annotated based on Chinese path...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>How many questions are in the dataset?</td>\n",
       "      <td>2,714</td>\n",
       "      <td>2,714</td>\n",
       "      <td>Our dataset is annotated based on Chinese path...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>What aspects have been compared between variou...</td>\n",
       "      <td>Perplexity, recall, latency, and energy usage</td>\n",
       "      <td>Quality measures using perplexity and recall, ...</td>\n",
       "      <td>For each model, we examined word-level perplex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>How many attention layers are there in their m...</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>The baseline model is a deep sequence-to-seque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>What are the three measures of bias which are ...</td>\n",
       "      <td>RIPA, WEAT, and Neighborhood bias</td>\n",
       "      <td>RIPA, Neighborhood Metric, WEAT</td>\n",
       "      <td>Geometric bias mitigation uses the cosine dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>How big is the dataset?</td>\n",
       "      <td>The dataset consists of 471,319 references fro...</td>\n",
       "      <td>903019 references</td>\n",
       "      <td>Overall, through the process described in Sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>How is the intensity of the PTSD established?</td>\n",
       "      <td>The intensity of PTSD is established based on ...</td>\n",
       "      <td>Given we have four intensity, No PTSD, Low Ris...</td>\n",
       "      <td>To provide an initial results, we take 50% of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>how is quality measured?</td>\n",
       "      <td>Accuracy and macro-F1 score</td>\n",
       "      <td>Accuracy and the macro-F1 (averaged F1 over po...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison of manuall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>What is the accuracy reported by state-of-the-...</td>\n",
       "      <td>The accuracy reported by state-of-the-art meth...</td>\n",
       "      <td>Answer with content missing: (Table 1)\\nPrevio...</td>\n",
       "      <td>In Table TABREF1, we summarize the quantitativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>How do the authors define or exemplify 'incorr...</td>\n",
       "      <td>Incorrect words are defined as missing or misp...</td>\n",
       "      <td>typos in spellings or ungrammatical words</td>\n",
       "      <td>Understanding a user's intent and sentiment is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>By how much do they outperform other models in...</td>\n",
       "      <td>By 6% to 8% in sentiment classification and by...</td>\n",
       "      <td>In the sentiment classification task by 6% to ...</td>\n",
       "      <td>Experimental results for the Twitter Sentiment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Which experiments are perfomed?</td>\n",
       "      <td>The experiments performed are on the WNC datas...</td>\n",
       "      <td>They used BERT-based models to detect subjecti...</td>\n",
       "      <td>In natural language, subjectivity refers to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Is ROUGE their only baseline?</td>\n",
       "      <td>No</td>\n",
       "      <td>No, other baseline metrics they use besides R...</td>\n",
       "      <td>Our first baseline is ROUGE-L BIBREF1 , since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>By how much does their system outperform the l...</td>\n",
       "      <td>The proposed model outperforms the lexicon-bas...</td>\n",
       "      <td>Under the retrieval evaluation setting, their ...</td>\n",
       "      <td>NVDM (Lexical, Neural) is a VAE-based approach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>How are the main international development top...</td>\n",
       "      <td>Based on the analysis of exclusive and semanti...</td>\n",
       "      <td>They focus on exclusivity and semantic cohere...</td>\n",
       "      <td>We assess the optimal number of topics that ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Is the semantic hierarchy representation used ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, Open IE</td>\n",
       "      <td>An extrinsic evaluation was carried out on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Is the model evaluated?</td>\n",
       "      <td>Yes, the model has been evaluated</td>\n",
       "      <td>the English version is evaluated. The German v...</td>\n",
       "      <td>For the English version, we performed both a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>How better is accuracy of new model compared t...</td>\n",
       "      <td>The accuracy of the new PRN model is significa...</td>\n",
       "      <td>Average accuracy of proposed model vs best pre...</td>\n",
       "      <td>Table TABREF29 presents the quantitative resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>How does the active learning model work?</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>Active learning methods has a learning engine ...</td>\n",
       "      <td>Active learning methods can generally be descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Did the annotators agreed and how much?</td>\n",
       "      <td>The annotators agreed moderately to substantia...</td>\n",
       "      <td>For event types and participant types, there w...</td>\n",
       "      <td>FLOAT SELECTED: Figure 4: Inter-annotator agre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>What datasets are used to evaluate this approach?</td>\n",
       "      <td>WN18 and YAGO3-10</td>\n",
       "      <td>Kinship and Nations knowledge graphs, YAGO3-1...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Data Statistics of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>How was the dataset collected?</td>\n",
       "      <td>The dataset was collected through a combinatio...</td>\n",
       "      <td>They crawled travel information from the Web ...</td>\n",
       "      <td>Database Construction: we crawled travel infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>What models other than standalone BERT is new ...</td>\n",
       "      <td>BERT$_\\text{base}$ and Attentive Mimicking</td>\n",
       "      <td>Only Bert base and Bert large are compared to ...</td>\n",
       "      <td>Results on WNLaMPro rare and medium are shown ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>How big is the performance difference between ...</td>\n",
       "      <td>The performance difference between this method...</td>\n",
       "      <td>Comparing with the highest performing baseline...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Compare our model wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>What approaches without reinforcement learning...</td>\n",
       "      <td>Neural Network Regressor (NNR) and Neural Netw...</td>\n",
       "      <td>classification, regression, neural methods</td>\n",
       "      <td>We conducted cross-validation experiments usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Which languages do they validate on?</td>\n",
       "      <td>All 31 languages with both UD and UniMorph data</td>\n",
       "      <td>Ar, Bg, Ca, Cs, Da, De, En, Es, Eu, Fa, Fi, Fr...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Token-level recall wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>What is the baseline method for the task?</td>\n",
       "      <td>The baseline method for the task is a neural n...</td>\n",
       "      <td>For the emotion recognition from text they use...</td>\n",
       "      <td>For the emotion recognition from text, we manu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>what amounts of size were used on german-english?</td>\n",
       "      <td>For German-English, the training corpus size u...</td>\n",
       "      <td>Training data with 159000, 80000, 40000, 20000...</td>\n",
       "      <td>We use the TED data from the IWSLT 2014 German...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>How big is the dataset?</td>\n",
       "      <td>7934 messages</td>\n",
       "      <td>Resulting dataset was 7934 messages for train...</td>\n",
       "      <td>Dataset: Based on some earlier work, only avai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>What MC abbreviate for?</td>\n",
       "      <td>MC abbreviates for Machine Comprehension</td>\n",
       "      <td>machine comprehension</td>\n",
       "      <td>Enabling computers to understand given documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>What are their correlation results?</td>\n",
       "      <td>The correlation results for Q1-Q5 on DUC-05, D...</td>\n",
       "      <td>High correlation results range from 0.472 to 0...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Spearman’s ρ, Kendall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>What simpler models do they look at?</td>\n",
       "      <td>They look at simpler models such as ROUGE, Lan...</td>\n",
       "      <td>BiGRUs with attention, ROUGE, Language model,...</td>\n",
       "      <td>Methods ::: Baselines ::: BiGRU s with attenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>What linguistic quality aspects are addressed?</td>\n",
       "      <td>FIVE LINGUISTIC QUALITY ASPECTS</td>\n",
       "      <td>Grammaticality, non-redundancy, referential cl...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: SUM-QE rates summari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>What dataset do they use?</td>\n",
       "      <td>Text-code parallel corpus similar to Fig. FIGR...</td>\n",
       "      <td>A parallel corpus where the source is an Engli...</td>\n",
       "      <td>SMT techniques require a parallel corpus in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>What is typical GAN architecture for each text...</td>\n",
       "      <td>* Semantic Enhancement GANs: Use of attention ...</td>\n",
       "      <td>Semantic Enhancement GANs: DC-GANs, MC-GAN\\nRe...</td>\n",
       "      <td>In this section, we propose a taxonomy to summ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>What language do the agents talk in?</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>English</td>\n",
       "      <td>Tourist: I can't go straight any further. Guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>How much better is performance of proposed met...</td>\n",
       "      <td>The proposed method outperforms state-of-the-a...</td>\n",
       "      <td>Accuracy of best proposed method KANE (LSTM+Co...</td>\n",
       "      <td>Experimental results of entity classification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>What baseline model is used?</td>\n",
       "      <td>HUMAN EVALUATORS</td>\n",
       "      <td>Human evaluators</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Performance of human ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>What stylistic features are used to detect dru...</td>\n",
       "      <td>Sentiment analysis, slur detection, and langua...</td>\n",
       "      <td>LDA unigrams (Presence/Count), POS Ratio, #Nam...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Our Feature Set for D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>What is the accuracy of the proposed technique?</td>\n",
       "      <td>90.1%</td>\n",
       "      <td>51.7 and 51.6 on 4th and 8th grade question se...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: TUPLEINF is significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Which retrieval system was used for baselines?</td>\n",
       "      <td>The baseline retrieval system used for these e...</td>\n",
       "      <td>The dataset comes with a ranked set of relevan...</td>\n",
       "      <td>Each dataset consists of a collection of recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>How much better was the BLSTM-CNN-CRF than the...</td>\n",
       "      <td>The BLSTM-CNN-CRF outperformed the BLSTM-CRF b...</td>\n",
       "      <td>Best BLSTM-CNN-CRF had F1 score 86.87 vs 86.69...</td>\n",
       "      <td>Table 2 shows our experiments on two models wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>What supplemental tasks are used for multitask...</td>\n",
       "      <td>Task C, which involves predicting the relation...</td>\n",
       "      <td>Multitask learning is used for the task of pre...</td>\n",
       "      <td>Automation of cQA forums can be divided into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>How much performance gap between their approac...</td>\n",
       "      <td>10.5% performance gap</td>\n",
       "      <td>0.007 MAP on Task A, 0.032 MAP on Task B, 0.05...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Compared with other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>How big is their model?</td>\n",
       "      <td>The proposed AEN-GloVe model has a relatively ...</td>\n",
       "      <td>Proposed model has 1.16 million parameters and...</td>\n",
       "      <td>To figure out whether the proposed AEN-GloVe i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>How many emotions do they look at?</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>The final annotation categories for the datase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>What approach did previous models use for mult...</td>\n",
       "      <td>Previous models used a single-span head method...</td>\n",
       "      <td>Only MTMSM specifically tried to tackle the mu...</td>\n",
       "      <td>MTMSN BIBREF4 is the first, and only model so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>What is difference in peformance between propo...</td>\n",
       "      <td>The proposed model outperforms the state-of-th...</td>\n",
       "      <td>For single-span questions, the proposed LARGE-...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Performance of differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>What is the performance of proposed model on e...</td>\n",
       "      <td>Our proposed model outperformed all other mode...</td>\n",
       "      <td>The proposed model achieves  EM 77,63 and F1 8...</td>\n",
       "      <td>Table TABREF25 shows the results on DROP's tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>How accurate is the aspect based sentiment cla...</td>\n",
       "      <td>65.13% ± 2.52%</td>\n",
       "      <td>BiLSTM-XR-Dev Estimation accuracy is 83.31 for...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Average accuracies an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>What were the non-neural baselines used for th...</td>\n",
       "      <td>Pre-extracted edit trees</td>\n",
       "      <td>The Lemming model in BIBREF17</td>\n",
       "      <td>BIBREF17: The Lemming model is a log-linear mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>What are the models evaluated on?</td>\n",
       "      <td>The models are evaluated on both question answ...</td>\n",
       "      <td>They evaluate F1 score and agent's test perfor...</td>\n",
       "      <td>We build the iSQuAD and iNewsQA datasets based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>What is the results of multimodal compared to ...</td>\n",
       "      <td>The multimodal models (TABREF31) outperform th...</td>\n",
       "      <td>Unimodal LSTM vs Best Multimodal (FCM)\\n- F sc...</td>\n",
       "      <td>Table TABREF31 shows the F-score, the Area Und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>What were their performance results?</td>\n",
       "      <td>The performance results of the proposed method...</td>\n",
       "      <td>On SearchSnippets dataset ACC 77.01%, NMI 62.9...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Comparison of ACC of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>By how much did they outperform the other meth...</td>\n",
       "      <td>By an average of 10% to 20% in terms of ACC an...</td>\n",
       "      <td>on SearchSnippets dataset by 6.72% in ACC, by ...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Comparison of ACC of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>What is the state of the art?</td>\n",
       "      <td>XLM (MLM+TLM) is the current state of the art ...</td>\n",
       "      <td>POS and DP task: CONLL 2018\\nNER task: (no ext...</td>\n",
       "      <td>We will compare to the more recent cross-lingu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>What difficulties does sentiment analysis on T...</td>\n",
       "      <td>Twitter sentiment analysis faces challenges du...</td>\n",
       "      <td>Tweets noisy nature, use of creative spelling ...</td>\n",
       "      <td>Pre-processing. Tweets are subject to standard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>How many sentence transformations on average a...</td>\n",
       "      <td>4.262\\n\\nThis is calculated by dividing the to...</td>\n",
       "      <td>27.41 transformation on average of single seed...</td>\n",
       "      <td>In the second round, we collected 293 annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>What annotations are available in the dataset?</td>\n",
       "      <td>* Two distinct paraphrases of each sentence\\n*...</td>\n",
       "      <td>For each source sentence, transformation sente...</td>\n",
       "      <td>We asked for two distinct paraphrases of each ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>How are possible sentence transformations repr...</td>\n",
       "      <td>The possible sentence transformations are repr...</td>\n",
       "      <td>Yes, as new sentences.</td>\n",
       "      <td>In the second round, we collected 293 annotati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>What are all 15 types of modifications ilustra...</td>\n",
       "      <td>The 15 types of modifications illustrated in t...</td>\n",
       "      <td>- paraphrase 1\\n- paraphrase 2\\n- different me...</td>\n",
       "      <td>We selected 15 modifications types to collect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>What were their results on the three datasets?</td>\n",
       "      <td>The authors achieved an accuracy of 90.2% on t...</td>\n",
       "      <td>accuracy of 86.63 on STS, 85.14 on Sanders and...</td>\n",
       "      <td>FLOAT SELECTED: Table IV ACCURACY OF DIFFERENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>What semantic rules are proposed?</td>\n",
       "      <td>The proposed semantic rules are displayed in T...</td>\n",
       "      <td>rules that compute polarity of words after POS...</td>\n",
       "      <td>In Twitter social networking, people express t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>What is the performance of the model?</td>\n",
       "      <td>The model achieves a test accuracy of around 0...</td>\n",
       "      <td>Experiment 1: ACC around 0.5 with 50% noise ra...</td>\n",
       "      <td>The test accuracy curves with the noise rates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>What was the performance of both approaches on...</td>\n",
       "      <td>Both approaches achieved similar performance o...</td>\n",
       "      <td>ERR of 19.05 with i-vectors and 15.52 with x-v...</td>\n",
       "      <td>FLOAT SELECTED: Table 4. EER(%) results of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>What genres are covered?</td>\n",
       "      <td>ALL GENRES</td>\n",
       "      <td>genre, entertainment, interview, singing, play...</td>\n",
       "      <td>FLOAT SELECTED: Table 1. The distribution over...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Which of the two speech recognition models wor...</td>\n",
       "      <td>The x-vector system works better overall on CN...</td>\n",
       "      <td>x-vector</td>\n",
       "      <td>FLOAT SELECTED: Table 4. EER(%) results of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>By how much is performance on CN-Celeb inferio...</td>\n",
       "      <td>12.3%\\n\\nBased on the EER(%) results provided ...</td>\n",
       "      <td>For i-vector system, performances are 11.75% i...</td>\n",
       "      <td>FLOAT SELECTED: Table 4. EER(%) results of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>How do the authors measure performance?</td>\n",
       "      <td>The authors measure performance using accuracy</td>\n",
       "      <td>Accuracy across six datasets</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Accuracies of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>What is the latest paper covered by this survey?</td>\n",
       "      <td>\"NQG-BERT: A BERT-based Neural Question Genera...</td>\n",
       "      <td>Kim et al. (2019)</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Existing NQG models w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>What learning paradigms do they cover in this ...</td>\n",
       "      <td>Both traditional and neural learning paradigms...</td>\n",
       "      <td>Considering \"What\" and \"How\" separately versus...</td>\n",
       "      <td>Past research took a reductionist approach, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>What are all the input modalities considered i...</td>\n",
       "      <td>textual inputs (declarative sentences), knowle...</td>\n",
       "      <td>Textual inputs, knowledge bases, and images.</td>\n",
       "      <td>Question generation is an NLG task for which t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>How do this framework facilitate demographic i...</td>\n",
       "      <td>This framework facilitates demographic inferen...</td>\n",
       "      <td>Demographic information is predicted using wei...</td>\n",
       "      <td>We employ BIBREF73 's weighted lexicon of term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>How is the data annotated?</td>\n",
       "      <td>The data is annotated with depression symptoms...</td>\n",
       "      <td>The data are self-reported by Twitter users an...</td>\n",
       "      <td>Self-disclosure clues have been extensively ut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Where does the information on individual-level...</td>\n",
       "      <td>The information on individual-level demographi...</td>\n",
       "      <td>From Twitter profile descriptions of the users.</td>\n",
       "      <td>Age Enabled Ground-truth Dataset: We extract u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>What is the source of the user interaction data?</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Sociability from ego-network on Twitter</td>\n",
       "      <td>The recent advancements in deep neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>What is the source of the textual data?</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Users' tweets</td>\n",
       "      <td>The recent advancements in deep neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>What is the source of the visual data?</td>\n",
       "      <td>The visual data is from posted images</td>\n",
       "      <td>Profile pictures from the Twitter users' profi...</td>\n",
       "      <td>The recent advancements in deep neural network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>What result from experiments suggest that natu...</td>\n",
       "      <td>The NLP representation outperforms other metho...</td>\n",
       "      <td>Average reward across 5 seeds show that NLP re...</td>\n",
       "      <td>Results of the DQN-based agent are presented i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Which datasets are used in the paper?</td>\n",
       "      <td>* BIBREF27: Moral Foundations Dictionary\\n* BI...</td>\n",
       "      <td>Google N-grams\\nCOHA\\nMoral Foundations Dictio...</td>\n",
       "      <td>To ground moral sentiment in text, we leverage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>How do they quantify moral relevance?</td>\n",
       "      <td>They quantify moral relevance based on the not...</td>\n",
       "      <td>By complementing morally relevant seed words w...</td>\n",
       "      <td>To implement the first tier of our framework a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>How much is proposed model better in perplexit...</td>\n",
       "      <td>The proposed model is significantly better in ...</td>\n",
       "      <td>Perplexity of the best model is 65.58 compared...</td>\n",
       "      <td>As illustrated in Table TABREF12 (ID 1). Given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Do they train a different training method exce...</td>\n",
       "      <td>No, they do not train a different training met...</td>\n",
       "      <td>Answer with content missing: (list missing) \\n...</td>\n",
       "      <td>Since the official test set has not been relea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>How do they define upward and downward reasoning?</td>\n",
       "      <td>Upward reasoning is defined as the ability to ...</td>\n",
       "      <td>Upward reasoning is defined as going from one ...</td>\n",
       "      <td>A context is upward entailing (shown by [... $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Do they annotate their own dataset or use an e...</td>\n",
       "      <td>They use an existing dataset</td>\n",
       "      <td>Use an existing one</td>\n",
       "      <td>For our experiments, we select a dataset whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>What kind of neural network architecture do th...</td>\n",
       "      <td>A Siamese Neural Network Architecture with two...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>We adopt the approach in BIBREF4 , modifying i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>What web and user-generated NER datasets are u...</td>\n",
       "      <td>Web and user-generated NER datasets used for t...</td>\n",
       "      <td>MUC, CoNLL, ACE, OntoNotes, MSM, Ritter, UMBC</td>\n",
       "      <td>Since the goal of this study is to compare NER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>Which unlabeled data do they pretrain with?</td>\n",
       "      <td>WSJ and full Librispeech, as well as a combina...</td>\n",
       "      <td>1000 hours of WSJ audio data</td>\n",
       "      <td>We consider pre-training on the audio data (wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>How many convolutional layers does their model...</td>\n",
       "      <td>Sure! Based on the context you provided, the a...</td>\n",
       "      <td>wav2vec has 12 convolutional layers</td>\n",
       "      <td>Given raw audio samples INLINEFORM0 , we apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>How big are the datasets?</td>\n",
       "      <td>The in-house dataset has 15,250 documents, whi...</td>\n",
       "      <td>In-house dataset consists of  3716 documents \\...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Number of documents i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>What baselines did they compare their model with?</td>\n",
       "      <td>BIBREF20, BIBREF23, and BIBREF6</td>\n",
       "      <td>the baseline where path generation uses a stan...</td>\n",
       "      <td>The baseline approach is based on BIBREF20 . I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>What was the performance of their model?</td>\n",
       "      <td>Their model achieved an EM score of 85.6% and ...</td>\n",
       "      <td>For test-repeated set, EM score of 61.17, F1 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Performance of differ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>What evaluation metrics are used?</td>\n",
       "      <td>EM, Recall, Precision, and GM</td>\n",
       "      <td>exact match, f1 score, edit distance and goal ...</td>\n",
       "      <td>We compare the performance of translation appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>How were the navigation instructions collected?</td>\n",
       "      <td>The navigation instructions were collected thr...</td>\n",
       "      <td>using Amazon Mechanical Turk using simulated e...</td>\n",
       "      <td>This work also contributes a new dataset of IN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>What language is the experiment done in?</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>english language</td>\n",
       "      <td>While the dataset was collected with simulated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>What additional features are proposed for futu...</td>\n",
       "      <td>* Clinical sentiment analysis scores\\n* Distin...</td>\n",
       "      <td>distinguishing between clinically positive and...</td>\n",
       "      <td>Our current feature set for training a machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>What are their initial results on this task?</td>\n",
       "      <td>The initial results on this task show that the...</td>\n",
       "      <td>Achieved the highest per-domain scores on Subs...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Overall and domain-sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>How is morphology knowledge implemented in the...</td>\n",
       "      <td>By using a morphologically motivated segmentat...</td>\n",
       "      <td>A BPE model is applied to the stem after morph...</td>\n",
       "      <td>The problem with morpheme segmentation is that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>How is the performance on the task evaluated?</td>\n",
       "      <td>The performance on the task is evaluated based...</td>\n",
       "      <td>Comparison of test accuracies of neural networ...</td>\n",
       "      <td>Neural network models, and specifically sequen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>what datasets were used?</td>\n",
       "      <td>IWSLT14 German-English, Turkish-English, and W...</td>\n",
       "      <td>IWSLT14 German-English, IWSLT14 Turkish-Englis...</td>\n",
       "      <td>We use three datasets for our experiments: IWS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>How do they obtain human judgements?</td>\n",
       "      <td>Crowdsourced human judgments</td>\n",
       "      <td>Using crowdsourcing</td>\n",
       "      <td>As the book is too small to train any models, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Does this approach perform better in the multi...</td>\n",
       "      <td>The approach performs better in the single-dom...</td>\n",
       "      <td>single-domain setting</td>\n",
       "      <td>FLOAT SELECTED: Table 3: The joint goal accura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>How many samples did they generate for the art...</td>\n",
       "      <td>30,000</td>\n",
       "      <td>70,000</td>\n",
       "      <td>In a new experiment, we train the models on pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Why does not the approach from English work on...</td>\n",
       "      <td>Because other languages, like Spanish, have gr...</td>\n",
       "      <td>Because, unlike other languages, English does ...</td>\n",
       "      <td>To date, the NLP community has focused primari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>How do they measure grammaticality?</td>\n",
       "      <td>They measure grammaticality using the log rati...</td>\n",
       "      <td>by calculating log ratio of grammatical phrase...</td>\n",
       "      <td>Because our approach is specifically intended ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>What is the difference in recall score between...</td>\n",
       "      <td>The system using Wikipedia titles as reference...</td>\n",
       "      <td>Between the model and Stanford, Spacy and Flai...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Comparison with Tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>What is their f1 score and recall?</td>\n",
       "      <td>F1 score: 0.85\\nRecall: 0.88</td>\n",
       "      <td>F1 score and Recall are 68.66, 80.08 with Trad...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Comparison with Tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>How many layers does their system have?</td>\n",
       "      <td>3 layers</td>\n",
       "      <td>4 layers</td>\n",
       "      <td>FLOAT SELECTED: Figure 1. BERT + Bi-GRU + CRF,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>What context modelling methods are evaluated?</td>\n",
       "      <td>13 different context modeling methods are eval...</td>\n",
       "      <td>Concat\\nTurn\\nGate\\nAction Copy\\nTree Copy\\nSQ...</td>\n",
       "      <td>To conduct a thorough comparison, we evaluate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>Is the baseline a non-heirarchical model like ...</td>\n",
       "      <td>No. The baseline is a hierarchical transformer...</td>\n",
       "      <td>There were hierarchical and non-hierarchical b...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results of various mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>How better are results compared to baseline mo...</td>\n",
       "      <td>The results are significantly better ($p&lt;0.001...</td>\n",
       "      <td>F1 score of best authors' model is 55.98 compa...</td>\n",
       "      <td>We see that parent quality is a simple yet eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>How big is dataset used for training/testing?</td>\n",
       "      <td>The dataset used for training/testing consists...</td>\n",
       "      <td>4,261  days for France and 4,748 for the UK</td>\n",
       "      <td>Our work aims at predicting time series using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>What geometric properties do embeddings display?</td>\n",
       "      <td>The embeddings display clustering properties, ...</td>\n",
       "      <td>Winter and summer words formed two separate cl...</td>\n",
       "      <td>The initial analyses of the embedding matrices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>How accurate is model trained on text exclusiv...</td>\n",
       "      <td>The model trained on text exclusively achieves...</td>\n",
       "      <td>Relative error is less than 5%</td>\n",
       "      <td>The main contribution of our paper is to sugge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>What was their result on Stance Sentiment Emot...</td>\n",
       "      <td>The proposed system outperformed the state-of-...</td>\n",
       "      <td>F1 score of 66.66%</td>\n",
       "      <td>FLOAT SELECTED: TABLE II F-SCORE OF VARIOUS MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>What performance did they obtain on the SemEva...</td>\n",
       "      <td>The proposed system obtained an F1-score of 85...</td>\n",
       "      <td>F1 score of 82.10%</td>\n",
       "      <td>We implement our model in Python using Tensorf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>What are the state-of-the-art systems?</td>\n",
       "      <td>The state-of-the-art systems for sentiment and...</td>\n",
       "      <td>For sentiment analysis UWB, INF-UFRGS-OPINION-...</td>\n",
       "      <td>FLOAT SELECTED: TABLE III COMPARISON WITH THE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>What is the size of their collected dataset?</td>\n",
       "      <td>3347 utterances</td>\n",
       "      <td>3347 unique utterances</td>\n",
       "      <td>Our AV in-cabin data-set includes 30 hours of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>What kind of features are used by the HMM mode...</td>\n",
       "      <td>The HMM models in the hybrid approach use feat...</td>\n",
       "      <td>A continuous emission HMM uses the hidden stat...</td>\n",
       "      <td>We compare a hybrid HMM-LSTM approach with a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>What kind of information do the HMMs learn tha...</td>\n",
       "      <td>The HMMs learn information related to spaces a...</td>\n",
       "      <td>The HMM can identify punctuation or pick up on...</td>\n",
       "      <td>We interpret the HMM and LSTM states in the hy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>How large is the gap in performance between th...</td>\n",
       "      <td>The gap in performance between the HMMs and th...</td>\n",
       "      <td>With similar number of parameters, the log lik...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Predictive loglikelih...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>what was their system's f1 performance?</td>\n",
       "      <td>12 F1 points</td>\n",
       "      <td>Proposed model achieves 0.86, 0.924, 0.71 F1 s...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: F1 Results3 The appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>How much more coverage is in the new dataset?</td>\n",
       "      <td>The new dataset has approximately 25% more cov...</td>\n",
       "      <td>278 more annotations</td>\n",
       "      <td>The measured precision with respect to PropBan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>How was quality measured?</td>\n",
       "      <td>Quality was measured using F1 score with 5 gen...</td>\n",
       "      <td>Inter-annotator agreement, comparison against ...</td>\n",
       "      <td>Dataset Quality Analysis ::: Inter-Annotator A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>What is different in the improved annotation p...</td>\n",
       "      <td>The improved annotation protocol uses trained ...</td>\n",
       "      <td>a trained worker consolidates existing annotat...</td>\n",
       "      <td>We adopt the annotation machinery of BIBREF5 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>What data were they used to train the multilin...</td>\n",
       "      <td>The multilingual encoder was trained on the WM...</td>\n",
       "      <td>WMT 2014 En-Fr parallel corpus</td>\n",
       "      <td>For the MT task, we use the WMT 2014 En $\\left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>From when are many VQA datasets collected?</td>\n",
       "      <td>Late 2014</td>\n",
       "      <td>late 2014</td>\n",
       "      <td>VQA research began in earnest in late 2014 whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>What is task success rate achieved?</td>\n",
       "      <td>96.0%</td>\n",
       "      <td>96-97.6% using the objects color or shape and ...</td>\n",
       "      <td>To test our model, we generated 500 new scenar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Does proposed end-to-end approach learn in rei...</td>\n",
       "      <td>Supervised learning</td>\n",
       "      <td>supervised learning</td>\n",
       "      <td>To train our model, we generated a dataset of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>How is performance of this system measured?</td>\n",
       "      <td>Performance of this system is measured using h...</td>\n",
       "      <td>using the BLEU score as a quantitative metric ...</td>\n",
       "      <td>We use the BLEU BIBREF30 metric on the validat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>How big dataset is used for training this system?</td>\n",
       "      <td>The system is trained on a dataset of 15,000 i...</td>\n",
       "      <td>For the question generation model 15,000 image...</td>\n",
       "      <td>We use MS COCO, Bing and Flickr datasets from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>How do they obtain word lattices from words?</td>\n",
       "      <td>They obtain word lattices from words by treati...</td>\n",
       "      <td>By considering words as vertices and generatin...</td>\n",
       "      <td>Word Lattice As shown in Figure FIGREF4 , a wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>How better is proposed method than baselines p...</td>\n",
       "      <td>MEED outperforms the baselines in terms of per...</td>\n",
       "      <td>Perplexity of proposed MEED model is 19.795 vs...</td>\n",
       "      <td>Table TABREF34 gives the perplexity scores obt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Who manually annotated the semantic roles for ...</td>\n",
       "      <td>The authors of the paper manually annotated th...</td>\n",
       "      <td>Authors</td>\n",
       "      <td>In this paper, we manually annotate the predic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>How do they obtain region descriptions and obj...</td>\n",
       "      <td>They obtain region descriptions and object ann...</td>\n",
       "      <td>they are available in the Visual Genome dataset</td>\n",
       "      <td>In this work, we introduce a methodology that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Which training dataset allowed for the best ge...</td>\n",
       "      <td>The training dataset that allowed for the best...</td>\n",
       "      <td>MultiNLI</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Test accuracies (%). ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Which models were compared?</td>\n",
       "      <td>BiLSTM-max, ESIM, KIM, ESIM + ELMo, and BERT</td>\n",
       "      <td>BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and ...</td>\n",
       "      <td>For sentence encoding models, we chose a simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>What is private dashboard?</td>\n",
       "      <td>Private leaderboard</td>\n",
       "      <td>Private dashboard is leaderboard where competi...</td>\n",
       "      <td>For each model having the best fit on the dev ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>What is public dashboard?</td>\n",
       "      <td>The public dashboard is the public test set</td>\n",
       "      <td>Public dashboard where competitors can see the...</td>\n",
       "      <td>For each model having the best fit on the dev ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>What dataset do they use?</td>\n",
       "      <td>VLSP 2016 Sentiment Analysis, VLSP 2018 Sentim...</td>\n",
       "      <td>They used Wiki Vietnamese language and Vietnam...</td>\n",
       "      <td>The fundamental idea of this system is how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Do the use word embeddings alone or they repla...</td>\n",
       "      <td>The use of word embeddings in the proposed mod...</td>\n",
       "      <td>They use it as addition to previous model - th...</td>\n",
       "      <td>While the co-occurrence representation yields ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>How many natural language explanations are hum...</td>\n",
       "      <td>10,426</td>\n",
       "      <td>Totally 6980 validation and test image-sentenc...</td>\n",
       "      <td>e-SNLI-VE-2.0 is the combination of SNLI-VE-2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>What is the dataset used as input to the Word2...</td>\n",
       "      <td>The dataset used as input to the Word2Vec algo...</td>\n",
       "      <td>Italian Wikipedia and Google News extraction p...</td>\n",
       "      <td>The dataset needed to train the W2V was obtain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>What methodology is used to compensate for lim...</td>\n",
       "      <td>Use of influential tweeters to label tweets in...</td>\n",
       "      <td>Influential tweeters ( who they define as indi...</td>\n",
       "      <td>The first data batch consists of tweets releva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>What are the baseline state of the art models?</td>\n",
       "      <td>The baseline state of the art models are the R...</td>\n",
       "      <td>Stanford NER, BiLSTM+CRF, LSTM+CNN+CRF, T-NER ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Evaluation results of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>How do they extract causality from text?</td>\n",
       "      <td>They extract causality from text by selecting ...</td>\n",
       "      <td>They identify documents that contain the unigr...</td>\n",
       "      <td>Causal documents were chosen to contain one oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>What is the source of the \"control\" corpus?</td>\n",
       "      <td>Temporally matched Twitter posts that do not c...</td>\n",
       "      <td>Randomly selected from a Twitter dump, tempora...</td>\n",
       "      <td>Data was collected from a 10% uniform sample o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>What are the selection criteria for \"causal st...</td>\n",
       "      <td>The selection criteria for \"causal statements\"...</td>\n",
       "      <td>Presence of only the exact unigrams 'caused', ...</td>\n",
       "      <td>Causal documents were chosen to contain one oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Do they use expert annotations, crowdsourcing,...</td>\n",
       "      <td>Automatic methods</td>\n",
       "      <td>Only automatic methods</td>\n",
       "      <td>The rest of this paper is organized as follows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>how do they collect the comparable corpus?</td>\n",
       "      <td>They collected the comparable corpus by select...</td>\n",
       "      <td>Randomly from a Twitter dump</td>\n",
       "      <td>Data was collected from a 10% uniform sample o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>How do they collect the control corpus?</td>\n",
       "      <td>Control documents were selected randomly</td>\n",
       "      <td>Randomly from Twitter</td>\n",
       "      <td>Data was collected from a 10% uniform sample o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>What are resolution model variables?</td>\n",
       "      <td>Resolution model variables are $\\Pi = \\lbrace ...</td>\n",
       "      <td>Variables in the set {str, prec, attr} indicat...</td>\n",
       "      <td>According to previous work BIBREF17 , BIBREF18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Is the model presented in the paper state of t...</td>\n",
       "      <td>NO.\\n\\nWhile the model presented in the paper ...</td>\n",
       "      <td>No, supervised models perform better for this ...</td>\n",
       "      <td>To make a thorough empirical comparison with p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>What was the result of the highest performing ...</td>\n",
       "      <td>The highest performing system in Task 1 was \"S...</td>\n",
       "      <td>For task 1 best F1 score was 0.9391 on closed ...</td>\n",
       "      <td>There are 74 participants who are signing up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>What do they mean by answer styles?</td>\n",
       "      <td>The answer styles refer to the two types of an...</td>\n",
       "      <td>well-formed sentences vs concise answers</td>\n",
       "      <td>We conducted experiments on the two tasks of M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>What are the baselines that Masque is compared...</td>\n",
       "      <td>Seo et al. (2017), Tan et al. (2018), Devlin e...</td>\n",
       "      <td>BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Mult...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Performance of our an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>What is the performance achieved on NarrativeQA?</td>\n",
       "      <td>bTay et al. (2018) achieved an F1 score of 85....</td>\n",
       "      <td>Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, R...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Performance of our an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>What is an \"answer style\"?</td>\n",
       "      <td>An \"answer style\" refers to the type of abstra...</td>\n",
       "      <td>well-formed sentences vs concise answers</td>\n",
       "      <td>We conducted experiments on the two tasks of M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>How are the EAU text spans annotated?</td>\n",
       "      <td>The EAU text spans are annotated with sentimen...</td>\n",
       "      <td>Answer with content missing: (Data and pre-pro...</td>\n",
       "      <td>Tree-based sentiment annotations are sentiment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Which Twitter corpus was used to train the wor...</td>\n",
       "      <td>The Twitter corpus used to train the word vect...</td>\n",
       "      <td>They collected tweets in Russian language usin...</td>\n",
       "      <td>Twitter provides well-documented API, which al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>How does proposed word embeddings compare to S...</td>\n",
       "      <td>Proposed word embeddings outperform Sindhi fas...</td>\n",
       "      <td>Proposed SG model vs SINDHI FASTTEXT:\\nAverage...</td>\n",
       "      <td>Generally, closer words are considered more im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>How many uniue words are in the dataset?</td>\n",
       "      <td>23,456 unique words</td>\n",
       "      <td>908456 unique words are available in collected...</td>\n",
       "      <td>The large corpus acquired from multiple resour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Which baseline methods are used?</td>\n",
       "      <td>The baseline methods used are the standard par...</td>\n",
       "      <td>standard parametrized attention and a non-atte...</td>\n",
       "      <td>Table 1 shows the BLEU scores of our model on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>How much is the BLEU score?</td>\n",
       "      <td>27.4</td>\n",
       "      <td>Ranges from 44.22 to 100.00 depending on K and...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: BLEU scores and compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Which datasets are used in experiments?</td>\n",
       "      <td>The datasets used in experiments are the Seque...</td>\n",
       "      <td>Sequence Copy Task and WMT'17</td>\n",
       "      <td>Due to the reduction of computational time com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>What are new best results on standard benchmark?</td>\n",
       "      <td>Ours-Procrustes achieves new best results on s...</td>\n",
       "      <td>New best results of accuracy (P@1) on Vecmap:\\...</td>\n",
       "      <td>Table TABREF15 shows the final results on Vecm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>How better is performance compared to competit...</td>\n",
       "      <td>Ours-Procrustes outperforms competitive baseli...</td>\n",
       "      <td>Proposed method vs best baseline result on Vec...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Accuracy (P@1) on Vec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>What 6 language pairs is experimented on?</td>\n",
       "      <td>English-German, English-French, English-Italia...</td>\n",
       "      <td>EN&lt;-&gt;ES\\nEN&lt;-&gt;DE\\nEN&lt;-&gt;IT\\nEN&lt;-&gt;EO\\nEN&lt;-&gt;MS\\nE...</td>\n",
       "      <td>Table TABREF13 shows the inconsistency rates o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>How do they enrich the positional embedding wi...</td>\n",
       "      <td>They enrich the positional embedding with leng...</td>\n",
       "      <td>They introduce new trigonometric encoding whic...</td>\n",
       "      <td>Methods ::: Length Encoding Method Inspired by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>How do they condition the output to a given ta...</td>\n",
       "      <td>They condition the output to a given target-so...</td>\n",
       "      <td>They use three groups short/normal/long transl...</td>\n",
       "      <td>Methods ::: Length Token Method Our first appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>Is this library implemented into Torch or is f...</td>\n",
       "      <td>Torch-Struct is implemented on top of PyTorch</td>\n",
       "      <td>It uses deep learning framework (pytorch)</td>\n",
       "      <td>With this challenge in mind, we introduce Torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>How does this compare to traditional calibrati...</td>\n",
       "      <td>This method differs from traditional calibrati...</td>\n",
       "      <td>No reliability diagrams are provided and no ex...</td>\n",
       "      <td>Compared to using external models for confiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>What's the input representation of OpenIE tupl...</td>\n",
       "      <td>The input representation of OpenIE tuples into...</td>\n",
       "      <td>word embeddings</td>\n",
       "      <td>Our training method in sec:ours could potentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Is CRWIZ already used for data collection, wha...</td>\n",
       "      <td>CRWIZ has been used for data collection, and t...</td>\n",
       "      <td>Yes, CRWIZ has been used for data collection a...</td>\n",
       "      <td>For the intitial data collection using the CRW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>What contextual features are used?</td>\n",
       "      <td>download, malware, malicious</td>\n",
       "      <td>The words that can indicate the characteristic...</td>\n",
       "      <td>IOCs in cybersecurity articles are often descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>How is the data in RAFAEL labelled?</td>\n",
       "      <td>The data in RAFAEL is labelled with morphosynt...</td>\n",
       "      <td>Using a set of annotation tools such as Morfeu...</td>\n",
       "      <td>Secondly, texts go through a cascade of annota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>How is the fluctuation in the sense of the wor...</td>\n",
       "      <td>Surrounding Uniformity (SU) measures the fluct...</td>\n",
       "      <td>Our method performs a statistical test to dete...</td>\n",
       "      <td>Distributed representation of word sense provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>By how much does SPNet outperforms state-of-th...</td>\n",
       "      <td>SPNet outperforms state-of-the-art abstractive...</td>\n",
       "      <td>SPNet vs best baseline:\\nROUGE-1: 90.97 vs 90....</td>\n",
       "      <td>We show all the models' results in Table TABRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Is it expected to have speaker role, semantic ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Not at the moment, but summaries can be additi...</td>\n",
       "      <td>Moreover, we can easily extend SPNet to other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>How does new evaluation metric considers criti...</td>\n",
       "      <td>CIC considers critical informative entities by...</td>\n",
       "      <td>Answer with content missing: (formula for CIC)...</td>\n",
       "      <td>In this case, the summary has a high ROUGE sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>What are state of the art methods MMM is compa...</td>\n",
       "      <td>State-of-the-art methods MMM is compared to in...</td>\n",
       "      <td>FTLM++, BERT-large, XLNet</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Accuracy on the DREAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>What are the problems related to ambiguity in ...</td>\n",
       "      <td>Ambiguity in PICO sentence prediction tasks ca...</td>\n",
       "      <td>Some sentences are associated to ambiguous dim...</td>\n",
       "      <td>Sentences 1 and 2 are labelled incorrectly, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>How is knowledge stored in the memory?</td>\n",
       "      <td>The knowledge is stored in the dynamic memory</td>\n",
       "      <td>entity memory and relational memory.</td>\n",
       "      <td>There are three main components to the model: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>How do they measure the diversity of inferences?</td>\n",
       "      <td>They measure the diversity of inferences using...</td>\n",
       "      <td>by number of distinct n-grams</td>\n",
       "      <td>We first compare the perplexity of CWVAE with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>By how much do they improve the accuracy of in...</td>\n",
       "      <td>They improve the accuracy of inferences over s...</td>\n",
       "      <td>ON Event2Mind, the accuracy of proposed method...</td>\n",
       "      <td>We first compare the perplexity of CWVAE with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>How does the context-aware variational autoenc...</td>\n",
       "      <td>By learning a context-aware latent variable in...</td>\n",
       "      <td>CWVAE is trained on an auxiliary dataset to l...</td>\n",
       "      <td>In addition to the traditional VAE structure, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>How much improvement does their method get ove...</td>\n",
       "      <td>2.3 BLEU-4 points</td>\n",
       "      <td>0.08 points on the 2011 test set, 0.44 points ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Domain adaptation res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>By how much do they outpeform previous results...</td>\n",
       "      <td>The CNN and LSTM models outperform previous re...</td>\n",
       "      <td>Their best average precision tops previous bes...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Final test set result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>How many paraphrases are generated per question?</td>\n",
       "      <td>10n paraphrases are generated per question</td>\n",
       "      <td>10*n paraphrases, where n depends on the numbe...</td>\n",
       "      <td>For WebQuestions, we use 8 handcrafted part-of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>How strong was the correlation between exercis...</td>\n",
       "      <td>Strong.\\n\\nThe context states that the stronge...</td>\n",
       "      <td>weak correlation with p-value of 0.08</td>\n",
       "      <td>The main DDEO topics showed some level of inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>How were topics of interest about DDEO identif...</td>\n",
       "      <td>Topics of interest about DDEO were identified ...</td>\n",
       "      <td>using topic modeling model Latent Dirichlet Al...</td>\n",
       "      <td>To discover topics from the collected tweets, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>How do their train their embeddings?</td>\n",
       "      <td>They train their embeddings using the embeddin...</td>\n",
       "      <td>The embeddings are learned several times using...</td>\n",
       "      <td>For each variable in encoding set, learn the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>How do they model travel behavior?</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>The data from collected travel surveys is used...</td>\n",
       "      <td>Differently to textual data, our goal in this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>How do their interpret the coefficients?</td>\n",
       "      <td>The coefficients from the embeddings and PCA m...</td>\n",
       "      <td>The coefficients are projected back to the dum...</td>\n",
       "      <td>We will apply the methodology to the well-know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>By how much do they outperform previous state-...</td>\n",
       "      <td>ORNN outperforms previous state-of-the-art mod...</td>\n",
       "      <td>Proposed ORNN has 0.769, 1.238, 0.818, 0.772 c...</td>\n",
       "      <td>All models are trained and evaluated using the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>What is the performance difference between pro...</td>\n",
       "      <td>The proposed method (FlowSeq) achieves competi...</td>\n",
       "      <td>Difference is around 1 BLEU score lower on ave...</td>\n",
       "      <td>Table TABREF40 illustrates the BLEU scores of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>What benchmarks are created?</td>\n",
       "      <td>HotpotQA and MedHop</td>\n",
       "      <td>Answer with content missing: (formula) The acc...</td>\n",
       "      <td>In HotpotQA, on average we can find 6 candidat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>What percentage fewer errors did professional ...</td>\n",
       "      <td>Professional translations made 35% fewer error...</td>\n",
       "      <td>36%</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Classification of err...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>What was the weakness in Hassan et al's evalua...</td>\n",
       "      <td>The weakness in Hassan et al.'s evaluation des...</td>\n",
       "      <td>MT developers to which crowd workers were comp...</td>\n",
       "      <td>The human evaluation of MT output in research ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>What evidence do they present that the model a...</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>Using model gradients with respect to input fe...</td>\n",
       "      <td>One way to analyze the model is to compute mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>In what way is the input restructured?</td>\n",
       "      <td>The input is restructured to begin with a [STA...</td>\n",
       "      <td>In four entity-centric ways - entity-first, en...</td>\n",
       "      <td>Our approach consists of structuring input to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>What language is the Twitter content in?</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>In this work, we analyze a set of tweets relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>What evaluations did the authors use on their ...</td>\n",
       "      <td>BLEU scores, average number of words in transl...</td>\n",
       "      <td>BLEU scores, exact matches of words in both tr...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Experiment results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>What accuracy does CNN model achieve?</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Combined per-pixel accuracy for character line...</td>\n",
       "      <td>FLOAT SELECTED: TABLE IV: Class-wise average I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>How many documents are in the Indiscapes dataset?</td>\n",
       "      <td>100 documents</td>\n",
       "      <td>508</td>\n",
       "      <td>FLOAT SELECTED: TABLE III: Scripts in the INDI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>What are simulated datasets collected?</td>\n",
       "      <td>Simulated datasets of document revisions</td>\n",
       "      <td>There are 6 simulated datasets collected which...</td>\n",
       "      <td>The generation process of the simulated data s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>What human evaluation metrics were used in the...</td>\n",
       "      <td>Fluency and relevance</td>\n",
       "      <td>rating questions on a scale of 1-5 based on fl...</td>\n",
       "      <td>For the human evaluation, we follow the standa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>For the purposes of this paper, how is somethi...</td>\n",
       "      <td>Domain specific knowledge is determined to be ...</td>\n",
       "      <td>reviews under distinct product categories are ...</td>\n",
       "      <td>Amazon Reviews Dataset BIBREF24 is a large dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>What type of model are the ELMo representation...</td>\n",
       "      <td>Bidirectional Long Short-Term Memory (BiLSTM) ...</td>\n",
       "      <td>A bi-LSTM with max-pooling on top of it</td>\n",
       "      <td>The usage of a purely character-based input wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>By how much does using phonetic feedback impro...</td>\n",
       "      <td>Using phonetic feedback improves state-of-the-...</td>\n",
       "      <td>Improved AECNN-T by 2.1 and AECNN-T-SM BY 0.9</td>\n",
       "      <td>In addition to the setting without any paralle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>what are the baselines?</td>\n",
       "      <td>The baselines are Attention Sum Reader (AS Rea...</td>\n",
       "      <td>AS Reader, GA Reader, CAS Reader</td>\n",
       "      <td>Table TABREF17 shows our results on CMRC-2017 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>What are the results of the experiment?</td>\n",
       "      <td>The results of the experiment are not specifie...</td>\n",
       "      <td>They were able to create a language model from...</td>\n",
       "      <td>The BD-4SK-ASR Dataset ::: The Language Model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>How was the dataset collected?</td>\n",
       "      <td>The dataset was collected by extracting 200 se...</td>\n",
       "      <td>extracted text from Sorani Kurdish books of pr...</td>\n",
       "      <td>To develop the dataset, we extracted 200 sente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>How many annotators participated?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Two thousand narration files were created. We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>How do they show their model discovers underly...</td>\n",
       "      <td>By visualizing the syntactic distance estimate...</td>\n",
       "      <td>By visualizing syntactic distance estimated by...</td>\n",
       "      <td>In Figure FIGREF32 , we visualize the syntacti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>How do they measure performance of language mo...</td>\n",
       "      <td>They measure performance of language model tas...</td>\n",
       "      <td>BPC, Perplexity</td>\n",
       "      <td>In Table TABREF39 , our results are comparable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>How are content clusters used to improve the p...</td>\n",
       "      <td>The content clusters are used as additional fe...</td>\n",
       "      <td>they are used as additional features in a supe...</td>\n",
       "      <td>As a further application of our work, we have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>What cluster identification method is used in ...</td>\n",
       "      <td>Markov Stability (MS) clustering</td>\n",
       "      <td>A combination of Minimum spanning trees, K-Nea...</td>\n",
       "      <td>The trained Doc2Vec model is subsequently used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Why did they think this was a good idea?</td>\n",
       "      <td>To leverage the knowledge and experience of TC...</td>\n",
       "      <td>They think it will help human TCM practitioner...</td>\n",
       "      <td>During the long history of TCM, there has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>What QA models were used?</td>\n",
       "      <td>The QA models used are GloVe BIBREF40, CharCNN...</td>\n",
       "      <td>A pointer network decodes the answer from a bi...</td>\n",
       "      <td>The input of our model are the words in the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>How do their results compare against other com...</td>\n",
       "      <td>N-GrAM outperformed other competitors in the P...</td>\n",
       "      <td>They achieved best result in the PAN 2017 shar...</td>\n",
       "      <td>FLOAT SELECTED: Table 8. Results (accuracy) on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>On which task does do model do worst?</td>\n",
       "      <td>The gender task</td>\n",
       "      <td>Gender prediction task</td>\n",
       "      <td>N-GrAM ranked first in all cases except for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>On which task does do model do best?</td>\n",
       "      <td>The joint task</td>\n",
       "      <td>Variety prediction task</td>\n",
       "      <td>N-GrAM ranked first in all cases except for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>How does counterfactual data augmentation aim ...</td>\n",
       "      <td>By swapping gendered words with their counterf...</td>\n",
       "      <td>The training dataset is augmented by swapping ...</td>\n",
       "      <td>One of the solutions that has been proposed fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>In the targeted data collection approach, what...</td>\n",
       "      <td>Referring nouns or pronouns</td>\n",
       "      <td>Gendered characters in the dataset</td>\n",
       "      <td>There are a larger number of male-gendered cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>How do they determine which words are informat...</td>\n",
       "      <td>They determine which words are informative bas...</td>\n",
       "      <td>Informative are those that will not be suppres...</td>\n",
       "      <td>Data dependent regularization. As explained in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>What improvement does the MOE model make over ...</td>\n",
       "      <td>The MOE model achieves a lower test perplexity...</td>\n",
       "      <td>Perpexity is improved from 34.7 to 28.0.</td>\n",
       "      <td>The two models achieved test perplexity of INL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>What is the difference in performance between ...</td>\n",
       "      <td>The interpretable system (e.g. vectors and cos...</td>\n",
       "      <td>Accuracy of best interpretible system was 0.39...</td>\n",
       "      <td>The experimental results are presented in Tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Which language-pair had the better performance?</td>\n",
       "      <td>The English-French language pair had better pe...</td>\n",
       "      <td>French-English</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Results obtained for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Which psycholinguistic and basic linguistic fe...</td>\n",
       "      <td>Emotion Sensor Feature and selected topical si...</td>\n",
       "      <td>Emotion Sensor Feature, Part of Speech, Punctu...</td>\n",
       "      <td>Exploiting psycho-linguistic features with bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>How have the differences in communication styl...</td>\n",
       "      <td>The differences in communication styles betwee...</td>\n",
       "      <td>Systems do not perform well both in Facebook a...</td>\n",
       "      <td>Most of the above-discussed systems either sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>What data/studies do the authors provide to su...</td>\n",
       "      <td>The authors do not provide any specific data o...</td>\n",
       "      <td>None</td>\n",
       "      <td>The informal setting/environment of social med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>What datasets are used to evaluate the model?</td>\n",
       "      <td>WN18 and FB15k</td>\n",
       "      <td>WN18, FB15k</td>\n",
       "      <td>As we show below, STransE performs better than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>What baseline models do they compare against?</td>\n",
       "      <td>Against a set of strong baseline models, inclu...</td>\n",
       "      <td>SLQA, Rusalka, HMA Model (single), TriAN (sing...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Experimental Results ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>What are the differences with previous applica...</td>\n",
       "      <td>Our approach differs from previous application...</td>\n",
       "      <td>This approach considers related images</td>\n",
       "      <td>One common point in all the approaches yet has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>How much improvement is gained from the propos...</td>\n",
       "      <td>The proposed approaches result in a non-termin...</td>\n",
       "      <td>It eliminates non-termination in some models f...</td>\n",
       "      <td>Table TABREF44 shows that consistent nucleus a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Is infinite-length sequence generation a resul...</td>\n",
       "      <td>No</td>\n",
       "      <td>There are is a strong conjecture that it might...</td>\n",
       "      <td>We extended the notion of consistency of a rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>How big is dataset for this challenge?</td>\n",
       "      <td>123,287 images</td>\n",
       "      <td>133,287 images</td>\n",
       "      <td>We use the VisDial v1.0 BIBREF0 dataset to tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>How better is performance of proposed model co...</td>\n",
       "      <td>The proposed model outperforms the baselines b...</td>\n",
       "      <td>Proposed model achive 66+-22 win rate, baselin...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Final win rate on sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>What DCGs are used?</td>\n",
       "      <td>DCGs used are Lexicon and 1st/3rd step convers...</td>\n",
       "      <td>Author's own DCG rules are defined from scratch.</td>\n",
       "      <td>convertible.pl: implementing DCG rules for 1st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>What is the performance difference of using a ...</td>\n",
       "      <td>Using a generated summary vs. a user-written o...</td>\n",
       "      <td>2.7 accuracy points</td>\n",
       "      <td>Table TABREF34 and Table TABREF35 show the fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>What evaluation metrics did they look at?</td>\n",
       "      <td>They looked at normalized averages between 0 a...</td>\n",
       "      <td>accuracy with standard deviation</td>\n",
       "      <td>Los resultados de la evaluación se presentan e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>What are the datasets used for the task?</td>\n",
       "      <td>CELEX, IIT-Guwahat, and Festival datasets</td>\n",
       "      <td>Datasets used are Celex (English, Dutch), Fest...</td>\n",
       "      <td>FLOAT SELECTED: TABLE I DATASETS AND LANGUAGES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>What is the accuracy of the model for the six ...</td>\n",
       "      <td>The accuracy of the model for the six language...</td>\n",
       "      <td>Authors report their best models have followin...</td>\n",
       "      <td>We tested three model versions against all dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>Which models achieve state-of-the-art performa...</td>\n",
       "      <td>The proposed model and Liang's hyphenation alg...</td>\n",
       "      <td>CELEX (Dutch and English) - SVM-HMM\\nFestival,...</td>\n",
       "      <td>FLOAT SELECTED: TABLE II REPORTED ACCURACIES O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Which competitive relational classification mo...</td>\n",
       "      <td>TransE BIBREF3 and FB15K BIBREF3</td>\n",
       "      <td>For relation prediction they test TransE and f...</td>\n",
       "      <td>In this section, we consider two kinds of rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>How do they gather human judgements for simila...</td>\n",
       "      <td>They gather human judgments for similarity bet...</td>\n",
       "      <td>By assessing similarity of 360 pairs of relati...</td>\n",
       "      <td>Human Judgments Following BIBREF11 , BIBREF12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>What text classification task is considered?</td>\n",
       "      <td>Text classification task is considered as clas...</td>\n",
       "      <td>To classify a text as belonging to one of the ...</td>\n",
       "      <td>We trained word embeddings and a uni-direction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>What novel class of recurrent-like networks is...</td>\n",
       "      <td>Recurrent-like neural networks with nested int...</td>\n",
       "      <td>A network, whose learned functions satisfy a c...</td>\n",
       "      <td>First, we propose a class of recurrent-like ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>How much bigger is Switchboard-2000 than Switc...</td>\n",
       "      <td>Switchboard-2000 is approximately 6 times bigg...</td>\n",
       "      <td>Switchboard-2000 contains 1700 more hours of s...</td>\n",
       "      <td>This study focuses on Switchboard-300, a stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>What domains are detected in this paper?</td>\n",
       "      <td>Neural activity in visual cortex</td>\n",
       "      <td>Answer with content missing: (Experimental set...</td>\n",
       "      <td>Experimental Setup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Why do they think this task is hard?  What is ...</td>\n",
       "      <td>The task is hard because of the complexity of ...</td>\n",
       "      <td>1. there may be situations where more than one...</td>\n",
       "      <td>Although not done in this work, an alternative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>How do they generate the synthetic dataset?</td>\n",
       "      <td>They generate the synthetic dataset by samplin...</td>\n",
       "      <td>using generative process</td>\n",
       "      <td>We performed experiments on synthetically gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>What is the average length of the claims?</td>\n",
       "      <td>The average length of the claims is INLINEFORM2</td>\n",
       "      <td>Average claim length is 8.9 tokens.</td>\n",
       "      <td>FLOAT SELECTED: Table 2: A summary of PERSPECT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>What debate topics are included in the dataset?</td>\n",
       "      <td>Politics, World, Society, and 10+ other topics</td>\n",
       "      <td>Ethics, Gender, Human rights, Sports, Freedom ...</td>\n",
       "      <td>FLOAT SELECTED: Figure 3: Distribution of clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>By how much, the proposed method improves BiDA...</td>\n",
       "      <td>2.3% and 1.7% improvement over BiDAF and DCN, ...</td>\n",
       "      <td>In terms of F1 score, the Hybrid approach impr...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Effect of Character E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>What are the linguistic differences between ea...</td>\n",
       "      <td>The linguistic differences between each class ...</td>\n",
       "      <td>Each class has different patterns in adjective...</td>\n",
       "      <td>Generic Sarcasm. We first examine the differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>what genres do they songs fall under?</td>\n",
       "      <td>The songs fall under the following genres:\\n\\n...</td>\n",
       "      <td>Gospel, Sertanejo, MPB, Forró, Pagode, Rock, S...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The number of songs a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>To what other competitive baselines is this ap...</td>\n",
       "      <td>VHRED (attn) and MMI</td>\n",
       "      <td>LSTMs with and without attention, HRED, VHRED ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Automatic Evaluation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>How is human evaluation performed, what was th...</td>\n",
       "      <td>Human evaluation was performed using pairwise ...</td>\n",
       "      <td>Through Amazon MTurk annotators to determine p...</td>\n",
       "      <td>We thus also conducted human studies on Amazon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>How much better were results of the proposed m...</td>\n",
       "      <td>The proposed models were significantly better ...</td>\n",
       "      <td>on diversity 6.87 and on relevance 4.6 points ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Automatic Evaluation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Which one of the four proposed models performe...</td>\n",
       "      <td>LFT</td>\n",
       "      <td>the hybrid model MinAvgOut + RL</td>\n",
       "      <td>We employ several complementary metrics to cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>How much is proposed model better than baselin...</td>\n",
       "      <td>The proposed model (GDP) is significantly bett...</td>\n",
       "      <td>most of the models have similar performance on...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: The performance of ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>By how much is precission increased?</td>\n",
       "      <td>Precision increased by 15.6% compared to the b...</td>\n",
       "      <td>ROUGE-1 increases by 0.05, ROUGE-2 by 0.06 and...</td>\n",
       "      <td>FLOAT SELECTED: Figure 3: ROUGE Quality of pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>What labels are in the dataset?</td>\n",
       "      <td>STRESS, ANXIETY, SOCIAL MEDIA</td>\n",
       "      <td>binary label of stress or not stress</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: An example of stress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>How are customer satisfaction, customer frustr...</td>\n",
       "      <td>Customer satisfaction, customer frustration, a...</td>\n",
       "      <td>By annotators on Amazon Mechanical Turk.</td>\n",
       "      <td>Using these filters as pre-processing methods,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>How many improvements on the French-German tra...</td>\n",
       "      <td>3 improvements on the French-German translatio...</td>\n",
       "      <td>one</td>\n",
       "      <td>While the mixing strategy compensates for most...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>How do they prevent the model complexity incre...</td>\n",
       "      <td>By using a state tracking model independent of...</td>\n",
       "      <td>They exclude slot-specific parameters and inco...</td>\n",
       "      <td>To solve this problem, we need a state trackin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>How do they measure model size?</td>\n",
       "      <td>They measure model size in terms of parameters</td>\n",
       "      <td>By the number of parameters.</td>\n",
       "      <td>Furthermore, as SIM has no slot-specific neura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Which model architecture do they for sentence ...</td>\n",
       "      <td>A multi-task model architecture with a combina...</td>\n",
       "      <td>Answer with content missing: (Skip-thought vec...</td>\n",
       "      <td>We select the following training objectives to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Which data sources do they use?</td>\n",
       "      <td>Table 1</td>\n",
       "      <td>- En-Fr (WMT14)\\n- En-De (WMT15)\\n- Skipthough...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: An approximate number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>How were breast cancer related posts compiled ...</td>\n",
       "      <td>The breast cancer related posts were compiled ...</td>\n",
       "      <td>By using  keywords `breast' AND `cancer' in tw...</td>\n",
       "      <td>We collected tweets from two distinct Spritzer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>What machine learning and NLP methods were use...</td>\n",
       "      <td>The machine learning and NLP methods used to s...</td>\n",
       "      <td>ML  logistic regression classifier combined wi...</td>\n",
       "      <td>Sentence classification combines natural langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>What approach performs better in experiments g...</td>\n",
       "      <td>The global latent variable</td>\n",
       "      <td>PPL: SVT\\nDiversity: GVT\\nEmbeddings Similarit...</td>\n",
       "      <td>Compare to baseline models, the GVT achieves r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Which translation system do they use to transl...</td>\n",
       "      <td>BIBREF6</td>\n",
       "      <td>Attention-based translation model with convolu...</td>\n",
       "      <td>Attention-base translation model We use the sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Which pre-trained English NER model do they use?</td>\n",
       "      <td>Flair</td>\n",
       "      <td>Bidirectional LSTM based NER model of Flair</td>\n",
       "      <td>Pre-trained English NER model We construct the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>How much of the ASR grapheme set is shared bet...</td>\n",
       "      <td>432 characters</td>\n",
       "      <td>Little overlap except common basic Latin alpha...</td>\n",
       "      <td>The character sets of these 7 languages have l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>What are the languages used to test the model?</td>\n",
       "      <td>Hindi, English, and German</td>\n",
       "      <td>Hindi, English and German (German task won)</td>\n",
       "      <td>The dataset at HASOC 2019 were given in three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>Which language has the lowest error rate reduc...</td>\n",
       "      <td>ARABIC (ar)\\n\\nIn the table provided, the erro...</td>\n",
       "      <td>thai</td>\n",
       "      <td>FLOAT SELECTED: Table 9 Character error rates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>How is moral bias measured?</td>\n",
       "      <td>By calculating the cosine similarity between t...</td>\n",
       "      <td>Answer with content missing: (formula 1) bias(...</td>\n",
       "      <td>Analogous to word embeddings, sentence embeddi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>What metrics are used for evaluation?</td>\n",
       "      <td>WER (Word Error Rate)</td>\n",
       "      <td>word error rate</td>\n",
       "      <td>The Density Ratio method consistently outperfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>How much training data is used?</td>\n",
       "      <td>Approximately 3 billion sub-word tokens</td>\n",
       "      <td>163,110,000 utterances</td>\n",
       "      <td>The following data sources were used to train ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>How does their model differ from BERT?</td>\n",
       "      <td>The model used in the experiments is a pre-tra...</td>\n",
       "      <td>Their model does not differ from BERT.</td>\n",
       "      <td>In all our experiments, we used the out-of-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>How does explicit constraint on the KL diverge...</td>\n",
       "      <td>The explicit constraint on the KL divergence t...</td>\n",
       "      <td>Answer with content missing: (Formula 2) Formu...</td>\n",
       "      <td>Given the above interpretation, we now turn to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>what was the baseline?</td>\n",
       "      <td>The baseline was the default values of the par...</td>\n",
       "      <td>There is no baseline.</td>\n",
       "      <td>This paper experimented with two different mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>How big is dataset used?</td>\n",
       "      <td>10000</td>\n",
       "      <td>553,451 documents</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistics of the dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>How much better does this baseline neural mode...</td>\n",
       "      <td>10.2% better</td>\n",
       "      <td>The model outperforms at every point in the\\ni...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: PR curve on our impl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>What are the baseline models?</td>\n",
       "      <td>Concatenation-CNN (C-CNN) and the baseline mod...</td>\n",
       "      <td>MC-CNN\\nMVCNN\\nCNN</td>\n",
       "      <td>We compared our proposed approaches to a stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>By how much of MGNC-CNN out perform the baseli...</td>\n",
       "      <td>MGNC-CNN outperforms the baselines by approxim...</td>\n",
       "      <td>In terms of Subj the Average MGNC-CNN is bette...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results mean (min, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>What is increase in percentage of humor contai...</td>\n",
       "      <td>An increase of 22.6% in humor contained in hea...</td>\n",
       "      <td>Humor in headlines (TitleStylist vs Multitask ...</td>\n",
       "      <td>The human evaluation is to have a comprehensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>What are the languages they consider in this p...</td>\n",
       "      <td>English, Russian, Arabic, Chinese, German, Spa...</td>\n",
       "      <td>The languages considered were English, Chinese...</td>\n",
       "      <td>To test this hypothesis we first trained UG-WG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Did they experiment with tasks other than word...</td>\n",
       "      <td>No</td>\n",
       "      <td>They experimented with sentiment analysis and ...</td>\n",
       "      <td>To test this hypothesis we first trained UG-WG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>What evaluation metrics are used?</td>\n",
       "      <td>The evaluation metrics used are accuracy and I...</td>\n",
       "      <td>Accuracy on each dataset and the average accur...</td>\n",
       "      <td>Table TABREF34 shows the performances of the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>What kind of Youtube video transcripts did the...</td>\n",
       "      <td>They used a variety of YouTube video transcrip...</td>\n",
       "      <td>youtube video transcripts on news covering dif...</td>\n",
       "      <td>We focused evaluation over a small but diversi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>What makes it a more reliable metric?</td>\n",
       "      <td>The inclusivity of INLINEFORM0, which consider...</td>\n",
       "      <td>It takes into account the agreement between di...</td>\n",
       "      <td>Results form Table TABREF31 may give an idea t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>How much in experiments is performance improve...</td>\n",
       "      <td>Performance is improved by around 10% on avera...</td>\n",
       "      <td>Answer with content missing: (Table 1) The per...</td>\n",
       "      <td>Adversarial training can often improve model r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>How is the delta-softmax calculated?</td>\n",
       "      <td>The delta-softmax is calculated as the reducti...</td>\n",
       "      <td>Answer with content missing: (Formula) Formula...</td>\n",
       "      <td>We reason that, if a token is important for pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Which two datasets does the resource come from?</td>\n",
       "      <td>The resource comes from two datasets, one coll...</td>\n",
       "      <td>two surveys by two groups - school students an...</td>\n",
       "      <td>The resource is composed of data from two diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>What is the size of the second dataset?</td>\n",
       "      <td>240</td>\n",
       "      <td>1 000 labeled dialogues for training and 240 u...</td>\n",
       "      <td>The two datasets used for the challenge are Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>How large is the first dataset?</td>\n",
       "      <td>The first dataset, Friends, contains 1,000 lab...</td>\n",
       "      <td>1 000 labeled dialogues for training and 240 u...</td>\n",
       "      <td>The two datasets used for the challenge are Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Who was the top-scoring team?</td>\n",
       "      <td>Team B, with a micro-F1 score of 88.5% for Emo...</td>\n",
       "      <td>IDEA</td>\n",
       "      <td>FLOAT SELECTED: Table 6: F-scores for Friends ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>Why is big data not appropriate for this task?</td>\n",
       "      <td>Big data is not appropriate for this task beca...</td>\n",
       "      <td>Training embeddings from small-corpora can inc...</td>\n",
       "      <td>Word embeddings have risen in popularity for N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>What is an example of a computational social s...</td>\n",
       "      <td>Analyzing the topic embeddings of State of the...</td>\n",
       "      <td>Visualization of State of the union addresses</td>\n",
       "      <td>I also performed several case studies. I obtai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>Which major geographical regions are studied?</td>\n",
       "      <td>Northeast, South, West, and Midwest</td>\n",
       "      <td>Northeast U.S, South U.S., West U.S. and Midwe...</td>\n",
       "      <td>We examine other features regarding the charac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>How strong is the correlation between the prev...</td>\n",
       "      <td>Weak</td>\n",
       "      <td>0.9098 correlation</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Linear regression res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>How are the topics embedded in the #MeToo twee...</td>\n",
       "      <td>The topics in the #MeToo tweets are extracted ...</td>\n",
       "      <td>Using Latent Dirichlet Allocation on TF-IDF tr...</td>\n",
       "      <td>In order to understand the latent topics of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>Which geographical regions correlate to the tr...</td>\n",
       "      <td>The Northeast, West, and South regions correla...</td>\n",
       "      <td>Northeast U.S., West U.S. and South U.S.</td>\n",
       "      <td>Observing the results of the linear regression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>What two components are included in their prop...</td>\n",
       "      <td>Evidence extraction and answer synthesis</td>\n",
       "      <td>evidence extraction and answer synthesis</td>\n",
       "      <td>In this paper, we present an extraction-then-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Which modifications do they make to well-estab...</td>\n",
       "      <td>They modify the attention mechanism from locat...</td>\n",
       "      <td>Replacing attention mechanism to query-key att...</td>\n",
       "      <td>Traditional text-to-speech (TTS) systems are c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>How was speed measured?</td>\n",
       "      <td>Time</td>\n",
       "      <td>how long it takes the system to lemmatize a se...</td>\n",
       "      <td>In terms of speed, our system was able to lemm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>What were their accuracy results on the task?</td>\n",
       "      <td>85.11%</td>\n",
       "      <td>97.32%</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Lemmatization accurac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>What two types the Chinese reading comprehensi...</td>\n",
       "      <td>User Query Track and Cloze Track</td>\n",
       "      <td>cloze-style reading comprehension and user que...</td>\n",
       "      <td>Cloze Track: In this track, the participants a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>For which languages most of the existing MRC d...</td>\n",
       "      <td>ENGLISH</td>\n",
       "      <td>English</td>\n",
       "      <td>The previously mentioned datasets are all in E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Which sentiment analysis tasks are addressed?</td>\n",
       "      <td>Binary-class and multi-class cross-domain sent...</td>\n",
       "      <td>12 binary-class classification and multi-class...</td>\n",
       "      <td>We conducted experiments on the Amazon reviews...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Which 3 NLP areas are cited the most?</td>\n",
       "      <td>1. Natural Language Understanding\\n2. Machine ...</td>\n",
       "      <td>machine translation, statistical machine, sent...</td>\n",
       "      <td>FLOAT SELECTED: Figure 33 The most cited areas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>Which journal and conference are cited the mos...</td>\n",
       "      <td>ACM Transactions on Computer Systems (TOCS) an...</td>\n",
       "      <td>CL Journal and EMNLP conference</td>\n",
       "      <td>FLOAT SELECTED: Figure 25 Average citations fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>Which 5 languages appear most frequently in AA...</td>\n",
       "      <td>English, Spanish, Chinese, Japanese, and Korean</td>\n",
       "      <td>English, Chinese, French, Japanese and Arabic</td>\n",
       "      <td>FLOAT SELECTED: Figure 11 A treemap of the 122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>How much F1 was improved after adding skip con...</td>\n",
       "      <td>The F1 score improved by 2.3% after adding ski...</td>\n",
       "      <td>Simple Skip improves F1 from 74.34 to 74.81\\nT...</td>\n",
       "      <td>Table TABREF20 reports the F1 and EM scores ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>How much gain does the model achieve with pret...</td>\n",
       "      <td>The model achieves a gain of approximately 3-4...</td>\n",
       "      <td>0.8 points on Binary; 0.7 points on Fine-Grain...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Test set results of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>What is the highest accuracy score achieved?</td>\n",
       "      <td>0.85</td>\n",
       "      <td>82.0%</td>\n",
       "      <td>FLOAT SELECTED: Table 4: The performance of cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>What are the three datasets used in the paper?</td>\n",
       "      <td>The three datasets used in the paper are:\\n\\n1...</td>\n",
       "      <td>Data released for APDA shared task contains 3 ...</td>\n",
       "      <td>For the purpose of our experiments, we use dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>What is improvement in accuracy for short Joke...</td>\n",
       "      <td>8% improvement in accuracy for short jokes com...</td>\n",
       "      <td>It had the highest accuracy comparing to all d...</td>\n",
       "      <td>Our experiment with the Short Jokes dataset fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>What baseline did they compare Entity-GCN to?</td>\n",
       "      <td>BiDAF BIBREF3 and FastQA BIBREF6</td>\n",
       "      <td>Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver...</td>\n",
       "      <td>In this experiment, we compare our Enitity-GCN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>How did they get relations between mentions?</td>\n",
       "      <td>They got relations between mentions using thre...</td>\n",
       "      <td>Assign a value to the relation based on whethe...</td>\n",
       "      <td>To each node $v_i$ , we associate a continuous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>How did they detect entity mentions?</td>\n",
       "      <td>They detected entity mentions by using a simpl...</td>\n",
       "      <td>Exact matches to the entity string and predict...</td>\n",
       "      <td>In an offline step, we organize the content of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>What performance does the Entity-GCN get on WI...</td>\n",
       "      <td>The Entity-GCN achieves high performance on WI...</td>\n",
       "      <td>During testing: 67.6 for single model without ...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Accuracy of different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>What document context was added?</td>\n",
       "      <td>Preceding and following sentences</td>\n",
       "      <td>Preceding and following sentence of each metap...</td>\n",
       "      <td>We extracted 200 sentence pairs from BIBREF3 '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>What were the results of the first experiment?</td>\n",
       "      <td>The results of the first experiment were an F-...</td>\n",
       "      <td>Best performance achieved is 0.72 F1 score</td>\n",
       "      <td>We also observe that the best combination seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>By how much does their model outperform existi...</td>\n",
       "      <td>Their model outperforms existing methods by ap...</td>\n",
       "      <td>Answer with content missing: (Table II) Propos...</td>\n",
       "      <td>We compare our best F1 score with other state-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>What is the performance of their model?</td>\n",
       "      <td>The model has a competitive advantage in deali...</td>\n",
       "      <td>Answer with content missing: (Table II) Propos...</td>\n",
       "      <td>We compare our best F1 score with other state-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>How do they damage different neural modules?</td>\n",
       "      <td>They damage different neural modules by random...</td>\n",
       "      <td>Damage to neural modules is done by randomly i...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results for artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>How long are the datasets?</td>\n",
       "      <td>The datasets are of varying lengths, with the ...</td>\n",
       "      <td>Travel dataset contains 4100 raw samples, 1129...</td>\n",
       "      <td>We compile three Chinese text corpora from onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>What are the sources of the data?</td>\n",
       "      <td>Online user reviews from the hotel, mobile pho...</td>\n",
       "      <td>User reviews written in Chinese collected onli...</td>\n",
       "      <td>We compile three Chinese text corpora from onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>What is the new labeling strategy?</td>\n",
       "      <td>Two-stage labeling strategy</td>\n",
       "      <td>They use a two-stage labeling strategy where i...</td>\n",
       "      <td>We address the above issues with a new methodo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>How are their changes evaluated?</td>\n",
       "      <td>The changes are evaluated based on the accurac...</td>\n",
       "      <td>The changes are evaluated based on accuracy of...</td>\n",
       "      <td>To evaluate the performance of our approach, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>What are the six target languages?</td>\n",
       "      <td>English, Spanish, French, German, Italian, and...</td>\n",
       "      <td>Answer with content missing: (3 Experimental S...</td>\n",
       "      <td>Given the initial distributional or specialise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>What is the size of the released dataset?</td>\n",
       "      <td>2247 triples</td>\n",
       "      <td>440 sentences, 2247 triples extracted from tho...</td>\n",
       "      <td>We used two different data sources in our eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Which OpenIE systems were used?</td>\n",
       "      <td>OpenIE 4 BIBREF5 and MinIE BIBREF7</td>\n",
       "      <td>OpenIE4 and MiniIE</td>\n",
       "      <td>We evaluate two OIE systems (i.e. extractors)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>how are the bidirectional lms obtained?</td>\n",
       "      <td>The bidirectional LMs are obtained by concaten...</td>\n",
       "      <td>They pre-train forward and backward LMs separa...</td>\n",
       "      <td>In our final system, after pre-training the fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>what metrics are used in evaluation?</td>\n",
       "      <td>micro-averaged INLINEFORM0</td>\n",
       "      <td>micro-averaged F1</td>\n",
       "      <td>We evaluate our approach on two well benchmark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>what results do they achieve?</td>\n",
       "      <td>* For the CoNLL 2003 NER task, the authors ach...</td>\n",
       "      <td>91.93% F1 score on CoNLL 2003 NER task and 96....</td>\n",
       "      <td>Our main contribution is to show that the cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>what previous systems were compared to?</td>\n",
       "      <td>Previous systems compared to are those without...</td>\n",
       "      <td>Chiu and Nichols (2016), Lample et al. (2016),...</td>\n",
       "      <td>Tables TABREF15 and TABREF16 compare results f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Are this models usually semi/supervised or uns...</td>\n",
       "      <td>Semi/supervised.\\n\\nThese models are trained o...</td>\n",
       "      <td>Both supervised and unsupervised, depending on...</td>\n",
       "      <td>Machine translation finds use in cheminformati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>When they say \"comparable performance\", how mu...</td>\n",
       "      <td>A negligible performance drop</td>\n",
       "      <td>Performance was comparable, with the proposed ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Results on test data....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>What types of word representations are they ev...</td>\n",
       "      <td>Both GloVe and SGNS are evaluating word embedd...</td>\n",
       "      <td>GloVE; SGNS</td>\n",
       "      <td>We trained word embeddings using either GloVe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>What type of recurrent layers does the model use?</td>\n",
       "      <td>GRU (Gated Recurrent Units)</td>\n",
       "      <td>GRU</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: The proposed model w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>What is a word confusion network?</td>\n",
       "      <td>A word confusion network (cnet) is a type of i...</td>\n",
       "      <td>It is a network used to encode speech lattices...</td>\n",
       "      <td>We take a first step towards integrating ASR i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>What evaluation metrics were used in the exper...</td>\n",
       "      <td>BIBREF16, accuracy, and MRR (Mean Reciprocal R...</td>\n",
       "      <td>For sentence-level prediction they used tolera...</td>\n",
       "      <td>Metrics. We use tolerance accuracy BIBREF16, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>What kind of instructional videos are in the d...</td>\n",
       "      <td>Screencast tutorial videos</td>\n",
       "      <td>tutorial videos for a photo-editing software</td>\n",
       "      <td>The remainder of this paper is structured as f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>What baseline algorithms were presented?</td>\n",
       "      <td>Baseline1, Baseline2, and Baseline3</td>\n",
       "      <td>a sentence-level prediction algorithm, a segme...</td>\n",
       "      <td>Our video question answering task is novel and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>How does TP-N2F compare to LSTM-based Seq2Seq ...</td>\n",
       "      <td>TP-N2F is faster than LSTM-based Seq2Seq in bo...</td>\n",
       "      <td>Full Testing Set accuracy: 84.02\\nCleaned Test...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results of AlgoLisp d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>What is the performance proposed model achieve...</td>\n",
       "      <td>State-of-the-art performance on both the full ...</td>\n",
       "      <td>Full Testing Set Accuracy: 84.02\\nCleaned Test...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results of AlgoLisp d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>What is the performance proposed model achieve...</td>\n",
       "      <td>The proposed model achieved an execution accur...</td>\n",
       "      <td>Operation accuracy: 71.89\\nExecution accuracy:...</td>\n",
       "      <td>Given a natural-language math problem, we need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>What previous methods is the proposed method c...</td>\n",
       "      <td>The proposed method is compared against previo...</td>\n",
       "      <td>BLSTM+Attention+BLSTM\\nHierarchical BLSTM-CRF\\...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Comparison results wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>What is the baseline model used?</td>\n",
       "      <td>DrQA+CoQA</td>\n",
       "      <td>The baseline models used are DrQA modified to ...</td>\n",
       "      <td>DrQA is a CRC baseline coming with the CoQA da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>What domains are present in the data?</td>\n",
       "      <td>Services (salons, dentists, doctors, etc.)</td>\n",
       "      <td>Alarm, Banks, Buses, Calendar, Events, Flights...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: The total number of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>How many texts/datapoints are in the SemEval, ...</td>\n",
       "      <td>* SemEval: 12,345\\n* TASS: 10,246\\n* SENTIPOLC...</td>\n",
       "      <td>Total number of annotated data:\\nSemeval'15: 1...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Datasets details from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>In which languages did the approach outperform...</td>\n",
       "      <td>Arabic.\\n\\nAccording to the context, the appro...</td>\n",
       "      <td>Arabic, German, Portuguese, Russian, Swedish</td>\n",
       "      <td>In BIBREF3 , BIBREF2 , the authors study the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Which is the baseline model?</td>\n",
       "      <td>AG-RNN-LID</td>\n",
       "      <td>The three baseline models are the i-vector mod...</td>\n",
       "      <td>As the first step, we build three baseline LID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>What is the main contribution of the paper?</td>\n",
       "      <td>The main contribution of the paper is the prop...</td>\n",
       "      <td>Proposing an improved RNN model, the phonetic ...</td>\n",
       "      <td>All the present neural LID methods are based o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>How do they get the formal languages?</td>\n",
       "      <td>They get the formal languages from a context-f...</td>\n",
       "      <td>These are well-known formal languages some of ...</td>\n",
       "      <td>BIBREF7 investigated the learning capabilities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>What is a confusion network or lattice?</td>\n",
       "      <td>A confusion network or lattice is a graph-like...</td>\n",
       "      <td>graph-like structures where arcs connect nodes...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 2: Standard ASR outputs A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>How close do clusters match to ground truth to...</td>\n",
       "      <td>The clusters match ground truth tone categorie...</td>\n",
       "      <td>NMI between cluster assignments and ground tru...</td>\n",
       "      <td>To test this hypothesis, we evaluate the model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>what are the evaluation metrics?</td>\n",
       "      <td>Precision, Recall, F1 score</td>\n",
       "      <td>Precision, Recall, F1</td>\n",
       "      <td>FLOAT SELECTED: Table 5: CoNLL 2003 English re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>which datasets were used in evaluation?</td>\n",
       "      <td>SONAR-1 and Ancora 2.0</td>\n",
       "      <td>CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkar...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Datasets used for tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>what are the baselines?</td>\n",
       "      <td>local features</td>\n",
       "      <td>Perceptron model using the local features.</td>\n",
       "      <td>Our system learns Perceptron models BIBREF37 u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>What monolingual word representations are used?</td>\n",
       "      <td>AraVec for Arabic, FastText for French, and Wo...</td>\n",
       "      <td>AraVec for Arabic, FastText for French, and Wo...</td>\n",
       "      <td>Feature-based models. We used state-of-the-art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Do they build one model per topic or on all to...</td>\n",
       "      <td>They build one model per topic</td>\n",
       "      <td>One model per topic.</td>\n",
       "      <td>The turkers are asked to indicate their prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Do they quantitavely or qualitatively evalute ...</td>\n",
       "      <td>Quantitatively</td>\n",
       "      <td>They evaluate quantitatively.</td>\n",
       "      <td>In this section, we evaluate the proposed meth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>How well does their system perform on the deve...</td>\n",
       "      <td>The system achieves a relative improvement of ...</td>\n",
       "      <td>EER 16.04, Cmindet 0.6012, Cdet 0.6107</td>\n",
       "      <td>In this section we present the results obtaine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>Which of the classifiers showed the best perfo...</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Logistic regression</td>\n",
       "      <td>FLOAT SELECTED: TABLE II: A comparison of clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>How are the keywords associated with events su...</td>\n",
       "      <td>By using a Bayesian approach to learn which te...</td>\n",
       "      <td>By using a Bayesian approach  and by using wor...</td>\n",
       "      <td>We approached the first and second challenges ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>What is different in BERT-gen from standard BERT?</td>\n",
       "      <td>The use of a left-to-right attention mask to r...</td>\n",
       "      <td>They use a left-to-right attention mask so tha...</td>\n",
       "      <td>As we iteratively concatenate the generated to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>How are multimodal representations combined?</td>\n",
       "      <td>The multimodal representations are combined us...</td>\n",
       "      <td>The image feature vectors are mapped into BERT...</td>\n",
       "      <td>To investigate whether our BERT-based model ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>What is the problem with existing metrics that...</td>\n",
       "      <td>Existing metrics do not accurately capture the...</td>\n",
       "      <td>Answer with content missing: (whole introducti...</td>\n",
       "      <td>Building Extractive CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>How are discourse embeddings analyzed?</td>\n",
       "      <td>T-SNE clustering is used to analyze discourse ...</td>\n",
       "      <td>They perform t-SNE clustering to analyze disco...</td>\n",
       "      <td>To further study the information encoded in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>How are discourse features incorporated into t...</td>\n",
       "      <td>Discourse features are incorporated into the m...</td>\n",
       "      <td>They derive entity grid with grammatical relat...</td>\n",
       "      <td>CNN2-PV. This model (Figure FIGREF10 , left+ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>What discourse features are used?</td>\n",
       "      <td>GR and RST discourse features</td>\n",
       "      <td>Entity grid with grammatical relations and RST...</td>\n",
       "      <td>CNN2-PV. This model (Figure FIGREF10 , left+ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>What are proof paths?</td>\n",
       "      <td>Proof paths are the sequences of proof states ...</td>\n",
       "      <td>A sequence of logical statements represented i...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1. A visual depiction o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>What external sources are used?</td>\n",
       "      <td>Raw Text, Automatically Segmented Text, Hetero...</td>\n",
       "      <td>Raw data from Gigaword, Automatically segmente...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Statistics of externa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>How much better peformance is achieved in huma...</td>\n",
       "      <td>The proposed comparative evaluator with skill ...</td>\n",
       "      <td>Pearson correlation to human judgement - propo...</td>\n",
       "      <td>The experimental results are summarized in Tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>How much transcribed data is available for for...</td>\n",
       "      <td>16 hours and 48 minutes of transcribed Ainu la...</td>\n",
       "      <td>Transcribed data is available for duration of ...</td>\n",
       "      <td>The corpus we have prepared for ASR in this st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>What baseline approaches do they compare against?</td>\n",
       "      <td>Previous best results</td>\n",
       "      <td>HotspotQA: Yang, Ding, Muppet\\nFever: Hanselow...</td>\n",
       "      <td>We chose the best system based on the dev set,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>how many domains did they experiment with?</td>\n",
       "      <td>2 domains</td>\n",
       "      <td>2</td>\n",
       "      <td>We demonstrated the utility of Katecheo by dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>How long is the dataset?</td>\n",
       "      <td>The dataset contains 4000 reviews (1000 positi...</td>\n",
       "      <td>8000</td>\n",
       "      <td>Data set. For the cross-domain polarity classi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>What is a string kernel?</td>\n",
       "      <td>A string kernel is a method for measuring the ...</td>\n",
       "      <td>String kernel is a technique that uses charact...</td>\n",
       "      <td>In recent years, methods based on string kerne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>How do they correlate NED with emotional bond ...</td>\n",
       "      <td>They compute the correlation of the proposed N...</td>\n",
       "      <td>They compute Pearson’s correlation between NED...</td>\n",
       "      <td>According to prior work, both from domain theo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>What was their F1 score on the Bengali NER cor...</td>\n",
       "      <td>5.5 points F1</td>\n",
       "      <td>52.0%</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Bengali manual annota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>What is the size of the dataset?</td>\n",
       "      <td>300,000 sentences</td>\n",
       "      <td>300,000 sentences with 1.5 million single-quiz...</td>\n",
       "      <td>Using our platform, we extracted anonymized us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>How many examples do they have in the target d...</td>\n",
       "      <td>0</td>\n",
       "      <td>Around 388k examples, 194k from tst2013 (in-do...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: German→English: Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>What is the baseline model?</td>\n",
       "      <td>ATTS2S BIBREF8</td>\n",
       "      <td>a RNN-based seq2seq VC model called ATTS2S bas...</td>\n",
       "      <td>Next, we compared our VTN model with an RNN-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Where did they get training data?</td>\n",
       "      <td>Table 1</td>\n",
       "      <td>AmazonQA and ConciergeQA datasets</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Precision (P), Recall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>What extraction model did they use?</td>\n",
       "      <td>Multi-Encoder, Constrained-Decoder model</td>\n",
       "      <td>Multi-Encoder, Constrained-Decoder model</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Multi-Encoder, Const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Which datasets did they experiment on?</td>\n",
       "      <td>Table 1</td>\n",
       "      <td>ConciergeQA and AmazonQA</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Various types of trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>How do slot binary classifiers improve perform...</td>\n",
       "      <td>Slot binary classifiers improve performance by...</td>\n",
       "      <td>by adding extra supervision to generate the sl...</td>\n",
       "      <td>This paper proposes the Flexibly-Structured Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>What baselines have been used in this work?</td>\n",
       "      <td>NDM BIBREF7, LIDM BIBREF9, KVRN BIBREF13, and ...</td>\n",
       "      <td>NDM, LIDM, KVRN, and TSCP/RL</td>\n",
       "      <td>We compare FSDM with four baseline methods and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>what bottlenecks were identified?</td>\n",
       "      <td>Confusion among active words at certain nodes ...</td>\n",
       "      <td>Confusion in recognizing the words that are ac...</td>\n",
       "      <td>In this paper we proposed a methodology to ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>By how much do they outperform BiLSTMs in Sent...</td>\n",
       "      <td>They outperform BiLSTMs in Sentiment Analysis ...</td>\n",
       "      <td>Proposed RCRN outperforms ablative baselines B...</td>\n",
       "      <td>On the 16 review datasets (Table TABREF22 ) fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>what state of the accuracy did they obtain?</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>51.5</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracies on the Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>what models did they compare to?</td>\n",
       "      <td>the models compared to are tree-LSTM BIBREF21,...</td>\n",
       "      <td>High-order CNN, Tree-LSTM, DRNN, DCNN, CNN-MC,...</td>\n",
       "      <td>The test-set accuracies obtained by different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>which benchmark tasks did they experiment on?</td>\n",
       "      <td>sentiment classification and text classification</td>\n",
       "      <td>They used Stanford Sentiment Treebank benchma...</td>\n",
       "      <td>Experiments on two benchmark data sets, the St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>How is the proficiency score calculated?</td>\n",
       "      <td>The proficiency score is calculated by summing...</td>\n",
       "      <td>They used 6 indicators for proficiency (same f...</td>\n",
       "      <td>Tables and report some statistics extracted fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>What proficiency indicators are used to the sc...</td>\n",
       "      <td>6 proficiency indicators are used to score the...</td>\n",
       "      <td>6 indicators:\\n- lexical richness\\n- pronuncia...</td>\n",
       "      <td>FLOAT SELECTED: Table 4: List of the indicator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>What accuracy is achieved by the speech recogn...</td>\n",
       "      <td>The speech recognition system achieves an accu...</td>\n",
       "      <td>Accuracy not available: WER results are report...</td>\n",
       "      <td>Table , extracted from BIBREF0, reports WERs o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>How is the speech recognition system evaluated?</td>\n",
       "      <td>WER (Word Error Rate) is used to evaluate the ...</td>\n",
       "      <td>Speech recognition system is evaluated using W...</td>\n",
       "      <td>Table , extracted from BIBREF0, reports WERs o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>How many of the utterances are transcribed?</td>\n",
       "      <td>75.6% of the utterances are transcribed</td>\n",
       "      <td>Total number of transcribed utterances includi...</td>\n",
       "      <td>Speakers were assigned either to training or e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>How many utterances are in the corpus?</td>\n",
       "      <td>2000</td>\n",
       "      <td>Total number of utterances available is: 70607...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Spoken data collected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>By how much does their model outperform both t...</td>\n",
       "      <td>Their model outperforms both state-of-the-art ...</td>\n",
       "      <td>w.r.t Rouge-1 their model outperforms by 0.98%...</td>\n",
       "      <td>Evaluation on DUC2004: DUC 2004 ( BIBREF15 ) i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>What is the state-of-the art?</td>\n",
       "      <td>The state-of-the-art is the `Read-Again' encod...</td>\n",
       "      <td>neural attention model with a convolutional en...</td>\n",
       "      <td>Very recently, the success of deep neural netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>What was the performance on the self-collected...</td>\n",
       "      <td>🔥 OUTPERFORMED THE BASELINE 🔥</td>\n",
       "      <td>F1 scores of 86.16 on slot filling and 94.56 o...</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Results on our CAIS d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>What is the size of their dataset?</td>\n",
       "      <td>1000</td>\n",
       "      <td>10,001 utterances</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Dataset statistics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>how was the dataset built?</td>\n",
       "      <td>The dataset was built by gathering queries fro...</td>\n",
       "      <td>Questions are gathered from anonymized, aggreg...</td>\n",
       "      <td>Questions are gathered from anonymized, aggreg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>what processing was done on the speeches befor...</td>\n",
       "      <td>The speeches were pre-processed by removing al...</td>\n",
       "      <td>Remove numbers and interjections</td>\n",
       "      <td>To estimate speakers' position we use Wordscor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>What is the performance change of the textual ...</td>\n",
       "      <td>There is a significant decrease in performance...</td>\n",
       "      <td>10 Epochs: pearson-Spearman correlation  drops...</td>\n",
       "      <td>Figure FIGREF12stsa and FIGREF12stsb shows Pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Which sentiment analysis data set has a larger...</td>\n",
       "      <td>SST-2.\\n\\nBased on the plots in Figures FIGREF...</td>\n",
       "      <td>SST-2 dataset</td>\n",
       "      <td>Let us discuss the results from the above ment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>How much is pre-training loss increased in Low...</td>\n",
       "      <td>The pre-training loss increases linearly with ...</td>\n",
       "      <td>The increase is linearly from lowest on averag...</td>\n",
       "      <td>We've seen that over-pruning BERT deletes info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>What is the average length of the recordings?</td>\n",
       "      <td>30-50 minutes</td>\n",
       "      <td>40 minutes</td>\n",
       "      <td>Each game's video ranges from 30 to 50 minutes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>What were their results?</td>\n",
       "      <td>The results were not significant</td>\n",
       "      <td>Best model achieved F-score 74.7 on NALCS and ...</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Test Results on the N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>What is the prediction accuracy of the model?</td>\n",
       "      <td>85.6%</td>\n",
       "      <td>mean prediction accuracy 0.99582651\\nS&amp;P 500 A...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Predicted Mean MPA re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>What is the dataset used in the paper?</td>\n",
       "      <td>The dataset used in the paper is a collection ...</td>\n",
       "      <td>historical S&amp;P 500 component stocks\\n 306242 n...</td>\n",
       "      <td>The data for this project are two parts, the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>How does the SCAN dataset evaluate composition...</td>\n",
       "      <td>By systematically holding out the training set...</td>\n",
       "      <td>it systematically holds out inputs in the trai...</td>\n",
       "      <td>A recently published dataset called SCAN BIBRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>How much does this system outperform prior work?</td>\n",
       "      <td>This system outperforms prior work by approxim...</td>\n",
       "      <td>The system outperforms by 27.7% the LSTM model...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracy on the ListO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>What are the baseline systems that are compare...</td>\n",
       "      <td>The baseline systems are compared against Rand...</td>\n",
       "      <td>The system is compared to baseline models: LST...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Accuracy on the ListO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>What systems are tested?</td>\n",
       "      <td>The systems tested are the VoxCeleb-based syst...</td>\n",
       "      <td>BULATS i-vector/PLDA\\nBULATS x-vector/PLDA\\nVo...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. % EER performance of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>What benchmark datasets they use?</td>\n",
       "      <td>VQA and GeoQA</td>\n",
       "      <td>VQA and GeoQA</td>\n",
       "      <td>Our first task is the recently-introduced Visu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>How do they combine MonaLog with BERT?</td>\n",
       "      <td>They hybridize MonaLog with BERT for compositi...</td>\n",
       "      <td>They use Monalog for data-augmentation to fine...</td>\n",
       "      <td>In this work, we introduce a new logical infer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>How do they select monotonicity facts?</td>\n",
       "      <td>MonaLog selects monotonicity facts based on th...</td>\n",
       "      <td>They derive it from Wordnet</td>\n",
       "      <td>MonaLog utilizes two auxiliary sets. First, a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>What are the 12 categories devised?</td>\n",
       "      <td>12 categories devised are Institute1, Institut...</td>\n",
       "      <td>Economics, Genocide, Geography, History, Human...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistics of the cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>what are the off-the-shelf systems discussed i...</td>\n",
       "      <td>There are several off-the-shelf systems discus...</td>\n",
       "      <td>Answer with content missing: (Names of many id...</td>\n",
       "      <td>TextCat is the most well-known Perl implementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>How many rules had to be defined?</td>\n",
       "      <td>3 rules</td>\n",
       "      <td>WikiSQL - 2 rules (SELECT, WHERE)\\nSimpleQuest...</td>\n",
       "      <td>We describe our rules for WikiSQL here. We fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>What was performance of classifiers before/aft...</td>\n",
       "      <td>Before using distant supervision, the classifi...</td>\n",
       "      <td>Bi-LSTM: For low resource &lt;17k clean data: Usi...</td>\n",
       "      <td>The experimental results for Yorùbá are given ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>How big are the datasets used?</td>\n",
       "      <td>The datasets used are CMRC 2018 (simplified Ch...</td>\n",
       "      <td>Evaluation datasets used:\\nCMRC 2018 - 18939 q...</td>\n",
       "      <td>We evaluate our approaches on two public Chine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>What datasets are used for training/testing mo...</td>\n",
       "      <td>The dataset used for training/testing models i...</td>\n",
       "      <td>Microsoft Research dataset containing movie, t...</td>\n",
       "      <td>The experiment dataset comes from Microsoft Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>How better is gCAS approach compared to other ...</td>\n",
       "      <td>gCAS approach is better than other approaches ...</td>\n",
       "      <td>For entity  F1 in the movie, taxi and restaura...</td>\n",
       "      <td>FLOAT SELECTED: Table 5: Entity F1 and Success...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>What is specific to gCAS cell?</td>\n",
       "      <td>The gCAS cell is specific in that it is compos...</td>\n",
       "      <td>It has three sequentially connected units to o...</td>\n",
       "      <td>In this paper, we introduce a novel policy mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>What is the source of external knowledge?</td>\n",
       "      <td>English Wikipedia</td>\n",
       "      <td>counts of predicate-argument tuples from Engli...</td>\n",
       "      <td>The second type is the selectional preference ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>What were the sizes of the test sets?</td>\n",
       "      <td>Test Set 1: 57 drug labels\\nTest Set 2: 66 dru...</td>\n",
       "      <td>Test set 1 contained 57 drug labels and 8208 s...</td>\n",
       "      <td>Each drug label is a collection of sections (e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Which datasets are used?</td>\n",
       "      <td>The datasets used are:\\n\\n* ABSA SemEval 2014-...</td>\n",
       "      <td>ABSA SemEval 2014-2016 datasets\\nYelp Academic...</td>\n",
       "      <td>Table TABREF7 shows the ABSA datasets from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>How much does it minimally cost to fine-tune s...</td>\n",
       "      <td>$12.36 per hour</td>\n",
       "      <td>$1,728</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Pretraining costs of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>What models are included in baseline benchmark...</td>\n",
       "      <td>DistilBERT, BERT, and RoBERTa</td>\n",
       "      <td>BERT, XLNET RoBERTa, ALBERT, DistilBERT</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Pretraining costs of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>It looks like learning to paraphrase questions...</td>\n",
       "      <td>They are trained separately.\\n\\nIn the context...</td>\n",
       "      <td>using multiple pivot sentences</td>\n",
       "      <td>BIBREF11 revisit bilingual pivoting in the con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>How much more accurate is the model than the b...</td>\n",
       "      <td>NAGM is significantly more accurate than the b...</td>\n",
       "      <td>For the Oshiete-goo dataset, the NAGM model's ...</td>\n",
       "      <td>NAGMWA is much better than the other methods e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>What is new state-of-the-art performance on Co...</td>\n",
       "      <td>RelAwe with DepPath&amp;RelPath achieves new state...</td>\n",
       "      <td>In closed setting 84.22 F1 and in open 87.35 F1.</td>\n",
       "      <td>Table TABREF46 shows that our Open model achie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>What are two strong baseline methods authors r...</td>\n",
       "      <td>BERT and RoBERTa</td>\n",
       "      <td>Marcheggiani and Titov (2017) and Cai et al. (...</td>\n",
       "      <td>FLOAT SELECTED: Table 7: SRL results on the Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>How many category tags are considered?</td>\n",
       "      <td>4</td>\n",
       "      <td>14 categories</td>\n",
       "      <td>FLOAT SELECTED: Figure 5. The results are spli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>What domain does the dataset fall into?</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>YouTube videos</td>\n",
       "      <td>We perform our experiments using ActivityNet C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>How are EAC evaluated?</td>\n",
       "      <td>EACs are evaluated using a combination of qual...</td>\n",
       "      <td>Qualitatively through efficiency, effectivenes...</td>\n",
       "      <td>We characterize the evaluation of Emotionally-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>What is triangulation?</td>\n",
       "      <td>Triangulation is a method used to determine th...</td>\n",
       "      <td>Answer with content missing: (Chapter 3) The c...</td>\n",
       "      <td>Conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>What languages do they use?</td>\n",
       "      <td>English, Spanish, Arabic, and Mandarin Chinese</td>\n",
       "      <td>Train languages are: Cantonese, Bengali, Pasht...</td>\n",
       "      <td>In this work, the experiments are conducted us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>How they evaluate their approach?</td>\n",
       "      <td>Sure! Here's the answer to the question based ...</td>\n",
       "      <td>They  evaluate newly proposed models in severa...</td>\n",
       "      <td>Our contributions are as follows: We propose t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>How large is the corpus?</td>\n",
       "      <td>The corpus contains 5 languages (English, Ital...</td>\n",
       "      <td>It contains 106,350 documents</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistical summary o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>How large is the dataset?</td>\n",
       "      <td>The dataset is quite large, with over 100,000 ...</td>\n",
       "      <td>over 104k documents</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Statistical summary o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>What was their perplexity score?</td>\n",
       "      <td>3.58 BLEU points</td>\n",
       "      <td>Perplexity score 142.84 on dev and 138.91 on test</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Language Modeling Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>What parallel corpus did they use?</td>\n",
       "      <td>They used a parallel corpus of English and Man...</td>\n",
       "      <td>Parallel monolingual corpus in English and Man...</td>\n",
       "      <td>In this section, we present the experimental s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>In which setting they achieve the state of the...</td>\n",
       "      <td>Ours+VGG(2) setting</td>\n",
       "      <td>in open-ended task esp. for counting-type ques...</td>\n",
       "      <td>FLOAT SELECTED: Table 4. Evaluation results on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>What they formulate the question generation as?</td>\n",
       "      <td>LASSO optimization problem</td>\n",
       "      <td>LASSO optimization problem</td>\n",
       "      <td>Our idea is the BQ generation for MQ and, at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Was the degree of offensiveness taken as how g...</td>\n",
       "      <td>The degree of offensiveness was based on how p...</td>\n",
       "      <td>Personal thought of the annotator.</td>\n",
       "      <td>The surveys consisted of 20 tweets presented i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>Which embeddings do they detect biases in?</td>\n",
       "      <td>BIBREF2 and Reddit dataset</td>\n",
       "      <td>Word embeddings trained on GoogleNews and Word...</td>\n",
       "      <td>For both word2vec BIBREF0 and gensim BIBREF7 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>What are the two PharmaCoNER subtasks?</td>\n",
       "      <td>Subtask 1: Identifying entities with offsets a...</td>\n",
       "      <td>Entity identification with offset mapping and ...</td>\n",
       "      <td>Although the competition proposes two differen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>How do they perform data augmentation?</td>\n",
       "      <td>They perform data augmentation by adding sente...</td>\n",
       "      <td>They randomly sample sentences from Wikipedia ...</td>\n",
       "      <td>We first inspect the frequencies of object and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>What are the characteristics of the city dialect?</td>\n",
       "      <td>The city dialect is characterized by a more un...</td>\n",
       "      <td>Lexicon of the cities tend to use most forms o...</td>\n",
       "      <td>After averaging over all concepts, we lose inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>What are the characteristics of the rural dial...</td>\n",
       "      <td>The rural dialect has more specific words in i...</td>\n",
       "      <td>It uses particular forms of a concept rather t...</td>\n",
       "      <td>After averaging over all concepts, we lose inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>What is the performance of the models on the t...</td>\n",
       "      <td>The performance of the models on the tasks is ...</td>\n",
       "      <td>Overall accuracy per model is: 5-gram (60.5), ...</td>\n",
       "      <td>An LM's overall performance on *X can be measu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>What other non-neural baselines do the authors...</td>\n",
       "      <td>BoW and BIBREF31</td>\n",
       "      <td>bag of words, tf-idf, bag-of-means</td>\n",
       "      <td>is the standard word counting method whereby t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>On what dataset is Aristo system trained?</td>\n",
       "      <td>Aristo system is trained on the ARC dataset</td>\n",
       "      <td>Aristo Corpus\\nRegents 4th\\nRegents 8th\\nRegen...</td>\n",
       "      <td>Several methods make use of the Aristo Corpus,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>How many roles are proposed?</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Most common syntactic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>What language technologies have been introduce...</td>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>- Font &amp; Keyboard\\n- Speech-to-Text\\n- Text-to...</td>\n",
       "      <td>Often, many state-of-the-art tools cannot be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>How do they define local variance?</td>\n",
       "      <td>Local variance is defined as the reciprocal of...</td>\n",
       "      <td>The reciprocal of the variance of the attentio...</td>\n",
       "      <td>As discussed in section SECREF1, the attention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>how do they measure discussion quality?</td>\n",
       "      <td>through the annotation scheme, which captures ...</td>\n",
       "      <td>Measuring three aspects: argumentation, specif...</td>\n",
       "      <td>As a first step towards developing an automate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>what were the baselines?</td>\n",
       "      <td>The baselines were pre-identified predicates a...</td>\n",
       "      <td>2008 Punyakanok et al. \\n2009 Zhao et al. + ME...</td>\n",
       "      <td>Generally, the above work is summarized in Tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>Which soft-selection approaches are evaluated?</td>\n",
       "      <td>Soft-selection approaches evaluated are attent...</td>\n",
       "      <td>LSTM and BERT</td>\n",
       "      <td>Previous attention-based methods can be catego...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>How big is slot filing dataset?</td>\n",
       "      <td>The slot filling dataset has approximately 22,...</td>\n",
       "      <td>Dataset has 1737 train, 497 dev and 559 test s...</td>\n",
       "      <td>In our experiments, we use Onsei Intent Slot d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>How large is the dataset they generate?</td>\n",
       "      <td>The dataset they generate is 10,000 sentences</td>\n",
       "      <td>4.756 million sentences</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Number of run-on (RO)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>What are the weaknesses of their proposed inte...</td>\n",
       "      <td>Bias due to dataset selection and word coverage</td>\n",
       "      <td>can be biased by dataset used and may generate...</td>\n",
       "      <td>Our interpretability measurements are based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>What advantages does their proposed method of ...</td>\n",
       "      <td>Their proposed method of quantifying interpret...</td>\n",
       "      <td>it is less expensive and quantifies interpreta...</td>\n",
       "      <td>In the word embedding literature, the problem ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>How was lexical diversity measured?</td>\n",
       "      <td>Lexical diversity was measured by comparing th...</td>\n",
       "      <td>By computing number of unique responses and nu...</td>\n",
       "      <td>To study the lexical and semantic diversities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>Which existing models does this approach outpe...</td>\n",
       "      <td>This approach outperforms the existing BART an...</td>\n",
       "      <td>RNN-context, SRB, CopyNet, RNN-distract, DRGD</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Comparisons with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>What human evaluation method is proposed?</td>\n",
       "      <td>Simple human evaluation method</td>\n",
       "      <td>comparing the summary with the text instead of...</td>\n",
       "      <td>More detailed explanation is introduced in Sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>What languages are represented in the dataset?</td>\n",
       "      <td>English and Japanese are the most represented ...</td>\n",
       "      <td>EN, JA, ES, AR, PT, KO, TH, FR, TR, RU, IT, DE...</td>\n",
       "      <td>FLOAT SELECTED: Table 2. Twitter corpus distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>How faster is training and decoding compared t...</td>\n",
       "      <td>Our model is faster than former models in both...</td>\n",
       "      <td>Proposed vs best baseline:\\nDecoding: 8541 vs ...</td>\n",
       "      <td>In order to verify the time complexity analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>What datasets are used to evaluate the model?</td>\n",
       "      <td>WN18 and FB15k</td>\n",
       "      <td>WN18 and FB15k</td>\n",
       "      <td>FLOAT SELECTED: Table 1: The knowledge base co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>What is the source of the dataset?</td>\n",
       "      <td>The dataset is sourced from a combination of m...</td>\n",
       "      <td>Online sites tagged as fake news site by Veraf...</td>\n",
       "      <td>We work with a dataset composed of 3,206 news ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>What were the baselines?</td>\n",
       "      <td>The baseline model used in this study is a Sia...</td>\n",
       "      <td>Siamese neural network consisting of an embedd...</td>\n",
       "      <td>We use a siamese neural network, shown to perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>What metadata is included?</td>\n",
       "      <td>* Claim instance ID\\n* Entity mention ID\\n* En...</td>\n",
       "      <td>besides claim, label and claim url, it also in...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: An example of a claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Do the images have multilingual annotations or...</td>\n",
       "      <td>Monolingual annotations</td>\n",
       "      <td>monolingual</td>\n",
       "      <td>We experiment using a dataset derived from Goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>How much important is the visual grounding in ...</td>\n",
       "      <td>Sure! Here's my answer based on the provided c...</td>\n",
       "      <td>performance is significantly degraded without ...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Crosslingual semantic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>How is the generative model evaluated?</td>\n",
       "      <td>The generative model is evaluated using BLEU s...</td>\n",
       "      <td>Comparing BLEU score of model with and without...</td>\n",
       "      <td>We train an LSTM with and without attention on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>What is an example of a health-related tweet?</td>\n",
       "      <td>A health-related tweet could be \"Just finished...</td>\n",
       "      <td>The health benefits of alcohol consumption are...</td>\n",
       "      <td>FLOAT SELECTED: Fig. 1. Proposed representatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>What is the challenge for other language excep...</td>\n",
       "      <td>Lack of annotated datasets and linguistic feat...</td>\n",
       "      <td>not researched as much as English</td>\n",
       "      <td>Given the fact that the research on offensive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>How many categories of offensive language were...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>In sub-task C the goal is to classify the targ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Which matching features do they employ?</td>\n",
       "      <td>Multi-perspective matching features</td>\n",
       "      <td>Matching features from matching sentences from...</td>\n",
       "      <td>In this paper, we propose the MIMN model for N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>By how much does their method outperform the m...</td>\n",
       "      <td>1.75x</td>\n",
       "      <td>Their average improvement in Character Error R...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Experimental results.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>How large is the corpus they use?</td>\n",
       "      <td>100,000 words</td>\n",
       "      <td>449050</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Experimental conditions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>How many shared layers are in the system?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Optimal hyperparamete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>How many additional task-specific layers are i...</td>\n",
       "      <td>2</td>\n",
       "      <td>2 for the ADE dataset and 3 for the CoNLL04 da...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Optimal hyperparamete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>How many layers of self-attention does the mod...</td>\n",
       "      <td>3 layers of self-attention</td>\n",
       "      <td>1, 4, 8, 16, 32, 64</td>\n",
       "      <td>FLOAT SELECTED: Table 6: Evaluation of effect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>what are the state of the art methods?</td>\n",
       "      <td>The state-of-the-art methods for video caption...</td>\n",
       "      <td>S2VT, RGB (VGG), RGB (VGG)+Flow (AlexNet), LST...</td>\n",
       "      <td>We also evaluate our Joint-BiLSTM structure by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Which four languages do they experiment with?</td>\n",
       "      <td>English, Spanish, French, and Chinese</td>\n",
       "      <td>German, English, Italian, Chinese</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Datasets used for var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Does DCA or GMM-based attention perform better...</td>\n",
       "      <td>GMM-based attention performs better in experim...</td>\n",
       "      <td>About the same performance</td>\n",
       "      <td>FLOAT SELECTED: Table 3. MOS naturalness resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>What evaluation metric is used?</td>\n",
       "      <td>AVERAGE AND ONE STANDARD DEVIATION</td>\n",
       "      <td>F1 and Weighted-F1</td>\n",
       "      <td>FLOAT SELECTED: Table 10: Results of experimen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Is any data-to-text generation model trained o...</td>\n",
       "      <td>Yes, the results show that the NLG model train...</td>\n",
       "      <td>Yes, Transformer based seq2seq is evaluated wi...</td>\n",
       "      <td>The NLG model we use to establish a baseline f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>How are the potentially relevant text fragment...</td>\n",
       "      <td>By generating a query based on the claim's ver...</td>\n",
       "      <td>Generate a query out of the claim and queryin...</td>\n",
       "      <td>This step consists of generating a query out o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>What dataset did they use?</td>\n",
       "      <td>The datasets used in the experiment are not sp...</td>\n",
       "      <td>weibo-100k, Ontonotes, LCQMC and XNLI</td>\n",
       "      <td>Table TABREF14 shows the experiment measuring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>What is the size of the dataset?</td>\n",
       "      <td>2,425 dialogues for training, 302 for validati...</td>\n",
       "      <td>3029</td>\n",
       "      <td>We use the publicly available dataset KVRET BI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>What are the 12 AV approaches which are examined?</td>\n",
       "      <td>The 12 AV approaches examined are listed in Ta...</td>\n",
       "      <td>MOCC, OCCAV, COAV, AVeer, GLAD, DistAV, Unmask...</td>\n",
       "      <td>As a basis for our experiments, we reimplement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>how was annotation done?</td>\n",
       "      <td>Annotation was done using Amazon Mechanical Tu...</td>\n",
       "      <td>Annotation was done with the help of annotator...</td>\n",
       "      <td>With the gathered comments, we reconstructed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>How do they measure correlation between the pr...</td>\n",
       "      <td>They measure correlation between prediction an...</td>\n",
       "      <td>They look at the performance accuracy of expla...</td>\n",
       "      <td>We would expect that explanation performance s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>What are the results achieved from the introdu...</td>\n",
       "      <td>Improved accuracy and faster convergence</td>\n",
       "      <td>Their model resulted in values of 0.476, 0.672...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Comparison of differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>How do they incorporate human advice?</td>\n",
       "      <td>They incorporate human advice by explicitly re...</td>\n",
       "      <td>by converting human advice to first-order logi...</td>\n",
       "      <td>While most relational learning methods restric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>What affective-based features are used?</td>\n",
       "      <td>Emolex, EmoSenticNet, Dictionary of Affect in ...</td>\n",
       "      <td>affective features provided by different emoti...</td>\n",
       "      <td>We used the following affective resources rely...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>How big is performance improvement proposed me...</td>\n",
       "      <td>The performance improvement proposed methods a...</td>\n",
       "      <td>Data augmentation (es)  improved Adv es by 20%...</td>\n",
       "      <td>The performance of the base model described in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>By how much does transfer learning improve per...</td>\n",
       "      <td>22.6% improvement in performance</td>\n",
       "      <td>In task 1 best transfer learning strategy impr...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Transfer learning per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>What baseline is used?</td>\n",
       "      <td>Linear Support Vector Machine (BIBREF7)</td>\n",
       "      <td>SVM</td>\n",
       "      <td>The baseline classifier uses a linear Support ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>What topic clusters are identified by LDA?</td>\n",
       "      <td>LDA identifies topic clusters such as American...</td>\n",
       "      <td>Clusters of Twitter user ids from accounts of ...</td>\n",
       "      <td>For offensive language detection in Twitter, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>How much do they outperform previous state-of-...</td>\n",
       "      <td>BERT-pair models outperform previous state-of-...</td>\n",
       "      <td>On subtask 3 best proposed model has F1 score ...</td>\n",
       "      <td>Results on SemEval-2014 are presented in Table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>How big is the provided treebank?</td>\n",
       "      <td>The provided treebank consists of 1,448 tweets</td>\n",
       "      <td>1448 sentences more than the dataset from Bhat...</td>\n",
       "      <td>Recently bhat-EtAl:2017:EACLshort provided a C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>what dataset was used?</td>\n",
       "      <td>ADAPT-Microsoft dataset</td>\n",
       "      <td>The dataset from a joint ADAPT-Microsoft project</td>\n",
       "      <td>The data stems from a joint ADAPT-Microsoft pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>What are the citation intent labels in the dat...</td>\n",
       "      <td>The citation intent labels in the datasets are...</td>\n",
       "      <td>Background, extends, uses, motivation, compare...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Characteristics of Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>How is quality of annotation measured?</td>\n",
       "      <td>Quality of annotation is measured through a te...</td>\n",
       "      <td>Annotators went through various phases to make...</td>\n",
       "      <td>To control the quality, we ensured that a sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>What accuracy score do they obtain?</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>the best performing model obtained an accuracy...</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Performance evaluatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>What is the 12 class bilingual text?</td>\n",
       "      <td>Bilingual text with 12 classes</td>\n",
       "      <td>Appreciation, Satisfied, Peripheral complaint,...</td>\n",
       "      <td>FLOAT SELECTED: Table 1. Description of class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Which are the sequence model architectures thi...</td>\n",
       "      <td>LSTM-based, CNN-based, and transformer-based a...</td>\n",
       "      <td>The sequence model architectures which this me...</td>\n",
       "      <td>The sequence modeling layer models the depende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>What percentage of improvement in inference s...</td>\n",
       "      <td>Our method achieves a 3x improvement in infere...</td>\n",
       "      <td>Across 4 datasets, the best performing propose...</td>\n",
       "      <td>Table TABREF34 shows the inference speed of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>What is the metric that is measures in this pa...</td>\n",
       "      <td>ABX error rate</td>\n",
       "      <td>error rate in a minimal pair ABX discriminatio...</td>\n",
       "      <td>To test if the learned representations can sep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Was evaluation metrics and criteria were used ...</td>\n",
       "      <td>Yes, evaluation metrics and criteria were used...</td>\n",
       "      <td>BLEU scores</td>\n",
       "      <td>We train all the models on an Nvidia RTX 2080T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>What are the two decoding functions?</td>\n",
       "      <td>The two decoding functions are:\\n\\n1. The line...</td>\n",
       "      <td>a linear projection and a bijective function w...</td>\n",
       "      <td>In this case, the decoding function is a linea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>What are the domains covered in the dataset?</td>\n",
       "      <td>The domains covered in the dataset are:\\n\\n1. ...</td>\n",
       "      <td>Alarm\\nBank\\nBus\\nCalendar\\nEvent\\nFlight\\nHom...</td>\n",
       "      <td>The 17 domains (`Alarm' domain not included in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>How are the two different models trained?</td>\n",
       "      <td>BERT-BASE and BERT-LARGE are trained using dif...</td>\n",
       "      <td>They pre-train the models using 600000 article...</td>\n",
       "      <td>We use the additional INLINEFORM0 training art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>How long is the dataset?</td>\n",
       "      <td>645 articles</td>\n",
       "      <td>645, 600000</td>\n",
       "      <td>We focus primarily on the smaller data set of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>How big are negative effects of proposed techn...</td>\n",
       "      <td>NEGLIGIBLE</td>\n",
       "      <td>The negative effects were insignificant.</td>\n",
       "      <td>We have presented adaptive schedules for multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Are this techniques used in training multiling...</td>\n",
       "      <td>Yes, these techniques are used in training mul...</td>\n",
       "      <td>English to French and English to German</td>\n",
       "      <td>We extract data from the WMT'14 English-French...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>What metric is used to measure performance?</td>\n",
       "      <td>Accuracy and F1 scores are used to measure per...</td>\n",
       "      <td>Accuracy and F1 score for supervised tasks, Pe...</td>\n",
       "      <td>We use a standard set of supervised as well as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>How do Zipf and Herdan-Heap's laws differ?</td>\n",
       "      <td>Zipf's law and Herdan-Heap's law differ in the...</td>\n",
       "      <td>Zipf's law describes change of word frequency ...</td>\n",
       "      <td>Statistical characterization of languages has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>How are the synthetic examples generated?</td>\n",
       "      <td>The synthetic examples are generated using thr...</td>\n",
       "      <td>Random perturbation of Wikipedia sentences usi...</td>\n",
       "      <td>One way to expose Bleurt to a wide variety of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>By how much does the new parser outperform the...</td>\n",
       "      <td>The new parser outperforms the current state-o...</td>\n",
       "      <td>Proposed method achieves 94.5 UAS and 92.4 LAS...</td>\n",
       "      <td>Table TABREF12 compares our novel system with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>What experimental evaluation is used?</td>\n",
       "      <td>Online Learning</td>\n",
       "      <td>root mean square error between the actual and ...</td>\n",
       "      <td>Once the KryptoOracle engine was bootstrapped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>How is the architecture fault-tolerant?</td>\n",
       "      <td>KryptoOracle's architecture is fault-tolerant ...</td>\n",
       "      <td>By using Apache Spark which stores all executi...</td>\n",
       "      <td>KryptoOracle has been built in the Apache ecos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>Which elements of the platform are modular?</td>\n",
       "      <td>The platform's modular elements include its Sp...</td>\n",
       "      <td>handling large volume incoming data, sentiment...</td>\n",
       "      <td>In this paper we provide a novel real-time and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Could you tell me more about the metrics used ...</td>\n",
       "      <td>Sure! The performance evaluation metrics used ...</td>\n",
       "      <td>BLUE utilizes different metrics for each of th...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: BLUE tasks The aim of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>What are the tasks that this method has shown ...</td>\n",
       "      <td>Monolingual and cross-lingual word similarity,...</td>\n",
       "      <td>bilingual dictionary induction, monolingual an...</td>\n",
       "      <td>Our experimental results show that the propose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>Why does the model improve in monolingual spac...</td>\n",
       "      <td>The model improves in monolingual spaces becau...</td>\n",
       "      <td>because word pair similarity increases if the ...</td>\n",
       "      <td>As a complement of this analysis we show some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>How is annotation projection done when languag...</td>\n",
       "      <td>The annotation projection is done using word a...</td>\n",
       "      <td>Word alignments are generated for parallel tex...</td>\n",
       "      <td>AMR is not grounded in the input sentence, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>What's the precision of the system?</td>\n",
       "      <td>The precision of the system is 85.6% on S-Lite...</td>\n",
       "      <td>0.8320 on semantic typing, 0.7194 on entity ma...</td>\n",
       "      <td>FLOAT SELECTED: Table 3. Overall typing perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Which of the two ensembles yields the best per...</td>\n",
       "      <td>E-BERT</td>\n",
       "      <td>Answer with content missing: (Table 2) CONCAT ...</td>\n",
       "      <td>Figure FIGREF5 shows that E-BERT performs comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>What is the new initialization method proposed...</td>\n",
       "      <td>Pre-trained vector initialization</td>\n",
       "      <td>They initialize their word and entity embeddin...</td>\n",
       "      <td>Training our model implicitly embeds the vocab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>How was a quality control performed so that th...</td>\n",
       "      <td>The dataset was cleaned and quality control wa...</td>\n",
       "      <td>The authors believe that the Wikilinks corpus ...</td>\n",
       "      <td>Wikilinks can be seen as a large-scale, natura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Is it a neural model? How is it trained?</td>\n",
       "      <td>No, it is not a neural model. It is a probabil...</td>\n",
       "      <td>No, it is a probabilistic model trained by fin...</td>\n",
       "      <td>Here we describe the components of our probabi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>How they evaluate quality of generated output?</td>\n",
       "      <td>$n$-gram based similarity metrics and human ev...</td>\n",
       "      <td>Through human evaluation where they are asked ...</td>\n",
       "      <td>Automatic evaluation of Natural Language Gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>What are the four forums the data comes from?</td>\n",
       "      <td>Blackhat, Nulled, Brown, and Gazetteers</td>\n",
       "      <td>Darkode,  Hack Forums, Blackhat and Nulled.</td>\n",
       "      <td>FLOAT SELECTED: Table 3: Test set results at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>How are sentence embeddings incorporated into ...</td>\n",
       "      <td>Sentence embeddings are incorporated into the ...</td>\n",
       "      <td>BERT generates sentence embeddings that repres...</td>\n",
       "      <td>There exist many word/sentence embeddings whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>How different is the dataset size of source an...</td>\n",
       "      <td>The dataset size of the source task is usually...</td>\n",
       "      <td>the training dataset is large while the target...</td>\n",
       "      <td>The procedure of transfer learning in this wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>What type of documents are supported by the an...</td>\n",
       "      <td>PDFs and Microsoft Word documents</td>\n",
       "      <td>Variety of formats supported (PDF, Word...), u...</td>\n",
       "      <td>All the capabilities described in this paper c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>What are the strong baselines you have?</td>\n",
       "      <td>Strong baselines: 256 hidden states of LSTMs, ...</td>\n",
       "      <td>optimize single task with no synthetic data</td>\n",
       "      <td>We optimized our single-task baseline to get a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>What are causal attribution networks?</td>\n",
       "      <td>Causal attribution networks are collections of...</td>\n",
       "      <td>networks where nodes represent causes and effe...</td>\n",
       "      <td>In this work we compare causal attribution net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>how did they ask if a tweet was racist?</td>\n",
       "      <td>They used a common sense definition of racist ...</td>\n",
       "      <td>if it includes  negative utterances, negative ...</td>\n",
       "      <td>The classification of racist insults presents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>How does the model compute the likelihood of e...</td>\n",
       "      <td>The model computes the likelihood of executing...</td>\n",
       "      <td>By treating logical forms as a latent variable...</td>\n",
       "      <td>Since the training data consists only of utter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>What are state of the art methods authors comp...</td>\n",
       "      <td>Hybrid CNN BIBREF15 and LSTM with attention BI...</td>\n",
       "      <td>ISOT dataset: LLVM\\nLiar dataset: Hybrid CNN a...</td>\n",
       "      <td>Table TABREF21 shows the performance of non-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>How much improvement do they get?</td>\n",
       "      <td>11.2% improvement</td>\n",
       "      <td>Their GTRS approach got an improvement of 3.89...</td>\n",
       "      <td>FLOAT SELECTED: Table 7. Experimental results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>Which languages do they test on?</td>\n",
       "      <td>They test on various languages</td>\n",
       "      <td>Answer with content missing: (Applications sec...</td>\n",
       "      <td>Space requirements might still be considerable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>What limitations are mentioned?</td>\n",
       "      <td>Small sample size, sampling bias, low inter-ra...</td>\n",
       "      <td>deciding publisher partisanship, risk annotato...</td>\n",
       "      <td>We identified some limitations during the proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>What are the baselines?</td>\n",
       "      <td>The baselines are the scores achieved by the p...</td>\n",
       "      <td>CNN, LSTM, BERT</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results of baselines ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>What semantic features help in detecting wheth...</td>\n",
       "      <td>Content accuracy, coherence, and consistency w...</td>\n",
       "      <td>No feature is given, only discussion that sema...</td>\n",
       "      <td>Many practical fake news detection algorithms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Is the assumption that natural language is sta...</td>\n",
       "      <td>NO.\\n\\nAccording to Manning and Schütze, the a...</td>\n",
       "      <td>It is not completely valid for natural languag...</td>\n",
       "      <td>Manning and Schütze argue that, even though no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>Which models do they try out?</td>\n",
       "      <td>They try out linear and nonlinear models</td>\n",
       "      <td>DocQA, SAN, QANet, ASReader, LM, Random Guess</td>\n",
       "      <td>FLOAT SELECTED: Table 4: Performance of variou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>What are the competing models?</td>\n",
       "      <td>The competing models are:\\n\\n1. Transformer-XL...</td>\n",
       "      <td>TEACHER FORCING (TF), SCHEDULED SAMPLING (SS),...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Results on EMNLP2017 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>How is the input triple translated to a slot-f...</td>\n",
       "      <td>The input triple is translated to a slot-filli...</td>\n",
       "      <td>The relation R(x,y) is mapped onto a question ...</td>\n",
       "      <td>We show that it is possible to reduce relation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>How is module that analyzes behavioral state t...</td>\n",
       "      <td>The module that analyzes behavioral state is t...</td>\n",
       "      <td>pre-trained to identify the presence of behavi...</td>\n",
       "      <td>The behavior model was implemented using an RN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>Can the model add new relations to the knowled...</td>\n",
       "      <td>No, the model cannot add new relations to the ...</td>\n",
       "      <td>The model does not add new relations to the kn...</td>\n",
       "      <td>In ConMask, we use a similar idea to select th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>Do twitter users tend to tweet about the DOS a...</td>\n",
       "      <td>NO.\\n\\nOnly 50% of the tweets in $D_a$ (the at...</td>\n",
       "      <td>The dataset contains about 590 tweets about DD...</td>\n",
       "      <td>In this subsection we discuss the experiment o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>What is the training and test data used?</td>\n",
       "      <td>The training data is $D_b$ (5229 tweets collec...</td>\n",
       "      <td>Tweets related to a Bank of America DDos attac...</td>\n",
       "      <td>We collected tweets related to five different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>What writing styles are present in the corpus?</td>\n",
       "      <td>A variety of writing styles are present in the...</td>\n",
       "      <td>current news, historical news, free time, spor...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Stylistic domains and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>What meta-information is being transferred?</td>\n",
       "      <td>Relation meta and gradient meta</td>\n",
       "      <td>high-order representation of a relation, loss ...</td>\n",
       "      <td>The relation-specific meta information is help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>What datasets are used to evaluate the approach?</td>\n",
       "      <td>NELL-One and Wiki-One</td>\n",
       "      <td>NELL-One, Wiki-One</td>\n",
       "      <td>We use two datasets, NELL-One and Wiki-One whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>How much is performance hurt when using too sm...</td>\n",
       "      <td>Performance can be hurt when using too small a...</td>\n",
       "      <td>comparing to the results from reducing the num...</td>\n",
       "      <td>The number of layers ($N_{src}$-$N_{mt}$-$N_{p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>What neural machine translation models can lea...</td>\n",
       "      <td>Neural machine translation models can learn tr...</td>\n",
       "      <td>Multilingual Neural Machine Translation Models</td>\n",
       "      <td>Various multilingual extensions of NMT have al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>How does the semi-automatic construction proce...</td>\n",
       "      <td>The semi-automatic construction process works ...</td>\n",
       "      <td>Automatic transcription of 5000 tokens through...</td>\n",
       "      <td>In order to make the corpus collection easier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>What does \"explicitly leverages their probabil...</td>\n",
       "      <td>The training framework explicitly leverages th...</td>\n",
       "      <td>The framework jointly learns parametrized QA a...</td>\n",
       "      <td>Moreover, QA and QG have probabilistic correla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>What is WNGT 2019 shared task?</td>\n",
       "      <td>The 2019 Workshop on Neural Generation of Text...</td>\n",
       "      <td>efficiency task aimed  at reducing the number ...</td>\n",
       "      <td>The Transformer network BIBREF3 is a neural se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>Was any variation in results observed based on...</td>\n",
       "      <td>No variation in results was observed based on ...</td>\n",
       "      <td>It is observed some variability - but not sign...</td>\n",
       "      <td>On another note, we apply our formalization to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Can the approach be generalized to other techn...</td>\n",
       "      <td>Yes. The approach can be generalized to other ...</td>\n",
       "      <td>There is no reason to think that this approach...</td>\n",
       "      <td>FLOAT SELECTED: Figure 2: NMT training after r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>What dataset they use for evaluation?</td>\n",
       "      <td>Gigaword corpus</td>\n",
       "      <td>The same 2K set from Gigaword used in BIBREF7</td>\n",
       "      <td>We validate our approach on the Gigaword corpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Which regions of the United States do they con...</td>\n",
       "      <td>The lower 48 states</td>\n",
       "      <td>all regions except those that are colored black</td>\n",
       "      <td>FLOAT SELECTED: Fig 5. (A) The average verb re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>How is performance measured?</td>\n",
       "      <td>Performance is measured using the area under t...</td>\n",
       "      <td>they use ROC curves and cross-validation</td>\n",
       "      <td>To assess the predictive capability of this an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>What is novel in author's approach?</td>\n",
       "      <td>The author's approach is novel in using self-p...</td>\n",
       "      <td>They use self-play learning , optimize the mod...</td>\n",
       "      <td>Our novelties include: Using self-play learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>How large is the Dialog State Tracking Dataset?</td>\n",
       "      <td>The Dialog State Tracking Dataset is composed ...</td>\n",
       "      <td>1,618 training dialogs, 500 validation dialogs...</td>\n",
       "      <td>FLOAT SELECTED: Table 1: Data used in this pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>What dataset is used for train/test of this me...</td>\n",
       "      <td>The training dataset is a mixture of neutral a...</td>\n",
       "      <td>Training datasets: TTS System dataset and embe...</td>\n",
       "      <td>Experimental Protocol ::: Datasets ::: Trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>How much is the gap between using the proposed...</td>\n",
       "      <td>The proposed objective outperformed cross-entr...</td>\n",
       "      <td>The mixed objective improves EM by 2.5% and F1...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Ablation study on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>How many domains of ontologies do they gather ...</td>\n",
       "      <td>4 domains of ontologies</td>\n",
       "      <td>5 domains: software, stuff, african wildlife, ...</td>\n",
       "      <td>The Software Ontology (SWO) BIBREF5 is include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>what is the practical application for this paper?</td>\n",
       "      <td>Improving natural language processing (NLP) me...</td>\n",
       "      <td>Improve existing NLP methods. Improve linguist...</td>\n",
       "      <td>Morphology deals with the internal structure o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>What's the method used here?</td>\n",
       "      <td>BERT-based encoder-decoder framework with LSTM...</td>\n",
       "      <td>Two neural networks: an extractor based on an ...</td>\n",
       "      <td>Our model consists of two neural network modul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>By how much does their method outperform state...</td>\n",
       "      <td>AE-HCN(-CNN) outperforms state-of-the-art OOD ...</td>\n",
       "      <td>AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...</td>\n",
       "      <td>The goal of this paper is to propose a novel O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>What are dilated convolutions?</td>\n",
       "      <td>Dilated convolutions are a type of convolution...</td>\n",
       "      <td>Similar to standard convolutional networks but...</td>\n",
       "      <td>In this work we focus on end-to-end stateless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>what are the three methods presented in the pa...</td>\n",
       "      <td>BERT, RoBERTa, and DistilBERT</td>\n",
       "      <td>Optimized TF-IDF, iterated TF-IDF, BERT re-ran...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: MAP scoring of new me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>what datasets did the authors use?</td>\n",
       "      <td>The authors used the Reddit dataset, the Twitt...</td>\n",
       "      <td>Kaggle\\nSubversive Kaggle\\nWikipedia\\nSubversi...</td>\n",
       "      <td>We trained and tested our neural network with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>How much performance improvements they achieve...</td>\n",
       "      <td>+4.3% dev F1</td>\n",
       "      <td>Compared to baselines SAN (Table 1) shows  imp...</td>\n",
       "      <td>FLOAT SELECTED: Table 2: Test performance on S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>What is the baseline?</td>\n",
       "      <td>A baseline multi-task architecture inspired by...</td>\n",
       "      <td>The baseline is a multi-task architecture insp...</td>\n",
       "      <td>We compare the results of our model to a basel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>What is the network architecture?</td>\n",
       "      <td>A multi-task Bi-Directional Recurrent Neural N...</td>\n",
       "      <td>The network architecture has a multi-task Bi-D...</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Our Hierarchical Net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>What does recurrent deep stacking network do?</td>\n",
       "      <td>RDSN stacks and concatenates the outputs of pr...</td>\n",
       "      <td>Stacks and joins outputs of previous frames wi...</td>\n",
       "      <td>As indicated in its name, Recurrent Deep Stack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>What is the reward model for the reinforcement...</td>\n",
       "      <td>The reward model for the reinforcement learnin...</td>\n",
       "      <td>reward 1 for successfully completing the task,...</td>\n",
       "      <td>We defined the reward as being 1 for successfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Does this paper propose a new task that others...</td>\n",
       "      <td>No. The paper does not propose a new task, but...</td>\n",
       "      <td>No, there has been previous work on recognizin...</td>\n",
       "      <td>Interesting prior work on quantifying social n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>How big is their dataset?</td>\n",
       "      <td>2.1 million predicate instances</td>\n",
       "      <td>3 million webpages processed with a CCG parser...</td>\n",
       "      <td>Much recent work on semantic parsing has been ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>What task do they evaluate on?</td>\n",
       "      <td>Open-domain fill-in-the-blank natural language...</td>\n",
       "      <td>Fill-in-the-blank natural language questions</td>\n",
       "      <td>We demonstrate our approach on the task of ans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>How many feature maps are generated for a give...</td>\n",
       "      <td>τ feature maps</td>\n",
       "      <td>3 feature maps for a given tuple</td>\n",
       "      <td>FLOAT SELECTED: Figure 1: Process involved in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                    what language pairs are explored?   \n",
       "1              what are the topics pulled from Reddit?   \n",
       "2      What accuracy does the proposed system achieve?   \n",
       "3                 What crowdsourcing platform is used?   \n",
       "4    On how many language pairs do they show that p...   \n",
       "5    Which information about text structure is incl...   \n",
       "6    What experiments are proposed to test that upp...   \n",
       "7    How do they calculate a static embedding for e...   \n",
       "8         What is the performance of BERT on the task?   \n",
       "9                   how is model compactness measured?   \n",
       "10                 Who were the human evaluators used?   \n",
       "11   Which methods are considered to find examples ...   \n",
       "12               What biases are found in the dataset?   \n",
       "13   What discourse relations does it work best/wor...   \n",
       "14   On top of BERT does the RNN layer work better ...   \n",
       "15                        How was this data collected?   \n",
       "16               What is the average length of dialog?   \n",
       "17   How does the IPA label data after interacting ...   \n",
       "18                    How was the audio data gathered?   \n",
       "19                     What is the GhostVLAD approach?   \n",
       "20   Which 7 Indian languages do they experiment with?   \n",
       "21                What is the invertibility condition?   \n",
       "22   Which neural architecture do they use as a bas...   \n",
       "23                 What metric is used for evaluation?   \n",
       "24         Which eight NER tasks did they evaluate on?   \n",
       "25   Do they focus on Reading Comprehension or mult...   \n",
       "26         After how many hops does accuracy decrease?   \n",
       "27                       What languages are evaluated?   \n",
       "28                             What is MSD prediction?   \n",
       "29               What other models do they compare to?   \n",
       "30                 What evaluation metric do they use?   \n",
       "31   What are the results from these proposed strat...   \n",
       "32          How much better than the baseline is LiLi?   \n",
       "33   What are the components of the general knowled...   \n",
       "34               How many labels do the datasets have?   \n",
       "35             What are the source and target domains?   \n",
       "36   How do they deal with unknown distribution sen...   \n",
       "37   What conclusions do the authors draw from thei...   \n",
       "38                         How id Depechemood trained?   \n",
       "39   How are similarities and differences between t...   \n",
       "40   How are prominent topics idenified in Dabiq an...   \n",
       "41                            Which datasets are used?   \n",
       "42         What are previous state of the art results?   \n",
       "43   What source-target language pairs were used in...   \n",
       "44       How large is their MNER SnapCaptions dataset?   \n",
       "45                 What is masked document generation?   \n",
       "46     What useful information does attention capture?   \n",
       "47   In what cases is attention different from alig...   \n",
       "48           Which baselines did they compare against?   \n",
       "49                   What baselines did they consider?   \n",
       "50                      How was the dataset annotated?   \n",
       "51                   What is the size of this dataset?   \n",
       "52                      Where does the data come from?   \n",
       "53    Ngrams of which length are aligned using PARENT?   \n",
       "54   How many people participated in their evaluati...   \n",
       "55   By how much more does PARENT correlate with hu...   \n",
       "56   Which stock market sector achieved the best pe...   \n",
       "57   How do the authors evidence the claim that man...   \n",
       "58                         what datasets did they use?   \n",
       "59   How much does their model outperform existing ...   \n",
       "60                What was the baseline for this task?   \n",
       "61         What is a second order co-ocurrence matrix?   \n",
       "62                       How many humans participated?   \n",
       "63   What word level and character level model base...   \n",
       "64            How were the human judgements assembled?   \n",
       "65   Which other approaches do they compare their m...   \n",
       "66   What results do they achieve using their propo...   \n",
       "67   How do they combine a deep learning model with...   \n",
       "68   What are the models used for the baseline of t...   \n",
       "69       How is non-standard pronunciation identified?   \n",
       "70             What novel PMI variants are introduced?   \n",
       "71   What are the disadvantages to clipping negativ...   \n",
       "72   Why are statistics from finite corpora unrelia...   \n",
       "73   Which two pairs of ERPs from the literature be...   \n",
       "74                             What datasets are used?   \n",
       "75            which datasets did they experiment with?   \n",
       "76   What kind of celebrities do they obtain tweets...   \n",
       "77   How did they extend LAMA evaluation framework ...   \n",
       "78   What summarization algorithms did the authors ...   \n",
       "79   What methods were used for sentence classifica...   \n",
       "80        What modern MRC gold standards are analyzed?   \n",
       "81            What language is explored in this paper?   \n",
       "82             How long of dialog history is captured?   \n",
       "83           What was the score of the proposed model?   \n",
       "84                  What hyperparameters are explored?   \n",
       "85   what aspects of conversation flow do they look...   \n",
       "86                       what is the state of the art?   \n",
       "87           What is the Random Kitchen Sink approach?   \n",
       "88               How do they define similar equations?   \n",
       "89    What are the three steps to feature elimination?   \n",
       "90                       How is the dataset annotated?   \n",
       "91   Which architecture do they use for the encoder...   \n",
       "92               How does their decoder generate text?   \n",
       "93            What dataset is used to train the model?   \n",
       "94   Which race and gender are given higher sentime...   \n",
       "95   What criteria are used to select the 8,640 Eng...   \n",
       "96                            what were the baselines?   \n",
       "97           what competitive results did they obtain?   \n",
       "98   By how much is performance improved with multi...   \n",
       "99            How much is performance improved on NLI?   \n",
       "100                           What is active learning?   \n",
       "101                             what was the baseline?   \n",
       "102             How is segmentation quality evaluated?   \n",
       "103                      How do they compare lexicons?   \n",
       "104  How larger are the training sets of these vers...   \n",
       "105  What is the improvement in performance for Est...   \n",
       "106               what is the state of the art on WSJ?   \n",
       "107         what is the size of the augmented dataset?   \n",
       "108  Why are current ELS's not sufficiently effective?   \n",
       "109       How many sentences does the dataset contain?   \n",
       "110                              What is the baseline?   \n",
       "111                   What is the size of the dataset?   \n",
       "112  How many different types of entities exist in ...   \n",
       "113             How big is the new Nepali NER dataset?   \n",
       "114  What is the performance improvement of the gra...   \n",
       "115  Which variation provides the best results on t...   \n",
       "116  What are the different variations of the atten...   \n",
       "117                What dataset is used for this work?   \n",
       "118         What were the datasets used in this paper?   \n",
       "119            What is the performance of classifiers?   \n",
       "120                What classifiers have been trained?   \n",
       "121         How many layers does the UTCNN model have?   \n",
       "122                            What are the baselines?   \n",
       "123        What transfer learning tasks are evaluated?   \n",
       "124  What other sentence embeddings methods are eva...   \n",
       "125  Which shallow approaches did they experiment w...   \n",
       "126  which non-english language had the best perfor...   \n",
       "127  how did the authors translate the reviews to o...   \n",
       "128  What are the five different binary classificat...   \n",
       "129  How was the spatial aspect of the EEG signal c...   \n",
       "130                Which real-world datasets are used?   \n",
       "131  How are the interpretability merits of the app...   \n",
       "132  How are the accuracy merits of the approach de...   \n",
       "133                      What is a wizard of oz setup?   \n",
       "134                       What baseline model is used?   \n",
       "135  How do they determine the exact section to use...   \n",
       "136  What features are used to represent the novelt...   \n",
       "137  What features are used to represent the salien...   \n",
       "138                      How was annotation performed?   \n",
       "139  What activation function do they use in their ...   \n",
       "140                            How are chunks defined?   \n",
       "141          How big is the dataset used in this work?   \n",
       "142    How is a \"chunk of posts\" defined in this work?   \n",
       "143                 Which evaluation methods are used?   \n",
       "144  How are sentences selected from the summary gr...   \n",
       "145               What is the size of the new dataset?   \n",
       "146      What kinds of offensive content are explored?   \n",
       "147  How long is the dataset for each step of hiera...   \n",
       "148  In the proposed metric, how is content relevan...   \n",
       "149  What different correlations result when using ...   \n",
       "150        how is mitigation of gender bias evaluated?   \n",
       "151                         What tasks were evaluated?   \n",
       "152           What are their results on both datasets?   \n",
       "153               by how much did their model improve?   \n",
       "154               what are the sizes of both datasets?   \n",
       "155  What are the distinctive characteristics of ho...   \n",
       "156             How many annotators tagged each tweet?   \n",
       "157  In what way is the offensive dataset not biase...   \n",
       "158  What are the difficulties in modelling the iro...   \n",
       "159   How did the authors find ironic data on twitter?   \n",
       "160  Who judged the irony accuracy, sentiment prese...   \n",
       "161                     How were the tweets annotated?   \n",
       "162                         What are hashtag features?   \n",
       "163  For how many probe tasks the shallow-syntax-aw...   \n",
       "164                What are the black-box probes used?   \n",
       "165  How does this model overcome the assumption th...   \n",
       "166  What are the industry classes defined in this ...   \n",
       "167        What are the hyperparameters of the bi-GRU?   \n",
       "168  Does the algorithm improve on the state-of-the...   \n",
       "169        What background knowledge do they leverage?   \n",
       "170                   What NLP tasks do they consider?   \n",
       "171          How do they define robustness of a model?   \n",
       "172  Are the annotations automatic or manually crea...   \n",
       "173                How long are the essays on average?   \n",
       "174    What neural models are used to encode the text?   \n",
       "175          What TIMIT datasets are used for testing?   \n",
       "176        What state-of-the-art results are achieved?   \n",
       "177               What baselines do they compare with?   \n",
       "178              What datasets are used in evaluation?   \n",
       "179               What is the tagging scheme employed?   \n",
       "180  How they extract \"structured answer-relevant r...   \n",
       "181              How big are significant improvements?   \n",
       "182                         What dataset did they use?   \n",
       "183                  What was their highest MRR score?   \n",
       "184  How do they measure which words are under-tran...   \n",
       "185  How do their models decide how much improtance...   \n",
       "186  Which data do they use as a starting point for...   \n",
       "187  How do they select instances to their hold-out...   \n",
       "188  How do the authors examine whether a model is ...   \n",
       "189  What type of system does the baseline classifi...   \n",
       "190                What are the user-defined keywords?   \n",
       "191          What are the baselines used in the paper?   \n",
       "192  How better is performance compared to previous...   \n",
       "193  How does Gaussian-masked directional multi-hea...   \n",
       "194    What are strong baselines model is compared to?   \n",
       "195  What additional features and context are propo...   \n",
       "196  What evidence do the authors present that the ...   \n",
       "197                      What are the existing biases?   \n",
       "198              What biases does their model capture?   \n",
       "199         which neural embedding model works better?   \n",
       "200  What is the degree of dimension reduction of t...   \n",
       "201  For which languages do they build word embeddi...   \n",
       "202  What experiments do they use to quantify the e...   \n",
       "203  What is the additive modification to the objec...   \n",
       "204  How do they encourage understanding of literat...   \n",
       "205  Why challenges does word segmentation in Vietn...   \n",
       "206  How successful are the approaches used to solv...   \n",
       "207    Which two news domains are country-independent?   \n",
       "208  How is the political bias of different sources...   \n",
       "209                     How was the dataset collected?   \n",
       "210         How do they verify generalization ability?   \n",
       "211  Do they only use adjacent entity mentions or u...   \n",
       "212     Why is lemmatization not necessary in English?   \n",
       "213      How big was the corpora they trained ELMo on?   \n",
       "214                              What dataset is used?   \n",
       "215       What does the \"sensitivity\" quantity denote?   \n",
       "216                What end tasks do they evaluate on?   \n",
       "217              What is a semicharacter architecture?   \n",
       "218  Why is the adversarial setting appropriate for...   \n",
       "219                How do the backoff strategies work?   \n",
       "220         which algorithm was the highest performer?   \n",
       "221                             what dataset was used?   \n",
       "222  How large are the improvements of the Attentio...   \n",
       "223  Which machine learning methods are used in exp...   \n",
       "224                      how was the speech collected?   \n",
       "225                        what topics did they label?   \n",
       "226  what levels of document preprocessing are look...   \n",
       "227  what keyphrase extraction models were reassessed?   \n",
       "228  How many different phenotypes are present in t...   \n",
       "229   What are 10 other phenotypes that are annotated?   \n",
       "230          What are the network's baseline features?   \n",
       "231                What tasks are used for evaluation?   \n",
       "232  HOw does the method perform compared with base...   \n",
       "233                      What baseline method is used?   \n",
       "234  What details are given about the Twitter dataset?   \n",
       "235  What details are given about the movie domain ...   \n",
       "236         what pretrained word embeddings were used?   \n",
       "237               What evaluation metrics did look at?   \n",
       "238                            What datasets are used?   \n",
       "239  How much improvement is gained from Adversaria...   \n",
       "240     why are their techniques cheaper to implement?   \n",
       "241                              what dataset is used?   \n",
       "242                  what language pairs are explored?   \n",
       "243  What are the organic and inorganic ways to sho...   \n",
       "244  How do profile changes vary for influential le...   \n",
       "245          how small of a dataset did they train on?   \n",
       "246               what was their character error rate?   \n",
       "247           which lstm models did they compare with?   \n",
       "248  Do they use datasets with transcribed text or ...   \n",
       "249                      By how much did they improve?   \n",
       "250                         What dataset did they use?   \n",
       "251  Which natural language(s) are studied in this ...   \n",
       "252              What metrics are used for evaluation?   \n",
       "253  What natural language(s) are the recipes writt...   \n",
       "254  Which multiple datasets did they train on duri...   \n",
       "255  what is the size of the real-world civil case ...   \n",
       "256                  What rouge score do they achieve?   \n",
       "257   What was their performance on emotion detection?   \n",
       "258  What is the benchmark dataset and is its quali...   \n",
       "259                       How do they detect spammers?   \n",
       "260                            What are the baselines?   \n",
       "261                         What datasets do they use?   \n",
       "262            What domains are covered in the corpus?   \n",
       "263  By how much does their best model outperform t...   \n",
       "264          How does their simple voting scheme work?   \n",
       "265  How do they obtain the new context represetation?   \n",
       "266           What is the performance of the baseline?   \n",
       "267     What was the performance of multilingual BERT?   \n",
       "268  What is an unordered text document, do these a...   \n",
       "269          Who were the experts used for annotation?   \n",
       "270  Is this hashtag prediction task an established...   \n",
       "271     What other tasks do they test their method on?   \n",
       "272     What is the state of the art system mentioned?   \n",
       "273                   Do they use large or small BERT?   \n",
       "274          What is their system's absolute accuracy?   \n",
       "275  Which is more useful, visual or textual features?   \n",
       "276                       Which languages do they use?   \n",
       "277                       How large is their data set?   \n",
       "278                what linguistics features are used?   \n",
       "279              what dataset statistics are provided?   \n",
       "280                        how was the data collected?   \n",
       "281  What is best performing model among author's s...   \n",
       "282  What extracted features were most influencial ...   \n",
       "283  Did ensemble schemes help in boosting peforman...   \n",
       "284  Which basic neural architecture perform best b...   \n",
       "285  What participating systems had better results ...   \n",
       "286  What is specific to multi-granularity and mult...   \n",
       "287  How much training data from the non-English la...   \n",
       "288   How is the model transferred to other languages?   \n",
       "289       How was the StackExchange dataset collected?   \n",
       "290     What is the size of the StackExchange dataset?   \n",
       "291                           What were the baselines?   \n",
       "292  What labels for antisocial events are availabl...   \n",
       "293         What are two datasets model is applied to?   \n",
       "294                         What is the McGurk effect?   \n",
       "295  what phenomena do they mention is hard to capt...   \n",
       "296            by how much did the BLEU score improve?   \n",
       "297                                       What is NER?   \n",
       "298  How better does new approach behave than exist...   \n",
       "299  How much is classification performance improve...   \n",
       "300             What subtasks did they participate in?   \n",
       "301                         What dataset did they use?   \n",
       "302                 What are the 12 languages covered?   \n",
       "303  What type of evaluation is proposed for this t...   \n",
       "304                  What baseline system is proposed?   \n",
       "305  How were crowd workers instructed to identify ...   \n",
       "306                  How is pseudo-perplexity defined?   \n",
       "307               What is the model architecture used?   \n",
       "308       How is the data used for training annotated?   \n",
       "309                what quantitative analysis is done?   \n",
       "310               by how much did nus outperform abus?   \n",
       "311          Which dataset has been used in this work?   \n",
       "312                  What can word subspace represent?   \n",
       "313  How big are improvements of small-scale unbala...   \n",
       "314                    How big is dataset for testing?   \n",
       "315  What are the qualitative experiments performed...   \n",
       "316  What were their results on the classification ...   \n",
       "317  Which hyperparameters were varied in the exper...   \n",
       "318                   How were the cluster extracted?    \n",
       "319                  what were the evaluation metrics?   \n",
       "320                   what english datasets were used?   \n",
       "321                  which chinese datasets were used?   \n",
       "322              What were their distribution results?   \n",
       "323           How did they determine fake news tweets?   \n",
       "324    What is their definition of tweets going viral?   \n",
       "325  What are the characteristics of the accounts t...   \n",
       "326  How is the ground truth for fake news establis...   \n",
       "327  Where does the ancient Chinese dataset come from?   \n",
       "328  How big is the difference in performance betwe...   \n",
       "329  In what 8 languages is PolyResponse engine use...   \n",
       "330  How many question types do they find in the da...   \n",
       "331  How do they analyze contextual similaries acro...   \n",
       "332               What were their performance results?   \n",
       "333  What datasets are used to assess the performan...   \n",
       "334            IS the graph representation supervised?   \n",
       "335  Is the G-BERT model useful beyond the task con...   \n",
       "336  Do they introduce errors in the data or does t...   \n",
       "337  What is the difference of the proposed model w...   \n",
       "338  Does the model evaluated on NLG datasets or di...   \n",
       "339      How is the quality of singing voice measured?   \n",
       "340     what previous RNN models do they compare with?   \n",
       "341  What are the languages they use in their exper...   \n",
       "342         How do they match annotators to instances?   \n",
       "343  How much data is needed to train the task-spec...   \n",
       "344                          Who are the crowdworkers?   \n",
       "345  Which sentiment class is the most accurately p...   \n",
       "346                           what were the baselines?   \n",
       "347                         What BERT models are used?   \n",
       "348  What experiments are used to demonstrate the b...   \n",
       "349            Which component is the least impactful?   \n",
       "350  Which component has the greatest impact on per...   \n",
       "351             What is the message passing framework?   \n",
       "352                  What is the best reported system?   \n",
       "353                  What cognitive features are used?   \n",
       "354  What approaches do they use towards text analy...   \n",
       "355                          What is the seed lexicon?   \n",
       "356                              What are the results?   \n",
       "357      How are relations used to propagate polarity?   \n",
       "358                      How big is the Japanese data?   \n",
       "359  How big are improvements of supervszed learnin...   \n",
       "360  How does their model learn using mostly raw data?   \n",
       "361         How big is seed lexicon used for training?   \n",
       "362  How do the various social phenomena examined m...   \n",
       "363  How did the select the 300 Reddit communities ...   \n",
       "364  How is the clinical text structuring task defi...   \n",
       "365  Is all text in this dataset a question, or are...   \n",
       "366             How many questions are in the dataset?   \n",
       "367  What aspects have been compared between variou...   \n",
       "368  How many attention layers are there in their m...   \n",
       "369  What are the three measures of bias which are ...   \n",
       "370                            How big is the dataset?   \n",
       "371      How is the intensity of the PTSD established?   \n",
       "372                           how is quality measured?   \n",
       "373  What is the accuracy reported by state-of-the-...   \n",
       "374  How do the authors define or exemplify 'incorr...   \n",
       "375  By how much do they outperform other models in...   \n",
       "376                    Which experiments are perfomed?   \n",
       "377                      Is ROUGE their only baseline?   \n",
       "378  By how much does their system outperform the l...   \n",
       "379  How are the main international development top...   \n",
       "380  Is the semantic hierarchy representation used ...   \n",
       "381                            Is the model evaluated?   \n",
       "382  How better is accuracy of new model compared t...   \n",
       "383           How does the active learning model work?   \n",
       "384            Did the annotators agreed and how much?   \n",
       "385  What datasets are used to evaluate this approach?   \n",
       "386                     How was the dataset collected?   \n",
       "387  What models other than standalone BERT is new ...   \n",
       "388  How big is the performance difference between ...   \n",
       "389  What approaches without reinforcement learning...   \n",
       "390               Which languages do they validate on?   \n",
       "391          What is the baseline method for the task?   \n",
       "392  what amounts of size were used on german-english?   \n",
       "393                            How big is the dataset?   \n",
       "394                            What MC abbreviate for?   \n",
       "395                What are their correlation results?   \n",
       "396               What simpler models do they look at?   \n",
       "397     What linguistic quality aspects are addressed?   \n",
       "398                          What dataset do they use?   \n",
       "399  What is typical GAN architecture for each text...   \n",
       "400               What language do the agents talk in?   \n",
       "401  How much better is performance of proposed met...   \n",
       "402                       What baseline model is used?   \n",
       "403  What stylistic features are used to detect dru...   \n",
       "404    What is the accuracy of the proposed technique?   \n",
       "405     Which retrieval system was used for baselines?   \n",
       "406  How much better was the BLSTM-CNN-CRF than the...   \n",
       "407  What supplemental tasks are used for multitask...   \n",
       "408  How much performance gap between their approac...   \n",
       "409                            How big is their model?   \n",
       "410                 How many emotions do they look at?   \n",
       "411  What approach did previous models use for mult...   \n",
       "412  What is difference in peformance between propo...   \n",
       "413  What is the performance of proposed model on e...   \n",
       "414  How accurate is the aspect based sentiment cla...   \n",
       "415  What were the non-neural baselines used for th...   \n",
       "416                  What are the models evaluated on?   \n",
       "417  What is the results of multimodal compared to ...   \n",
       "418               What were their performance results?   \n",
       "419  By how much did they outperform the other meth...   \n",
       "420                      What is the state of the art?   \n",
       "421  What difficulties does sentiment analysis on T...   \n",
       "422  How many sentence transformations on average a...   \n",
       "423     What annotations are available in the dataset?   \n",
       "424  How are possible sentence transformations repr...   \n",
       "425  What are all 15 types of modifications ilustra...   \n",
       "426     What were their results on the three datasets?   \n",
       "427                  What semantic rules are proposed?   \n",
       "428              What is the performance of the model?   \n",
       "429  What was the performance of both approaches on...   \n",
       "430                           What genres are covered?   \n",
       "431  Which of the two speech recognition models wor...   \n",
       "432  By how much is performance on CN-Celeb inferio...   \n",
       "433            How do the authors measure performance?   \n",
       "434   What is the latest paper covered by this survey?   \n",
       "435  What learning paradigms do they cover in this ...   \n",
       "436  What are all the input modalities considered i...   \n",
       "437  How do this framework facilitate demographic i...   \n",
       "438                         How is the data annotated?   \n",
       "439  Where does the information on individual-level...   \n",
       "440  What is the source of the user interaction data?    \n",
       "441           What is the source of the textual data?    \n",
       "442            What is the source of the visual data?    \n",
       "443  What result from experiments suggest that natu...   \n",
       "444              Which datasets are used in the paper?   \n",
       "445              How do they quantify moral relevance?   \n",
       "446  How much is proposed model better in perplexit...   \n",
       "447  Do they train a different training method exce...   \n",
       "448  How do they define upward and downward reasoning?   \n",
       "449  Do they annotate their own dataset or use an e...   \n",
       "450  What kind of neural network architecture do th...   \n",
       "451  What web and user-generated NER datasets are u...   \n",
       "452        Which unlabeled data do they pretrain with?   \n",
       "453  How many convolutional layers does their model...   \n",
       "454                          How big are the datasets?   \n",
       "455  What baselines did they compare their model with?   \n",
       "456           What was the performance of their model?   \n",
       "457                  What evaluation metrics are used?   \n",
       "458    How were the navigation instructions collected?   \n",
       "459           What language is the experiment done in?   \n",
       "460  What additional features are proposed for futu...   \n",
       "461       What are their initial results on this task?   \n",
       "462  How is morphology knowledge implemented in the...   \n",
       "463      How is the performance on the task evaluated?   \n",
       "464                           what datasets were used?   \n",
       "465               How do they obtain human judgements?   \n",
       "466  Does this approach perform better in the multi...   \n",
       "467  How many samples did they generate for the art...   \n",
       "468  Why does not the approach from English work on...   \n",
       "469                How do they measure grammaticality?   \n",
       "470  What is the difference in recall score between...   \n",
       "471                 What is their f1 score and recall?   \n",
       "472            How many layers does their system have?   \n",
       "473      What context modelling methods are evaluated?   \n",
       "474  Is the baseline a non-heirarchical model like ...   \n",
       "475  How better are results compared to baseline mo...   \n",
       "476      How big is dataset used for training/testing?   \n",
       "477   What geometric properties do embeddings display?   \n",
       "478  How accurate is model trained on text exclusiv...   \n",
       "479  What was their result on Stance Sentiment Emot...   \n",
       "480  What performance did they obtain on the SemEva...   \n",
       "481             What are the state-of-the-art systems?   \n",
       "482       What is the size of their collected dataset?   \n",
       "483  What kind of features are used by the HMM mode...   \n",
       "484  What kind of information do the HMMs learn tha...   \n",
       "485  How large is the gap in performance between th...   \n",
       "486            what was their system's f1 performance?   \n",
       "487      How much more coverage is in the new dataset?   \n",
       "488                          How was quality measured?   \n",
       "489  What is different in the improved annotation p...   \n",
       "490  What data were they used to train the multilin...   \n",
       "491         From when are many VQA datasets collected?   \n",
       "492               What is task success rate achieved?    \n",
       "493  Does proposed end-to-end approach learn in rei...   \n",
       "494        How is performance of this system measured?   \n",
       "495  How big dataset is used for training this system?   \n",
       "496       How do they obtain word lattices from words?   \n",
       "497  How better is proposed method than baselines p...   \n",
       "498  Who manually annotated the semantic roles for ...   \n",
       "499  How do they obtain region descriptions and obj...   \n",
       "500  Which training dataset allowed for the best ge...   \n",
       "501                        Which models were compared?   \n",
       "502                         What is private dashboard?   \n",
       "503                          What is public dashboard?   \n",
       "504                          What dataset do they use?   \n",
       "505  Do the use word embeddings alone or they repla...   \n",
       "506  How many natural language explanations are hum...   \n",
       "507  What is the dataset used as input to the Word2...   \n",
       "508  What methodology is used to compensate for lim...   \n",
       "509     What are the baseline state of the art models?   \n",
       "510           How do they extract causality from text?   \n",
       "511        What is the source of the \"control\" corpus?   \n",
       "512  What are the selection criteria for \"causal st...   \n",
       "513  Do they use expert annotations, crowdsourcing,...   \n",
       "514         how do they collect the comparable corpus?   \n",
       "515            How do they collect the control corpus?   \n",
       "516               What are resolution model variables?   \n",
       "517  Is the model presented in the paper state of t...   \n",
       "518  What was the result of the highest performing ...   \n",
       "519                What do they mean by answer styles?   \n",
       "520  What are the baselines that Masque is compared...   \n",
       "521   What is the performance achieved on NarrativeQA?   \n",
       "522                         What is an \"answer style\"?   \n",
       "523              How are the EAU text spans annotated?   \n",
       "524  Which Twitter corpus was used to train the wor...   \n",
       "525  How does proposed word embeddings compare to S...   \n",
       "526           How many uniue words are in the dataset?   \n",
       "527                   Which baseline methods are used?   \n",
       "528                        How much is the BLEU score?   \n",
       "529            Which datasets are used in experiments?   \n",
       "530   What are new best results on standard benchmark?   \n",
       "531  How better is performance compared to competit...   \n",
       "532          What 6 language pairs is experimented on?   \n",
       "533  How do they enrich the positional embedding wi...   \n",
       "534  How do they condition the output to a given ta...   \n",
       "535  Is this library implemented into Torch or is f...   \n",
       "536  How does this compare to traditional calibrati...   \n",
       "537  What's the input representation of OpenIE tupl...   \n",
       "538  Is CRWIZ already used for data collection, wha...   \n",
       "539                 What contextual features are used?   \n",
       "540                How is the data in RAFAEL labelled?   \n",
       "541  How is the fluctuation in the sense of the wor...   \n",
       "542  By how much does SPNet outperforms state-of-th...   \n",
       "543  Is it expected to have speaker role, semantic ...   \n",
       "544  How does new evaluation metric considers criti...   \n",
       "545  What are state of the art methods MMM is compa...   \n",
       "546  What are the problems related to ambiguity in ...   \n",
       "547             How is knowledge stored in the memory?   \n",
       "548   How do they measure the diversity of inferences?   \n",
       "549  By how much do they improve the accuracy of in...   \n",
       "550  How does the context-aware variational autoenc...   \n",
       "551  How much improvement does their method get ove...   \n",
       "552  By how much do they outpeform previous results...   \n",
       "553   How many paraphrases are generated per question?   \n",
       "554  How strong was the correlation between exercis...   \n",
       "555  How were topics of interest about DDEO identif...   \n",
       "556               How do their train their embeddings?   \n",
       "557                 How do they model travel behavior?   \n",
       "558           How do their interpret the coefficients?   \n",
       "559  By how much do they outperform previous state-...   \n",
       "560  What is the performance difference between pro...   \n",
       "561                       What benchmarks are created?   \n",
       "562  What percentage fewer errors did professional ...   \n",
       "563  What was the weakness in Hassan et al's evalua...   \n",
       "564  What evidence do they present that the model a...   \n",
       "565             In what way is the input restructured?   \n",
       "566           What language is the Twitter content in?   \n",
       "567  What evaluations did the authors use on their ...   \n",
       "568              What accuracy does CNN model achieve?   \n",
       "569  How many documents are in the Indiscapes dataset?   \n",
       "570             What are simulated datasets collected?   \n",
       "571  What human evaluation metrics were used in the...   \n",
       "572  For the purposes of this paper, how is somethi...   \n",
       "573  What type of model are the ELMo representation...   \n",
       "574  By how much does using phonetic feedback impro...   \n",
       "575                            what are the baselines?   \n",
       "576            What are the results of the experiment?   \n",
       "577                     How was the dataset collected?   \n",
       "578                  How many annotators participated?   \n",
       "579  How do they show their model discovers underly...   \n",
       "580  How do they measure performance of language mo...   \n",
       "581  How are content clusters used to improve the p...   \n",
       "582  What cluster identification method is used in ...   \n",
       "583           Why did they think this was a good idea?   \n",
       "584                          What QA models were used?   \n",
       "585  How do their results compare against other com...   \n",
       "586              On which task does do model do worst?   \n",
       "587               On which task does do model do best?   \n",
       "588  How does counterfactual data augmentation aim ...   \n",
       "589  In the targeted data collection approach, what...   \n",
       "590  How do they determine which words are informat...   \n",
       "591  What improvement does the MOE model make over ...   \n",
       "592  What is the difference in performance between ...   \n",
       "593    Which language-pair had the better performance?   \n",
       "594  Which psycholinguistic and basic linguistic fe...   \n",
       "595  How have the differences in communication styl...   \n",
       "596  What data/studies do the authors provide to su...   \n",
       "597      What datasets are used to evaluate the model?   \n",
       "598      What baseline models do they compare against?   \n",
       "599  What are the differences with previous applica...   \n",
       "600  How much improvement is gained from the propos...   \n",
       "601  Is infinite-length sequence generation a resul...   \n",
       "602             How big is dataset for this challenge?   \n",
       "603  How better is performance of proposed model co...   \n",
       "604                                What DCGs are used?   \n",
       "605  What is the performance difference of using a ...   \n",
       "606          What evaluation metrics did they look at?   \n",
       "607           What are the datasets used for the task?   \n",
       "608  What is the accuracy of the model for the six ...   \n",
       "609  Which models achieve state-of-the-art performa...   \n",
       "610  Which competitive relational classification mo...   \n",
       "611  How do they gather human judgements for simila...   \n",
       "612       What text classification task is considered?   \n",
       "613  What novel class of recurrent-like networks is...   \n",
       "614  How much bigger is Switchboard-2000 than Switc...   \n",
       "615           What domains are detected in this paper?   \n",
       "616  Why do they think this task is hard?  What is ...   \n",
       "617        How do they generate the synthetic dataset?   \n",
       "618          What is the average length of the claims?   \n",
       "619    What debate topics are included in the dataset?   \n",
       "620  By how much, the proposed method improves BiDA...   \n",
       "621  What are the linguistic differences between ea...   \n",
       "622              what genres do they songs fall under?   \n",
       "623  To what other competitive baselines is this ap...   \n",
       "624  How is human evaluation performed, what was th...   \n",
       "625  How much better were results of the proposed m...   \n",
       "626  Which one of the four proposed models performe...   \n",
       "627  How much is proposed model better than baselin...   \n",
       "628               By how much is precission increased?   \n",
       "629                    What labels are in the dataset?   \n",
       "630  How are customer satisfaction, customer frustr...   \n",
       "631  How many improvements on the French-German tra...   \n",
       "632  How do they prevent the model complexity incre...   \n",
       "633                    How do they measure model size?   \n",
       "634  Which model architecture do they for sentence ...   \n",
       "635                    Which data sources do they use?   \n",
       "636  How were breast cancer related posts compiled ...   \n",
       "637  What machine learning and NLP methods were use...   \n",
       "638  What approach performs better in experiments g...   \n",
       "639  Which translation system do they use to transl...   \n",
       "640   Which pre-trained English NER model do they use?   \n",
       "641  How much of the ASR grapheme set is shared bet...   \n",
       "642     What are the languages used to test the model?   \n",
       "643  Which language has the lowest error rate reduc...   \n",
       "644                        How is moral bias measured?   \n",
       "645              What metrics are used for evaluation?   \n",
       "646                    How much training data is used?   \n",
       "647             How does their model differ from BERT?   \n",
       "648  How does explicit constraint on the KL diverge...   \n",
       "649                             what was the baseline?   \n",
       "650                           How big is dataset used?   \n",
       "651  How much better does this baseline neural mode...   \n",
       "652                      What are the baseline models?   \n",
       "653  By how much of MGNC-CNN out perform the baseli...   \n",
       "654  What is increase in percentage of humor contai...   \n",
       "655  What are the languages they consider in this p...   \n",
       "656  Did they experiment with tasks other than word...   \n",
       "657                  What evaluation metrics are used?   \n",
       "658  What kind of Youtube video transcripts did the...   \n",
       "659              What makes it a more reliable metric?   \n",
       "660  How much in experiments is performance improve...   \n",
       "661               How is the delta-softmax calculated?   \n",
       "662    Which two datasets does the resource come from?   \n",
       "663            What is the size of the second dataset?   \n",
       "664                    How large is the first dataset?   \n",
       "665                      Who was the top-scoring team?   \n",
       "666     Why is big data not appropriate for this task?   \n",
       "667  What is an example of a computational social s...   \n",
       "668      Which major geographical regions are studied?   \n",
       "669  How strong is the correlation between the prev...   \n",
       "670  How are the topics embedded in the #MeToo twee...   \n",
       "671  Which geographical regions correlate to the tr...   \n",
       "672  What two components are included in their prop...   \n",
       "673  Which modifications do they make to well-estab...   \n",
       "674                            How was speed measured?   \n",
       "675      What were their accuracy results on the task?   \n",
       "676  What two types the Chinese reading comprehensi...   \n",
       "677  For which languages most of the existing MRC d...   \n",
       "678      Which sentiment analysis tasks are addressed?   \n",
       "679              Which 3 NLP areas are cited the most?   \n",
       "680  Which journal and conference are cited the mos...   \n",
       "681  Which 5 languages appear most frequently in AA...   \n",
       "682  How much F1 was improved after adding skip con...   \n",
       "683  How much gain does the model achieve with pret...   \n",
       "684       What is the highest accuracy score achieved?   \n",
       "685     What are the three datasets used in the paper?   \n",
       "686  What is improvement in accuracy for short Joke...   \n",
       "687      What baseline did they compare Entity-GCN to?   \n",
       "688       How did they get relations between mentions?   \n",
       "689               How did they detect entity mentions?   \n",
       "690  What performance does the Entity-GCN get on WI...   \n",
       "691                   What document context was added?   \n",
       "692     What were the results of the first experiment?   \n",
       "693  By how much does their model outperform existi...   \n",
       "694            What is the performance of their model?   \n",
       "695       How do they damage different neural modules?   \n",
       "696                         How long are the datasets?   \n",
       "697                  What are the sources of the data?   \n",
       "698                 What is the new labeling strategy?   \n",
       "699                   How are their changes evaluated?   \n",
       "700                 What are the six target languages?   \n",
       "701          What is the size of the released dataset?   \n",
       "702                    Which OpenIE systems were used?   \n",
       "703            how are the bidirectional lms obtained?   \n",
       "704               what metrics are used in evaluation?   \n",
       "705                      what results do they achieve?   \n",
       "706            what previous systems were compared to?   \n",
       "707  Are this models usually semi/supervised or uns...   \n",
       "708  When they say \"comparable performance\", how mu...   \n",
       "709  What types of word representations are they ev...   \n",
       "710  What type of recurrent layers does the model use?   \n",
       "711                  What is a word confusion network?   \n",
       "712  What evaluation metrics were used in the exper...   \n",
       "713  What kind of instructional videos are in the d...   \n",
       "714           What baseline algorithms were presented?   \n",
       "715  How does TP-N2F compare to LSTM-based Seq2Seq ...   \n",
       "716  What is the performance proposed model achieve...   \n",
       "717  What is the performance proposed model achieve...   \n",
       "718  What previous methods is the proposed method c...   \n",
       "719                   What is the baseline model used?   \n",
       "720              What domains are present in the data?   \n",
       "721  How many texts/datapoints are in the SemEval, ...   \n",
       "722  In which languages did the approach outperform...   \n",
       "723                       Which is the baseline model?   \n",
       "724       What is the main contribution of the paper?    \n",
       "725              How do they get the formal languages?   \n",
       "726            What is a confusion network or lattice?   \n",
       "727  How close do clusters match to ground truth to...   \n",
       "728                   what are the evaluation metrics?   \n",
       "729            which datasets were used in evaluation?   \n",
       "730                            what are the baselines?   \n",
       "731    What monolingual word representations are used?   \n",
       "732  Do they build one model per topic or on all to...   \n",
       "733  Do they quantitavely or qualitatively evalute ...   \n",
       "734  How well does their system perform on the deve...   \n",
       "735  Which of the classifiers showed the best perfo...   \n",
       "736  How are the keywords associated with events su...   \n",
       "737  What is different in BERT-gen from standard BERT?   \n",
       "738       How are multimodal representations combined?   \n",
       "739  What is the problem with existing metrics that...   \n",
       "740             How are discourse embeddings analyzed?   \n",
       "741  How are discourse features incorporated into t...   \n",
       "742                  What discourse features are used?   \n",
       "743                              What are proof paths?   \n",
       "744                    What external sources are used?   \n",
       "745  How much better peformance is achieved in huma...   \n",
       "746  How much transcribed data is available for for...   \n",
       "747  What baseline approaches do they compare against?   \n",
       "748         how many domains did they experiment with?   \n",
       "749                           How long is the dataset?   \n",
       "750                           What is a string kernel?   \n",
       "751  How do they correlate NED with emotional bond ...   \n",
       "752  What was their F1 score on the Bengali NER cor...   \n",
       "753                   What is the size of the dataset?   \n",
       "754  How many examples do they have in the target d...   \n",
       "755                        What is the baseline model?   \n",
       "756                  Where did they get training data?   \n",
       "757                What extraction model did they use?   \n",
       "758             Which datasets did they experiment on?   \n",
       "759  How do slot binary classifiers improve perform...   \n",
       "760        What baselines have been used in this work?   \n",
       "761                  what bottlenecks were identified?   \n",
       "762  By how much do they outperform BiLSTMs in Sent...   \n",
       "763        what state of the accuracy did they obtain?   \n",
       "764                   what models did they compare to?   \n",
       "765      which benchmark tasks did they experiment on?   \n",
       "766           How is the proficiency score calculated?   \n",
       "767  What proficiency indicators are used to the sc...   \n",
       "768  What accuracy is achieved by the speech recogn...   \n",
       "769    How is the speech recognition system evaluated?   \n",
       "770        How many of the utterances are transcribed?   \n",
       "771             How many utterances are in the corpus?   \n",
       "772  By how much does their model outperform both t...   \n",
       "773                      What is the state-of-the art?   \n",
       "774  What was the performance on the self-collected...   \n",
       "775                 What is the size of their dataset?   \n",
       "776                         how was the dataset built?   \n",
       "777  what processing was done on the speeches befor...   \n",
       "778  What is the performance change of the textual ...   \n",
       "779  Which sentiment analysis data set has a larger...   \n",
       "780  How much is pre-training loss increased in Low...   \n",
       "781      What is the average length of the recordings?   \n",
       "782                           What were their results?   \n",
       "783      What is the prediction accuracy of the model?   \n",
       "784             What is the dataset used in the paper?   \n",
       "785  How does the SCAN dataset evaluate composition...   \n",
       "786   How much does this system outperform prior work?   \n",
       "787  What are the baseline systems that are compare...   \n",
       "788                           What systems are tested?   \n",
       "789                  What benchmark datasets they use?   \n",
       "790             How do they combine MonaLog with BERT?   \n",
       "791             How do they select monotonicity facts?   \n",
       "792                What are the 12 categories devised?   \n",
       "793  what are the off-the-shelf systems discussed i...   \n",
       "794                  How many rules had to be defined?   \n",
       "795  What was performance of classifiers before/aft...   \n",
       "796                     How big are the datasets used?   \n",
       "797  What datasets are used for training/testing mo...   \n",
       "798  How better is gCAS approach compared to other ...   \n",
       "799                     What is specific to gCAS cell?   \n",
       "800          What is the source of external knowledge?   \n",
       "801              What were the sizes of the test sets?   \n",
       "802                           Which datasets are used?   \n",
       "803  How much does it minimally cost to fine-tune s...   \n",
       "804  What models are included in baseline benchmark...   \n",
       "805  It looks like learning to paraphrase questions...   \n",
       "806  How much more accurate is the model than the b...   \n",
       "807  What is new state-of-the-art performance on Co...   \n",
       "808  What are two strong baseline methods authors r...   \n",
       "809             How many category tags are considered?   \n",
       "810            What domain does the dataset fall into?   \n",
       "811                             How are EAC evaluated?   \n",
       "812                             What is triangulation?   \n",
       "813                        What languages do they use?   \n",
       "814                  How they evaluate their approach?   \n",
       "815                           How large is the corpus?   \n",
       "816                          How large is the dataset?   \n",
       "817                   What was their perplexity score?   \n",
       "818                 What parallel corpus did they use?   \n",
       "819  In which setting they achieve the state of the...   \n",
       "820    What they formulate the question generation as?   \n",
       "821  Was the degree of offensiveness taken as how g...   \n",
       "822         Which embeddings do they detect biases in?   \n",
       "823             What are the two PharmaCoNER subtasks?   \n",
       "824             How do they perform data augmentation?   \n",
       "825  What are the characteristics of the city dialect?   \n",
       "826  What are the characteristics of the rural dial...   \n",
       "827  What is the performance of the models on the t...   \n",
       "828  What other non-neural baselines do the authors...   \n",
       "829          On what dataset is Aristo system trained?   \n",
       "830                       How many roles are proposed?   \n",
       "831  What language technologies have been introduce...   \n",
       "832                 How do they define local variance?   \n",
       "833            how do they measure discussion quality?   \n",
       "834                           what were the baselines?   \n",
       "835     Which soft-selection approaches are evaluated?   \n",
       "836                    How big is slot filing dataset?   \n",
       "837            How large is the dataset they generate?   \n",
       "838  What are the weaknesses of their proposed inte...   \n",
       "839  What advantages does their proposed method of ...   \n",
       "840                How was lexical diversity measured?   \n",
       "841  Which existing models does this approach outpe...   \n",
       "842          What human evaluation method is proposed?   \n",
       "843     What languages are represented in the dataset?   \n",
       "844  How faster is training and decoding compared t...   \n",
       "845      What datasets are used to evaluate the model?   \n",
       "846                 What is the source of the dataset?   \n",
       "847                           What were the baselines?   \n",
       "848                         What metadata is included?   \n",
       "849  Do the images have multilingual annotations or...   \n",
       "850  How much important is the visual grounding in ...   \n",
       "851             How is the generative model evaluated?   \n",
       "852      What is an example of a health-related tweet?   \n",
       "853  What is the challenge for other language excep...   \n",
       "854  How many categories of offensive language were...   \n",
       "855            Which matching features do they employ?   \n",
       "856  By how much does their method outperform the m...   \n",
       "857                  How large is the corpus they use?   \n",
       "858          How many shared layers are in the system?   \n",
       "859  How many additional task-specific layers are i...   \n",
       "860  How many layers of self-attention does the mod...   \n",
       "861             what are the state of the art methods?   \n",
       "862      Which four languages do they experiment with?   \n",
       "863  Does DCA or GMM-based attention perform better...   \n",
       "864                    What evaluation metric is used?   \n",
       "865  Is any data-to-text generation model trained o...   \n",
       "866  How are the potentially relevant text fragment...   \n",
       "867                         What dataset did they use?   \n",
       "868                   What is the size of the dataset?   \n",
       "869  What are the 12 AV approaches which are examined?   \n",
       "870                           how was annotation done?   \n",
       "871  How do they measure correlation between the pr...   \n",
       "872  What are the results achieved from the introdu...   \n",
       "873              How do they incorporate human advice?   \n",
       "874            What affective-based features are used?   \n",
       "875  How big is performance improvement proposed me...   \n",
       "876  By how much does transfer learning improve per...   \n",
       "877                             What baseline is used?   \n",
       "878         What topic clusters are identified by LDA?   \n",
       "879  How much do they outperform previous state-of-...   \n",
       "880                  How big is the provided treebank?   \n",
       "881                             what dataset was used?   \n",
       "882  What are the citation intent labels in the dat...   \n",
       "883             How is quality of annotation measured?   \n",
       "884                What accuracy score do they obtain?   \n",
       "885               What is the 12 class bilingual text?   \n",
       "886  Which are the sequence model architectures thi...   \n",
       "887   What percentage of improvement in inference s...   \n",
       "888  What is the metric that is measures in this pa...   \n",
       "889  Was evaluation metrics and criteria were used ...   \n",
       "890               What are the two decoding functions?   \n",
       "891       What are the domains covered in the dataset?   \n",
       "892          How are the two different models trained?   \n",
       "893                           How long is the dataset?   \n",
       "894  How big are negative effects of proposed techn...   \n",
       "895  Are this techniques used in training multiling...   \n",
       "896        What metric is used to measure performance?   \n",
       "897         How do Zipf and Herdan-Heap's laws differ?   \n",
       "898          How are the synthetic examples generated?   \n",
       "899  By how much does the new parser outperform the...   \n",
       "900              What experimental evaluation is used?   \n",
       "901            How is the architecture fault-tolerant?   \n",
       "902        Which elements of the platform are modular?   \n",
       "903  Could you tell me more about the metrics used ...   \n",
       "904  What are the tasks that this method has shown ...   \n",
       "905  Why does the model improve in monolingual spac...   \n",
       "906  How is annotation projection done when languag...   \n",
       "907                What's the precision of the system?   \n",
       "908  Which of the two ensembles yields the best per...   \n",
       "909  What is the new initialization method proposed...   \n",
       "910  How was a quality control performed so that th...   \n",
       "911           Is it a neural model? How is it trained?   \n",
       "912     How they evaluate quality of generated output?   \n",
       "913      What are the four forums the data comes from?   \n",
       "914  How are sentence embeddings incorporated into ...   \n",
       "915  How different is the dataset size of source an...   \n",
       "916  What type of documents are supported by the an...   \n",
       "917            What are the strong baselines you have?   \n",
       "918              What are causal attribution networks?   \n",
       "919            how did they ask if a tweet was racist?   \n",
       "920  How does the model compute the likelihood of e...   \n",
       "921  What are state of the art methods authors comp...   \n",
       "922                  How much improvement do they get?   \n",
       "923                   Which languages do they test on?   \n",
       "924                    What limitations are mentioned?   \n",
       "925                            What are the baselines?   \n",
       "926  What semantic features help in detecting wheth...   \n",
       "927  Is the assumption that natural language is sta...   \n",
       "928                      Which models do they try out?   \n",
       "929                     What are the competing models?   \n",
       "930  How is the input triple translated to a slot-f...   \n",
       "931  How is module that analyzes behavioral state t...   \n",
       "932  Can the model add new relations to the knowled...   \n",
       "933  Do twitter users tend to tweet about the DOS a...   \n",
       "934           What is the training and test data used?   \n",
       "935     What writing styles are present in the corpus?   \n",
       "936        What meta-information is being transferred?   \n",
       "937   What datasets are used to evaluate the approach?   \n",
       "938  How much is performance hurt when using too sm...   \n",
       "939  What neural machine translation models can lea...   \n",
       "940  How does the semi-automatic construction proce...   \n",
       "941  What does \"explicitly leverages their probabil...   \n",
       "942                     What is WNGT 2019 shared task?   \n",
       "943  Was any variation in results observed based on...   \n",
       "944  Can the approach be generalized to other techn...   \n",
       "945              What dataset they use for evaluation?   \n",
       "946  Which regions of the United States do they con...   \n",
       "947                       How is performance measured?   \n",
       "948                What is novel in author's approach?   \n",
       "949    How large is the Dialog State Tracking Dataset?   \n",
       "950  What dataset is used for train/test of this me...   \n",
       "951  How much is the gap between using the proposed...   \n",
       "952  How many domains of ontologies do they gather ...   \n",
       "953  what is the practical application for this paper?   \n",
       "954                       What's the method used here?   \n",
       "955  By how much does their method outperform state...   \n",
       "956                     What are dilated convolutions?   \n",
       "957  what are the three methods presented in the pa...   \n",
       "958                 what datasets did the authors use?   \n",
       "959  How much performance improvements they achieve...   \n",
       "960                              What is the baseline?   \n",
       "961                  What is the network architecture?   \n",
       "962      What does recurrent deep stacking network do?   \n",
       "963  What is the reward model for the reinforcement...   \n",
       "964  Does this paper propose a new task that others...   \n",
       "965                          How big is their dataset?   \n",
       "966                     What task do they evaluate on?   \n",
       "967  How many feature maps are generated for a give...   \n",
       "\n",
       "                                                answer  \\\n",
       "0    English (En), Arabic (Ar), Spanish (Es), and R...   \n",
       "1           politics, business, science, and AskReddit   \n",
       "2    The proposed system achieves an accuracy of [i...   \n",
       "3                       Amazon Mechanical Turk (MTurk)   \n",
       "4    5.\\n\\nIn the experiment, preordering the assis...   \n",
       "5    Text structure information included in the cor...   \n",
       "6    The experiments proposed to test that upper la...   \n",
       "7    They calculate a static embedding for each wor...   \n",
       "8    BERT outperforms all other systems in terms of...   \n",
       "9    Model compactness is measured in terms of its ...   \n",
       "10   20 evaluators were recruited from the institution   \n",
       "11   1. Tagging descriptions with part-of-speech in...   \n",
       "12   The dataset appears to have biases in the way ...   \n",
       "13   The model works best for the Temporal discours...   \n",
       "14   The Transformer layer works better than the RN...   \n",
       "15   Through crowdsourcing on the platform CrowdFlo...   \n",
       "16                                           3.5 turns   \n",
       "17   The IPA labels data after interacting with use...   \n",
       "18   The audio data was gathered from the All India...   \n",
       "19   GhostVLAD is an extension of the NetVLAD appro...   \n",
       "20   Kannada, Hindi, Telugu, Malayalam, Bengali, an...   \n",
       "21   The invertibility condition is that INLINEFORM...   \n",
       "22                                 Attention mechanism   \n",
       "23                                            F1 score   \n",
       "24                   They evaluated on eight NER tasks   \n",
       "25                  Multiple choice question answering   \n",
       "26                                              2 hops   \n",
       "27                                  English and German   \n",
       "28   MSD prediction is predicting the morphosyntact...   \n",
       "29   They compare to R.M.-Reader + Verifier, a more...   \n",
       "30             Ratio of correct translations (matches)   \n",
       "31   The proposed strategies of using knowledge-gra...   \n",
       "32   LiLi outperforms the baseline by a significant...   \n",
       "33   The components of the general knowledge learni...   \n",
       "34                 The datasets have 4 labels in total   \n",
       "35   Source domain: Book (BK), Electronics (E), Bea...   \n",
       "36   By modifying a naïve Bayesian classifier to re...   \n",
       "37   The authors conclude that both ISIS and Cathol...   \n",
       "38   Depechemood was trained using a lexicon-based ...   \n",
       "39   Similarities and differences between the texts...   \n",
       "40   Non-negative matrix factorization (NMF) was us...   \n",
       "41                              ShapeWorldICE datasets   \n",
       "42   The previous state-of-the-art results are show...   \n",
       "43   En-XX, Zh-XX, Jp-XX, Kr-XX (source-target lang...   \n",
       "44                                              10,000   \n",
       "45   Masked Document Generation (MDG) is a task tha...   \n",
       "46   Attention captures information beyond alignmen...   \n",
       "47   Attention differs from alignment for VERB and ...   \n",
       "48   They compared against previous treestructured ...   \n",
       "49                               BIBREF13 and BIBREF12   \n",
       "50   The dataset was annotated manually by grouping...   \n",
       "51                                      23,700 queries   \n",
       "52   The data comes from crowdsourcing tasks, inclu...   \n",
       "53                                 N-grams of length 3   \n",
       "54                                          500 people   \n",
       "55   PARENT correlates significantly better with hu...   \n",
       "56                                          Technology   \n",
       "57   The authors evidence the claim by surveying en...   \n",
       "58   The dataset used was a collection of 3500 ques...   \n",
       "59   The neural extractive models outperform existi...   \n",
       "60   A very simple logistic regression classifier w...   \n",
       "61   A second-order co-occurrence matrix is a matri...   \n",
       "62            9 medical coders and 4 medical residents   \n",
       "63   The word level and character level model basel...   \n",
       "64   The human judgements were assembled by a group...   \n",
       "65                                    Existing systems   \n",
       "66   The proposed approach achieves F-1 scores betw...   \n",
       "67   By using a redirection list and a disambiguati...   \n",
       "68   The baseline models used for the three NLP tas...   \n",
       "69   Non-standard pronunciation is identified throu...   \n",
       "70                                    NPMI and NNEGPMI   \n",
       "71   Sure! Here's the answer to the question at the...   \n",
       "72   The statistics from finite corpora are unrelia...   \n",
       "73                    N400 and P600, and N400 and N200   \n",
       "74   The datasets used are ERP data and eye-trackin...   \n",
       "75   UD1.2 treebanks for 16 languages: Bulgarian, C...   \n",
       "76                                 Twitter celebrities   \n",
       "77   They introduced the negated LAMA dataset by si...   \n",
       "78   The authors experimented with a few summarizat...   \n",
       "79   For sentence classification, the following met...   \n",
       "80           BIBREF15, BIBREF28, BIBREF7, and TABREF19   \n",
       "81                                             ENGLISH   \n",
       "82                                      2 dialog turns   \n",
       "83   The proposed model achieved an EM/F1 score of ...   \n",
       "84   The hyperparameters explored are the choice of...   \n",
       "85   Conversational flow features such as self-cove...   \n",
       "86   For NER-style F1, the state of the art is ACE2...   \n",
       "87   The Random Kitchen Sink (RKS) approach is a me...   \n",
       "88   They define similar equations using Euclidean ...   \n",
       "89   The three steps to feature elimination are:\\n\\...   \n",
       "90   The dataset is annotated with depression-relat...   \n",
       "91   The encoder uses a combination of convolutiona...   \n",
       "92   The decoder generates text by predicting the t...   \n",
       "93   The dataset used to train the model is the col...   \n",
       "94                         Female and African American   \n",
       "95   The 8,640 English sentences were selected base...   \n",
       "96   The baselines were the other models trained us...   \n",
       "97   Competitive results were obtained on both WSJ ...   \n",
       "98   Performance is improved by approximately 0.02 ...   \n",
       "99      4% absolute gain over BERTBase on the NLI task   \n",
       "100  Active learning is a technique for selectively...   \n",
       "101               The baseline was a strong NMT system   \n",
       "102  Segmentation quality is evaluated based on the...   \n",
       "103  The experts and crowd contributors have simila...   \n",
       "104  The training sets of these versions of ELMo ar...   \n",
       "105  2.42% improvement in performance for Estonian ...   \n",
       "106                                    INLINEFORM2 WER   \n",
       "107   The size of the augmented dataset is 500 samples   \n",
       "108  Low precision rates and design challenges in t...   \n",
       "109                                               6946   \n",
       "110  The baseline is the Stanford CRF model (BIBREF21)   \n",
       "111          The size of the dataset is 1000 sentences   \n",
       "112                                                  3   \n",
       "113  The new Nepali NER dataset has a size of 23,33...   \n",
       "114  The grapheme-level representation model outper...   \n",
       "115  The variation with the Projected Layer provide...   \n",
       "116  Four variations of the attention-based approac...   \n",
       "117  The dataset used for this work is the SociaL M...   \n",
       "118  The dataset used in this paper is a Twitter da...   \n",
       "119  The performance of the classifiers is good, wi...   \n",
       "120                              KNN, RF, SVM, and MLP   \n",
       "121                                           4 layers   \n",
       "122  SVM with unigram, bigram, and trigram features...   \n",
       "123  The seven SentEval transfer tasks evaluated ar...   \n",
       "124       InferSent and the Universal Sentence Encoder   \n",
       "125  Bag-of-Words and Support Vector Machine with l...   \n",
       "126                                              Dutch   \n",
       "127  The authors used machine translation to transl...   \n",
       "128  The five different binary classification tasks...   \n",
       "129  The spatial aspect of the EEG signal was compu...   \n",
       "130                    CyberAttack and PoliticianDeath   \n",
       "131  By providing human-understandable explanations...   \n",
       "132  The approach demonstrates significant improvem...   \n",
       "133  A Wizard of Oz setup is a simulated informatio...   \n",
       "134  B1. The first baseline uses only the salience-...   \n",
       "135  They use a multi-class classification problem ...   \n",
       "136  The novelty of news articles is represented by...   \n",
       "137  Baseline features, such as positional features...   \n",
       "138  Annotation was performed using WebAnno BIBREF7...   \n",
       "139                                             $relu$   \n",
       "140  Chunks are defined as sorted sequences of twee...   \n",
       "141  The dataset used in this work consists of 212 ...   \n",
       "142  A \"chunk of posts\" is defined as a sorted sequ...   \n",
       "143                      ROGUE-1, ROGUE-2, and ROGUE-L   \n",
       "144  The sentences are selected from the summary gr...   \n",
       "145          The size of the new dataset is 300 tweets   \n",
       "146  Targeted and untargeted insults and threats, a...   \n",
       "147  The dataset size for each step of the hierarch...   \n",
       "148  Content relevance is measured using informatio...   \n",
       "149  Different correlations result when using diffe...   \n",
       "150  The mitigation of gender bias is evaluated usi...   \n",
       "151  The 8 tasks evaluated in ReviewQA are:\\n\\n1. A...   \n",
       "152  On both datasets, the combination of the patte...   \n",
       "153  Their model improved by 2.11 BLEU, 1.7 FKGL, a...   \n",
       "154  WikiSmall: 89,042 sentence pairs (training) + ...   \n",
       "155  Arabic speakers use offensive language in a va...   \n",
       "156                    One annotator tagged each tweet   \n",
       "157  The offensive dataset is not biased by topic, ...   \n",
       "158  The difficulties in modelling the ironic patte...   \n",
       "159  The authors crawled over 2M tweets from Twitte...   \n",
       "160  Four annotators who are proficient in English ...   \n",
       "161  The tweets were annotated with stance informat...   \n",
       "162  Hashtag features refer to the presence or abse...   \n",
       "163  1.\\n\\nOut of the 9 tasks in the table, mSynC p...   \n",
       "164                                            BIBREF1   \n",
       "165  The Adversarial-neural Event Model (AEM) overc...   \n",
       "166  The industry classes defined in this paper are...   \n",
       "167  The hyperparameters of the bi-GRU are:\\n\\n* Ba...   \n",
       "168                                                YES   \n",
       "169                Labeled features as prior knowledge   \n",
       "170                                Text classification   \n",
       "171  The authors define robustness of a model as it...   \n",
       "172                                   Manually created   \n",
       "173  The average length of the essays is approximat...   \n",
       "174                     NBOW, LSTM, and attentive LSTM   \n",
       "175                                               D, H   \n",
       "176  The state-of-the-art results achieved are Prec...   \n",
       "177  They compare with three baselines: Random, Wor...   \n",
       "178                                            BIBREF9   \n",
       "179                                        INLINEFORM0   \n",
       "180  They extract \"structured answer-relevant relat...   \n",
       "181  The improvements are significant, with our pro...   \n",
       "182                      They used the Phase B dataset   \n",
       "183                                             0.6103   \n",
       "184  By using estimated word importance to detect u...   \n",
       "185  By using integrated gradients to calculate the...   \n",
       "186  Nurse-initiated telephone conversations for co...   \n",
       "187  They select instances for their hold-out test ...   \n",
       "188  By using adversarial sets, specifically AddSen...   \n",
       "189                             Naive Bayes classifier   \n",
       "190                $\\lbrace subway, manhattan\\rbrace $   \n",
       "191  The baselines used in the paper are Random For...   \n",
       "192  Our model achieves new state-of-the-art result...   \n",
       "193  Gaussian-masked directional multi-head attenti...   \n",
       "194  All the other models in the comparison, except...   \n",
       "195  Context tweets are proposed as additional feat...   \n",
       "196  The authors present evidence that the model ca...   \n",
       "197  Existing biases in hate speech detection datas...   \n",
       "198  The model captures biases from data collection...   \n",
       "199               The CRC model embeddings work better   \n",
       "200                                                  3   \n",
       "201                                            ENGLISH   \n",
       "202  Word intrusion test and semantic category-base...   \n",
       "203  The additive modification to the objective fun...   \n",
       "204  By categorizing each model based on the optimi...   \n",
       "205  Word segmentation in Vietnamese poses challeng...   \n",
       "206  The approaches used to solve word segmentation...   \n",
       "207  Mainstream and disinformation news domains are...   \n",
       "208  The political bias of different sources is inc...   \n",
       "209  The dataset was collected from standardized sc...   \n",
       "210  They verify generalization ability by evaluati...   \n",
       "211  They use more than just adjacent entity mentio...   \n",
       "212  It is not entirely true that lemmatization is ...   \n",
       "213  The corpora they trained ELMo on were approxim...   \n",
       "214                            English WIKIBIO dataset   \n",
       "215  The sensitivity quantity denotes the expected ...   \n",
       "216  They evaluate on sentiment classification and ...   \n",
       "217                      A semi-character architecture   \n",
       "218  Adversarial misspellings are appropriate for m...   \n",
       "219  The backoff strategies work by either passing ...   \n",
       "220                                        INLINEFORM7   \n",
       "221                Amazon search terms and editor tags   \n",
       "222  The Attention-Sum Reader model improves by 2.3...   \n",
       "223  SVMhmm BIBREF111 implementation of Structural ...   \n",
       "224  The speech was collected using an Android appl...   \n",
       "225  The topics labeled in the HPI notes include de...   \n",
       "226  Three incremental levels of document preproces...   \n",
       "227    The keyphrase extraction models were reassessed   \n",
       "228                                                 13   \n",
       "229  10 other phenotypes that are annotated are:\\n\\...   \n",
       "230                              100 baseline features   \n",
       "231                          Machine translation tasks   \n",
       "232  The method performs similarly or slightly bett...   \n",
       "233  SVM approach using unsupervised hand-crafted f...   \n",
       "234  The Twitter dataset has 1,716 tweets, with 973...   \n",
       "235  The movie domain dataset has 20,244 reviews wi...   \n",
       "236   GloVe BIBREF13 and Edinburgh embeddings BIBREF14   \n",
       "237  The evaluation metrics looked at were time tak...   \n",
       "238  The dataset used is a collection of 124 questi...   \n",
       "239  ARAML achieves a significant improvement of 10...   \n",
       "240  Because they do not require the availability o...   \n",
       "241                            Europarl corpus BIBREF5   \n",
       "242                  English-German and English-French   \n",
       "243  Organic ways to show political affiliation thr...   \n",
       "244  Influential leads are more likely to make chan...   \n",
       "245                                         1000 hours   \n",
       "246  The character error rate (CER) of the 9-layer ...   \n",
       "247  They compared 6-9 layer LSTM models trained wi...   \n",
       "248  They use both datasets with transcribed text a...   \n",
       "249  They improved by 2.5% absolute improvement in ...   \n",
       "250  The dataset used was the fine-grained sentimen...   \n",
       "251                                            English   \n",
       "252  The metrics used for evaluation are:\\n\\n* BPE ...   \n",
       "253                                            ENGLISH   \n",
       "254                          BF, BA, SFU, and Sherlock   \n",
       "255  The size of the real-world civil case dataset ...   \n",
       "256  Their Rouge scores on the CNN/DailyMail test s...   \n",
       "257  The model achieved an accuracy of 85.6% on the...   \n",
       "258  The benchmark dataset is the Social Honeypot d...   \n",
       "259  They detect spammers using a combination of Lo...   \n",
       "260  The baselines used in this study are:\\n\\n1. Ex...   \n",
       "261  They use three datasets: imdb400, yelp50, and ...   \n",
       "262  The corpus covers a wide range of domains, inc...   \n",
       "263  Their best model outperforms the state-of-the-...   \n",
       "264  The simple voting scheme works by applying mul...   \n",
       "265  They propose a new context representation call...   \n",
       "266                                              82.6%   \n",
       "267  Multilingual BERT achieved a performance of 85...   \n",
       "268  An unordered text document is a document that ...   \n",
       "269  Seven experts with legal training were used fo...   \n",
       "270                                        Established   \n",
       "271  They also test their method on task of predict...   \n",
       "272                                         Our system   \n",
       "273                    Small BERT (BERT$_\\text{BASE}$)   \n",
       "274  The absolute accuracy of their system is not p...   \n",
       "275  Both visual and textual features are useful fo...   \n",
       "276                                            English   \n",
       "277          Their dataset consists of 29,794 articles   \n",
       "278  Segmentation, POS tagging, stem templates, aff...   \n",
       "279  * 87% of questions had a clear category label\\...   \n",
       "280  via crowdsourcing on Amazon Mechanical Turk (M...   \n",
       "281  The author's best-performing model on the Test...   \n",
       "282  The pre-trained embeddings (FastText or BERT) ...   \n",
       "283  Yes, ensemble schemes helped in boosting perfo...   \n",
       "284  Sure! Here's my answer based on the given cont...   \n",
       "285  Only one system (System 4) had better results ...   \n",
       "286  Multi-granularity and multi-tasking neural arc...   \n",
       "287  A small amount of training data from the non-E...   \n",
       "288  The model is transferred to other languages by...   \n",
       "289  The StackExchange dataset was collected by usi...   \n",
       "290                                             10,000   \n",
       "291  The baselines were four non-neural extractive ...   \n",
       "292               Personal attacks and rule violations   \n",
       "293  The two datasets the model is applied to are t...   \n",
       "294  The McGurk effect is a phenomenon where the pe...   \n",
       "295                                        VP ellipsis   \n",
       "296                                           0.7 BLEU   \n",
       "297  Named Entity Recognition (NER) in the Biomedic...   \n",
       "298  New approach performs significantly better tha...   \n",
       "299  In experiments for low data regime and class-i...   \n",
       "300                     EI-Reg, EI-Oc, V-Reg, and V-Oc   \n",
       "301  They used the Affect in Tweets Distant Supervi...   \n",
       "302  12 languages covered in Multi-SimLex:\\n\\n1. Ch...   \n",
       "303                                  Manual evaluation   \n",
       "304      The proposed baseline system is not specified   \n",
       "305  Crowd workers were instructed to identify impo...   \n",
       "306  Pseudo-perplexity is defined as the inverse of...   \n",
       "307  A VQA deep learning architecture that combines...   \n",
       "308  The data used for training is annotated with a...   \n",
       "309          Descriptive statistics and visualizations   \n",
       "310  NUS outperformed ABUS by approximately 5.5% (9...   \n",
       "311                                  Reuters-8 dataset   \n",
       "312                              The context of a text   \n",
       "313  Improvements of small-scale unbalanced dataset...   \n",
       "314  The testing dataset contains approximately 15 ...   \n",
       "315  Qualitative experiments were performed on benc...   \n",
       "316  On the classification task, their best model a...   \n",
       "317  The hyperparameters varied in the experiments ...   \n",
       "318                   K-means++ with INLINEFORM0-Means   \n",
       "319  The evaluation metrics used in the study were ...   \n",
       "320      The dataset used was the Penn Treebank Corpus   \n",
       "321                                  CUHK03 and CUHK07   \n",
       "322  The distribution results for viral tweets cont...   \n",
       "323  They used the number of retweets to single out...   \n",
       "324  According to the context, the definition of tw...   \n",
       "325  Accounts spreading fake news have a higher cha...   \n",
       "326                         Manually, with limitations   \n",
       "327  Ancient Chinese history records and articles w...   \n",
       "328  The proposed model (ALOHA with HLA-OG during t...   \n",
       "329  English, German, Spanish, Mandarin, Polish, Ru...   \n",
       "330                                                  7   \n",
       "331  They do not analyze contextual similarities ac...   \n",
       "332  * For Wikipedia BIBREF4 and Twitter BIBREF8 da...   \n",
       "333  The system's performance is assessed using the...   \n",
       "334                                                 NO   \n",
       "335                                                Yes   \n",
       "336  The data already contains errors.\\n\\nIn the co...   \n",
       "337  The proposed model with a Refinement Adjustmen...   \n",
       "338                                       NLG datasets   \n",
       "339  The quality of singing voice is measured using...   \n",
       "340                           state-of-the-art methods   \n",
       "341                      English, Spanish, and Finnish   \n",
       "342  They match annotators to instances based on th...   \n",
       "343                                   57,505 sentences   \n",
       "344  Crowdworkers are individuals located in the US...   \n",
       "345                                           NEGATIVE   \n",
       "346  The baselines used in the experiment were bag-...   \n",
       "347                           BERT-base and BERT-large   \n",
       "348  The experiments used to demonstrate the benefi...   \n",
       "349  The number of message passing iterations (n) h...   \n",
       "350           The number of message passing iterations   \n",
       "351  The message passing framework is a method for ...   \n",
       "352                                The MILR classifier   \n",
       "353  Memory, Attention, Perception, and Processing ...   \n",
       "354  They use a combination of quantitative and qua...   \n",
       "355  The seed lexicon is a set of positive and nega...   \n",
       "356  The results show that BERT trained only with t...   \n",
       "357  Relations are used to propagate polarity throu...   \n",
       "358  The Japanese data consists of approximately 10...   \n",
       "359  Improvements of supervised learning results tr...   \n",
       "360  By exploiting discourse relations to efficient...   \n",
       "361            15 positive words and 15 negative words   \n",
       "362  Dynamic and distinctive communities have highe...   \n",
       "363  The 300 Reddit communities were selected based...   \n",
       "364  The clinical text structuring task is defined ...   \n",
       "365  No, not all text in this dataset is a question...   \n",
       "366                                              2,714   \n",
       "367      Perplexity, recall, latency, and energy usage   \n",
       "368                                                  1   \n",
       "369                  RIPA, WEAT, and Neighborhood bias   \n",
       "370  The dataset consists of 471,319 references fro...   \n",
       "371  The intensity of PTSD is established based on ...   \n",
       "372                        Accuracy and macro-F1 score   \n",
       "373  The accuracy reported by state-of-the-art meth...   \n",
       "374  Incorrect words are defined as missing or misp...   \n",
       "375  By 6% to 8% in sentiment classification and by...   \n",
       "376  The experiments performed are on the WNC datas...   \n",
       "377                                                 No   \n",
       "378  The proposed model outperforms the lexicon-bas...   \n",
       "379  Based on the analysis of exclusive and semanti...   \n",
       "380                                                Yes   \n",
       "381                  Yes, the model has been evaluated   \n",
       "382  The accuracy of the new PRN model is significa...   \n",
       "383  Sure! Here's the answer to the question based ...   \n",
       "384  The annotators agreed moderately to substantia...   \n",
       "385                                  WN18 and YAGO3-10   \n",
       "386  The dataset was collected through a combinatio...   \n",
       "387         BERT$_\\text{base}$ and Attentive Mimicking   \n",
       "388  The performance difference between this method...   \n",
       "389  Neural Network Regressor (NNR) and Neural Netw...   \n",
       "390    All 31 languages with both UD and UniMorph data   \n",
       "391  The baseline method for the task is a neural n...   \n",
       "392  For German-English, the training corpus size u...   \n",
       "393                                      7934 messages   \n",
       "394           MC abbreviates for Machine Comprehension   \n",
       "395  The correlation results for Q1-Q5 on DUC-05, D...   \n",
       "396  They look at simpler models such as ROUGE, Lan...   \n",
       "397                    FIVE LINGUISTIC QUALITY ASPECTS   \n",
       "398  Text-code parallel corpus similar to Fig. FIGR...   \n",
       "399  * Semantic Enhancement GANs: Use of attention ...   \n",
       "400                                            ENGLISH   \n",
       "401  The proposed method outperforms state-of-the-a...   \n",
       "402                                   HUMAN EVALUATORS   \n",
       "403  Sentiment analysis, slur detection, and langua...   \n",
       "404                                              90.1%   \n",
       "405  The baseline retrieval system used for these e...   \n",
       "406  The BLSTM-CNN-CRF outperformed the BLSTM-CRF b...   \n",
       "407  Task C, which involves predicting the relation...   \n",
       "408                              10.5% performance gap   \n",
       "409  The proposed AEN-GloVe model has a relatively ...   \n",
       "410                                                  9   \n",
       "411  Previous models used a single-span head method...   \n",
       "412  The proposed model outperforms the state-of-th...   \n",
       "413  Our proposed model outperformed all other mode...   \n",
       "414                                     65.13% ± 2.52%   \n",
       "415                           Pre-extracted edit trees   \n",
       "416  The models are evaluated on both question answ...   \n",
       "417  The multimodal models (TABREF31) outperform th...   \n",
       "418  The performance results of the proposed method...   \n",
       "419  By an average of 10% to 20% in terms of ACC an...   \n",
       "420  XLM (MLM+TLM) is the current state of the art ...   \n",
       "421  Twitter sentiment analysis faces challenges du...   \n",
       "422  4.262\\n\\nThis is calculated by dividing the to...   \n",
       "423  * Two distinct paraphrases of each sentence\\n*...   \n",
       "424  The possible sentence transformations are repr...   \n",
       "425  The 15 types of modifications illustrated in t...   \n",
       "426  The authors achieved an accuracy of 90.2% on t...   \n",
       "427  The proposed semantic rules are displayed in T...   \n",
       "428  The model achieves a test accuracy of around 0...   \n",
       "429  Both approaches achieved similar performance o...   \n",
       "430                                         ALL GENRES   \n",
       "431  The x-vector system works better overall on CN...   \n",
       "432  12.3%\\n\\nBased on the EER(%) results provided ...   \n",
       "433     The authors measure performance using accuracy   \n",
       "434  \"NQG-BERT: A BERT-based Neural Question Genera...   \n",
       "435  Both traditional and neural learning paradigms...   \n",
       "436  textual inputs (declarative sentences), knowle...   \n",
       "437  This framework facilitates demographic inferen...   \n",
       "438  The data is annotated with depression symptoms...   \n",
       "439  The information on individual-level demographi...   \n",
       "440                                            Twitter   \n",
       "441                                            Twitter   \n",
       "442              The visual data is from posted images   \n",
       "443  The NLP representation outperforms other metho...   \n",
       "444  * BIBREF27: Moral Foundations Dictionary\\n* BI...   \n",
       "445  They quantify moral relevance based on the not...   \n",
       "446  The proposed model is significantly better in ...   \n",
       "447  No, they do not train a different training met...   \n",
       "448  Upward reasoning is defined as the ability to ...   \n",
       "449                       They use an existing dataset   \n",
       "450  A Siamese Neural Network Architecture with two...   \n",
       "451  Web and user-generated NER datasets used for t...   \n",
       "452  WSJ and full Librispeech, as well as a combina...   \n",
       "453  Sure! Based on the context you provided, the a...   \n",
       "454  The in-house dataset has 15,250 documents, whi...   \n",
       "455                    BIBREF20, BIBREF23, and BIBREF6   \n",
       "456  Their model achieved an EM score of 85.6% and ...   \n",
       "457                      EM, Recall, Precision, and GM   \n",
       "458  The navigation instructions were collected thr...   \n",
       "459                                            ENGLISH   \n",
       "460  * Clinical sentiment analysis scores\\n* Distin...   \n",
       "461  The initial results on this task show that the...   \n",
       "462  By using a morphologically motivated segmentat...   \n",
       "463  The performance on the task is evaluated based...   \n",
       "464  IWSLT14 German-English, Turkish-English, and W...   \n",
       "465                       Crowdsourced human judgments   \n",
       "466  The approach performs better in the single-dom...   \n",
       "467                                             30,000   \n",
       "468  Because other languages, like Spanish, have gr...   \n",
       "469  They measure grammaticality using the log rati...   \n",
       "470  The system using Wikipedia titles as reference...   \n",
       "471                       F1 score: 0.85\\nRecall: 0.88   \n",
       "472                                           3 layers   \n",
       "473  13 different context modeling methods are eval...   \n",
       "474  No. The baseline is a hierarchical transformer...   \n",
       "475  The results are significantly better ($p<0.001...   \n",
       "476  The dataset used for training/testing consists...   \n",
       "477  The embeddings display clustering properties, ...   \n",
       "478  The model trained on text exclusively achieves...   \n",
       "479  The proposed system outperformed the state-of-...   \n",
       "480  The proposed system obtained an F1-score of 85...   \n",
       "481  The state-of-the-art systems for sentiment and...   \n",
       "482                                    3347 utterances   \n",
       "483  The HMM models in the hybrid approach use feat...   \n",
       "484  The HMMs learn information related to spaces a...   \n",
       "485  The gap in performance between the HMMs and th...   \n",
       "486                                       12 F1 points   \n",
       "487  The new dataset has approximately 25% more cov...   \n",
       "488  Quality was measured using F1 score with 5 gen...   \n",
       "489  The improved annotation protocol uses trained ...   \n",
       "490  The multilingual encoder was trained on the WM...   \n",
       "491                                          Late 2014   \n",
       "492                                              96.0%   \n",
       "493                                Supervised learning   \n",
       "494  Performance of this system is measured using h...   \n",
       "495  The system is trained on a dataset of 15,000 i...   \n",
       "496  They obtain word lattices from words by treati...   \n",
       "497  MEED outperforms the baselines in terms of per...   \n",
       "498  The authors of the paper manually annotated th...   \n",
       "499  They obtain region descriptions and object ann...   \n",
       "500  The training dataset that allowed for the best...   \n",
       "501       BiLSTM-max, ESIM, KIM, ESIM + ELMo, and BERT   \n",
       "502                                Private leaderboard   \n",
       "503        The public dashboard is the public test set   \n",
       "504  VLSP 2016 Sentiment Analysis, VLSP 2018 Sentim...   \n",
       "505  The use of word embeddings in the proposed mod...   \n",
       "506                                             10,426   \n",
       "507  The dataset used as input to the Word2Vec algo...   \n",
       "508  Use of influential tweeters to label tweets in...   \n",
       "509  The baseline state of the art models are the R...   \n",
       "510  They extract causality from text by selecting ...   \n",
       "511  Temporally matched Twitter posts that do not c...   \n",
       "512  The selection criteria for \"causal statements\"...   \n",
       "513                                  Automatic methods   \n",
       "514  They collected the comparable corpus by select...   \n",
       "515           Control documents were selected randomly   \n",
       "516  Resolution model variables are $\\Pi = \\lbrace ...   \n",
       "517  NO.\\n\\nWhile the model presented in the paper ...   \n",
       "518  The highest performing system in Task 1 was \"S...   \n",
       "519  The answer styles refer to the two types of an...   \n",
       "520  Seo et al. (2017), Tan et al. (2018), Devlin e...   \n",
       "521  bTay et al. (2018) achieved an F1 score of 85....   \n",
       "522  An \"answer style\" refers to the type of abstra...   \n",
       "523  The EAU text spans are annotated with sentimen...   \n",
       "524  The Twitter corpus used to train the word vect...   \n",
       "525  Proposed word embeddings outperform Sindhi fas...   \n",
       "526                                23,456 unique words   \n",
       "527  The baseline methods used are the standard par...   \n",
       "528                                               27.4   \n",
       "529  The datasets used in experiments are the Seque...   \n",
       "530  Ours-Procrustes achieves new best results on s...   \n",
       "531  Ours-Procrustes outperforms competitive baseli...   \n",
       "532  English-German, English-French, English-Italia...   \n",
       "533  They enrich the positional embedding with leng...   \n",
       "534  They condition the output to a given target-so...   \n",
       "535      Torch-Struct is implemented on top of PyTorch   \n",
       "536  This method differs from traditional calibrati...   \n",
       "537  The input representation of OpenIE tuples into...   \n",
       "538  CRWIZ has been used for data collection, and t...   \n",
       "539                       download, malware, malicious   \n",
       "540  The data in RAFAEL is labelled with morphosynt...   \n",
       "541  Surrounding Uniformity (SU) measures the fluct...   \n",
       "542  SPNet outperforms state-of-the-art abstractive...   \n",
       "543                                                 No   \n",
       "544  CIC considers critical informative entities by...   \n",
       "545  State-of-the-art methods MMM is compared to in...   \n",
       "546  Ambiguity in PICO sentence prediction tasks ca...   \n",
       "547      The knowledge is stored in the dynamic memory   \n",
       "548  They measure the diversity of inferences using...   \n",
       "549  They improve the accuracy of inferences over s...   \n",
       "550  By learning a context-aware latent variable in...   \n",
       "551                                  2.3 BLEU-4 points   \n",
       "552  The CNN and LSTM models outperform previous re...   \n",
       "553         10n paraphrases are generated per question   \n",
       "554  Strong.\\n\\nThe context states that the stronge...   \n",
       "555  Topics of interest about DDEO were identified ...   \n",
       "556  They train their embeddings using the embeddin...   \n",
       "557  Sure! Here's the answer to the question based ...   \n",
       "558  The coefficients from the embeddings and PCA m...   \n",
       "559  ORNN outperforms previous state-of-the-art mod...   \n",
       "560  The proposed method (FlowSeq) achieves competi...   \n",
       "561                                HotpotQA and MedHop   \n",
       "562  Professional translations made 35% fewer error...   \n",
       "563  The weakness in Hassan et al.'s evaluation des...   \n",
       "564  Sure! Here's the answer to the question based ...   \n",
       "565  The input is restructured to begin with a [STA...   \n",
       "566                                            English   \n",
       "567  BLEU scores, average number of words in transl...   \n",
       "568                                               0.75   \n",
       "569                                      100 documents   \n",
       "570           Simulated datasets of document revisions   \n",
       "571                              Fluency and relevance   \n",
       "572  Domain specific knowledge is determined to be ...   \n",
       "573  Bidirectional Long Short-Term Memory (BiLSTM) ...   \n",
       "574  Using phonetic feedback improves state-of-the-...   \n",
       "575  The baselines are Attention Sum Reader (AS Rea...   \n",
       "576  The results of the experiment are not specifie...   \n",
       "577  The dataset was collected by extracting 200 se...   \n",
       "578                                                  1   \n",
       "579  By visualizing the syntactic distance estimate...   \n",
       "580  They measure performance of language model tas...   \n",
       "581  The content clusters are used as additional fe...   \n",
       "582                   Markov Stability (MS) clustering   \n",
       "583  To leverage the knowledge and experience of TC...   \n",
       "584  The QA models used are GloVe BIBREF40, CharCNN...   \n",
       "585  N-GrAM outperformed other competitors in the P...   \n",
       "586                                    The gender task   \n",
       "587                                     The joint task   \n",
       "588  By swapping gendered words with their counterf...   \n",
       "589                        Referring nouns or pronouns   \n",
       "590  They determine which words are informative bas...   \n",
       "591  The MOE model achieves a lower test perplexity...   \n",
       "592  The interpretable system (e.g. vectors and cos...   \n",
       "593  The English-French language pair had better pe...   \n",
       "594  Emotion Sensor Feature and selected topical si...   \n",
       "595  The differences in communication styles betwee...   \n",
       "596  The authors do not provide any specific data o...   \n",
       "597                                     WN18 and FB15k   \n",
       "598  Against a set of strong baseline models, inclu...   \n",
       "599  Our approach differs from previous application...   \n",
       "600  The proposed approaches result in a non-termin...   \n",
       "601                                                 No   \n",
       "602                                     123,287 images   \n",
       "603  The proposed model outperforms the baselines b...   \n",
       "604  DCGs used are Lexicon and 1st/3rd step convers...   \n",
       "605  Using a generated summary vs. a user-written o...   \n",
       "606  They looked at normalized averages between 0 a...   \n",
       "607          CELEX, IIT-Guwahat, and Festival datasets   \n",
       "608  The accuracy of the model for the six language...   \n",
       "609  The proposed model and Liang's hyphenation alg...   \n",
       "610                   TransE BIBREF3 and FB15K BIBREF3   \n",
       "611  They gather human judgments for similarity bet...   \n",
       "612  Text classification task is considered as clas...   \n",
       "613  Recurrent-like neural networks with nested int...   \n",
       "614  Switchboard-2000 is approximately 6 times bigg...   \n",
       "615                   Neural activity in visual cortex   \n",
       "616  The task is hard because of the complexity of ...   \n",
       "617  They generate the synthetic dataset by samplin...   \n",
       "618    The average length of the claims is INLINEFORM2   \n",
       "619     Politics, World, Society, and 10+ other topics   \n",
       "620  2.3% and 1.7% improvement over BiDAF and DCN, ...   \n",
       "621  The linguistic differences between each class ...   \n",
       "622  The songs fall under the following genres:\\n\\n...   \n",
       "623                               VHRED (attn) and MMI   \n",
       "624  Human evaluation was performed using pairwise ...   \n",
       "625  The proposed models were significantly better ...   \n",
       "626                                                LFT   \n",
       "627  The proposed model (GDP) is significantly bett...   \n",
       "628  Precision increased by 15.6% compared to the b...   \n",
       "629                      STRESS, ANXIETY, SOCIAL MEDIA   \n",
       "630  Customer satisfaction, customer frustration, a...   \n",
       "631  3 improvements on the French-German translatio...   \n",
       "632  By using a state tracking model independent of...   \n",
       "633     They measure model size in terms of parameters   \n",
       "634  A multi-task model architecture with a combina...   \n",
       "635                                            Table 1   \n",
       "636  The breast cancer related posts were compiled ...   \n",
       "637  The machine learning and NLP methods used to s...   \n",
       "638                         The global latent variable   \n",
       "639                                            BIBREF6   \n",
       "640                                              Flair   \n",
       "641                                     432 characters   \n",
       "642                         Hindi, English, and German   \n",
       "643  ARABIC (ar)\\n\\nIn the table provided, the erro...   \n",
       "644  By calculating the cosine similarity between t...   \n",
       "645                              WER (Word Error Rate)   \n",
       "646            Approximately 3 billion sub-word tokens   \n",
       "647  The model used in the experiments is a pre-tra...   \n",
       "648  The explicit constraint on the KL divergence t...   \n",
       "649  The baseline was the default values of the par...   \n",
       "650                                              10000   \n",
       "651                                       10.2% better   \n",
       "652  Concatenation-CNN (C-CNN) and the baseline mod...   \n",
       "653  MGNC-CNN outperforms the baselines by approxim...   \n",
       "654  An increase of 22.6% in humor contained in hea...   \n",
       "655  English, Russian, Arabic, Chinese, German, Spa...   \n",
       "656                                                 No   \n",
       "657  The evaluation metrics used are accuracy and I...   \n",
       "658  They used a variety of YouTube video transcrip...   \n",
       "659  The inclusivity of INLINEFORM0, which consider...   \n",
       "660  Performance is improved by around 10% on avera...   \n",
       "661  The delta-softmax is calculated as the reducti...   \n",
       "662  The resource comes from two datasets, one coll...   \n",
       "663                                                240   \n",
       "664  The first dataset, Friends, contains 1,000 lab...   \n",
       "665  Team B, with a micro-F1 score of 88.5% for Emo...   \n",
       "666  Big data is not appropriate for this task beca...   \n",
       "667  Analyzing the topic embeddings of State of the...   \n",
       "668                Northeast, South, West, and Midwest   \n",
       "669                                               Weak   \n",
       "670  The topics in the #MeToo tweets are extracted ...   \n",
       "671  The Northeast, West, and South regions correla...   \n",
       "672           Evidence extraction and answer synthesis   \n",
       "673  They modify the attention mechanism from locat...   \n",
       "674                                               Time   \n",
       "675                                             85.11%   \n",
       "676                   User Query Track and Cloze Track   \n",
       "677                                            ENGLISH   \n",
       "678  Binary-class and multi-class cross-domain sent...   \n",
       "679  1. Natural Language Understanding\\n2. Machine ...   \n",
       "680  ACM Transactions on Computer Systems (TOCS) an...   \n",
       "681    English, Spanish, Chinese, Japanese, and Korean   \n",
       "682  The F1 score improved by 2.3% after adding ski...   \n",
       "683  The model achieves a gain of approximately 3-4...   \n",
       "684                                               0.85   \n",
       "685  The three datasets used in the paper are:\\n\\n1...   \n",
       "686  8% improvement in accuracy for short jokes com...   \n",
       "687                   BiDAF BIBREF3 and FastQA BIBREF6   \n",
       "688  They got relations between mentions using thre...   \n",
       "689  They detected entity mentions by using a simpl...   \n",
       "690  The Entity-GCN achieves high performance on WI...   \n",
       "691                  Preceding and following sentences   \n",
       "692  The results of the first experiment were an F-...   \n",
       "693  Their model outperforms existing methods by ap...   \n",
       "694  The model has a competitive advantage in deali...   \n",
       "695  They damage different neural modules by random...   \n",
       "696  The datasets are of varying lengths, with the ...   \n",
       "697  Online user reviews from the hotel, mobile pho...   \n",
       "698                        Two-stage labeling strategy   \n",
       "699  The changes are evaluated based on the accurac...   \n",
       "700  English, Spanish, French, German, Italian, and...   \n",
       "701                                       2247 triples   \n",
       "702                 OpenIE 4 BIBREF5 and MinIE BIBREF7   \n",
       "703  The bidirectional LMs are obtained by concaten...   \n",
       "704                         micro-averaged INLINEFORM0   \n",
       "705  * For the CoNLL 2003 NER task, the authors ach...   \n",
       "706  Previous systems compared to are those without...   \n",
       "707  Semi/supervised.\\n\\nThese models are trained o...   \n",
       "708                      A negligible performance drop   \n",
       "709  Both GloVe and SGNS are evaluating word embedd...   \n",
       "710                        GRU (Gated Recurrent Units)   \n",
       "711  A word confusion network (cnet) is a type of i...   \n",
       "712  BIBREF16, accuracy, and MRR (Mean Reciprocal R...   \n",
       "713                         Screencast tutorial videos   \n",
       "714                Baseline1, Baseline2, and Baseline3   \n",
       "715  TP-N2F is faster than LSTM-based Seq2Seq in bo...   \n",
       "716  State-of-the-art performance on both the full ...   \n",
       "717  The proposed model achieved an execution accur...   \n",
       "718  The proposed method is compared against previo...   \n",
       "719                                          DrQA+CoQA   \n",
       "720         Services (salons, dentists, doctors, etc.)   \n",
       "721  * SemEval: 12,345\\n* TASS: 10,246\\n* SENTIPOLC...   \n",
       "722  Arabic.\\n\\nAccording to the context, the appro...   \n",
       "723                                         AG-RNN-LID   \n",
       "724  The main contribution of the paper is the prop...   \n",
       "725  They get the formal languages from a context-f...   \n",
       "726  A confusion network or lattice is a graph-like...   \n",
       "727  The clusters match ground truth tone categorie...   \n",
       "728                        Precision, Recall, F1 score   \n",
       "729                             SONAR-1 and Ancora 2.0   \n",
       "730                                     local features   \n",
       "731  AraVec for Arabic, FastText for French, and Wo...   \n",
       "732                     They build one model per topic   \n",
       "733                                     Quantitatively   \n",
       "734  The system achieves a relative improvement of ...   \n",
       "735                                      Random Forest   \n",
       "736  By using a Bayesian approach to learn which te...   \n",
       "737  The use of a left-to-right attention mask to r...   \n",
       "738  The multimodal representations are combined us...   \n",
       "739  Existing metrics do not accurately capture the...   \n",
       "740  T-SNE clustering is used to analyze discourse ...   \n",
       "741  Discourse features are incorporated into the m...   \n",
       "742                      GR and RST discourse features   \n",
       "743  Proof paths are the sequences of proof states ...   \n",
       "744  Raw Text, Automatically Segmented Text, Hetero...   \n",
       "745  The proposed comparative evaluator with skill ...   \n",
       "746  16 hours and 48 minutes of transcribed Ainu la...   \n",
       "747                              Previous best results   \n",
       "748                                          2 domains   \n",
       "749  The dataset contains 4000 reviews (1000 positi...   \n",
       "750  A string kernel is a method for measuring the ...   \n",
       "751  They compute the correlation of the proposed N...   \n",
       "752                                      5.5 points F1   \n",
       "753                                  300,000 sentences   \n",
       "754                                                  0   \n",
       "755                                     ATTS2S BIBREF8   \n",
       "756                                            Table 1   \n",
       "757           Multi-Encoder, Constrained-Decoder model   \n",
       "758                                            Table 1   \n",
       "759  Slot binary classifiers improve performance by...   \n",
       "760  NDM BIBREF7, LIDM BIBREF9, KVRN BIBREF13, and ...   \n",
       "761  Confusion among active words at certain nodes ...   \n",
       "762  They outperform BiLSTMs in Sentiment Analysis ...   \n",
       "763                                              87.5%   \n",
       "764  the models compared to are tree-LSTM BIBREF21,...   \n",
       "765   sentiment classification and text classification   \n",
       "766  The proficiency score is calculated by summing...   \n",
       "767  6 proficiency indicators are used to score the...   \n",
       "768  The speech recognition system achieves an accu...   \n",
       "769  WER (Word Error Rate) is used to evaluate the ...   \n",
       "770            75.6% of the utterances are transcribed   \n",
       "771                                               2000   \n",
       "772  Their model outperforms both state-of-the-art ...   \n",
       "773  The state-of-the-art is the `Read-Again' encod...   \n",
       "774                      🔥 OUTPERFORMED THE BASELINE 🔥   \n",
       "775                                               1000   \n",
       "776  The dataset was built by gathering queries fro...   \n",
       "777  The speeches were pre-processed by removing al...   \n",
       "778  There is a significant decrease in performance...   \n",
       "779  SST-2.\\n\\nBased on the plots in Figures FIGREF...   \n",
       "780  The pre-training loss increases linearly with ...   \n",
       "781                                      30-50 minutes   \n",
       "782                   The results were not significant   \n",
       "783                                              85.6%   \n",
       "784  The dataset used in the paper is a collection ...   \n",
       "785  By systematically holding out the training set...   \n",
       "786  This system outperforms prior work by approxim...   \n",
       "787  The baseline systems are compared against Rand...   \n",
       "788  The systems tested are the VoxCeleb-based syst...   \n",
       "789                                      VQA and GeoQA   \n",
       "790  They hybridize MonaLog with BERT for compositi...   \n",
       "791  MonaLog selects monotonicity facts based on th...   \n",
       "792  12 categories devised are Institute1, Institut...   \n",
       "793  There are several off-the-shelf systems discus...   \n",
       "794                                            3 rules   \n",
       "795  Before using distant supervision, the classifi...   \n",
       "796  The datasets used are CMRC 2018 (simplified Ch...   \n",
       "797  The dataset used for training/testing models i...   \n",
       "798  gCAS approach is better than other approaches ...   \n",
       "799  The gCAS cell is specific in that it is compos...   \n",
       "800                                  English Wikipedia   \n",
       "801  Test Set 1: 57 drug labels\\nTest Set 2: 66 dru...   \n",
       "802  The datasets used are:\\n\\n* ABSA SemEval 2014-...   \n",
       "803                                    $12.36 per hour   \n",
       "804                      DistilBERT, BERT, and RoBERTa   \n",
       "805  They are trained separately.\\n\\nIn the context...   \n",
       "806  NAGM is significantly more accurate than the b...   \n",
       "807  RelAwe with DepPath&RelPath achieves new state...   \n",
       "808                                   BERT and RoBERTa   \n",
       "809                                                  4   \n",
       "810                                            YouTube   \n",
       "811  EACs are evaluated using a combination of qual...   \n",
       "812  Triangulation is a method used to determine th...   \n",
       "813     English, Spanish, Arabic, and Mandarin Chinese   \n",
       "814  Sure! Here's the answer to the question based ...   \n",
       "815  The corpus contains 5 languages (English, Ital...   \n",
       "816  The dataset is quite large, with over 100,000 ...   \n",
       "817                                   3.58 BLEU points   \n",
       "818  They used a parallel corpus of English and Man...   \n",
       "819                                Ours+VGG(2) setting   \n",
       "820                         LASSO optimization problem   \n",
       "821  The degree of offensiveness was based on how p...   \n",
       "822                         BIBREF2 and Reddit dataset   \n",
       "823  Subtask 1: Identifying entities with offsets a...   \n",
       "824  They perform data augmentation by adding sente...   \n",
       "825  The city dialect is characterized by a more un...   \n",
       "826  The rural dialect has more specific words in i...   \n",
       "827  The performance of the models on the tasks is ...   \n",
       "828                                   BoW and BIBREF31   \n",
       "829        Aristo system is trained on the ARC dataset   \n",
       "830                                                  8   \n",
       "831                                Machine Translation   \n",
       "832  Local variance is defined as the reciprocal of...   \n",
       "833  through the annotation scheme, which captures ...   \n",
       "834  The baselines were pre-identified predicates a...   \n",
       "835  Soft-selection approaches evaluated are attent...   \n",
       "836  The slot filling dataset has approximately 22,...   \n",
       "837      The dataset they generate is 10,000 sentences   \n",
       "838    Bias due to dataset selection and word coverage   \n",
       "839  Their proposed method of quantifying interpret...   \n",
       "840  Lexical diversity was measured by comparing th...   \n",
       "841  This approach outperforms the existing BART an...   \n",
       "842                     Simple human evaluation method   \n",
       "843  English and Japanese are the most represented ...   \n",
       "844  Our model is faster than former models in both...   \n",
       "845                                     WN18 and FB15k   \n",
       "846  The dataset is sourced from a combination of m...   \n",
       "847  The baseline model used in this study is a Sia...   \n",
       "848  * Claim instance ID\\n* Entity mention ID\\n* En...   \n",
       "849                            Monolingual annotations   \n",
       "850  Sure! Here's my answer based on the provided c...   \n",
       "851  The generative model is evaluated using BLEU s...   \n",
       "852  A health-related tweet could be \"Just finished...   \n",
       "853  Lack of annotated datasets and linguistic feat...   \n",
       "854                                                  3   \n",
       "855                Multi-perspective matching features   \n",
       "856                                              1.75x   \n",
       "857                                      100,000 words   \n",
       "858                                                  2   \n",
       "859                                                  2   \n",
       "860                         3 layers of self-attention   \n",
       "861  The state-of-the-art methods for video caption...   \n",
       "862              English, Spanish, French, and Chinese   \n",
       "863  GMM-based attention performs better in experim...   \n",
       "864                 AVERAGE AND ONE STANDARD DEVIATION   \n",
       "865  Yes, the results show that the NLG model train...   \n",
       "866  By generating a query based on the claim's ver...   \n",
       "867  The datasets used in the experiment are not sp...   \n",
       "868  2,425 dialogues for training, 302 for validati...   \n",
       "869  The 12 AV approaches examined are listed in Ta...   \n",
       "870  Annotation was done using Amazon Mechanical Tu...   \n",
       "871  They measure correlation between prediction an...   \n",
       "872           Improved accuracy and faster convergence   \n",
       "873  They incorporate human advice by explicitly re...   \n",
       "874  Emolex, EmoSenticNet, Dictionary of Affect in ...   \n",
       "875  The performance improvement proposed methods a...   \n",
       "876                   22.6% improvement in performance   \n",
       "877            Linear Support Vector Machine (BIBREF7)   \n",
       "878  LDA identifies topic clusters such as American...   \n",
       "879  BERT-pair models outperform previous state-of-...   \n",
       "880     The provided treebank consists of 1,448 tweets   \n",
       "881                            ADAPT-Microsoft dataset   \n",
       "882  The citation intent labels in the datasets are...   \n",
       "883  Quality of annotation is measured through a te...   \n",
       "884                                              85.2%   \n",
       "885                     Bilingual text with 12 classes   \n",
       "886  LSTM-based, CNN-based, and transformer-based a...   \n",
       "887  Our method achieves a 3x improvement in infere...   \n",
       "888                                     ABX error rate   \n",
       "889  Yes, evaluation metrics and criteria were used...   \n",
       "890  The two decoding functions are:\\n\\n1. The line...   \n",
       "891  The domains covered in the dataset are:\\n\\n1. ...   \n",
       "892  BERT-BASE and BERT-LARGE are trained using dif...   \n",
       "893                                       645 articles   \n",
       "894                                         NEGLIGIBLE   \n",
       "895  Yes, these techniques are used in training mul...   \n",
       "896  Accuracy and F1 scores are used to measure per...   \n",
       "897  Zipf's law and Herdan-Heap's law differ in the...   \n",
       "898  The synthetic examples are generated using thr...   \n",
       "899  The new parser outperforms the current state-o...   \n",
       "900                                    Online Learning   \n",
       "901  KryptoOracle's architecture is fault-tolerant ...   \n",
       "902  The platform's modular elements include its Sp...   \n",
       "903  Sure! The performance evaluation metrics used ...   \n",
       "904  Monolingual and cross-lingual word similarity,...   \n",
       "905  The model improves in monolingual spaces becau...   \n",
       "906  The annotation projection is done using word a...   \n",
       "907  The precision of the system is 85.6% on S-Lite...   \n",
       "908                                             E-BERT   \n",
       "909                  Pre-trained vector initialization   \n",
       "910  The dataset was cleaned and quality control wa...   \n",
       "911  No, it is not a neural model. It is a probabil...   \n",
       "912  $n$-gram based similarity metrics and human ev...   \n",
       "913            Blackhat, Nulled, Brown, and Gazetteers   \n",
       "914  Sentence embeddings are incorporated into the ...   \n",
       "915  The dataset size of the source task is usually...   \n",
       "916                  PDFs and Microsoft Word documents   \n",
       "917  Strong baselines: 256 hidden states of LSTMs, ...   \n",
       "918  Causal attribution networks are collections of...   \n",
       "919  They used a common sense definition of racist ...   \n",
       "920  The model computes the likelihood of executing...   \n",
       "921  Hybrid CNN BIBREF15 and LSTM with attention BI...   \n",
       "922                                  11.2% improvement   \n",
       "923                     They test on various languages   \n",
       "924  Small sample size, sampling bias, low inter-ra...   \n",
       "925  The baselines are the scores achieved by the p...   \n",
       "926  Content accuracy, coherence, and consistency w...   \n",
       "927  NO.\\n\\nAccording to Manning and Schütze, the a...   \n",
       "928           They try out linear and nonlinear models   \n",
       "929  The competing models are:\\n\\n1. Transformer-XL...   \n",
       "930  The input triple is translated to a slot-filli...   \n",
       "931  The module that analyzes behavioral state is t...   \n",
       "932  No, the model cannot add new relations to the ...   \n",
       "933  NO.\\n\\nOnly 50% of the tweets in $D_a$ (the at...   \n",
       "934  The training data is $D_b$ (5229 tweets collec...   \n",
       "935  A variety of writing styles are present in the...   \n",
       "936                    Relation meta and gradient meta   \n",
       "937                              NELL-One and Wiki-One   \n",
       "938  Performance can be hurt when using too small a...   \n",
       "939  Neural machine translation models can learn tr...   \n",
       "940  The semi-automatic construction process works ...   \n",
       "941  The training framework explicitly leverages th...   \n",
       "942  The 2019 Workshop on Neural Generation of Text...   \n",
       "943  No variation in results was observed based on ...   \n",
       "944  Yes. The approach can be generalized to other ...   \n",
       "945                                    Gigaword corpus   \n",
       "946                                The lower 48 states   \n",
       "947  Performance is measured using the area under t...   \n",
       "948  The author's approach is novel in using self-p...   \n",
       "949  The Dialog State Tracking Dataset is composed ...   \n",
       "950  The training dataset is a mixture of neutral a...   \n",
       "951  The proposed objective outperformed cross-entr...   \n",
       "952                            4 domains of ontologies   \n",
       "953  Improving natural language processing (NLP) me...   \n",
       "954  BERT-based encoder-decoder framework with LSTM...   \n",
       "955  AE-HCN(-CNN) outperforms state-of-the-art OOD ...   \n",
       "956  Dilated convolutions are a type of convolution...   \n",
       "957                      BERT, RoBERTa, and DistilBERT   \n",
       "958  The authors used the Reddit dataset, the Twitt...   \n",
       "959                                       +4.3% dev F1   \n",
       "960  A baseline multi-task architecture inspired by...   \n",
       "961  A multi-task Bi-Directional Recurrent Neural N...   \n",
       "962  RDSN stacks and concatenates the outputs of pr...   \n",
       "963  The reward model for the reinforcement learnin...   \n",
       "964  No. The paper does not propose a new task, but...   \n",
       "965                    2.1 million predicate instances   \n",
       "966  Open-domain fill-in-the-blank natural language...   \n",
       "967                                     τ feature maps   \n",
       "\n",
       "                                        correct_answer  \\\n",
       "0    De-En, En-Fr, Fr-En, En-Es, Ro-En, En-De, Ar-E...   \n",
       "1     training data has posts from politics, busine...   \n",
       "2    F1 scores of 85.99 on the DL-PS data,  75.15 o...   \n",
       "3     They did not use any platform, instead they h...   \n",
       "4                                                   5    \n",
       "5     paragraph, lines, textspan element (paragraph...   \n",
       "6    They measure self-similarity, intra-sentence s...   \n",
       "7    They use the first principal component of a wo...   \n",
       "8    F1 scores are:\\nHUBES-PHI: Detection(0.965), C...   \n",
       "9                             Using file size on disk    \n",
       "10              20 annotatos from author's institution   \n",
       "11    Looking for adjectives marking the noun \"baby...   \n",
       "12                                        Ethnic bias    \n",
       "13    Best: Expansion (Exp). Worst: Comparison (Comp).   \n",
       "14                               The transformer layer   \n",
       "15    The crowdsourcing platform CrowdFlower was us...   \n",
       "16   4.49 turns 4.5 turns per dialog (8533 turns / ...   \n",
       "17   It defined a sequence labeling task to extract...   \n",
       "18   Through the All India Radio new channel where ...   \n",
       "19    An extension of NetVLAD which replaces hard a...   \n",
       "20   Hindi, English, Kannada, Telugu, Assamese, Ben...   \n",
       "21           The neural projector must be invertible.    \n",
       "22   GRU-based encoder, interaction block, and clas...   \n",
       "23   F1, precision, recall, accuracy Precision, rec...   \n",
       "24   BC5CDR-disease, NCBI-disease, BC5CDR-chem, BC4...   \n",
       "25                 MULTIPLE CHOICE QUESTION ANSWERING    \n",
       "26                                  one additional hop   \n",
       "27   German, English, Spanish, Finnish, French, Rus...   \n",
       "28   The task of predicting MSD tags: V, PST, V.PCT...   \n",
       "29   SAN Baseline, BNA, DocQA, R.M-Reader, R.M-Read...   \n",
       "30                                           Accuracy    \n",
       "31   Reward of 11.8 for the A2C-chained model, 41.8...   \n",
       "32   In case of Freebase knowledge base, LiLi model...   \n",
       "33   Answer with content missing: (list)\\nLiLi shou...   \n",
       "34   719313 Book, Electronics, Beauty and Music eac...   \n",
       "35   Book, electronics, beauty, music, IMDB, Yelp, ...   \n",
       "36   The Näive-Bayes classifier is corrected so it ...   \n",
       "37    By comparing scores for each word calculated ...   \n",
       "38   By multiplying crowd-annotated document-emotio...   \n",
       "39   By using topic modeling and unsupervised emoti...   \n",
       "40    Using NMF based topic modeling and their cohe...   \n",
       "41   Existential (OneShape, MultiShapes), Spacial (...   \n",
       "42   Overall F1 score:\\n- He and Sun (2017) 58.23\\n...   \n",
       "43   En-Fr, En-Zh, En-Jp, En-Kr, Zh-En, Zh-Fr, Zh-J...   \n",
       "44                                               10000   \n",
       "45   A task for seq2seq model pra-training that rec...   \n",
       "46                   Alignment points of the POS tags.   \n",
       "47             For certain POS tags, e.g. VERB, PRON.    \n",
       "48   Various tree structured neural networks includ...   \n",
       "49              Linear SVM, RBF SVM, and Random Forest   \n",
       "50   intents are annotated manually with guidance f...   \n",
       "51     23,700 queries, including 22,500 in-scope qu...   \n",
       "52   crowsourcing platform For ins scope data colle...   \n",
       "53    Answer with content missing: (Parent subsecti...   \n",
       "54                                          about 500    \n",
       "55   Best proposed metric has average correlation w...   \n",
       "56                Energy with accuracy of 0.538 Energy   \n",
       "57             By conducting a survey among engineers    \n",
       "58   Dataset of total 3500 questions from the Inter...   \n",
       "59   Best proposed model result vs best previous re...   \n",
       "60   The baseline system for the SLC task is a very...   \n",
       "61    The matrix containing co-occurrences of the w...   \n",
       "62                                                  16   \n",
       "63   None Word-level Memory Neural Networks (MemNNs...   \n",
       "64   50 human annotators ranked a random sample of ...   \n",
       "65   Akbik et al. (2018), Link et al. (2012) They c...   \n",
       "66   F-1 score on the OntoNotes is 88%, and it is 5...   \n",
       "67   Entities from a deep learning model are linked...   \n",
       "68    For speech synthesis, they build a speech clu...   \n",
       "69    Original transcription was labeled with addit...   \n",
       "70                               clipped PMI; NNEGPMI    \n",
       "71   It may lead to poor rare word representations ...   \n",
       "72    A finite corpora may entirely omit rare word ...   \n",
       "73   Answer with content missing: (Whole Method and...   \n",
       "74   Answer with content missing: (Whole Method and...   \n",
       "75   Universal Dependencies v1.2 treebanks for the ...   \n",
       "76   Amitabh Bachchan, Ariana Grande, Barack Obama,...   \n",
       "77    Create the negated LAMA dataset and  query th...   \n",
       "78   LSA, TextRank, LexRank and ILP-based summary. ...   \n",
       "79   Logistic Regression, Multinomial Naive Bayes, ...   \n",
       "80    MSMARCO,  HOTPOTQA, RECORD,  MULTIRC, NEWSQA,...   \n",
       "81                                    English language   \n",
       "82                                 two previous turns    \n",
       "83   Best results authors obtain is EM 51.10 and F1...   \n",
       "84   Dimension size, window size, architecture, alg...   \n",
       "85   The time devoted to self-coverage, opponent-co...   \n",
       "86   Babelfy, DBpedia Spotlight, Entityclassifier.e...   \n",
       "87   Random Kitchen Sink method uses a kernel funct...   \n",
       "88   By using Euclidean distance computed between t...   \n",
       "89    reduced the dataset by eliminating features, ...   \n",
       "90    The annotations are based on evidence of depr...   \n",
       "91    In encoder they use convolutional, NIN and bi...   \n",
       "92    Decoder predicts the sequence of phoneme or g...   \n",
       "93    Collected tweets and opening and closing stoc...   \n",
       "94   Females are given higher sentiment intensity w...   \n",
       "95   Sentences involving at least one race- or gend...   \n",
       "96    LF-MMI Attention\\nSeq2Seq \\nRNN-T \\nChar E2E ...   \n",
       "97   In case of read speech datasets,  their best m...   \n",
       "98   by 2.3-6.8 points in f1 score for intent recog...   \n",
       "99    The average score improved by 1.4 points over...   \n",
       "100  A process of training a model when selected un...   \n",
       "101                                    M2M Transformer   \n",
       "102  Segmentation quality is evaluated by calculati...   \n",
       "103  Human evaluators were asked to evaluate on a s...   \n",
       "104               By 14 times. up to 1.95 times larger   \n",
       "105                          5 percent points. 0.05 F1   \n",
       "106                                 CNN-DNN-BLSTM-HMM    \n",
       "107                                                609   \n",
       "108    Linked entities may be ambiguous or too common    \n",
       "109                                              3606    \n",
       "110   Bam et al. SVM, Ma and Hovy w/glove, Lample e...   \n",
       "111  Dataset contains 3606 total sentences and 7908...   \n",
       "112  OurNepali contains 3 different types of entiti...   \n",
       "113  3606 sentences Dataset contains 3606 total sen...   \n",
       "114  On OurNepali test dataset Grapheme-level repre...   \n",
       "115  the model with multi-attention mechanism and a...   \n",
       "116  classic RNN model, avgRNN model, attentionRNN ...   \n",
       "117  Twitter dataset provided by the organizers The...   \n",
       "118  The dataset from the SociaL Media And Harassme...   \n",
       "119   Using F1 Micro measure, the KNN classifier pe...   \n",
       "120                                 KNN\\nRF\\nSVM\\nMLP    \n",
       "121                                       eight layers   \n",
       "122   SVM with unigram, bigram, trigram features, w...   \n",
       "123    Semantic Textual Similarity, sentiment predi...   \n",
       "124  GloVe, BERT, Universal Sentence Encoder, TF-ID...   \n",
       "125   SVM with linear kernel using bag-of-words fea...   \n",
       "126                                           Russsian   \n",
       "127                     Using Google translation API.    \n",
       "128   presence/absence of consonants, presence/abse...   \n",
       "129   They use four-layered 2D CNN and two fully co...   \n",
       "130  Tweets related to CyberAttack and tweets relat...   \n",
       "131  By involving humans for post-hoc evaluation of...   \n",
       "132   By evaluating the performance of the approach...   \n",
       "133   a setup where the seeker interacts with a rea...   \n",
       "134  For Article-Entity placement, they consider tw...   \n",
       "135  They use a multi-class classifier to determine...   \n",
       "136  KL-divergences of language models for the news...   \n",
       "137  Salience features positional features, occurre...   \n",
       "138  Experienced medical doctors used a linguistic ...   \n",
       "139   Activation function is hyperparameter. Possib...   \n",
       "140  Chunks is group of tweets from single account ...   \n",
       "141  Total dataset size: 171 account (522967 tweets...   \n",
       "142                             sequence of $s$ tweets   \n",
       "143  Quantitative evaluation methods using ROUGE, R...   \n",
       "144    Two methods: first is to simply pick initial...   \n",
       "145   14,100 tweets Dataset contains total of 14100...   \n",
       "146  non-targeted profanity and swearing, targeted ...   \n",
       "147  Level A: 14100 Tweets\\nLevel B: 4640 Tweets\\nL...   \n",
       "148  The content relevance between the candidate su...   \n",
       "149   Using Pearson corelation measure,  for exampl...   \n",
       "150                 Using INLINEFORM0 and INLINEFORM1    \n",
       "151   Detection of an aspect in a review, Predictio...   \n",
       "152  Combining  pattern based and Machine translati...   \n",
       "153  For the WikiLarge dataset, the improvement ove...   \n",
       "154   WikiSmall  89 142 sentence pair and  WikiLarg...   \n",
       "155  Frequent use of direct animal name calling, us...   \n",
       "156    One One experienced annotator tagged all tweets   \n",
       "157  It does not use a seed list to gather tweets s...   \n",
       "158   ironies are often obscure and hard to understand   \n",
       "159  They developed a classifier to find ironic sen...   \n",
       "160  Irony accuracy is judged only by human ; senri...   \n",
       "161  tweets are annotated with only Favor or Agains...   \n",
       "162  hashtag features contain whether there is any ...   \n",
       "163                                                  3   \n",
       "164  CCG Supertagging CCGBank , PTB part-of-speech ...   \n",
       "165   by learning a projection function between the...   \n",
       "166  technology, religion, fashion, publishing, spo...   \n",
       "167  They use the embedding layer with a size 35 an...   \n",
       "168   From all reported results proposed method (NB...   \n",
       "169   labelled features, which are words whose pres...   \n",
       "170  text classification for themes including senti...   \n",
       "171  ability to accurately classify texts even when...   \n",
       "172                                         Automatic    \n",
       "173                                        204 tokens    \n",
       "174                        NBOW, LSTM, attentive LSTM    \n",
       "175  Once split into 8 subsets (A-H), the test set ...   \n",
       "176  F1 score of 92.19 on homographic pun detection...   \n",
       "177  They compare with the following models: by Ped...   \n",
       "178   A homographic and heterographic benchmark dat...   \n",
       "179  A new tagging scheme that tags the words befor...   \n",
       "180  Using the OpenIE toolbox and applying heuristi...   \n",
       "181  Metrics show better results on all metrics com...   \n",
       "182  BioASQ  dataset A dataset provided by BioASQ c...   \n",
       "183                                            0.5115    \n",
       "184  They measured the under-translated words with ...   \n",
       "185   They compute the gradient of the output at ea...   \n",
       "186  A sample from nurse-initiated telephone conver...   \n",
       "187  1264 instances from simulated data, 1280 insta...   \n",
       "188  By evaluating their model on adversarial sets ...   \n",
       "189   Classification system use n-grams, bag-of-wor...   \n",
       "190  Words that a user wants them to appear in the ...   \n",
       "191  GloVe vectors trained on Wikipedia Corpus with...   \n",
       "192  F1 score of 97.5 on MSR and 95.7 on AS MSR: 97...   \n",
       "193  pays attentions to adjacent characters and cas...   \n",
       "194  Baseline models are:\\n- Chen et al., 2015a\\n- ...   \n",
       "195  using tweets that one has replied or quoted to...   \n",
       "196  The authors showed few tweets where neither an...   \n",
       "197   sampling tweets from specific keywords create...   \n",
       "198  Data annotation biases where tweet containing ...   \n",
       "199                                     the CRX model    \n",
       "200  The number of dimensions can be reduced by up ...   \n",
       "201                                            English   \n",
       "202  Human evaluation for interpretability using th...   \n",
       "203  The cost function for any one of the words of ...   \n",
       "204  They group the existing works in terms of the ...   \n",
       "205  Acquire very large Vietnamese corpus and build...   \n",
       "206  Their accuracy in word segmentation is about 9...   \n",
       "207                mainstream news and disinformation    \n",
       "208  By assigning a political bias label to each ne...   \n",
       "209  from 3rd to 9th grade science questions collec...   \n",
       "210  By calculating Macro F1 metric at the document...   \n",
       "211  NCEL considers only adjacent mentions. More th...   \n",
       "212  Advanced neural architectures and contextualiz...   \n",
       "213  2174000000, 989000000 2174 million tokens for ...   \n",
       "214  English WIKIBIO, French WIKIBIO , German WIKIB...   \n",
       "215   The expected number of unique outputs a word ...   \n",
       "216  Sentiment analysis and paraphrase detection un...   \n",
       "217  A semi-character based RNN (ScRNN) treats the ...   \n",
       "218  Adversarial misspellings are a real-world problem   \n",
       "219  In pass-through, the recognizer passes on the ...   \n",
       "220  A hybrid model consisting of best performing p...   \n",
       "221    E-book annotation data: editor tags, Amazon ...   \n",
       "222   Answer with content missing: (Table 2) Accura...   \n",
       "223                 Structural Support Vector Machine    \n",
       "224  The speech was collected from respondents usin...   \n",
       "225  Demographics Age, DiagnosisHistory, Medication...   \n",
       "226                      Level 1, Level 2 and Level 3.   \n",
       "227  Answer with content missing: (LVL1, LVL2, LVL3...   \n",
       "228   Thirteen different phenotypes are present in ...   \n",
       "229  Adv. Heart Disease, Adv. Lung Disease, Alcohol...   \n",
       "230                   The features extracted from CNN.   \n",
       "231  four machine translation tasks: German -> Engl...   \n",
       "232  On the datasets DE-EN, JA-EN, RO-EN, and EN-DE...   \n",
       "233  using word2vec to create features that are use...   \n",
       "234   one of the Twitter datasets is about Turkish ...   \n",
       "235  there are 20,244 reviews divided into positive...   \n",
       "236         Pretrained word embeddings  were not used    \n",
       "237  precision, recall, F1 and accuracy Response ti...   \n",
       "238  Custom dataset with user questions; set of doc...   \n",
       "239  ARAM has achieved improvement over all baselin...   \n",
       "240  They use a slightly modified copy of the targe...   \n",
       "241   Europarl tests from 2006, 2007, 2008; WMT new...   \n",
       "242  English-German, English-French. English-German...   \n",
       "243  Organic: mention of political parties names in...   \n",
       "244  Influential leaders are more likely to change ...   \n",
       "245                                23085 hours of data   \n",
       "246  2.49% for  layer-wise training, 2.63% for dist...   \n",
       "247  Unidirectional LSTM networks with 2, 6, 7, 8, ...   \n",
       "248                  They use text transcription. both   \n",
       "249                          They decrease MAE in 0.34   \n",
       "250   high-quality datasets  from SemEval-2016 “Sen...   \n",
       "251                                            English   \n",
       "252  Byte-Pair Encoding perplexity  (BPE PPL),\\nBLE...   \n",
       "253                                   English English    \n",
       "254   BioScope Abstracts, SFU, and BioScope Full Pa...   \n",
       "255                                 100 000 documents    \n",
       "256  Best results on unigram:\\nCNN/Daily Mail: Rogu...   \n",
       "257  Answer with content missing: (Table 3) Best au...   \n",
       "258  Social Honeypot dataset (public) and Weibo dat...   \n",
       "259  Extract features from the LDA model and use th...   \n",
       "260   Answer with content missing: (Experimental Se...   \n",
       "261                 1 IMDB dataset and 2 Yelp datasets   \n",
       "262       No specific domain is covered in the corpus.   \n",
       "263  0.8% F1 better than the best state-of-the-art ...   \n",
       "264   Among all the classes predicted by several mo...   \n",
       "265  They use two independent convolutional and max...   \n",
       "266  M-Bert had 76.6 F1 macro score. 75.1% and 75.6...   \n",
       "267  BERT had 76.6 F1 macro score on x-stance dataset.   \n",
       "268  A unordered text document is one where sentenc...   \n",
       "269                   Individuals with legal training    \n",
       "270                                  established task    \n",
       "271                                               None   \n",
       "272  Two knowledge-based systems,\\ntwo traditional ...   \n",
       "273                              small BERT small BERT   \n",
       "274  59.4% on wikipedia dataset, 93.4% on peer-revi...   \n",
       "275  It depends on the dataset. Experimental result...   \n",
       "276                                            English   \n",
       "277  a sample of  29,794 wikipedia articles and 2,7...   \n",
       "278                    POS, gender/number and stem POS   \n",
       "279  More than 2,100 texts were paired with 15 ques...   \n",
       "280  The data was collected using 3 components: des...   \n",
       "281  For SLC task, the \"ltuorp\" team  has the best ...   \n",
       "282                                        Linguistic    \n",
       "283  The best ensemble topped the best single model...   \n",
       "284                                               BERT   \n",
       "285  For SLC task : Ituorp, ProperGander and YMJA  ...   \n",
       "286  An output layer for each task Multi-tasking is...   \n",
       "287                 No data. Pretrained model is used.   \n",
       "288  Build a bilingual language model,   learn the ...   \n",
       "289  they obtained computer science related topics ...   \n",
       "290                              around 332k questions   \n",
       "291  CopyRNN (Meng et al., 2017), Multi-Task (Ye an...   \n",
       "292  The Conversations Gone Awry dataset is labelle...   \n",
       "293   An expanded version of the existing 'Conversa...   \n",
       "294  a perceptual illusion, where listening to a sp...   \n",
       "295  Four discourse phenomena - deixis, lexical coh...   \n",
       "296                                   On average 0.64    \n",
       "297   Named Entity Recognition, including entities ...   \n",
       "298   On Coin Collector, proposed model finds short...   \n",
       "299  Low data: SST-5, TREC, IMDB around 1-2 accurac...   \n",
       "300  Answer with content missing: (Subscript 1: \"We...   \n",
       "301   Selection of tweets with for each tweet a lab...   \n",
       "302  Chinese Mandarin, Welsh, English, Estonian, Fi...   \n",
       "303  Answer with content missing: (Evaluation Metri...   \n",
       "304  Answer with content missing: (Baseline Method ...   \n",
       "305   They break down the task of importance annota...   \n",
       "306  Answer with content missing: (formulas in sele...   \n",
       "307  LSTM to encode the question, VGG16 to extract ...   \n",
       "308  The number of redundant answers to collect fro...   \n",
       "309  Answer with content missing: (Evaluation secti...   \n",
       "310  Average success rate is higher by 2.6 percent ...   \n",
       "311    The Reuters-8 dataset (with stop words removed)   \n",
       "312  Word vectors, usually in the context of others...   \n",
       "313   it has 0.024 improvement in accuracy comparin...   \n",
       "314  30 terms, each term-sanse pair has around 15 s...   \n",
       "315  Spearman correlation values of GM_KL model eva...   \n",
       "316                          F1 score result of 0.8099   \n",
       "317  number of clusters, seed value in clustering, ...   \n",
       "318  Word clusters are extracted using k-means on w...   \n",
       "319   Unlabeled sentence-level F1, perplexity, gram...   \n",
       "320  Answer with content missing: (Data section) Pe...   \n",
       "321  Answer with content missing: (Data section) Ch...   \n",
       "322  Distributions of Followers, Friends and URLs a...   \n",
       "323  an expert annotator determined if the tweet fe...   \n",
       "324  Viral tweets are the ones that are retweeted m...   \n",
       "325  Accounts that spread fake news are mostly unve...   \n",
       "326       Ground truth is not established in the paper   \n",
       "327   Ancient Chinese history records in several dy...   \n",
       "328  Metric difference between Aloha and best basel...   \n",
       "329  English, German, Spanish, Mandarin, Polish, Ru...   \n",
       "330                                                  7   \n",
       "331  They compare the tasks that the datasets are s...   \n",
       "332  best model achieves 0.94 F1 score for Wikipedi...   \n",
       "333    LORELEI datasets of Uzbek, Mandarin and Turkish   \n",
       "334  The graph representation appears to be semi-su...   \n",
       "335  There is nothing specific about the approach t...   \n",
       "336                        Data already contain errors   \n",
       "337  Introduce a \"Refinement Adjustment LSTM-based ...   \n",
       "338                          NLG datasets NLG datasets   \n",
       "339   Automatic: Normalized cross correlation (NCC)...   \n",
       "340  Variational LSTM, CharCNN, Pointer Sentinel-LS...   \n",
       "341  English\\nFrench\\nSpanish\\nGerman\\nGreek\\nBulga...   \n",
       "342  Annotations from experts are used if they have...   \n",
       "343                  57,505 sentences 57,505 sentences   \n",
       "344  people in the US that use Amazon Mechanical Turk    \n",
       "345                                  neutral sentiment   \n",
       "346      BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN    \n",
       "347    BERT-base, BERT-large, BERT-uncased, BERT-cased   \n",
       "348   Calculate test log-likelihood on the three co...   \n",
       "349  Based on table results provided changing direc...   \n",
       "350  Increasing number of message passing iteration...   \n",
       "351  It is a framework used to describe algorithms ...   \n",
       "352  Gaze Sarcasm using Multi Instance Logistic Reg...   \n",
       "353  Readability (RED),  Number of Words (LEN), Avg...   \n",
       "354   Modeling considerations:  the variables (both...   \n",
       "355  a vocabulary of positive and negative predicat...   \n",
       "356  Using all data to train: AL -- BiGRU achieved ...   \n",
       "357  based on the relation between events, the sugg...   \n",
       "358  7000000 pairs of events were extracted from th...   \n",
       "359                                                 3%   \n",
       "360  by exploiting discourse relations to propagate...   \n",
       "361                                           30 words   \n",
       "362  Dynamic communities have substantially higher ...   \n",
       "363  They selected all the subreddits from January ...   \n",
       "364   CTS is extracting structural data from medica...   \n",
       "365  the dataset consists of pathology reports incl...   \n",
       "366                                             2,714    \n",
       "367  Quality measures using perplexity and recall, ...   \n",
       "368                                                one   \n",
       "369                    RIPA, Neighborhood Metric, WEAT   \n",
       "370                                  903019 references   \n",
       "371  Given we have four intensity, No PTSD, Low Ris...   \n",
       "372  Accuracy and the macro-F1 (averaged F1 over po...   \n",
       "373  Answer with content missing: (Table 1)\\nPrevio...   \n",
       "374          typos in spellings or ungrammatical words   \n",
       "375  In the sentiment classification task by 6% to ...   \n",
       "376  They used BERT-based models to detect subjecti...   \n",
       "377   No, other baseline metrics they use besides R...   \n",
       "378  Under the retrieval evaluation setting, their ...   \n",
       "379   They focus on exclusivity and semantic cohere...   \n",
       "380                                      Yes, Open IE    \n",
       "381  the English version is evaluated. The German v...   \n",
       "382  Average accuracy of proposed model vs best pre...   \n",
       "383  Active learning methods has a learning engine ...   \n",
       "384  For event types and participant types, there w...   \n",
       "385   Kinship and Nations knowledge graphs, YAGO3-1...   \n",
       "386   They crawled travel information from the Web ...   \n",
       "387  Only Bert base and Bert large are compared to ...   \n",
       "388  Comparing with the highest performing baseline...   \n",
       "389        classification, regression, neural methods    \n",
       "390  Ar, Bg, Ca, Cs, Da, De, En, Es, Eu, Fa, Fi, Fr...   \n",
       "391  For the emotion recognition from text they use...   \n",
       "392  Training data with 159000, 80000, 40000, 20000...   \n",
       "393   Resulting dataset was 7934 messages for train...   \n",
       "394                              machine comprehension   \n",
       "395  High correlation results range from 0.472 to 0...   \n",
       "396   BiGRUs with attention, ROUGE, Language model,...   \n",
       "397  Grammaticality, non-redundancy, referential cl...   \n",
       "398  A parallel corpus where the source is an Engli...   \n",
       "399  Semantic Enhancement GANs: DC-GANs, MC-GAN\\nRe...   \n",
       "400                                            English   \n",
       "401  Accuracy of best proposed method KANE (LSTM+Co...   \n",
       "402                                   Human evaluators   \n",
       "403  LDA unigrams (Presence/Count), POS Ratio, #Nam...   \n",
       "404  51.7 and 51.6 on 4th and 8th grade question se...   \n",
       "405  The dataset comes with a ranked set of relevan...   \n",
       "406  Best BLSTM-CNN-CRF had F1 score 86.87 vs 86.69...   \n",
       "407  Multitask learning is used for the task of pre...   \n",
       "408  0.007 MAP on Task A, 0.032 MAP on Task B, 0.05...   \n",
       "409  Proposed model has 1.16 million parameters and...   \n",
       "410                                                  9   \n",
       "411  Only MTMSM specifically tried to tackle the mu...   \n",
       "412  For single-span questions, the proposed LARGE-...   \n",
       "413  The proposed model achieves  EM 77,63 and F1 8...   \n",
       "414  BiLSTM-XR-Dev Estimation accuracy is 83.31 for...   \n",
       "415                      The Lemming model in BIBREF17   \n",
       "416  They evaluate F1 score and agent's test perfor...   \n",
       "417  Unimodal LSTM vs Best Multimodal (FCM)\\n- F sc...   \n",
       "418  On SearchSnippets dataset ACC 77.01%, NMI 62.9...   \n",
       "419  on SearchSnippets dataset by 6.72% in ACC, by ...   \n",
       "420  POS and DP task: CONLL 2018\\nNER task: (no ext...   \n",
       "421  Tweets noisy nature, use of creative spelling ...   \n",
       "422  27.41 transformation on average of single seed...   \n",
       "423  For each source sentence, transformation sente...   \n",
       "424                             Yes, as new sentences.   \n",
       "425  - paraphrase 1\\n- paraphrase 2\\n- different me...   \n",
       "426  accuracy of 86.63 on STS, 85.14 on Sanders and...   \n",
       "427  rules that compute polarity of words after POS...   \n",
       "428  Experiment 1: ACC around 0.5 with 50% noise ra...   \n",
       "429  ERR of 19.05 with i-vectors and 15.52 with x-v...   \n",
       "430  genre, entertainment, interview, singing, play...   \n",
       "431                                           x-vector   \n",
       "432  For i-vector system, performances are 11.75% i...   \n",
       "433                       Accuracy across six datasets   \n",
       "434                                  Kim et al. (2019)   \n",
       "435  Considering \"What\" and \"How\" separately versus...   \n",
       "436       Textual inputs, knowledge bases, and images.   \n",
       "437  Demographic information is predicted using wei...   \n",
       "438  The data are self-reported by Twitter users an...   \n",
       "439    From Twitter profile descriptions of the users.   \n",
       "440            Sociability from ego-network on Twitter   \n",
       "441                                      Users' tweets   \n",
       "442  Profile pictures from the Twitter users' profi...   \n",
       "443  Average reward across 5 seeds show that NLP re...   \n",
       "444  Google N-grams\\nCOHA\\nMoral Foundations Dictio...   \n",
       "445  By complementing morally relevant seed words w...   \n",
       "446  Perplexity of the best model is 65.58 compared...   \n",
       "447  Answer with content missing: (list missing) \\n...   \n",
       "448  Upward reasoning is defined as going from one ...   \n",
       "449                                Use an existing one   \n",
       "450                                                CNN   \n",
       "451      MUC, CoNLL, ACE, OntoNotes, MSM, Ritter, UMBC   \n",
       "452                       1000 hours of WSJ audio data   \n",
       "453                wav2vec has 12 convolutional layers   \n",
       "454  In-house dataset consists of  3716 documents \\...   \n",
       "455  the baseline where path generation uses a stan...   \n",
       "456  For test-repeated set, EM score of 61.17, F1 o...   \n",
       "457  exact match, f1 score, edit distance and goal ...   \n",
       "458  using Amazon Mechanical Turk using simulated e...   \n",
       "459                                   english language   \n",
       "460  distinguishing between clinically positive and...   \n",
       "461  Achieved the highest per-domain scores on Subs...   \n",
       "462  A BPE model is applied to the stem after morph...   \n",
       "463  Comparison of test accuracies of neural networ...   \n",
       "464  IWSLT14 German-English, IWSLT14 Turkish-Englis...   \n",
       "465                               Using crowdsourcing    \n",
       "466                              single-domain setting   \n",
       "467                                             70,000   \n",
       "468  Because, unlike other languages, English does ...   \n",
       "469  by calculating log ratio of grammatical phrase...   \n",
       "470  Between the model and Stanford, Spacy and Flai...   \n",
       "471  F1 score and Recall are 68.66, 80.08 with Trad...   \n",
       "472                                           4 layers   \n",
       "473  Concat\\nTurn\\nGate\\nAction Copy\\nTree Copy\\nSQ...   \n",
       "474  There were hierarchical and non-hierarchical b...   \n",
       "475  F1 score of best authors' model is 55.98 compa...   \n",
       "476        4,261  days for France and 4,748 for the UK   \n",
       "477  Winter and summer words formed two separate cl...   \n",
       "478                     Relative error is less than 5%   \n",
       "479                                 F1 score of 66.66%   \n",
       "480                                 F1 score of 82.10%   \n",
       "481  For sentiment analysis UWB, INF-UFRGS-OPINION-...   \n",
       "482                            3347 unique utterances    \n",
       "483  A continuous emission HMM uses the hidden stat...   \n",
       "484  The HMM can identify punctuation or pick up on...   \n",
       "485  With similar number of parameters, the log lik...   \n",
       "486  Proposed model achieves 0.86, 0.924, 0.71 F1 s...   \n",
       "487                               278 more annotations   \n",
       "488  Inter-annotator agreement, comparison against ...   \n",
       "489  a trained worker consolidates existing annotat...   \n",
       "490                     WMT 2014 En-Fr parallel corpus   \n",
       "491                                          late 2014   \n",
       "492  96-97.6% using the objects color or shape and ...   \n",
       "493                                supervised learning   \n",
       "494  using the BLEU score as a quantitative metric ...   \n",
       "495  For the question generation model 15,000 image...   \n",
       "496  By considering words as vertices and generatin...   \n",
       "497  Perplexity of proposed MEED model is 19.795 vs...   \n",
       "498                                            Authors   \n",
       "499    they are available in the Visual Genome dataset   \n",
       "500                                           MultiNLI   \n",
       "501  BiLSTM-max, HBMP, ESIM, KIM, ESIM + ELMo, and ...   \n",
       "502  Private dashboard is leaderboard where competi...   \n",
       "503  Public dashboard where competitors can see the...   \n",
       "504  They used Wiki Vietnamese language and Vietnam...   \n",
       "505  They use it as addition to previous model - th...   \n",
       "506  Totally 6980 validation and test image-sentenc...   \n",
       "507  Italian Wikipedia and Google News extraction p...   \n",
       "508  Influential tweeters ( who they define as indi...   \n",
       "509  Stanford NER, BiLSTM+CRF, LSTM+CNN+CRF, T-NER ...   \n",
       "510  They identify documents that contain the unigr...   \n",
       "511  Randomly selected from a Twitter dump, tempora...   \n",
       "512  Presence of only the exact unigrams 'caused', ...   \n",
       "513                             Only automatic methods   \n",
       "514                       Randomly from a Twitter dump   \n",
       "515                              Randomly from Twitter   \n",
       "516  Variables in the set {str, prec, attr} indicat...   \n",
       "517  No, supervised models perform better for this ...   \n",
       "518  For task 1 best F1 score was 0.9391 on closed ...   \n",
       "519           well-formed sentences vs concise answers   \n",
       "520  BiDAF, Deep Cascade QA, S-Net+CES2S, BERT+Mult...   \n",
       "521  Bleu-1: 54.11, Bleu-4: 30.43, METEOR: 26.13, R...   \n",
       "522           well-formed sentences vs concise answers   \n",
       "523  Answer with content missing: (Data and pre-pro...   \n",
       "524  They collected tweets in Russian language usin...   \n",
       "525  Proposed SG model vs SINDHI FASTTEXT:\\nAverage...   \n",
       "526  908456 unique words are available in collected...   \n",
       "527  standard parametrized attention and a non-atte...   \n",
       "528  Ranges from 44.22 to 100.00 depending on K and...   \n",
       "529                      Sequence Copy Task and WMT'17   \n",
       "530  New best results of accuracy (P@1) on Vecmap:\\...   \n",
       "531  Proposed method vs best baseline result on Vec...   \n",
       "532  EN<->ES\\nEN<->DE\\nEN<->IT\\nEN<->EO\\nEN<->MS\\nE...   \n",
       "533  They introduce new trigonometric encoding whic...   \n",
       "534  They use three groups short/normal/long transl...   \n",
       "535          It uses deep learning framework (pytorch)   \n",
       "536  No reliability diagrams are provided and no ex...   \n",
       "537                                    word embeddings   \n",
       "538  Yes, CRWIZ has been used for data collection a...   \n",
       "539  The words that can indicate the characteristic...   \n",
       "540  Using a set of annotation tools such as Morfeu...   \n",
       "541  Our method performs a statistical test to dete...   \n",
       "542  SPNet vs best baseline:\\nROUGE-1: 90.97 vs 90....   \n",
       "543  Not at the moment, but summaries can be additi...   \n",
       "544  Answer with content missing: (formula for CIC)...   \n",
       "545                          FTLM++, BERT-large, XLNet   \n",
       "546  Some sentences are associated to ambiguous dim...   \n",
       "547               entity memory and relational memory.   \n",
       "548                      by number of distinct n-grams   \n",
       "549  ON Event2Mind, the accuracy of proposed method...   \n",
       "550   CWVAE is trained on an auxiliary dataset to l...   \n",
       "551  0.08 points on the 2011 test set, 0.44 points ...   \n",
       "552  Their best average precision tops previous bes...   \n",
       "553  10*n paraphrases, where n depends on the numbe...   \n",
       "554              weak correlation with p-value of 0.08   \n",
       "555  using topic modeling model Latent Dirichlet Al...   \n",
       "556  The embeddings are learned several times using...   \n",
       "557  The data from collected travel surveys is used...   \n",
       "558  The coefficients are projected back to the dum...   \n",
       "559  Proposed ORNN has 0.769, 1.238, 0.818, 0.772 c...   \n",
       "560  Difference is around 1 BLEU score lower on ave...   \n",
       "561  Answer with content missing: (formula) The acc...   \n",
       "562                                                36%   \n",
       "563  MT developers to which crowd workers were comp...   \n",
       "564  Using model gradients with respect to input fe...   \n",
       "565  In four entity-centric ways - entity-first, en...   \n",
       "566                                            English   \n",
       "567  BLEU scores, exact matches of words in both tr...   \n",
       "568  Combined per-pixel accuracy for character line...   \n",
       "569                                                508   \n",
       "570  There are 6 simulated datasets collected which...   \n",
       "571  rating questions on a scale of 1-5 based on fl...   \n",
       "572  reviews under distinct product categories are ...   \n",
       "573            A bi-LSTM with max-pooling on top of it   \n",
       "574      Improved AECNN-T by 2.1 and AECNN-T-SM BY 0.9   \n",
       "575                   AS Reader, GA Reader, CAS Reader   \n",
       "576  They were able to create a language model from...   \n",
       "577  extracted text from Sorani Kurdish books of pr...   \n",
       "578                                                  1   \n",
       "579  By visualizing syntactic distance estimated by...   \n",
       "580                                    BPC, Perplexity   \n",
       "581  they are used as additional features in a supe...   \n",
       "582  A combination of Minimum spanning trees, K-Nea...   \n",
       "583  They think it will help human TCM practitioner...   \n",
       "584  A pointer network decodes the answer from a bi...   \n",
       "585  They achieved best result in the PAN 2017 shar...   \n",
       "586                             Gender prediction task   \n",
       "587                            Variety prediction task   \n",
       "588  The training dataset is augmented by swapping ...   \n",
       "589                 Gendered characters in the dataset   \n",
       "590  Informative are those that will not be suppres...   \n",
       "591           Perpexity is improved from 34.7 to 28.0.   \n",
       "592  Accuracy of best interpretible system was 0.39...   \n",
       "593                                     French-English   \n",
       "594  Emotion Sensor Feature, Part of Speech, Punctu...   \n",
       "595  Systems do not perform well both in Facebook a...   \n",
       "596                                               None   \n",
       "597                                        WN18, FB15k   \n",
       "598  SLQA, Rusalka, HMA Model (single), TriAN (sing...   \n",
       "599             This approach considers related images   \n",
       "600  It eliminates non-termination in some models f...   \n",
       "601  There are is a strong conjecture that it might...   \n",
       "602                                     133,287 images   \n",
       "603  Proposed model achive 66+-22 win rate, baselin...   \n",
       "604   Author's own DCG rules are defined from scratch.   \n",
       "605                                2.7 accuracy points   \n",
       "606                   accuracy with standard deviation   \n",
       "607  Datasets used are Celex (English, Dutch), Fest...   \n",
       "608  Authors report their best models have followin...   \n",
       "609  CELEX (Dutch and English) - SVM-HMM\\nFestival,...   \n",
       "610  For relation prediction they test TransE and f...   \n",
       "611  By assessing similarity of 360 pairs of relati...   \n",
       "612  To classify a text as belonging to one of the ...   \n",
       "613  A network, whose learned functions satisfy a c...   \n",
       "614  Switchboard-2000 contains 1700 more hours of s...   \n",
       "615  Answer with content missing: (Experimental set...   \n",
       "616  1. there may be situations where more than one...   \n",
       "617                           using generative process   \n",
       "618                Average claim length is 8.9 tokens.   \n",
       "619  Ethics, Gender, Human rights, Sports, Freedom ...   \n",
       "620  In terms of F1 score, the Hybrid approach impr...   \n",
       "621  Each class has different patterns in adjective...   \n",
       "622  Gospel, Sertanejo, MPB, Forró, Pagode, Rock, S...   \n",
       "623  LSTMs with and without attention, HRED, VHRED ...   \n",
       "624  Through Amazon MTurk annotators to determine p...   \n",
       "625  on diversity 6.87 and on relevance 4.6 points ...   \n",
       "626                    the hybrid model MinAvgOut + RL   \n",
       "627  most of the models have similar performance on...   \n",
       "628  ROUGE-1 increases by 0.05, ROUGE-2 by 0.06 and...   \n",
       "629               binary label of stress or not stress   \n",
       "630           By annotators on Amazon Mechanical Turk.   \n",
       "631                                                one   \n",
       "632  They exclude slot-specific parameters and inco...   \n",
       "633                       By the number of parameters.   \n",
       "634  Answer with content missing: (Skip-thought vec...   \n",
       "635  - En-Fr (WMT14)\\n- En-De (WMT15)\\n- Skipthough...   \n",
       "636  By using  keywords `breast' AND `cancer' in tw...   \n",
       "637  ML  logistic regression classifier combined wi...   \n",
       "638  PPL: SVT\\nDiversity: GVT\\nEmbeddings Similarit...   \n",
       "639  Attention-based translation model with convolu...   \n",
       "640        Bidirectional LSTM based NER model of Flair   \n",
       "641  Little overlap except common basic Latin alpha...   \n",
       "642        Hindi, English and German (German task won)   \n",
       "643                                               thai   \n",
       "644  Answer with content missing: (formula 1) bias(...   \n",
       "645                                    word error rate   \n",
       "646                             163,110,000 utterances   \n",
       "647             Their model does not differ from BERT.   \n",
       "648  Answer with content missing: (Formula 2) Formu...   \n",
       "649                              There is no baseline.   \n",
       "650                                  553,451 documents   \n",
       "651  The model outperforms at every point in the\\ni...   \n",
       "652                                 MC-CNN\\nMVCNN\\nCNN   \n",
       "653  In terms of Subj the Average MGNC-CNN is bette...   \n",
       "654  Humor in headlines (TitleStylist vs Multitask ...   \n",
       "655  The languages considered were English, Chinese...   \n",
       "656  They experimented with sentiment analysis and ...   \n",
       "657  Accuracy on each dataset and the average accur...   \n",
       "658  youtube video transcripts on news covering dif...   \n",
       "659  It takes into account the agreement between di...   \n",
       "660  Answer with content missing: (Table 1) The per...   \n",
       "661  Answer with content missing: (Formula) Formula...   \n",
       "662  two surveys by two groups - school students an...   \n",
       "663  1 000 labeled dialogues for training and 240 u...   \n",
       "664  1 000 labeled dialogues for training and 240 u...   \n",
       "665                                               IDEA   \n",
       "666  Training embeddings from small-corpora can inc...   \n",
       "667      Visualization of State of the union addresses   \n",
       "668  Northeast U.S, South U.S., West U.S. and Midwe...   \n",
       "669                                 0.9098 correlation   \n",
       "670  Using Latent Dirichlet Allocation on TF-IDF tr...   \n",
       "671           Northeast U.S., West U.S. and South U.S.   \n",
       "672           evidence extraction and answer synthesis   \n",
       "673  Replacing attention mechanism to query-key att...   \n",
       "674  how long it takes the system to lemmatize a se...   \n",
       "675                                             97.32%   \n",
       "676  cloze-style reading comprehension and user que...   \n",
       "677                                            English   \n",
       "678  12 binary-class classification and multi-class...   \n",
       "679  machine translation, statistical machine, sent...   \n",
       "680                    CL Journal and EMNLP conference   \n",
       "681      English, Chinese, French, Japanese and Arabic   \n",
       "682  Simple Skip improves F1 from 74.34 to 74.81\\nT...   \n",
       "683  0.8 points on Binary; 0.7 points on Fine-Grain...   \n",
       "684                                              82.0%   \n",
       "685  Data released for APDA shared task contains 3 ...   \n",
       "686  It had the highest accuracy comparing to all d...   \n",
       "687  Human, FastQA, BiDAF, Coref-GRU, MHPGM, Weaver...   \n",
       "688  Assign a value to the relation based on whethe...   \n",
       "689  Exact matches to the entity string and predict...   \n",
       "690  During testing: 67.6 for single model without ...   \n",
       "691  Preceding and following sentence of each metap...   \n",
       "692         Best performance achieved is 0.72 F1 score   \n",
       "693  Answer with content missing: (Table II) Propos...   \n",
       "694  Answer with content missing: (Table II) Propos...   \n",
       "695  Damage to neural modules is done by randomly i...   \n",
       "696  Travel dataset contains 4100 raw samples, 1129...   \n",
       "697  User reviews written in Chinese collected onli...   \n",
       "698  They use a two-stage labeling strategy where i...   \n",
       "699  The changes are evaluated based on accuracy of...   \n",
       "700  Answer with content missing: (3 Experimental S...   \n",
       "701  440 sentences, 2247 triples extracted from tho...   \n",
       "702                                 OpenIE4 and MiniIE   \n",
       "703  They pre-train forward and backward LMs separa...   \n",
       "704                                  micro-averaged F1   \n",
       "705  91.93% F1 score on CoNLL 2003 NER task and 96....   \n",
       "706  Chiu and Nichols (2016), Lample et al. (2016),...   \n",
       "707  Both supervised and unsupervised, depending on...   \n",
       "708  Performance was comparable, with the proposed ...   \n",
       "709                                        GloVE; SGNS   \n",
       "710                                                GRU   \n",
       "711  It is a network used to encode speech lattices...   \n",
       "712  For sentence-level prediction they used tolera...   \n",
       "713       tutorial videos for a photo-editing software   \n",
       "714  a sentence-level prediction algorithm, a segme...   \n",
       "715  Full Testing Set accuracy: 84.02\\nCleaned Test...   \n",
       "716  Full Testing Set Accuracy: 84.02\\nCleaned Test...   \n",
       "717  Operation accuracy: 71.89\\nExecution accuracy:...   \n",
       "718  BLSTM+Attention+BLSTM\\nHierarchical BLSTM-CRF\\...   \n",
       "719  The baseline models used are DrQA modified to ...   \n",
       "720  Alarm, Banks, Buses, Calendar, Events, Flights...   \n",
       "721  Total number of annotated data:\\nSemeval'15: 1...   \n",
       "722       Arabic, German, Portuguese, Russian, Swedish   \n",
       "723  The three baseline models are the i-vector mod...   \n",
       "724  Proposing an improved RNN model, the phonetic ...   \n",
       "725  These are well-known formal languages some of ...   \n",
       "726  graph-like structures where arcs connect nodes...   \n",
       "727  NMI between cluster assignments and ground tru...   \n",
       "728                              Precision, Recall, F1   \n",
       "729  CoNLL 2003, GermEval 2014, CoNLL 2002, Egunkar...   \n",
       "730         Perceptron model using the local features.   \n",
       "731  AraVec for Arabic, FastText for French, and Wo...   \n",
       "732                               One model per topic.   \n",
       "733                      They evaluate quantitatively.   \n",
       "734             EER 16.04, Cmindet 0.6012, Cdet 0.6107   \n",
       "735                                Logistic regression   \n",
       "736  By using a Bayesian approach  and by using wor...   \n",
       "737  They use a left-to-right attention mask so tha...   \n",
       "738  The image feature vectors are mapped into BERT...   \n",
       "739  Answer with content missing: (whole introducti...   \n",
       "740  They perform t-SNE clustering to analyze disco...   \n",
       "741  They derive entity grid with grammatical relat...   \n",
       "742  Entity grid with grammatical relations and RST...   \n",
       "743  A sequence of logical statements represented i...   \n",
       "744  Raw data from Gigaword, Automatically segmente...   \n",
       "745  Pearson correlation to human judgement - propo...   \n",
       "746  Transcribed data is available for duration of ...   \n",
       "747  HotspotQA: Yang, Ding, Muppet\\nFever: Hanselow...   \n",
       "748                                                  2   \n",
       "749                                               8000   \n",
       "750  String kernel is a technique that uses charact...   \n",
       "751  They compute Pearson’s correlation between NED...   \n",
       "752                                              52.0%   \n",
       "753  300,000 sentences with 1.5 million single-quiz...   \n",
       "754  Around 388k examples, 194k from tst2013 (in-do...   \n",
       "755  a RNN-based seq2seq VC model called ATTS2S bas...   \n",
       "756                  AmazonQA and ConciergeQA datasets   \n",
       "757           Multi-Encoder, Constrained-Decoder model   \n",
       "758                           ConciergeQA and AmazonQA   \n",
       "759  by adding extra supervision to generate the sl...   \n",
       "760                       NDM, LIDM, KVRN, and TSCP/RL   \n",
       "761  Confusion in recognizing the words that are ac...   \n",
       "762  Proposed RCRN outperforms ablative baselines B...   \n",
       "763                                               51.5   \n",
       "764  High-order CNN, Tree-LSTM, DRNN, DCNN, CNN-MC,...   \n",
       "765   They used Stanford Sentiment Treebank benchma...   \n",
       "766  They used 6 indicators for proficiency (same f...   \n",
       "767  6 indicators:\\n- lexical richness\\n- pronuncia...   \n",
       "768  Accuracy not available: WER results are report...   \n",
       "769  Speech recognition system is evaluated using W...   \n",
       "770  Total number of transcribed utterances includi...   \n",
       "771  Total number of utterances available is: 70607...   \n",
       "772  w.r.t Rouge-1 their model outperforms by 0.98%...   \n",
       "773  neural attention model with a convolutional en...   \n",
       "774  F1 scores of 86.16 on slot filling and 94.56 o...   \n",
       "775                                  10,001 utterances   \n",
       "776  Questions are gathered from anonymized, aggreg...   \n",
       "777                   Remove numbers and interjections   \n",
       "778  10 Epochs: pearson-Spearman correlation  drops...   \n",
       "779                                      SST-2 dataset   \n",
       "780  The increase is linearly from lowest on averag...   \n",
       "781                                         40 minutes   \n",
       "782  Best model achieved F-score 74.7 on NALCS and ...   \n",
       "783  mean prediction accuracy 0.99582651\\nS&P 500 A...   \n",
       "784  historical S&P 500 component stocks\\n 306242 n...   \n",
       "785  it systematically holds out inputs in the trai...   \n",
       "786  The system outperforms by 27.7% the LSTM model...   \n",
       "787  The system is compared to baseline models: LST...   \n",
       "788  BULATS i-vector/PLDA\\nBULATS x-vector/PLDA\\nVo...   \n",
       "789                                      VQA and GeoQA   \n",
       "790  They use Monalog for data-augmentation to fine...   \n",
       "791                        They derive it from Wordnet   \n",
       "792  Economics, Genocide, Geography, History, Human...   \n",
       "793  Answer with content missing: (Names of many id...   \n",
       "794  WikiSQL - 2 rules (SELECT, WHERE)\\nSimpleQuest...   \n",
       "795  Bi-LSTM: For low resource <17k clean data: Usi...   \n",
       "796  Evaluation datasets used:\\nCMRC 2018 - 18939 q...   \n",
       "797  Microsoft Research dataset containing movie, t...   \n",
       "798  For entity  F1 in the movie, taxi and restaura...   \n",
       "799  It has three sequentially connected units to o...   \n",
       "800  counts of predicate-argument tuples from Engli...   \n",
       "801  Test set 1 contained 57 drug labels and 8208 s...   \n",
       "802  ABSA SemEval 2014-2016 datasets\\nYelp Academic...   \n",
       "803                                             $1,728   \n",
       "804            BERT, XLNET RoBERTa, ALBERT, DistilBERT   \n",
       "805                     using multiple pivot sentences   \n",
       "806  For the Oshiete-goo dataset, the NAGM model's ...   \n",
       "807   In closed setting 84.22 F1 and in open 87.35 F1.   \n",
       "808  Marcheggiani and Titov (2017) and Cai et al. (...   \n",
       "809                                      14 categories   \n",
       "810                                     YouTube videos   \n",
       "811  Qualitatively through efficiency, effectivenes...   \n",
       "812  Answer with content missing: (Chapter 3) The c...   \n",
       "813  Train languages are: Cantonese, Bengali, Pasht...   \n",
       "814  They  evaluate newly proposed models in severa...   \n",
       "815                      It contains 106,350 documents   \n",
       "816                                over 104k documents   \n",
       "817  Perplexity score 142.84 on dev and 138.91 on test   \n",
       "818  Parallel monolingual corpus in English and Man...   \n",
       "819  in open-ended task esp. for counting-type ques...   \n",
       "820                         LASSO optimization problem   \n",
       "821                 Personal thought of the annotator.   \n",
       "822  Word embeddings trained on GoogleNews and Word...   \n",
       "823  Entity identification with offset mapping and ...   \n",
       "824  They randomly sample sentences from Wikipedia ...   \n",
       "825  Lexicon of the cities tend to use most forms o...   \n",
       "826  It uses particular forms of a concept rather t...   \n",
       "827  Overall accuracy per model is: 5-gram (60.5), ...   \n",
       "828                 bag of words, tf-idf, bag-of-means   \n",
       "829  Aristo Corpus\\nRegents 4th\\nRegents 8th\\nRegen...   \n",
       "830                                                 12   \n",
       "831  - Font & Keyboard\\n- Speech-to-Text\\n- Text-to...   \n",
       "832  The reciprocal of the variance of the attentio...   \n",
       "833  Measuring three aspects: argumentation, specif...   \n",
       "834  2008 Punyakanok et al. \\n2009 Zhao et al. + ME...   \n",
       "835                                     LSTM and BERT    \n",
       "836  Dataset has 1737 train, 497 dev and 559 test s...   \n",
       "837                            4.756 million sentences   \n",
       "838  can be biased by dataset used and may generate...   \n",
       "839  it is less expensive and quantifies interpreta...   \n",
       "840  By computing number of unique responses and nu...   \n",
       "841      RNN-context, SRB, CopyNet, RNN-distract, DRGD   \n",
       "842  comparing the summary with the text instead of...   \n",
       "843  EN, JA, ES, AR, PT, KO, TH, FR, TR, RU, IT, DE...   \n",
       "844  Proposed vs best baseline:\\nDecoding: 8541 vs ...   \n",
       "845                                     WN18 and FB15k   \n",
       "846  Online sites tagged as fake news site by Veraf...   \n",
       "847  Siamese neural network consisting of an embedd...   \n",
       "848  besides claim, label and claim url, it also in...   \n",
       "849                                        monolingual   \n",
       "850  performance is significantly degraded without ...   \n",
       "851  Comparing BLEU score of model with and without...   \n",
       "852  The health benefits of alcohol consumption are...   \n",
       "853                  not researched as much as English   \n",
       "854                                                  3   \n",
       "855  Matching features from matching sentences from...   \n",
       "856  Their average improvement in Character Error R...   \n",
       "857                                             449050   \n",
       "858                                                  1   \n",
       "859  2 for the ADE dataset and 3 for the CoNLL04 da...   \n",
       "860                                1, 4, 8, 16, 32, 64   \n",
       "861  S2VT, RGB (VGG), RGB (VGG)+Flow (AlexNet), LST...   \n",
       "862                  German, English, Italian, Chinese   \n",
       "863                         About the same performance   \n",
       "864                                 F1 and Weighted-F1   \n",
       "865  Yes, Transformer based seq2seq is evaluated wi...   \n",
       "866   Generate a query out of the claim and queryin...   \n",
       "867              weibo-100k, Ontonotes, LCQMC and XNLI   \n",
       "868                                               3029   \n",
       "869  MOCC, OCCAV, COAV, AVeer, GLAD, DistAV, Unmask...   \n",
       "870  Annotation was done with the help of annotator...   \n",
       "871  They look at the performance accuracy of expla...   \n",
       "872  Their model resulted in values of 0.476, 0.672...   \n",
       "873  by converting human advice to first-order logi...   \n",
       "874  affective features provided by different emoti...   \n",
       "875  Data augmentation (es)  improved Adv es by 20%...   \n",
       "876  In task 1 best transfer learning strategy impr...   \n",
       "877                                                SVM   \n",
       "878  Clusters of Twitter user ids from accounts of ...   \n",
       "879  On subtask 3 best proposed model has F1 score ...   \n",
       "880  1448 sentences more than the dataset from Bhat...   \n",
       "881   The dataset from a joint ADAPT-Microsoft project   \n",
       "882  Background, extends, uses, motivation, compare...   \n",
       "883  Annotators went through various phases to make...   \n",
       "884  the best performing model obtained an accuracy...   \n",
       "885  Appreciation, Satisfied, Peripheral complaint,...   \n",
       "886  The sequence model architectures which this me...   \n",
       "887  Across 4 datasets, the best performing propose...   \n",
       "888  error rate in a minimal pair ABX discriminatio...   \n",
       "889                                        BLEU scores   \n",
       "890  a linear projection and a bijective function w...   \n",
       "891  Alarm\\nBank\\nBus\\nCalendar\\nEvent\\nFlight\\nHom...   \n",
       "892  They pre-train the models using 600000 article...   \n",
       "893                                        645, 600000   \n",
       "894           The negative effects were insignificant.   \n",
       "895            English to French and English to German   \n",
       "896  Accuracy and F1 score for supervised tasks, Pe...   \n",
       "897  Zipf's law describes change of word frequency ...   \n",
       "898  Random perturbation of Wikipedia sentences usi...   \n",
       "899  Proposed method achieves 94.5 UAS and 92.4 LAS...   \n",
       "900  root mean square error between the actual and ...   \n",
       "901  By using Apache Spark which stores all executi...   \n",
       "902  handling large volume incoming data, sentiment...   \n",
       "903  BLUE utilizes different metrics for each of th...   \n",
       "904  bilingual dictionary induction, monolingual an...   \n",
       "905  because word pair similarity increases if the ...   \n",
       "906  Word alignments are generated for parallel tex...   \n",
       "907  0.8320 on semantic typing, 0.7194 on entity ma...   \n",
       "908  Answer with content missing: (Table 2) CONCAT ...   \n",
       "909  They initialize their word and entity embeddin...   \n",
       "910  The authors believe that the Wikilinks corpus ...   \n",
       "911  No, it is a probabilistic model trained by fin...   \n",
       "912  Through human evaluation where they are asked ...   \n",
       "913        Darkode,  Hack Forums, Blackhat and Nulled.   \n",
       "914  BERT generates sentence embeddings that repres...   \n",
       "915  the training dataset is large while the target...   \n",
       "916  Variety of formats supported (PDF, Word...), u...   \n",
       "917        optimize single task with no synthetic data   \n",
       "918  networks where nodes represent causes and effe...   \n",
       "919  if it includes  negative utterances, negative ...   \n",
       "920  By treating logical forms as a latent variable...   \n",
       "921  ISOT dataset: LLVM\\nLiar dataset: Hybrid CNN a...   \n",
       "922  Their GTRS approach got an improvement of 3.89...   \n",
       "923  Answer with content missing: (Applications sec...   \n",
       "924  deciding publisher partisanship, risk annotato...   \n",
       "925                                    CNN, LSTM, BERT   \n",
       "926  No feature is given, only discussion that sema...   \n",
       "927  It is not completely valid for natural languag...   \n",
       "928      DocQA, SAN, QANet, ASReader, LM, Random Guess   \n",
       "929  TEACHER FORCING (TF), SCHEDULED SAMPLING (SS),...   \n",
       "930  The relation R(x,y) is mapped onto a question ...   \n",
       "931  pre-trained to identify the presence of behavi...   \n",
       "932  The model does not add new relations to the kn...   \n",
       "933  The dataset contains about 590 tweets about DD...   \n",
       "934  Tweets related to a Bank of America DDos attac...   \n",
       "935  current news, historical news, free time, spor...   \n",
       "936  high-order representation of a relation, loss ...   \n",
       "937                                 NELL-One, Wiki-One   \n",
       "938  comparing to the results from reducing the num...   \n",
       "939     Multilingual Neural Machine Translation Models   \n",
       "940  Automatic transcription of 5000 tokens through...   \n",
       "941  The framework jointly learns parametrized QA a...   \n",
       "942  efficiency task aimed  at reducing the number ...   \n",
       "943  It is observed some variability - but not sign...   \n",
       "944  There is no reason to think that this approach...   \n",
       "945      The same 2K set from Gigaword used in BIBREF7   \n",
       "946    all regions except those that are colored black   \n",
       "947           they use ROC curves and cross-validation   \n",
       "948  They use self-play learning , optimize the mod...   \n",
       "949  1,618 training dialogs, 500 validation dialogs...   \n",
       "950  Training datasets: TTS System dataset and embe...   \n",
       "951  The mixed objective improves EM by 2.5% and F1...   \n",
       "952  5 domains: software, stuff, african wildlife, ...   \n",
       "953  Improve existing NLP methods. Improve linguist...   \n",
       "954  Two neural networks: an extractor based on an ...   \n",
       "955  AE-HCN outperforms by 17%, AE-HCN-CNN outperfo...   \n",
       "956  Similar to standard convolutional networks but...   \n",
       "957  Optimized TF-IDF, iterated TF-IDF, BERT re-ran...   \n",
       "958  Kaggle\\nSubversive Kaggle\\nWikipedia\\nSubversi...   \n",
       "959  Compared to baselines SAN (Table 1) shows  imp...   \n",
       "960  The baseline is a multi-task architecture insp...   \n",
       "961  The network architecture has a multi-task Bi-D...   \n",
       "962  Stacks and joins outputs of previous frames wi...   \n",
       "963  reward 1 for successfully completing the task,...   \n",
       "964  No, there has been previous work on recognizin...   \n",
       "965  3 million webpages processed with a CCG parser...   \n",
       "966       Fill-in-the-blank natural language questions   \n",
       "967                   3 feature maps for a given tuple   \n",
       "\n",
       "                                               context  \n",
       "0    For MultiUN corpus, we use four languages: Eng...  \n",
       "1    Data collection. Subreddits are sub-communitie...  \n",
       "2    FLOAT SELECTED: Table 2: Main results on the D...  \n",
       "3    With the purpose of obtaining evaluation datas...  \n",
       "4    We experimented with English INLINEFORM0 Hindi...  \n",
       "5    The paper at hand introduces a corpus develope...  \n",
       "6    We measure how contextual a word representatio...  \n",
       "7    FLOAT SELECTED: Table 1: The performance of va...  \n",
       "8    To finish with this experiment set, Table also...  \n",
       "9    Even if LangID-High does not present a more ac...  \n",
       "10   Human Evaluation Results. While automated eval...  \n",
       "11   It may be difficult to spot patterns by just l...  \n",
       "12   Ethnicity/race One interesting pattern is that...  \n",
       "13   The second row shows the performance of our ba...  \n",
       "14   In this paper, we propose a method that builds...  \n",
       "15   However, getting access to systems with real u...  \n",
       "16   We collected the dataset with 1900 dialogs and...  \n",
       "17   Named Entity Recognition: We defined a sequenc...  \n",
       "18   In this paper, we explore multiple pooling str...  \n",
       "19   GhostVLAD is an extension of the NetVLAD appro...  \n",
       "20   FLOAT SELECTED: Table 1: Dataset In this secti...  \n",
       "21   In this section, we introduce an invertibility...  \n",
       "22   We create two models both of which constitutes...  \n",
       "23   FLOAT SELECTED: Table 2: Clustering results on...  \n",
       "24   FLOAT SELECTED: Table 2: Top: Examples of with...  \n",
       "25   Automatically answering questions, especially ...  \n",
       "26   Our comprehensive assessment reveals several i...  \n",
       "27   FLOAT SELECTED: Table 2: Official shared task ...  \n",
       "28   FLOAT SELECTED: Table 1: Example input sentenc...  \n",
       "29   Table TABREF21 reports comparison results in l...  \n",
       "30   To test all the possible combinations of param...  \n",
       "31   FLOAT SELECTED: Figure 2: Ablation results on ...  \n",
       "32   Baselines. As none of the existing KBC methods...  \n",
       "33   We solve the OKBC problem by mimicking how hum...  \n",
       "34   FLOAT SELECTED: Table 1: Summary of datasets. ...  \n",
       "35   FLOAT SELECTED: Table 1: Summary of datasets. ...  \n",
       "36   Monosemous relatives have been employed multip...  \n",
       "37   Comparing these topics with those that appeare...  \n",
       "38   Depechemood is a lexicon-based emotion detecti...  \n",
       "39   What similarities and/or differences do these ...  \n",
       "40   Topic modeling methods are the more powerful t...  \n",
       "41   We develop a variety of ShapeWorldICE datasets...  \n",
       "42   FLOAT SELECTED: Table 1: The results of two pr...  \n",
       "43   FLOAT SELECTED: Table 2: EM/F1 score of multi-...  \n",
       "44   The SnapCaptions dataset is composed of 10K us...  \n",
       "45   Based on the above observations, we propose St...  \n",
       "46   Our analysis shows that attention models tradi...  \n",
       "47   To better understand how attention accuracy af...  \n",
       "48   FLOAT SELECTED: Table 1: The comparison of var...  \n",
       "49   We first use state-of-the-art PDTB taggers for...  \n",
       "50   We defined the intents with guidance from quer...  \n",
       "51   This paper fills this gap by analyzing intent ...  \n",
       "52   We introduce a new crowdsourced dataset of 23,...  \n",
       "53   We show that existing automatic metrics, inclu...  \n",
       "54   The data collection was performed separately f...  \n",
       "55   We use bootstrap sampling (500 iterations) ove...  \n",
       "56   FLOAT SELECTED: Table 8: Sector-level performa...  \n",
       "57   The above challenges often hinder the producti...  \n",
       "58   Though Bengali is the seventh most spoken lang...  \n",
       "59   The performance of all models on arXiv and Pub...  \n",
       "60   The baseline system for the SLC task is a very...  \n",
       "61   However, despite these successes distributiona...  \n",
       "62   MiniMayoSRS: The MayoSRS, developed by Pakhomo...  \n",
       "63   In our experiments, the Memory Neural Networks...  \n",
       "64   To ensure that the increase in BLEU score corr...  \n",
       "65   FLOAT SELECTED: Table 3: Comparison with exist...  \n",
       "66   The results for each class type are shown in T...  \n",
       "67   While these knowledge bases provide semantical...  \n",
       "68   Baseline Results ::: Speech Synthesis In our p...  \n",
       "69   In addition, the transcription includes annota...  \n",
       "70   where * denotes summation over the correspondi...  \n",
       "71   Why incorporate -PMI? $\\mathit {\\texttt {+}PPM...  \n",
       "72   Unfortunately, $\\mathit {PMI}(w,c)$ goes to ne...  \n",
       "73   This work is most closely related to the paper...  \n",
       "74   This work is most closely related to the paper...  \n",
       "75   We carried out our experiments on the Universa...  \n",
       "76   FLOAT SELECTED: Table 1: Twitter celebrities i...  \n",
       "77   This work analyzes the understanding of pretra...  \n",
       "78   We considered a dataset of 100 employees, wher...  \n",
       "79   We randomly selected 2000 sentences from the s...  \n",
       "80   We select contemporary MRC benchmarks to repre...  \n",
       "81   Figure FIGREF4 pictorially represents our meth...  \n",
       "82   The previously proposed contextual language mo...  \n",
       "83   To better demonstrate the effectiveness of the...  \n",
       "84   FLOAT SELECTED: Table 1: Hyper-parameter choic...  \n",
       "85   The flow of talking points . A side can either...  \n",
       "86   FLOAT SELECTED: Table 2: Comparison of annotat...  \n",
       "87   RKS approach proposed in BIBREF21, BIBREF22, e...  \n",
       "88   In addition to words, EqEmb models can capture...  \n",
       "89   Feature elimination strategies are often taken...  \n",
       "90   Specifically, we conducted a feature ablation ...  \n",
       "91   In this work, we use the raw waveform as the i...  \n",
       "92   where INLINEFORM0 , INLINEFORM1 is the number ...  \n",
       "93   A total of 2,50,000 tweets over a period of Au...  \n",
       "94   When predicting anger, joy, or valence, the nu...  \n",
       "95   We decided to use sentences involving at least...  \n",
       "96   We also evaluate the Jasper model's performanc...  \n",
       "97   We trained a smaller Jasper 10x3 model with SG...  \n",
       "98   FLOAT SELECTED: Table 1: Speech Embeddings Exp...  \n",
       "99   Table TABREF21 illustrates the experimental re...  \n",
       "100  Active learning sharply increases the performa...  \n",
       "101  We began with evaluating standard MT paradigms...  \n",
       "102  Two batch of tests were performed. The first o...  \n",
       "103  We perform a direct comparison of expert and c...  \n",
       "104  Recently, ELMoForManyLangs BIBREF6 project rel...  \n",
       "105  FLOAT SELECTED: Table 4: The results of NER ev...  \n",
       "106  Table TABREF11 shows Word Error Rates (WER) on...  \n",
       "107  FLOAT SELECTED: Table 1: Speech datasets used....  \n",
       "108  Despite its usefulness, linked entities extrac...  \n",
       "109  FLOAT SELECTED: Table 1: Dataset statistics In...  \n",
       "110  Similar approaches has been applied to many So...  \n",
       "111  After much time, we received the dataset from ...  \n",
       "112  FLOAT SELECTED: Table 1: Dataset statistics Ta...  \n",
       "113  FLOAT SELECTED: Table 1: Dataset statistics Af...  \n",
       "114  FLOAT SELECTED: Table 5: Comparison of differe...  \n",
       "115  We have evaluated our models considering the F...  \n",
       "116  We compare eight different models in our exper...  \n",
       "117  In this paper we present our work, which is a ...  \n",
       "118  In this paper we present our work, which is a ...  \n",
       "119  In order to evaluate our classifiers, we perfo...  \n",
       "120  FLOAT SELECTED: Table 2: Evaluation metrics fo...  \n",
       "121  Figure FIGREF10 illustrates the UTCNN model. A...  \n",
       "122  We pit our model against the following baselin...  \n",
       "123  We compare the SBERT sentence embeddings to ot...  \n",
       "124  FLOAT SELECTED: Table 1: Spearman rank correla...  \n",
       "125  As a first baseline we use Bag-of-Words, a wel...  \n",
       "126  Considering the improvements over the majority...  \n",
       "127  In order to eliminate the need to find data an...  \n",
       "128  We evaluate our model on a publicly available ...  \n",
       "129  In order to decode spatial connections between...  \n",
       "130  Datasets. We perform our experiments with two ...  \n",
       "131  Human-in-the-Loop Approaches. Our work extends...  \n",
       "132  Our approach improves LR by 5.17% (Accuracy) a...  \n",
       "133  Macaw also supports Wizard of Oz studies or in...  \n",
       "134  Here we introduce the evaluation setup and ana...  \n",
       "135  We model the ASP placement task as a successor...  \n",
       "136  An important feature when suggesting an articl...  \n",
       "137  Baseline Features. As discussed in Section SEC...  \n",
       "138  We asked medical doctors experienced in extrac...  \n",
       "139  Experimental Setup. We apply a 5 cross-validat...  \n",
       "140  Given a news Twitter account, we read its twee...  \n",
       "141  Data. We build a dataset of Twitter accounts b...  \n",
       "142  The main obstacle for detecting suspicious Twi...  \n",
       "143  For the evaluation of summaries we use the sta...  \n",
       "144  After parsing (Step 1) we have the AMR graphs ...  \n",
       "145  FLOAT SELECTED: Table 3: Distribution of label...  \n",
       "146  Level B categorizes the type of offense and tw...  \n",
       "147  The data included in OLID has been collected f...  \n",
       "148  Our proposed metric is based on analysis of th...  \n",
       "149  Table TABREF23 shows the Pearson, Spearman and...  \n",
       "150  Results for the experiments are listed in Tabl...  \n",
       "151  Table TABREF19 displays the performance of the...  \n",
       "152  The error detection results can be seen in Tab...  \n",
       "153  Results. Table 1 shows the results of all mode...  \n",
       "154  Dataset. We use two simplification datasets (W...  \n",
       "155  Next, we analyzed all tweets labeled as offens...  \n",
       "156  We developed the annotation guidelines jointly...  \n",
       "157  Disclaimer: Due to the nature of the paper, so...  \n",
       "158  Although some previous studies focus on irony ...  \n",
       "159  As neural networks are proved effective in iro...  \n",
       "160  In order to evaluate sentiment preservation, w...  \n",
       "161  We have decided to consider tweets about popul...  \n",
       "162  With an intention to exploit the contribution ...  \n",
       "163  Results in Table TABREF13 show ten probes. Aga...  \n",
       "164  Recent work has probed the knowledge encoded i...  \n",
       "165  To deal with these limitations, in this paper,...  \n",
       "166  FLOAT SELECTED: Table 1: Industry categories a...  \n",
       "167  Minimal pre-processing was done by converting ...  \n",
       "168  FLOAT SELECTED: Table 2: LID Accuracy Results....  \n",
       "169  We address the robustness problem on top of GE...  \n",
       "170  In this section, we first justify the approach...  \n",
       "171  GE-FL reduces the heavy load of instance annot...  \n",
       "172  We annotated the dataset at two levels: Part o...  \n",
       "173  FLOAT SELECTED: Figure 2: Histogram of documen...  \n",
       "174  In this paper, we use three encoders (NBOW, LS...  \n",
       "175  In order to achieve these configuration the TI...  \n",
       "176  FLOAT SELECTED: Table 1: Comparison results on...  \n",
       "177  FLOAT SELECTED: Table 1: Comparison results on...  \n",
       "178  We evaluate our model on two benchmark dataset...  \n",
       "179  The contexts have the characteristic that each...  \n",
       "180  To address this issue, we extract the structur...  \n",
       "181  Table TABREF30 shows automatic evaluation resu...  \n",
       "182  BioASQ organizers provide the training and tes...  \n",
       "183  FLOAT SELECTED: Table 1: Factoid Questions. In...  \n",
       "184  In this experiment, we propose to use the esti...  \n",
       "185  Following the formula, we can calculate the co...  \n",
       "186  We used recordings of nurse-initiated telephon...  \n",
       "187  To evaluate the effectiveness of our linguisti...  \n",
       "188  MRC Dataset. The MRC dataset used in this pape...  \n",
       "189  We experimented with four different classifier...  \n",
       "190  Nonetheless, GANs have continued to show their...  \n",
       "191       FLOAT SELECTED: Table 1: Results of RNN/LSTM  \n",
       "192  FLOAT SELECTED: Table 5: Results on PKU and MS...  \n",
       "193  Different from scaled dot-product attention, G...  \n",
       "194  Tables TABREF25 and TABREF26 reports the perfo...  \n",
       "195  While manually analyzing the raw dataset, we n...  \n",
       "196  By examining more samples and with respect to ...  \n",
       "197  As one of the first attempts in neural network...  \n",
       "198  By examining more samples and with respect to ...  \n",
       "199  FLOAT SELECTED: Table 5 Accuracy of concept ca...  \n",
       "200  FLOAT SELECTED: Table 8 Evaluation results of ...  \n",
       "201  FLOAT SELECTED: Table 2: We generate vectors f...  \n",
       "202  One of the main goals of this study is to impr...  \n",
       "203  Especially after the introduction of the word2...  \n",
       "204  Despite this, there is a lack of prior work wh...  \n",
       "205  There are several challenges on supervised lea...  \n",
       "206  There are several studies about the Vietnamese...  \n",
       "207  We collected tweets associated to a dozen US m...  \n",
       "208  As it is reported that conservatives and liber...  \n",
       "209  Questions: We make use of the 7,787 science ex...  \n",
       "210  Training We collect 50,000 Wikipedia articles ...  \n",
       "211  Complexity Analysis Compared with local method...  \n",
       "212  A long-standing tradition if the field of appl...  \n",
       "213  FLOAT SELECTED: Table 1: Training corpora For ...  \n",
       "214  FLOAT SELECTED: Table 1: Comparison of differe...  \n",
       "215  In NLP, we often get such invariance for free,...  \n",
       "216  For sentiment classification, we systematicall...  \n",
       "217  Inspired by the psycholinguistic studies BIBRE...  \n",
       "218  For all the interest in adversarial computer v...  \n",
       "219  While BIBREF7 demonstrate strong word recognit...  \n",
       "220  Hybrid approaches. Figure FIGREF11 shows the a...  \n",
       "221  Data used to generate recommendations. We empl...  \n",
       "222  If we take the best psr ensemble trained on CB...  \n",
       "223  We chose SVMhmm BIBREF111 implementation of St...  \n",
       "224  DeepMine is publicly available for everybody w...  \n",
       "225  FLOAT SELECTED: Table 1. HPI Categories and An...  \n",
       "226  While previous work clearly states that effici...  \n",
       "227  In this study, we concentrate our effort on re...  \n",
       "228  We have created a dataset of discharge summari...  \n",
       "229  Table defines each of the considered clinical ...  \n",
       "230  CNN can also be employed on the sarcasm datase...  \n",
       "231  We apply our adaptively sparse Transformers on...  \n",
       "232  FLOAT SELECTED: Table 1: Machine translation t...  \n",
       "233  In a recent work on sentiment analysis in Turk...  \n",
       "234  The second Turkish dataset is the Twitter corp...  \n",
       "235  For Turkish, as the first dataset, we utilised...  \n",
       "236  Word Vectors: We focus primarily on the word v...  \n",
       "237  FLOAT SELECTED: Table 15: Evaluation of differ...  \n",
       "238  Given that there is no public dataset availabl...  \n",
       "239  FLOAT SELECTED: Table 4: Automatic evaluation ...  \n",
       "240  In this paper, we have analyzed various ways t...  \n",
       "241  We are mostly interested with the following tr...  \n",
       "242  We are mostly interested with the following tr...  \n",
       "243  In this section, we first describe the phenome...  \n",
       "244  INSIGHT 1: Political handles are more likely t...  \n",
       "245  In this paper, we explore a entire deep LSTM R...  \n",
       "246  FLOAT SELECTED: Table 3. The CER and RTF of 9-...  \n",
       "247  There is a high real time requirement in real ...  \n",
       "248  We assume that speech transcripts can be extra...  \n",
       "249  Concerning the neural network architecture, we...  \n",
       "250  Ternary and fine-grained sentiment classificat...  \n",
       "251  The Propaganda Techniques Corpus (PTC) dataset...  \n",
       "252  FLOAT SELECTED: Table 2: Metrics on generated ...  \n",
       "253  FLOAT SELECTED: Figure 1: Sample data flow thr...  \n",
       "254  We use a default train-validation-test split o...  \n",
       "255  For experiments, we train and evaluate our mod...  \n",
       "256  We evaluated summarization quality automatical...  \n",
       "257  In Table TABREF26 we report the results of our...  \n",
       "258  We use one public dataset Social Honeypot data...  \n",
       "259  Using the LDA model, each person in the datase...  \n",
       "260  Experimental Setup In this section we present ...  \n",
       "261  We construct three datasets based on IMDB revi...  \n",
       "262  Common Voice BIBREF10 is a crowdsourcing speec...  \n",
       "263  Table TABREF16 shows the results of our models...  \n",
       "264  Finally, we combine our CNN and RNN models usi...  \n",
       "265  (1) We propose extended middle context, a new ...  \n",
       "266  FLOAT SELECTED: Table 6: Performance of BERT-l...  \n",
       "267  To put the supervised score into context we li...  \n",
       "268  To structure an unordered document is an essen...  \n",
       "269  To identify legally sound answers, we recruit ...  \n",
       "270  Hashtag prediction for social media has been a...  \n",
       "271  We test the character and word-level variants ...  \n",
       "272  FLOAT SELECTED: Table 3: F1-score (%) for fine...  \n",
       "273  We use the pre-trained uncased BERT$_\\mathrm {...  \n",
       "274  FLOAT SELECTED: Table 1: Experimental results....  \n",
       "275  We proposed to use visual renderings of docume...  \n",
       "276  The Wikipedia dataset consists of articles fro...  \n",
       "277  We randomly sampled 5,000 articles from each q...  \n",
       "278  Table TABREF17 lists the features that we used...  \n",
       "279  More than 2,100 texts were paired with 15 ques...  \n",
       "280  Machine comprehension datasets consist of thre...  \n",
       "281  FLOAT SELECTED: Table 2: Comparison of our sys...  \n",
       "282  FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...  \n",
       "283  FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...  \n",
       "284  FLOAT SELECTED: Table 3: SLC: Scores on Dev (i...  \n",
       "285  FLOAT SELECTED: Table 2: Comparison of our sys...  \n",
       "286  Shared Task: This work addresses the two tasks...  \n",
       "287  Do multilingual models always need to be train...  \n",
       "288  Do multilingual models always need to be train...  \n",
       "289  Inspired by the StackLite tag recommendation t...  \n",
       "290  FLOAT SELECTED: Table 1: Statistics of dataset...  \n",
       "291  We report our model's performance on the prese...  \n",
       "292  We consider two datasets, representing related...  \n",
       "293  To test the effectiveness of this new architec...  \n",
       "294  For the McGurk effect, we attempt an illusion ...  \n",
       "295  We analyze which discourse phenomena are hard ...  \n",
       "296  The BLEU scores are provided in Table TABREF24...  \n",
       "297  Named Entity Recognition (NER) in the Biomedic...  \n",
       "298  Results ::: CoinCollector In this setting, we ...  \n",
       "299  FLOAT SELECTED: Table 1: Accuracy of Data Mani...  \n",
       "300  Our submissions ranked second (EI-Reg), second...  \n",
       "301  For each task, the training data that was made...  \n",
       "302  Language Selection. Multi-SimLex comprises ele...  \n",
       "303  Baseline Experiments In this section, we brief...  \n",
       "304  Baseline Experiments In this section, we brief...  \n",
       "305  We break down the task of importance annotatio...  \n",
       "306  The goal of an language model is to assign mea...  \n",
       "307  We next adapt a VQA deep learning architecture...  \n",
       "308  FLOAT SELECTED: Fig. 6: We propose a novel app...  \n",
       "309                               Results and Analysis  \n",
       "310  Table TABREF18 shows the results of the cross-...  \n",
       "311  In this section we describe the experiments pe...  \n",
       "312  To tackle this problem, we introduce the novel...  \n",
       "313  The last group contains the results of our pro...  \n",
       "314  Our testing dataset takes MIMIC-III BIBREF18 a...  \n",
       "315  Table TABREF18 shows the Spearman correlation ...  \n",
       "316  Table TABREF29 gives three results from our su...  \n",
       "317  We cluster the embeddings with INLINEFORM0 -Me...  \n",
       "318  We cluster the embeddings with INLINEFORM0 -Me...  \n",
       "319  Table TABREF23 shows the unlabeled INLINEFORM0...  \n",
       "320                                 Experimental Setup  \n",
       "321                                 Experimental Setup  \n",
       "322  FLOAT SELECTED: Table 1: For each one of the s...  \n",
       "323  For our study, we used the number of retweets ...  \n",
       "324  One straightforward way of sharing information...  \n",
       "325  We found that 82 users within our sample were ...  \n",
       "326  The 1327 `viral' tweets were manually annotate...  \n",
       "327  Data Collection. To build the large ancient-mo...  \n",
       "328  Table TABREF44 shows average results of our au...  \n",
       "329  The PolyResponse restaurant search is currentl...  \n",
       "330  Fig. FIGREF4 shows the distributions of seven ...  \n",
       "331  All corpora provide datasets/splits for answer...  \n",
       "332  DNN based models coupled with transfer learnin...  \n",
       "333  For our single-label topic classification expe...  \n",
       "334  FLOAT SELECTED: Figure 2: The framework of G-B...  \n",
       "335  FLOAT SELECTED: Figure 2: The framework of G-B...  \n",
       "336  We use three languages in our experiments: Eng...  \n",
       "337  While the RNN-based generators with DA gating-...  \n",
       "338  We assessed the proposed models on four differ...  \n",
       "339  To compare the conversions between USVC and Pi...  \n",
       "340  Table TABREF23 compares the performance of the...  \n",
       "341  FLOAT SELECTED: Table 1: XNLI dev results (acc...  \n",
       "342  So far a system was trained on one type of dat...  \n",
       "343  Our contributions in this work are summarized ...  \n",
       "344  We used the 1,000-tweet dataset by BIBREF2 tha...  \n",
       "345  FLOAT SELECTED: Table 1: Average Correct Class...  \n",
       "346  The experiment results of validation on Friend...  \n",
       "347  FLOAT SELECTED: Table 6: Validation Results (F...  \n",
       "348  In this section, we describe the experimental ...  \n",
       "349  Results and ablations ::: Ablation studies To ...  \n",
       "350  Results and ablations ::: Ablation studies To ...  \n",
       "351  The MP framework is based on the core idea of ...  \n",
       "352  FLOAT SELECTED: Table 3: Classification result...  \n",
       "353  FLOAT SELECTED: Table 2: The complete set of f...  \n",
       "354  This contrasts with much of the work in comput...  \n",
       "355  The seed lexicon consists of positive and nega...  \n",
       "356  FLOAT SELECTED: Table 3: Performance of variou...  \n",
       "357  In this paper, we propose a simple and effecti...  \n",
       "358  As a raw corpus, we used a Japanese web corpus...  \n",
       "359  FLOAT SELECTED: Table 4: Results for small lab...  \n",
       "360  In this paper, we propose a simple and effecti...  \n",
       "361  We constructed our seed lexicon consisting of ...  \n",
       "362  We find that dynamic communities, such as Seah...  \n",
       "363  Our full dataset consists of all subreddits on...  \n",
       "364  FLOAT SELECTED: Fig. 1. An illustrative exampl...  \n",
       "365  Our dataset is annotated based on Chinese path...  \n",
       "366  Our dataset is annotated based on Chinese path...  \n",
       "367  For each model, we examined word-level perplex...  \n",
       "368  The baseline model is a deep sequence-to-seque...  \n",
       "369  Geometric bias mitigation uses the cosine dist...  \n",
       "370  Overall, through the process described in Sect...  \n",
       "371  To provide an initial results, we take 50% of ...  \n",
       "372  FLOAT SELECTED: Table 1: Comparison of manuall...  \n",
       "373  In Table TABREF1, we summarize the quantitativ...  \n",
       "374  Understanding a user's intent and sentiment is...  \n",
       "375  Experimental results for the Twitter Sentiment...  \n",
       "376  In natural language, subjectivity refers to th...  \n",
       "377  Our first baseline is ROUGE-L BIBREF1 , since ...  \n",
       "378  NVDM (Lexical, Neural) is a VAE-based approach...  \n",
       "379  We assess the optimal number of topics that ne...  \n",
       "380  An extrinsic evaluation was carried out on the...  \n",
       "381  For the English version, we performed both a t...  \n",
       "382  Table TABREF29 presents the quantitative resul...  \n",
       "383  Active learning methods can generally be descr...  \n",
       "384  FLOAT SELECTED: Figure 4: Inter-annotator agre...  \n",
       "385  FLOAT SELECTED: Table 2: Data Statistics of th...  \n",
       "386  Database Construction: we crawled travel infor...  \n",
       "387  Results on WNLaMPro rare and medium are shown ...  \n",
       "388  FLOAT SELECTED: Table 3: Compare our model wit...  \n",
       "389  We conducted cross-validation experiments usin...  \n",
       "390  FLOAT SELECTED: Table 3: Token-level recall wh...  \n",
       "391  For the emotion recognition from text, we manu...  \n",
       "392  We use the TED data from the IWSLT 2014 German...  \n",
       "393  Dataset: Based on some earlier work, only avai...  \n",
       "394  Enabling computers to understand given documen...  \n",
       "395  FLOAT SELECTED: Table 1: Spearman’s ρ, Kendall...  \n",
       "396  Methods ::: Baselines ::: BiGRU s with attenti...  \n",
       "397  FLOAT SELECTED: Figure 1: SUM-QE rates summari...  \n",
       "398  SMT techniques require a parallel corpus in th...  \n",
       "399  In this section, we propose a taxonomy to summ...  \n",
       "400  Tourist: I can't go straight any further. Guid...  \n",
       "401  Experimental results of entity classification ...  \n",
       "402  FLOAT SELECTED: Table 5: Performance of human ...  \n",
       "403  FLOAT SELECTED: Table 1: Our Feature Set for D...  \n",
       "404  FLOAT SELECTED: Table 2: TUPLEINF is significa...  \n",
       "405  Each dataset consists of a collection of recor...  \n",
       "406  Table 2 shows our experiments on two models wi...  \n",
       "407  Automation of cQA forums can be divided into t...  \n",
       "408  FLOAT SELECTED: Table 4: Compared with other s...  \n",
       "409  To figure out whether the proposed AEN-GloVe i...  \n",
       "410  The final annotation categories for the datase...  \n",
       "411  MTMSN BIBREF4 is the first, and only model so ...  \n",
       "412  FLOAT SELECTED: Table 2. Performance of differ...  \n",
       "413  Table TABREF25 shows the results on DROP's tes...  \n",
       "414  FLOAT SELECTED: Table 1: Average accuracies an...  \n",
       "415  BIBREF17: The Lemming model is a log-linear mo...  \n",
       "416  We build the iSQuAD and iNewsQA datasets based...  \n",
       "417  Table TABREF31 shows the F-score, the Area Und...  \n",
       "418  FLOAT SELECTED: Table 6: Comparison of ACC of ...  \n",
       "419  FLOAT SELECTED: Table 6: Comparison of ACC of ...  \n",
       "420  We will compare to the more recent cross-lingu...  \n",
       "421  Pre-processing. Tweets are subject to standard...  \n",
       "422  In the second round, we collected 293 annotati...  \n",
       "423  We asked for two distinct paraphrases of each ...  \n",
       "424  In the second round, we collected 293 annotati...  \n",
       "425  We selected 15 modifications types to collect ...  \n",
       "426  FLOAT SELECTED: Table IV ACCURACY OF DIFFERENT...  \n",
       "427  In Twitter social networking, people express t...  \n",
       "428  The test accuracy curves with the noise rates ...  \n",
       "429  FLOAT SELECTED: Table 4. EER(%) results of the...  \n",
       "430  FLOAT SELECTED: Table 1. The distribution over...  \n",
       "431  FLOAT SELECTED: Table 4. EER(%) results of the...  \n",
       "432  FLOAT SELECTED: Table 4. EER(%) results of the...  \n",
       "433  FLOAT SELECTED: Table 2: Accuracies of differe...  \n",
       "434  FLOAT SELECTED: Table 2: Existing NQG models w...  \n",
       "435  Past research took a reductionist approach, se...  \n",
       "436  Question generation is an NLG task for which t...  \n",
       "437  We employ BIBREF73 's weighted lexicon of term...  \n",
       "438  Self-disclosure clues have been extensively ut...  \n",
       "439  Age Enabled Ground-truth Dataset: We extract u...  \n",
       "440  The recent advancements in deep neural network...  \n",
       "441  The recent advancements in deep neural network...  \n",
       "442  The recent advancements in deep neural network...  \n",
       "443  Results of the DQN-based agent are presented i...  \n",
       "444  To ground moral sentiment in text, we leverage...  \n",
       "445  To implement the first tier of our framework a...  \n",
       "446  As illustrated in Table TABREF12 (ID 1). Given...  \n",
       "447  Since the official test set has not been relea...  \n",
       "448  A context is upward entailing (shown by [... $...  \n",
       "449  For our experiments, we select a dataset whose...  \n",
       "450  We adopt the approach in BIBREF4 , modifying i...  \n",
       "451  Since the goal of this study is to compare NER...  \n",
       "452  We consider pre-training on the audio data (wi...  \n",
       "453  Given raw audio samples INLINEFORM0 , we apply...  \n",
       "454  FLOAT SELECTED: Table 2: Number of documents i...  \n",
       "455  The baseline approach is based on BIBREF20 . I...  \n",
       "456  FLOAT SELECTED: Table 3: Performance of differ...  \n",
       "457  We compare the performance of translation appr...  \n",
       "458  This work also contributes a new dataset of IN...  \n",
       "459  While the dataset was collected with simulated...  \n",
       "460  Our current feature set for training a machine...  \n",
       "461  FLOAT SELECTED: Table 5: Overall and domain-sp...  \n",
       "462  The problem with morpheme segmentation is that...  \n",
       "463  Neural network models, and specifically sequen...  \n",
       "464  We use three datasets for our experiments: IWS...  \n",
       "465  As the book is too small to train any models, ...  \n",
       "466  FLOAT SELECTED: Table 3: The joint goal accura...  \n",
       "467  In a new experiment, we train the models on pa...  \n",
       "468  To date, the NLP community has focused primari...  \n",
       "469  Because our approach is specifically intended ...  \n",
       "470  FLOAT SELECTED: Table 2. Comparison with Tradi...  \n",
       "471  FLOAT SELECTED: Table 2. Comparison with Tradi...  \n",
       "472  FLOAT SELECTED: Figure 1. BERT + Bi-GRU + CRF,...  \n",
       "473  To conduct a thorough comparison, we evaluate ...  \n",
       "474  FLOAT SELECTED: Table 1: Results of various mo...  \n",
       "475  We see that parent quality is a simple yet eff...  \n",
       "476  Our work aims at predicting time series using ...  \n",
       "477  The initial analyses of the embedding matrices...  \n",
       "478  The main contribution of our paper is to sugge...  \n",
       "479  FLOAT SELECTED: TABLE II F-SCORE OF VARIOUS MO...  \n",
       "480  We implement our model in Python using Tensorf...  \n",
       "481  FLOAT SELECTED: TABLE III COMPARISON WITH THE ...  \n",
       "482  Our AV in-cabin data-set includes 30 hours of ...  \n",
       "483  We compare a hybrid HMM-LSTM approach with a c...  \n",
       "484  We interpret the HMM and LSTM states in the hy...  \n",
       "485  FLOAT SELECTED: Table 1: Predictive loglikelih...  \n",
       "486  FLOAT SELECTED: Table 2: F1 Results3 The appro...  \n",
       "487  The measured precision with respect to PropBan...  \n",
       "488  Dataset Quality Analysis ::: Inter-Annotator A...  \n",
       "489  We adopt the annotation machinery of BIBREF5 i...  \n",
       "490  For the MT task, we use the WMT 2014 En $\\left...  \n",
       "491  VQA research began in earnest in late 2014 whe...  \n",
       "492  To test our model, we generated 500 new scenar...  \n",
       "493  To train our model, we generated a dataset of ...  \n",
       "494  We use the BLEU BIBREF30 metric on the validat...  \n",
       "495  We use MS COCO, Bing and Flickr datasets from ...  \n",
       "496  Word Lattice As shown in Figure FIGREF4 , a wo...  \n",
       "497  Table TABREF34 gives the perplexity scores obt...  \n",
       "498  In this paper, we manually annotate the predic...  \n",
       "499  In this work, we introduce a methodology that ...  \n",
       "500  FLOAT SELECTED: Table 4: Test accuracies (%). ...  \n",
       "501  For sentence encoding models, we chose a simpl...  \n",
       "502  For each model having the best fit on the dev ...  \n",
       "503  For each model having the best fit on the dev ...  \n",
       "504  The fundamental idea of this system is how to ...  \n",
       "505  While the co-occurrence representation yields ...  \n",
       "506  e-SNLI-VE-2.0 is the combination of SNLI-VE-2....  \n",
       "507  The dataset needed to train the W2V was obtain...  \n",
       "508  The first data batch consists of tweets releva...  \n",
       "509  FLOAT SELECTED: Table 3: Evaluation results of...  \n",
       "510  Causal documents were chosen to contain one oc...  \n",
       "511  Data was collected from a 10% uniform sample o...  \n",
       "512  Causal documents were chosen to contain one oc...  \n",
       "513  The rest of this paper is organized as follows...  \n",
       "514  Data was collected from a 10% uniform sample o...  \n",
       "515  Data was collected from a 10% uniform sample o...  \n",
       "516  According to previous work BIBREF17 , BIBREF18...  \n",
       "517  To make a thorough empirical comparison with p...  \n",
       "518  There are 74 participants who are signing up t...  \n",
       "519  We conducted experiments on the two tasks of M...  \n",
       "520  FLOAT SELECTED: Table 2: Performance of our an...  \n",
       "521  FLOAT SELECTED: Table 5: Performance of our an...  \n",
       "522  We conducted experiments on the two tasks of M...  \n",
       "523  Tree-based sentiment annotations are sentiment...  \n",
       "524  Twitter provides well-documented API, which al...  \n",
       "525  Generally, closer words are considered more im...  \n",
       "526  The large corpus acquired from multiple resour...  \n",
       "527  Table 1 shows the BLEU scores of our model on ...  \n",
       "528  FLOAT SELECTED: Table 1: BLEU scores and compu...  \n",
       "529  Due to the reduction of computational time com...  \n",
       "530  Table TABREF15 shows the final results on Vecm...  \n",
       "531  FLOAT SELECTED: Table 4: Accuracy (P@1) on Vec...  \n",
       "532  Table TABREF13 shows the inconsistency rates o...  \n",
       "533  Methods ::: Length Encoding Method Inspired by...  \n",
       "534  Methods ::: Length Token Method Our first appr...  \n",
       "535  With this challenge in mind, we introduce Torc...  \n",
       "536  Compared to using external models for confiden...  \n",
       "537  Our training method in sec:ours could potentia...  \n",
       "538  For the intitial data collection using the CRW...  \n",
       "539  IOCs in cybersecurity articles are often descr...  \n",
       "540  Secondly, texts go through a cascade of annota...  \n",
       "541  Distributed representation of word sense provi...  \n",
       "542  We show all the models' results in Table TABRE...  \n",
       "543  Moreover, we can easily extend SPNet to other ...  \n",
       "544  In this case, the summary has a high ROUGE sco...  \n",
       "545  FLOAT SELECTED: Table 3: Accuracy on the DREAM...  \n",
       "546  Sentences 1 and 2 are labelled incorrectly, an...  \n",
       "547  There are three main components to the model: ...  \n",
       "548  We first compare the perplexity of CWVAE with ...  \n",
       "549  We first compare the perplexity of CWVAE with ...  \n",
       "550  In addition to the traditional VAE structure, ...  \n",
       "551  FLOAT SELECTED: Table 1: Domain adaptation res...  \n",
       "552  FLOAT SELECTED: Table 1: Final test set result...  \n",
       "553  For WebQuestions, we use 8 handcrafted part-of...  \n",
       "554  The main DDEO topics showed some level of inte...  \n",
       "555  To discover topics from the collected tweets, ...  \n",
       "556  For each variable in encoding set, learn the n...  \n",
       "557  Differently to textual data, our goal in this ...  \n",
       "558  We will apply the methodology to the well-know...  \n",
       "559  All models are trained and evaluated using the...  \n",
       "560  Table TABREF40 illustrates the BLEU scores of ...  \n",
       "561  In HotpotQA, on average we can find 6 candidat...  \n",
       "562  FLOAT SELECTED: Table 5: Classification of err...  \n",
       "563  The human evaluation of MT output in research ...  \n",
       "564  One way to analyze the model is to compute mod...  \n",
       "565  Our approach consists of structuring input to ...  \n",
       "566  In this work, we analyze a set of tweets relat...  \n",
       "567  FLOAT SELECTED: Table 1: Experiment results on...  \n",
       "568  FLOAT SELECTED: TABLE IV: Class-wise average I...  \n",
       "569  FLOAT SELECTED: TABLE III: Scripts in the INDI...  \n",
       "570  The generation process of the simulated data s...  \n",
       "571  For the human evaluation, we follow the standa...  \n",
       "572  Amazon Reviews Dataset BIBREF24 is a large dat...  \n",
       "573  The usage of a purely character-based input wo...  \n",
       "574  In addition to the setting without any paralle...  \n",
       "575  Table TABREF17 shows our results on CMRC-2017 ...  \n",
       "576  The BD-4SK-ASR Dataset ::: The Language Model ...  \n",
       "577  To develop the dataset, we extracted 200 sente...  \n",
       "578  Two thousand narration files were created. We ...  \n",
       "579  In Figure FIGREF32 , we visualize the syntacti...  \n",
       "580  In Table TABREF39 , our results are comparable...  \n",
       "581  As a further application of our work, we have ...  \n",
       "582  The trained Doc2Vec model is subsequently used...  \n",
       "583  During the long history of TCM, there has been...  \n",
       "584  The input of our model are the words in the in...  \n",
       "585  FLOAT SELECTED: Table 8. Results (accuracy) on...  \n",
       "586  N-GrAM ranked first in all cases except for th...  \n",
       "587  N-GrAM ranked first in all cases except for th...  \n",
       "588  One of the solutions that has been proposed fo...  \n",
       "589  There are a larger number of male-gendered cha...  \n",
       "590  Data dependent regularization. As explained in...  \n",
       "591  The two models achieved test perplexity of INL...  \n",
       "592  The experimental results are presented in Tabl...  \n",
       "593  FLOAT SELECTED: Table 5: Results obtained for ...  \n",
       "594  Exploiting psycho-linguistic features with bas...  \n",
       "595  Most of the above-discussed systems either sho...  \n",
       "596  The informal setting/environment of social med...  \n",
       "597  As we show below, STransE performs better than...  \n",
       "598  FLOAT SELECTED: Table 2: Experimental Results ...  \n",
       "599  One common point in all the approaches yet has...  \n",
       "600  Table TABREF44 shows that consistent nucleus a...  \n",
       "601  We extended the notion of consistency of a rec...  \n",
       "602  We use the VisDial v1.0 BIBREF0 dataset to tra...  \n",
       "603  FLOAT SELECTED: Table 1: Final win rate on sim...  \n",
       "604  convertible.pl: implementing DCG rules for 1st...  \n",
       "605  Table TABREF34 and Table TABREF35 show the fin...  \n",
       "606  Los resultados de la evaluación se presentan e...  \n",
       "607  FLOAT SELECTED: TABLE I DATASETS AND LANGUAGES...  \n",
       "608  We tested three model versions against all dat...  \n",
       "609  FLOAT SELECTED: TABLE II REPORTED ACCURACIES O...  \n",
       "610  In this section, we consider two kinds of rela...  \n",
       "611  Human Judgments Following BIBREF11 , BIBREF12 ...  \n",
       "612  We trained word embeddings and a uni-direction...  \n",
       "613  First, we propose a class of recurrent-like ne...  \n",
       "614  This study focuses on Switchboard-300, a stand...  \n",
       "615                                 Experimental Setup  \n",
       "616  Although not done in this work, an alternative...  \n",
       "617  We performed experiments on synthetically gene...  \n",
       "618  FLOAT SELECTED: Table 2: A summary of PERSPECT...  \n",
       "619  FLOAT SELECTED: Figure 3: Distribution of clai...  \n",
       "620  FLOAT SELECTED: Table 1: Effect of Character E...  \n",
       "621  Generic Sarcasm. We first examine the differen...  \n",
       "622  FLOAT SELECTED: Table 1: The number of songs a...  \n",
       "623  FLOAT SELECTED: Table 1: Automatic Evaluation ...  \n",
       "624  We thus also conducted human studies on Amazon...  \n",
       "625  FLOAT SELECTED: Table 1: Automatic Evaluation ...  \n",
       "626  We employ several complementary metrics to cap...  \n",
       "627  FLOAT SELECTED: Table 2: The performance of ba...  \n",
       "628  FLOAT SELECTED: Figure 3: ROUGE Quality of pro...  \n",
       "629  FLOAT SELECTED: Figure 1: An example of stress...  \n",
       "630  Using these filters as pre-processing methods,...  \n",
       "631  While the mixing strategy compensates for most...  \n",
       "632  To solve this problem, we need a state trackin...  \n",
       "633  Furthermore, as SIM has no slot-specific neura...  \n",
       "634  We select the following training objectives to...  \n",
       "635  FLOAT SELECTED: Table 1: An approximate number...  \n",
       "636  We collected tweets from two distinct Spritzer...  \n",
       "637  Sentence classification combines natural langu...  \n",
       "638  Compare to baseline models, the GVT achieves r...  \n",
       "639  Attention-base translation model We use the sy...  \n",
       "640  Pre-trained English NER model We construct the...  \n",
       "641  The character sets of these 7 languages have l...  \n",
       "642  The dataset at HASOC 2019 were given in three ...  \n",
       "643  FLOAT SELECTED: Table 9 Character error rates ...  \n",
       "644  Analogous to word embeddings, sentence embeddi...  \n",
       "645  The Density Ratio method consistently outperfo...  \n",
       "646  The following data sources were used to train ...  \n",
       "647  In all our experiments, we used the out-of-the...  \n",
       "648  Given the above interpretation, we now turn to...  \n",
       "649  This paper experimented with two different mod...  \n",
       "650  FLOAT SELECTED: Table 1: Statistics of the dat...  \n",
       "651  FLOAT SELECTED: Figure 2: PR curve on our impl...  \n",
       "652  We compared our proposed approaches to a stand...  \n",
       "653  FLOAT SELECTED: Table 1: Results mean (min, ma...  \n",
       "654  The human evaluation is to have a comprehensiv...  \n",
       "655  To test this hypothesis we first trained UG-WG...  \n",
       "656  To test this hypothesis we first trained UG-WG...  \n",
       "657  Table TABREF34 shows the performances of the d...  \n",
       "658  We focused evaluation over a small but diversi...  \n",
       "659  Results form Table TABREF31 may give an idea t...  \n",
       "660  Adversarial training can often improve model r...  \n",
       "661  We reason that, if a token is important for pr...  \n",
       "662  The resource is composed of data from two diff...  \n",
       "663  The two datasets used for the challenge are Fr...  \n",
       "664  The two datasets used for the challenge are Fr...  \n",
       "665  FLOAT SELECTED: Table 6: F-scores for Friends ...  \n",
       "666  Word embeddings have risen in popularity for N...  \n",
       "667  I also performed several case studies. I obtai...  \n",
       "668  We examine other features regarding the charac...  \n",
       "669  FLOAT SELECTED: Table 2: Linear regression res...  \n",
       "670  In order to understand the latent topics of th...  \n",
       "671  Observing the results of the linear regression...  \n",
       "672  In this paper, we present an extraction-then-s...  \n",
       "673  Traditional text-to-speech (TTS) systems are c...  \n",
       "674  In terms of speed, our system was able to lemm...  \n",
       "675  FLOAT SELECTED: Table 3: Lemmatization accurac...  \n",
       "676  Cloze Track: In this track, the participants a...  \n",
       "677  The previously mentioned datasets are all in E...  \n",
       "678  We conducted experiments on the Amazon reviews...  \n",
       "679  FLOAT SELECTED: Figure 33 The most cited areas...  \n",
       "680  FLOAT SELECTED: Figure 25 Average citations fo...  \n",
       "681  FLOAT SELECTED: Figure 11 A treemap of the 122...  \n",
       "682  Table TABREF20 reports the F1 and EM scores ob...  \n",
       "683  FLOAT SELECTED: Table 3: Test set results of o...  \n",
       "684  FLOAT SELECTED: Table 4: The performance of cl...  \n",
       "685  For the purpose of our experiments, we use dat...  \n",
       "686  Our experiment with the Short Jokes dataset fo...  \n",
       "687  In this experiment, we compare our Enitity-GCN...  \n",
       "688  To each node $v_i$ , we associate a continuous...  \n",
       "689  In an offline step, we organize the content of...  \n",
       "690  FLOAT SELECTED: Table 2: Accuracy of different...  \n",
       "691  We extracted 200 sentence pairs from BIBREF3 '...  \n",
       "692  We also observe that the best combination seem...  \n",
       "693  We compare our best F1 score with other state-...  \n",
       "694  We compare our best F1 score with other state-...  \n",
       "695  FLOAT SELECTED: Table 2: Results for artificia...  \n",
       "696  We compile three Chinese text corpora from onl...  \n",
       "697  We compile three Chinese text corpora from onl...  \n",
       "698  We address the above issues with a new methodo...  \n",
       "699  To evaluate the performance of our approach, w...  \n",
       "700  Given the initial distributional or specialise...  \n",
       "701  We used two different data sources in our eval...  \n",
       "702  We evaluate two OIE systems (i.e. extractors)....  \n",
       "703  In our final system, after pre-training the fo...  \n",
       "704  We evaluate our approach on two well benchmark...  \n",
       "705  Our main contribution is to show that the cont...  \n",
       "706  Tables TABREF15 and TABREF16 compare results f...  \n",
       "707  Machine translation finds use in cheminformati...  \n",
       "708  FLOAT SELECTED: Table 1: Results on test data....  \n",
       "709  We trained word embeddings using either GloVe ...  \n",
       "710  FLOAT SELECTED: Figure 1: The proposed model w...  \n",
       "711  We take a first step towards integrating ASR i...  \n",
       "712  Metrics. We use tolerance accuracy BIBREF16, w...  \n",
       "713  The remainder of this paper is structured as f...  \n",
       "714  Our video question answering task is novel and...  \n",
       "715  FLOAT SELECTED: Table 2: Results of AlgoLisp d...  \n",
       "716  FLOAT SELECTED: Table 2: Results of AlgoLisp d...  \n",
       "717  Given a natural-language math problem, we need...  \n",
       "718  FLOAT SELECTED: Table 4: Comparison results wi...  \n",
       "719  DrQA is a CRC baseline coming with the CoQA da...  \n",
       "720  FLOAT SELECTED: Table 2: The total number of i...  \n",
       "721  FLOAT SELECTED: Table 3: Datasets details from...  \n",
       "722  In BIBREF3 , BIBREF2 , the authors study the e...  \n",
       "723  As the first step, we build three baseline LID...  \n",
       "724  All the present neural LID methods are based o...  \n",
       "725  BIBREF7 investigated the learning capabilities...  \n",
       "726  FLOAT SELECTED: Fig. 2: Standard ASR outputs A...  \n",
       "727  To test this hypothesis, we evaluate the model...  \n",
       "728  FLOAT SELECTED: Table 5: CoNLL 2003 English re...  \n",
       "729  FLOAT SELECTED: Table 1: Datasets used for tra...  \n",
       "730  Our system learns Perceptron models BIBREF37 u...  \n",
       "731  Feature-based models. We used state-of-the-art...  \n",
       "732  The turkers are asked to indicate their prefer...  \n",
       "733  In this section, we evaluate the proposed meth...  \n",
       "734  In this section we present the results obtaine...  \n",
       "735  FLOAT SELECTED: TABLE II: A comparison of clas...  \n",
       "736  We approached the first and second challenges ...  \n",
       "737  As we iteratively concatenate the generated to...  \n",
       "738  To investigate whether our BERT-based model ca...  \n",
       "739                 Building Extractive CNN/Daily Mail  \n",
       "740  To further study the information encoded in th...  \n",
       "741  CNN2-PV. This model (Figure FIGREF10 , left+ce...  \n",
       "742  CNN2-PV. This model (Figure FIGREF10 , left+ce...  \n",
       "743  FLOAT SELECTED: Figure 1. A visual depiction o...  \n",
       "744  FLOAT SELECTED: Table 3: Statistics of externa...  \n",
       "745  The experimental results are summarized in Tab...  \n",
       "746  The corpus we have prepared for ASR in this st...  \n",
       "747  We chose the best system based on the dev set,...  \n",
       "748  We demonstrated the utility of Katecheo by dep...  \n",
       "749  Data set. For the cross-domain polarity classi...  \n",
       "750  In recent years, methods based on string kerne...  \n",
       "751  According to prior work, both from domain theo...  \n",
       "752  FLOAT SELECTED: Table 5: Bengali manual annota...  \n",
       "753  Using our platform, we extracted anonymized us...  \n",
       "754  FLOAT SELECTED: Figure 1: German→English: Lear...  \n",
       "755  Next, we compared our VTN model with an RNN-ba...  \n",
       "756  FLOAT SELECTED: Table 3: Precision (P), Recall...  \n",
       "757  FLOAT SELECTED: Figure 1: Multi-Encoder, Const...  \n",
       "758  FLOAT SELECTED: Table 1: Various types of trai...  \n",
       "759  This paper proposes the Flexibly-Structured Di...  \n",
       "760  We compare FSDM with four baseline methods and...  \n",
       "761  In this paper we proposed a methodology to ide...  \n",
       "762  On the 16 review datasets (Table TABREF22 ) fr...  \n",
       "763  FLOAT SELECTED: Table 1: Accuracies on the Sta...  \n",
       "764  The test-set accuracies obtained by different ...  \n",
       "765  Experiments on two benchmark data sets, the St...  \n",
       "766  Tables and report some statistics extracted fr...  \n",
       "767  FLOAT SELECTED: Table 4: List of the indicator...  \n",
       "768  Table , extracted from BIBREF0, reports WERs o...  \n",
       "769  Table , extracted from BIBREF0, reports WERs o...  \n",
       "770  Speakers were assigned either to training or e...  \n",
       "771  FLOAT SELECTED: Table 3: Spoken data collected...  \n",
       "772  Evaluation on DUC2004: DUC 2004 ( BIBREF15 ) i...  \n",
       "773  Very recently, the success of deep neural netw...  \n",
       "774  FLOAT SELECTED: Table 6: Results on our CAIS d...  \n",
       "775       FLOAT SELECTED: Table 2: Dataset statistics.  \n",
       "776  Questions are gathered from anonymized, aggreg...  \n",
       "777  To estimate speakers' position we use Wordscor...  \n",
       "778  Figure FIGREF12stsa and FIGREF12stsb shows Pea...  \n",
       "779  Let us discuss the results from the above ment...  \n",
       "780  We've seen that over-pruning BERT deletes info...  \n",
       "781  Each game's video ranges from 30 to 50 minutes...  \n",
       "782  FLOAT SELECTED: Table 3: Test Results on the N...  \n",
       "783  FLOAT SELECTED: Table 1: Predicted Mean MPA re...  \n",
       "784  The data for this project are two parts, the f...  \n",
       "785  A recently published dataset called SCAN BIBRE...  \n",
       "786  FLOAT SELECTED: Table 1: Accuracy on the ListO...  \n",
       "787  FLOAT SELECTED: Table 1: Accuracy on the ListO...  \n",
       "788  FLOAT SELECTED: Table 2. % EER performance of ...  \n",
       "789  Our first task is the recently-introduced Visu...  \n",
       "790  In this work, we introduce a new logical infer...  \n",
       "791  MonaLog utilizes two auxiliary sets. First, a ...  \n",
       "792  FLOAT SELECTED: Table 1: Statistics of the cor...  \n",
       "793  TextCat is the most well-known Perl implementa...  \n",
       "794  We describe our rules for WikiSQL here. We fir...  \n",
       "795  The experimental results for Yorùbá are given ...  \n",
       "796  We evaluate our approaches on two public Chine...  \n",
       "797  The experiment dataset comes from Microsoft Re...  \n",
       "798  FLOAT SELECTED: Table 5: Entity F1 and Success...  \n",
       "799  In this paper, we introduce a novel policy mod...  \n",
       "800  The second type is the selectional preference ...  \n",
       "801  Each drug label is a collection of sections (e...  \n",
       "802  Table TABREF7 shows the ABSA datasets from the...  \n",
       "803  FLOAT SELECTED: Table 1: Pretraining costs of ...  \n",
       "804  FLOAT SELECTED: Table 1: Pretraining costs of ...  \n",
       "805  BIBREF11 revisit bilingual pivoting in the con...  \n",
       "806  NAGMWA is much better than the other methods e...  \n",
       "807  Table TABREF46 shows that our Open model achie...  \n",
       "808  FLOAT SELECTED: Table 7: SRL results on the Ch...  \n",
       "809  FLOAT SELECTED: Figure 5. The results are spli...  \n",
       "810  We perform our experiments using ActivityNet C...  \n",
       "811  We characterize the evaluation of Emotionally-...  \n",
       "812                                         Conclusion  \n",
       "813  In this work, the experiments are conducted us...  \n",
       "814  Our contributions are as follows: We propose t...  \n",
       "815  FLOAT SELECTED: Table 1: Statistical summary o...  \n",
       "816  FLOAT SELECTED: Table 1: Statistical summary o...  \n",
       "817  FLOAT SELECTED: Table 3. Language Modeling Res...  \n",
       "818  In this section, we present the experimental s...  \n",
       "819  FLOAT SELECTED: Table 4. Evaluation results on...  \n",
       "820  Our idea is the BQ generation for MQ and, at t...  \n",
       "821  The surveys consisted of 20 tweets presented i...  \n",
       "822  For both word2vec BIBREF0 and gensim BIBREF7 w...  \n",
       "823  Although the competition proposes two differen...  \n",
       "824  We first inspect the frequencies of object and...  \n",
       "825  After averaging over all concepts, we lose inf...  \n",
       "826  After averaging over all concepts, we lose inf...  \n",
       "827  An LM's overall performance on *X can be measu...  \n",
       "828  is the standard word counting method whereby t...  \n",
       "829  Several methods make use of the Aristo Corpus,...  \n",
       "830  FLOAT SELECTED: Table 2: Most common syntactic...  \n",
       "831  Often, many state-of-the-art tools cannot be a...  \n",
       "832  As discussed in section SECREF1, the attention...  \n",
       "833  As a first step towards developing an automate...  \n",
       "834  Generally, the above work is summarized in Tab...  \n",
       "835  Previous attention-based methods can be catego...  \n",
       "836  In our experiments, we use Onsei Intent Slot d...  \n",
       "837  FLOAT SELECTED: Table 3: Number of run-on (RO)...  \n",
       "838  Our interpretability measurements are based on...  \n",
       "839  In the word embedding literature, the problem ...  \n",
       "840  To study the lexical and semantic diversities ...  \n",
       "841  FLOAT SELECTED: Table 3. Comparisons with the ...  \n",
       "842  More detailed explanation is introduced in Sec...  \n",
       "843  FLOAT SELECTED: Table 2. Twitter corpus distri...  \n",
       "844  In order to verify the time complexity analysi...  \n",
       "845  FLOAT SELECTED: Table 1: The knowledge base co...  \n",
       "846  We work with a dataset composed of 3,206 news ...  \n",
       "847  We use a siamese neural network, shown to perf...  \n",
       "848  FLOAT SELECTED: Table 1: An example of a claim...  \n",
       "849  We experiment using a dataset derived from Goo...  \n",
       "850  FLOAT SELECTED: Table 1: Crosslingual semantic...  \n",
       "851  We train an LSTM with and without attention on...  \n",
       "852  FLOAT SELECTED: Fig. 1. Proposed representatio...  \n",
       "853  Given the fact that the research on offensive ...  \n",
       "854  In sub-task C the goal is to classify the targ...  \n",
       "855  In this paper, we propose the MIMN model for N...  \n",
       "856     FLOAT SELECTED: Table 2: Experimental results.  \n",
       "857  FLOAT SELECTED: Table 1: Experimental conditions.  \n",
       "858  FLOAT SELECTED: Table 1: Optimal hyperparamete...  \n",
       "859  FLOAT SELECTED: Table 1: Optimal hyperparamete...  \n",
       "860  FLOAT SELECTED: Table 6: Evaluation of effect ...  \n",
       "861  We also evaluate our Joint-BiLSTM structure by...  \n",
       "862  FLOAT SELECTED: Table 1: Datasets used for var...  \n",
       "863  FLOAT SELECTED: Table 3. MOS naturalness resul...  \n",
       "864  FLOAT SELECTED: Table 10: Results of experimen...  \n",
       "865  The NLG model we use to establish a baseline f...  \n",
       "866  This step consists of generating a query out o...  \n",
       "867  Table TABREF14 shows the experiment measuring ...  \n",
       "868  We use the publicly available dataset KVRET BI...  \n",
       "869  As a basis for our experiments, we reimplement...  \n",
       "870  With the gathered comments, we reconstructed t...  \n",
       "871  We would expect that explanation performance s...  \n",
       "872  FLOAT SELECTED: Table 1: Comparison of differe...  \n",
       "873  While most relational learning methods restric...  \n",
       "874  We used the following affective resources rely...  \n",
       "875  The performance of the base model described in...  \n",
       "876  FLOAT SELECTED: Table 2: Transfer learning per...  \n",
       "877  The baseline classifier uses a linear Support ...  \n",
       "878  For offensive language detection in Twitter, u...  \n",
       "879  Results on SemEval-2014 are presented in Table...  \n",
       "880  Recently bhat-EtAl:2017:EACLshort provided a C...  \n",
       "881  The data stems from a joint ADAPT-Microsoft pr...  \n",
       "882  FLOAT SELECTED: Table 2: Characteristics of Sc...  \n",
       "883  To control the quality, we ensured that a sing...  \n",
       "884  FLOAT SELECTED: Table 3. Performance evaluatio...  \n",
       "885  FLOAT SELECTED: Table 1. Description of class ...  \n",
       "886  The sequence modeling layer models the depende...  \n",
       "887  Table TABREF34 shows the inference speed of ou...  \n",
       "888  To test if the learned representations can sep...  \n",
       "889  We train all the models on an Nvidia RTX 2080T...  \n",
       "890  In this case, the decoding function is a linea...  \n",
       "891  The 17 domains (`Alarm' domain not included in...  \n",
       "892  We use the additional INLINEFORM0 training art...  \n",
       "893  We focus primarily on the smaller data set of ...  \n",
       "894  We have presented adaptive schedules for multi...  \n",
       "895  We extract data from the WMT'14 English-French...  \n",
       "896  We use a standard set of supervised as well as...  \n",
       "897  Statistical characterization of languages has ...  \n",
       "898  One way to expose Bleurt to a wide variety of ...  \n",
       "899  Table TABREF12 compares our novel system with ...  \n",
       "900  Once the KryptoOracle engine was bootstrapped ...  \n",
       "901  KryptoOracle has been built in the Apache ecos...  \n",
       "902  In this paper we provide a novel real-time and...  \n",
       "903  FLOAT SELECTED: Table 1: BLUE tasks The aim of...  \n",
       "904  Our experimental results show that the propose...  \n",
       "905  As a complement of this analysis we show some ...  \n",
       "906  AMR is not grounded in the input sentence, the...  \n",
       "907  FLOAT SELECTED: Table 3. Overall typing perfor...  \n",
       "908  Figure FIGREF5 shows that E-BERT performs comp...  \n",
       "909  Training our model implicitly embeds the vocab...  \n",
       "910  Wikilinks can be seen as a large-scale, natura...  \n",
       "911  Here we describe the components of our probabi...  \n",
       "912  Automatic evaluation of Natural Language Gener...  \n",
       "913  FLOAT SELECTED: Table 3: Test set results at t...  \n",
       "914  There exist many word/sentence embeddings whic...  \n",
       "915  The procedure of transfer learning in this wor...  \n",
       "916  All the capabilities described in this paper c...  \n",
       "917  We optimized our single-task baseline to get a...  \n",
       "918  In this work we compare causal attribution net...  \n",
       "919  The classification of racist insults presents ...  \n",
       "920  Since the training data consists only of utter...  \n",
       "921  Table TABREF21 shows the performance of non-st...  \n",
       "922      FLOAT SELECTED: Table 7. Experimental results  \n",
       "923  Space requirements might still be considerable...  \n",
       "924  We identified some limitations during the proc...  \n",
       "925  FLOAT SELECTED: Table 2: Results of baselines ...  \n",
       "926  Many practical fake news detection algorithms ...  \n",
       "927  Manning and Schütze argue that, even though no...  \n",
       "928  FLOAT SELECTED: Table 4: Performance of variou...  \n",
       "929  FLOAT SELECTED: Table 2: Results on EMNLP2017 ...  \n",
       "930  We show that it is possible to reduce relation...  \n",
       "931  The behavior model was implemented using an RN...  \n",
       "932  In ConMask, we use a similar idea to select th...  \n",
       "933  In this subsection we discuss the experiment o...  \n",
       "934  We collected tweets related to five different ...  \n",
       "935  FLOAT SELECTED: Table 1: Stylistic domains and...  \n",
       "936  The relation-specific meta information is help...  \n",
       "937  We use two datasets, NELL-One and Wiki-One whi...  \n",
       "938  The number of layers ($N_{src}$-$N_{mt}$-$N_{p...  \n",
       "939  Various multilingual extensions of NMT have al...  \n",
       "940  In order to make the corpus collection easier ...  \n",
       "941  Moreover, QA and QG have probabilistic correla...  \n",
       "942  The Transformer network BIBREF3 is a neural se...  \n",
       "943  On another note, we apply our formalization to...  \n",
       "944  FLOAT SELECTED: Figure 2: NMT training after r...  \n",
       "945  We validate our approach on the Gigaword corpu...  \n",
       "946  FLOAT SELECTED: Fig 5. (A) The average verb re...  \n",
       "947  To assess the predictive capability of this an...  \n",
       "948  Our novelties include: Using self-play learnin...  \n",
       "949  FLOAT SELECTED: Table 1: Data used in this pap...  \n",
       "950  Experimental Protocol ::: Datasets ::: Trainin...  \n",
       "951  FLOAT SELECTED: Table 2: Ablation study on the...  \n",
       "952  The Software Ontology (SWO) BIBREF5 is include...  \n",
       "953  Morphology deals with the internal structure o...  \n",
       "954  Our model consists of two neural network modul...  \n",
       "955  The goal of this paper is to propose a novel O...  \n",
       "956  In this work we focus on end-to-end stateless ...  \n",
       "957  FLOAT SELECTED: Table 2: MAP scoring of new me...  \n",
       "958  We trained and tested our neural network with ...  \n",
       "959  FLOAT SELECTED: Table 2: Test performance on S...  \n",
       "960  We compare the results of our model to a basel...  \n",
       "961  FLOAT SELECTED: Figure 1: Our Hierarchical Net...  \n",
       "962  As indicated in its name, Recurrent Deep Stack...  \n",
       "963  We defined the reward as being 1 for successfu...  \n",
       "964  Interesting prior work on quantifying social n...  \n",
       "965  Much recent work on semantic parsing has been ...  \n",
       "966  We demonstrate our approach on the task of ans...  \n",
       "967  FLOAT SELECTED: Figure 1: Process involved in ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length: 124.06404958677686\n",
      "Minimum Length: 1\n",
      "Maximum Length: 853\n",
      "Median Length: 98.0\n",
      "Standard Deviation: 114.74877928045835\n"
     ]
    }
   ],
   "source": [
    "# INFORMATION OF ANSWER COLUMN (by characters)\n",
    "\n",
    "# Calculate statistics for string length in a column\n",
    "string_lengths = df['answer'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Compute statistics\n",
    "average_length = string_lengths.mean()\n",
    "min_length = string_lengths.min()\n",
    "max_length = string_lengths.max()\n",
    "median_length = string_lengths.median()\n",
    "std_dev = string_lengths.std()\n",
    "\n",
    "# Print statistics\n",
    "print(\"Average Length:\", average_length)\n",
    "print(\"Minimum Length:\", min_length)\n",
    "print(\"Maximum Length:\", max_length)\n",
    "print(\"Median Length:\", median_length)\n",
    "print(\"Standard Deviation:\", std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/ubuntu/iris_repos/data_preparation(QASA-QASPER)/4. populated data: generated answers/populated_qasper.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
