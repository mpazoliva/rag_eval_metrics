{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasper_shuffled_iris.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasper_shuffled_iris_100.csv\"\n",
    "df_100 = pd.read_csv(path_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
       "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
       "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bleurt', 'BEM', 'Bart',\n",
       "       'Prometheus', 'Faithfullnes', 'Relevancy', 'Correctness', 'RSim',\n",
       "       'Consistency', 'TSim', 'LLM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          int64\n",
      "question           object\n",
      "context            object\n",
      "correct_answer     object\n",
      "iris_answer        object\n",
      "Rouge1            float64\n",
      "Rouge2            float64\n",
      "RougeL            float64\n",
      "Bleu              float64\n",
      "Chrf              float64\n",
      "ChrfPlus          float64\n",
      "Meteor            float64\n",
      "Ter               float64\n",
      "Bert              float64\n",
      "WMS               float64\n",
      "SMS               float64\n",
      "Wisdm             float64\n",
      "Bart              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.046011\n",
      "std        0.062679\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.081772\n",
      "max        0.500000\n",
      "Name: Rouge1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge1 = df['Rouge1'].describe()\n",
    "print(statistics_rouge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.001416\n",
      "std        0.008746\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.095238\n",
      "Name: Rouge2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rouge2 = df['Rouge2'].describe()\n",
    "print(statistics_rouge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.001416\n",
      "std        0.008746\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.095238\n",
      "Name: RougeL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rougel = df['RougeL'].describe()\n",
    "print(statistics_rougel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.830566\n",
      "std        1.956832\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.049605\n",
      "75%        1.324147\n",
      "max       50.000000\n",
      "Name: Bleu, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleu = df['Bleu'].describe()\n",
    "print(statistics_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.040701\n",
      "std        0.051258\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.022762\n",
      "75%        0.069204\n",
      "max        0.381426\n",
      "Name: Meteor, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_meteor = df['Meteor'].describe()\n",
    "print(statistics_meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean      10.139116\n",
      "std        6.587107\n",
      "min        0.000000\n",
      "25%        4.756180\n",
      "50%        9.990111\n",
      "75%       15.314675\n",
      "max       30.165318\n",
      "Name: Chrf, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrf = df['Chrf'].describe()\n",
    "print(statistics_chrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       8.350629\n",
      "std        5.524659\n",
      "min        0.000000\n",
      "25%        3.908359\n",
      "50%        8.016622\n",
      "75%       12.387429\n",
      "max       26.291557\n",
      "Name: ChrfPlus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_chrfplus = df['ChrfPlus'].describe()\n",
    "print(statistics_chrfplus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.007305\n",
      "std        0.003661\n",
      "min        0.000106\n",
      "25%        0.003831\n",
      "50%        0.009901\n",
      "75%        0.009901\n",
      "max        0.012833\n",
      "Name: Ter, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_ter = df['Ter'].describe()\n",
    "print(statistics_ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.139276\n",
      "std        0.107661\n",
      "min       -0.092964\n",
      "25%        0.062456\n",
      "50%        0.127886\n",
      "75%        0.204565\n",
      "max        0.705655\n",
      "Name: Bert, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bert = df['Bert'].describe()\n",
    "print(statistics_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.284149\n",
      "std        0.161063\n",
      "min       -0.060984\n",
      "25%        0.184676\n",
      "50%        0.307965\n",
      "75%        0.395745\n",
      "max        0.794659\n",
      "Name: WMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wms = df['WMS'].describe()\n",
    "print(statistics_wms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.148374\n",
      "std        0.107201\n",
      "min       -0.086864\n",
      "25%        0.069866\n",
      "50%        0.140358\n",
      "75%        0.209234\n",
      "max        0.705655\n",
      "Name: SMS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_sms = df['SMS'].describe()\n",
    "print(statistics_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    745.000000\n",
      "mean       0.251139\n",
      "std        0.151980\n",
      "min        0.000000\n",
      "25%        0.125258\n",
      "50%        0.247440\n",
      "75%        0.362372\n",
      "max        0.745023\n",
      "Name: Wisdm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_wisdm = df['Wisdm'].describe()\n",
    "print(statistics_wisdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99.000000\n",
      "mean      0.062939\n",
      "std       0.029311\n",
      "min       0.036348\n",
      "25%       0.048239\n",
      "50%       0.056127\n",
      "75%       0.067721\n",
      "max       0.280340\n",
      "Name: Bleurt, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bleurt = df_100['Bleurt'].describe()\n",
    "print(statistics_bleurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99.000000\n",
      "mean      0.057341\n",
      "std       0.061158\n",
      "min       0.028687\n",
      "25%       0.042911\n",
      "50%       0.048951\n",
      "75%       0.053111\n",
      "max       0.586452\n",
      "Name: BEM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bem = df_100['BEM'].describe()\n",
    "print(statistics_bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    968.000000\n",
      "mean       0.006078\n",
      "std        0.006982\n",
      "min        0.000048\n",
      "25%        0.001694\n",
      "50%        0.003967\n",
      "75%        0.007974\n",
      "max        0.065722\n",
      "Name: Bart, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_bart = df['Bart'].describe()\n",
    "print(statistics_bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       1.050000\n",
      "std        0.297294\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        3.000000\n",
      "Name: Prometheus, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_prometheus = df_100['Prometheus'].describe()\n",
    "print(statistics_prometheus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.018000\n",
      "std        0.086899\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        0.700000\n",
      "Name: LLM, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_llm = df_100['LLM'].describe()\n",
    "print(statistics_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    67.000000\n",
      "mean      0.250000\n",
      "std       0.342353\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       0.500000\n",
      "max       1.000000\n",
      "Name: Faithfullnes, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_faithfulness = df_100['Faithfullnes'].describe()\n",
    "print(statistics_faithfulness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.715331\n",
      "std        0.167844\n",
      "min        0.000000\n",
      "25%        0.727315\n",
      "50%        0.748097\n",
      "75%        0.765789\n",
      "max        0.879748\n",
      "Name: Relevancy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rrel = df_100['Relevancy'].describe()\n",
    "print(statistics_rrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    99.000000\n",
      "mean      0.419688\n",
      "std       0.234457\n",
      "min       0.171780\n",
      "25%       0.188106\n",
      "50%       0.395853\n",
      "75%       0.624572\n",
      "max       0.869629\n",
      "Name: Correctness, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_correctness = df_100['Correctness'].describe()\n",
    "print(statistics_correctness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.749599\n",
      "std        0.029542\n",
      "min        0.687121\n",
      "25%        0.733142\n",
      "50%        0.747479\n",
      "75%        0.767761\n",
      "max        0.868348\n",
      "Name: RSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_rsim = df_100['RSim'].describe()\n",
    "print(statistics_rsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.094000\n",
      "std        0.212152\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        1.000000\n",
      "Name: Consistency, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_consistency = df_100['Consistency'].describe()\n",
    "print(statistics_consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    100.000000\n",
      "mean       0.030000\n",
      "std        0.171447\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        0.000000\n",
      "75%        0.000000\n",
      "max        1.000000\n",
      "Name: TSim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "statistics_tsim = df_100['TSim'].describe()\n",
    "print(statistics_tsim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0      Rouge1      Rouge2      RougeL        Bleu        Chrf  \\\n",
      "count  968.000000  968.000000  968.000000  968.000000  968.000000  968.000000   \n",
      "mean   483.500000    0.046011    0.001416    0.001416    0.830566   10.139116   \n",
      "std    279.581831    0.062679    0.008746    0.008746    1.956832    6.587107   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%    241.750000    0.000000    0.000000    0.000000    0.000000    4.756180   \n",
      "50%    483.500000    0.000000    0.000000    0.000000    0.049605    9.990111   \n",
      "75%    725.250000    0.081772    0.000000    0.000000    1.324147   15.314675   \n",
      "max    967.000000    0.500000    0.095238    0.095238   50.000000   30.165318   \n",
      "\n",
      "         ChrfPlus      Meteor         Ter        Bert         WMS         SMS  \\\n",
      "count  968.000000  968.000000  968.000000  968.000000  968.000000  968.000000   \n",
      "mean     8.350629    0.040701    0.007305    0.139276    0.284149    0.148374   \n",
      "std      5.524659    0.051258    0.003661    0.107661    0.161063    0.107201   \n",
      "min      0.000000    0.000000    0.000106   -0.092964   -0.060984   -0.086864   \n",
      "25%      3.908359    0.000000    0.003831    0.062456    0.184676    0.069866   \n",
      "50%      8.016622    0.022762    0.009901    0.127886    0.307965    0.140358   \n",
      "75%     12.387429    0.069204    0.009901    0.204565    0.395745    0.209234   \n",
      "max     26.291557    0.381426    0.012833    0.705655    0.794659    0.705655   \n",
      "\n",
      "            Wisdm        Bart  \n",
      "count  745.000000  968.000000  \n",
      "mean     0.251139    0.006078  \n",
      "std      0.151980    0.006982  \n",
      "min      0.000000    0.000048  \n",
      "25%      0.125258    0.001694  \n",
      "50%      0.247440    0.003967  \n",
      "75%      0.362372    0.007974  \n",
      "max      0.745023    0.065722  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0      Rouge1      Rouge2      RougeL        Bleu        Chrf  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
      "mean    49.500000    0.053411    0.001629    0.001629    0.823522   11.119558   \n",
      "std     29.011492    0.067129    0.007747    0.007747    0.956727    7.066865   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     24.750000    0.000000    0.000000    0.000000    0.000000    5.711982   \n",
      "50%     49.500000    0.033224    0.000000    0.000000    0.354250   11.058324   \n",
      "75%     74.250000    0.082550    0.000000    0.000000    1.379958   16.692837   \n",
      "max     99.000000    0.272727    0.052632    0.052632    3.265885   27.767673   \n",
      "\n",
      "         ChrfPlus      Meteor         Ter        Bert  ...        BEM  \\\n",
      "count  100.000000  100.000000  100.000000  100.000000  ...  99.000000   \n",
      "mean     9.249278    0.044415    0.007135    0.149615  ...   0.057341   \n",
      "std      6.001404    0.051707    0.003503    0.111477  ...   0.061158   \n",
      "min      0.000000    0.000000    0.000106   -0.073132  ...   0.028687   \n",
      "25%      4.935078    0.000000    0.004255    0.068376  ...   0.042911   \n",
      "50%      8.601350    0.026624    0.009901    0.144958  ...   0.048951   \n",
      "75%     13.784558    0.069449    0.009901    0.214417  ...   0.053111   \n",
      "max     23.580557    0.256552    0.011532    0.537764  ...   0.586452   \n",
      "\n",
      "             Bart  Prometheus  Faithfullnes   Relevancy  Correctness  \\\n",
      "count  100.000000  100.000000     67.000000  100.000000    99.000000   \n",
      "mean     0.005328    1.050000      0.250000    0.715331     0.419688   \n",
      "std      0.004630    0.297294      0.342353    0.167844     0.234457   \n",
      "min      0.000194    1.000000      0.000000    0.000000     0.171780   \n",
      "25%      0.001461    1.000000      0.000000    0.727315     0.188106   \n",
      "50%      0.003859    1.000000      0.000000    0.748097     0.395853   \n",
      "75%      0.008581    1.000000      0.500000    0.765789     0.624572   \n",
      "max      0.018205    3.000000      1.000000    0.879748     0.869629   \n",
      "\n",
      "             RSim  Consistency        TSim         LLM  \n",
      "count  100.000000   100.000000  100.000000  100.000000  \n",
      "mean     0.749599     0.094000    0.030000    0.018000  \n",
      "std      0.029542     0.212152    0.171447    0.086899  \n",
      "min      0.687121     0.000000    0.000000    0.000000  \n",
      "25%      0.733142     0.000000    0.000000    0.000000  \n",
      "50%      0.747479     0.000000    0.000000    0.000000  \n",
      "75%      0.767761     0.000000    0.000000    0.000000  \n",
      "max      0.868348     1.000000    1.000000    0.700000  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_100.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(df.describe())\n",
    "statistics_100 = pd.DataFrame(df_100.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_statistics_100 = statistics_100[['BEM', 'LLM', 'Correctness', 'Consistency', 'Prometheus', 'TSim', 'Faithfullnes', 'Relevancy', 'RSim']]\n",
    "final_df = pd.concat([statistics, sub_statistics_100], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>RougeL</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Chrf</th>\n",
       "      <th>ChrfPlus</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Ter</th>\n",
       "      <th>Bert</th>\n",
       "      <th>...</th>\n",
       "      <th>Bart</th>\n",
       "      <th>BEM</th>\n",
       "      <th>LLM</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Consistency</th>\n",
       "      <th>Prometheus</th>\n",
       "      <th>TSim</th>\n",
       "      <th>Faithfullnes</th>\n",
       "      <th>Relevancy</th>\n",
       "      <th>RSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>483.500000</td>\n",
       "      <td>0.046011</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.830566</td>\n",
       "      <td>10.139116</td>\n",
       "      <td>8.350629</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0.139276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.419688</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.715331</td>\n",
       "      <td>0.749599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.581831</td>\n",
       "      <td>0.062679</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>1.956832</td>\n",
       "      <td>6.587107</td>\n",
       "      <td>5.524659</td>\n",
       "      <td>0.051258</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.107661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.061158</td>\n",
       "      <td>0.086899</td>\n",
       "      <td>0.234457</td>\n",
       "      <td>0.212152</td>\n",
       "      <td>0.297294</td>\n",
       "      <td>0.171447</td>\n",
       "      <td>0.342353</td>\n",
       "      <td>0.167844</td>\n",
       "      <td>0.029542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>-0.092964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.028687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>241.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.756180</td>\n",
       "      <td>3.908359</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.062456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.042911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727315</td>\n",
       "      <td>0.733142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>483.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049605</td>\n",
       "      <td>9.990111</td>\n",
       "      <td>8.016622</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.127886</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.748097</td>\n",
       "      <td>0.747479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>725.250000</td>\n",
       "      <td>0.081772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.324147</td>\n",
       "      <td>15.314675</td>\n",
       "      <td>12.387429</td>\n",
       "      <td>0.069204</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.204565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>0.053111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624572</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.765789</td>\n",
       "      <td>0.767761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>967.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.165318</td>\n",
       "      <td>26.291557</td>\n",
       "      <td>0.381426</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.705655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065722</td>\n",
       "      <td>0.586452</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.869629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.879748</td>\n",
       "      <td>0.868348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      Rouge1      Rouge2      RougeL        Bleu        Chrf  \\\n",
       "count  968.000000  968.000000  968.000000  968.000000  968.000000  968.000000   \n",
       "mean   483.500000    0.046011    0.001416    0.001416    0.830566   10.139116   \n",
       "std    279.581831    0.062679    0.008746    0.008746    1.956832    6.587107   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%    241.750000    0.000000    0.000000    0.000000    0.000000    4.756180   \n",
       "50%    483.500000    0.000000    0.000000    0.000000    0.049605    9.990111   \n",
       "75%    725.250000    0.081772    0.000000    0.000000    1.324147   15.314675   \n",
       "max    967.000000    0.500000    0.095238    0.095238   50.000000   30.165318   \n",
       "\n",
       "         ChrfPlus      Meteor         Ter        Bert  ...        Bart  \\\n",
       "count  968.000000  968.000000  968.000000  968.000000  ...  968.000000   \n",
       "mean     8.350629    0.040701    0.007305    0.139276  ...    0.006078   \n",
       "std      5.524659    0.051258    0.003661    0.107661  ...    0.006982   \n",
       "min      0.000000    0.000000    0.000106   -0.092964  ...    0.000048   \n",
       "25%      3.908359    0.000000    0.003831    0.062456  ...    0.001694   \n",
       "50%      8.016622    0.022762    0.009901    0.127886  ...    0.003967   \n",
       "75%     12.387429    0.069204    0.009901    0.204565  ...    0.007974   \n",
       "max     26.291557    0.381426    0.012833    0.705655  ...    0.065722   \n",
       "\n",
       "             BEM         LLM  Correctness  Consistency  Prometheus  \\\n",
       "count  99.000000  100.000000    99.000000   100.000000  100.000000   \n",
       "mean    0.057341    0.018000     0.419688     0.094000    1.050000   \n",
       "std     0.061158    0.086899     0.234457     0.212152    0.297294   \n",
       "min     0.028687    0.000000     0.171780     0.000000    1.000000   \n",
       "25%     0.042911    0.000000     0.188106     0.000000    1.000000   \n",
       "50%     0.048951    0.000000     0.395853     0.000000    1.000000   \n",
       "75%     0.053111    0.000000     0.624572     0.000000    1.000000   \n",
       "max     0.586452    0.700000     0.869629     1.000000    3.000000   \n",
       "\n",
       "             TSim  Faithfullnes   Relevancy        RSim  \n",
       "count  100.000000     67.000000  100.000000  100.000000  \n",
       "mean     0.030000      0.250000    0.715331    0.749599  \n",
       "std      0.171447      0.342353    0.167844    0.029542  \n",
       "min      0.000000      0.000000    0.000000    0.687121  \n",
       "25%      0.000000      0.000000    0.727315    0.733142  \n",
       "50%      0.000000      0.000000    0.748097    0.747479  \n",
       "75%      0.000000      0.500000    0.765789    0.767761  \n",
       "max      1.000000      1.000000    0.879748    0.868348  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasper_shuffled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_100['std'] = df_100.select_dtypes(include=['number']).std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_100\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasper_shuffled_std.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3962\u001b[0m )\n\u001b[0;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics'"
     ]
    }
   ],
   "source": [
    "df_100.to_csv('/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/analyse results /statistics/qasper_shuffled_std.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df_100.sort_values(by='std')\n",
    "\n",
    "lowest_std_examples = sorted_df.head(3)\n",
    "\n",
    "# Get the 3 examples with the highest std\n",
    "highest_std_examples = sorted_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set options to ensure full display\n",
    "pd.set_option('display.max_columns', None)      # Show all columns\n",
    "pd.set_option('display.max_rows', None)         # Show all rows\n",
    "pd.set_option('display.max_colwidth', None)     # No truncation of column content\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Examples with Lowest Standard Deviation:\n",
      "                                     question  \\\n",
      "60       What was the baseline for this task?   \n",
      "84         What hyperparameters are explored?   \n",
      "97  what competitive results did they obtain?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                context  \\\n",
      "60                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The baseline system for the SLC task is a very simple logistic regression classifier with default parameters, where we represent the input instances with a single feature: the length of the sentence. The performance of this baseline on the SLC task is shown in Tables TABREF33 and TABREF34. The baseline for the FLC task generates spans and selects one of the 18 techniques randomly. The inefficacy of such a simple random baseline is illustrated in Tables TABREF36 and TABREF41. The baseline system for the SLC task is a very simple logistic regression classifier with default parameters, where we represent the input instances with a single feature: the length of the sentence. The performance of this baseline on the SLC task is shown in Tables TABREF33 and TABREF34. The baseline for the FLC task generates spans and selects one of the 18 techniques randomly. The inefficacy of such a simple random baseline is illustrated in Tables TABREF36 and TABREF41.   \n",
      "84                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   FLOAT SELECTED: Table 1: Hyper-parameter choices FLOAT SELECTED: Table 2: Network hyper-parameters To form the vocabulary, words occurring less than 5 times in the corpora were dropped, stop words removed using the natural language toolkit (NLTK) (BIBREF22) and data pre-processing carried out. Table TABREF2 describes most hyper-parameters explored for each dataset. In all, 80 runs (of about 160 minutes) were conducted for the 15MB Wiki Abstract dataset with 80 serialized models totaling 15.136GB while 80 runs (for over 320 hours) were conducted for the 711MB SW dataset, with 80 serialized models totaling over 145GB. Experiments for all combinations for 300 dimensions were conducted on the 3.9GB training set of the BW corpus and additional runs for other dimensions for the window 8 + skipgram + heirarchical softmax combination to verify the trend of quality of word vectors as dimensions are increased. FLOAT SELECTED: Table 1: Hyper-parameter choices   \n",
      "97  We trained a smaller Jasper 10x3 model with SGD with momentum optimizer for 400 epochs on a combined WSJ dataset (80 hours): LDC93S6A (WSJ0) and LDC94S13A (WSJ1). The results are provided in Table TABREF29 . FLOAT SELECTED: Table 6: WSJ End-to-End Models, WER (%) FLOAT SELECTED: Table 7: Hub5’00, WER (%) We also evaluate the Jasper model's performance on a conversational English corpus. The Hub5 Year 2000 (Hub5'00) evaluation (LDC2002S09, LDC2005S13) is widely used in academia. It is divided into two subsets: Switchboard (SWB) and Callhome (CHM). The training data for both the acoustic and language models consisted of the 2000hr Fisher+Switchboard training data (LDC2004S13, LDC2005S13, LDC97S62). Jasper DR 10x5 was trained using SGD with momentum for 50 epochs. We compare to other models trained using the same data and report Hub5'00 results in Table TABREF31 . FLOAT SELECTED: Table 6: WSJ End-to-End Models, WER (%) FLOAT SELECTED: Table 7: Hub5’00, WER (%) We trained a smaller Jasper 10x3 model with SGD with momentum optimizer for 400 epochs on a combined WSJ dataset (80 hours): LDC93S6A (WSJ0) and LDC94S13A (WSJ1). The results are provided in Table TABREF29 . We also evaluate the Jasper model's performance on a conversational English corpus. The Hub5 Year 2000 (Hub5'00) evaluation (LDC2002S09, LDC2005S13) is widely used in academia. It is divided into two subsets: Switchboard (SWB) and Callhome (CHM). The training data for both the acoustic and language models consisted of the 2000hr Fisher+Switchboard training data (LDC2004S13, LDC2005S13, LDC97S62). Jasper DR 10x5 was trained using SGD with momentum for 50 epochs. We compare to other models trained using the same data and report Hub5'00 results in Table TABREF31 .   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    correct_answer iris_answer    Rouge1  Rouge2  RougeL  Bleu      Chrf  ChrfPlus  Meteor       Ter      Bert  WMS       SMS  Wisdm    Bleurt       BEM      Bart  Prometheus  Faithfullnes  Relevancy  Correctness      RSim  Consistency  TSim  LLM       std  \n",
      "60                                                                                                                                                                                                                                                                                                                                     The baseline system for the SLC task is a very simple logistic regression classifier with default parameters. The baseline for the FLC task generates spans and selects one of the 18 techniques randomly.            2  0.000000     0.0     0.0   0.0  0.000000  0.000000     0.0  0.000303 -0.000160  0.0  0.122173    NaN -1.005474  0.069633  0.000878           1           0.0   0.767850     0.694423  0.777693          0.0   0.0  0.0  0.404708  \n",
      "84                                                                                                                                                                                                                                                                                                         Dimension size, window size, architecture, algorithm, epochs, hidden dimension size, learning rate, loss function, optimizer algorithm. Hyperparameters explored were: dimension size, window size, architecture, algorithm and epochs.       90.1%  0.000000     0.0     0.0   0.0  0.444444  0.317460     0.0  0.000370 -0.036102  0.0  0.013620    NaN -1.102628  0.034876  0.001925           1           NaN   0.779363     0.183280  0.733121          0.0   0.0  0.0  0.413997  \n",
      "97  In case of read speech datasets,  their best model got the highest nov93 score of 16.1 and the highest nov92 score of 13.3.\\nIn case of Conversational Speech, their best model got the highest SWB of 8.3 and the highest CHM of 19.3.  On WSJ datasets author's best approach achieves 9.3 and 6.9 WER compared to best results of 7.5 and 4.1 on nov93 and nov92 subsets.\\nOn Hub5'00 datasets author's best approach achieves WER of 7.8 and 16.2 compared to best result of 7.3 and 14.2 on Switchboard (SWB) and Callhome (CHM) subsets.           3  0.038462     0.0     0.0   0.0  1.154734  0.577367     0.0  0.000106  0.058061  0.0  0.130186    NaN -0.681380  0.043236  0.000768           1           NaN   0.713535     0.686165  0.744659          0.0   0.0  0.0  0.432403  \n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"3 Examples with Lowest Standard Deviation:\")\n",
    "print(lowest_std_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples with Highest Standard Deviation:\n",
      "                                                   question  \\\n",
      "7   How do they calculate a static embedding for each word?   \n",
      "90                            How is the dataset annotated?   \n",
      "59    How much does their model outperform existing models?   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              context  \\\n",
      "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       FLOAT SELECTED: Table 1: The performance of various static embeddings on word embedding benchmark tasks. The best result for each task is in bold. For the contextualizing models (ELMo, BERT, GPT-2), we use the first principal component of a word’s contextualized representations in a given layer as its static embedding. The static embeddings created using ELMo and BERT’s contextualized representations often outperform GloVe and FastText vectors. As noted earlier, we can create static embeddings for each word by taking the first principal component (PC) of its contextualized representations in a given layer. In Table TABREF34, we plot the performance of these PC static embeddings on several benchmark tasks. These tasks cover semantic similarity, analogy solving, and concept categorization: SimLex999 BIBREF21, MEN BIBREF22, WS353 BIBREF23, RW BIBREF24, SemEval-2012 BIBREF25, Google analogy solving BIBREF0 MSR analogy solving BIBREF26, BLESS BIBREF27 and AP BIBREF28. We leave out layers 3 - 10 in Table TABREF34 because their performance is between those of Layers 2 and 11.   \n",
      "90                                                                                                                                                                                                                                                                                                                                                            Specifically, we conducted a feature ablation study to assess the informativeness of each feature group and a feature elimination study to determine the optimal feature sets for classifying Twitter tweets. We leveraged an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13 . The dataset contains 9,473 annotations for 9,300 tweets. Each tweet is annotated as no evidence of depression (e.g., “Citizens fear an economic depression\") or evidence of depression (e.g., “depressed over disappointment\"). If a tweet is annotated evidence of depression, then it is further annotated with one or more depressive symptoms, for example, depressed mood (e.g., “feeling down in the dumps\"), disturbed sleep (e.g., “another restless night\"), or fatigue or loss of energy (e.g., “the fatigue is unbearable\") BIBREF10 . For each class, every annotation (9,473 tweets) is binarized as the positive class e.g., depressed mood=1 or negative class e.g., not depressed mood=0. Specifically, we conducted a feature ablation study to assess the informativeness of each feature group and a feature elimination study to determine the optimal feature sets for classifying Twitter tweets. We leveraged an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13 . The dataset contains 9,473 annotations for 9,300 tweets. Each tweet is annotated as no evidence of depression (e.g., “Citizens fear an economic depression\") or evidence of depression (e.g., “depressed over disappointment\"). If a tweet is annotated evidence of depression, then it is further annotated with one or more depressive symptoms, for example, depressed mood (e.g., “feeling down in the dumps\"), disturbed sleep (e.g., “another restless night\"), or fatigue or loss of energy (e.g., “the fatigue is unbearable\") BIBREF10 . For each class, every annotation (9,473 tweets) is binarized as the positive class e.g., depressed mood=1 or negative class e.g., not depressed mood=0.   \n",
      "59  The performance of all models on arXiv and Pubmed is shown in Table TABREF28 and Table TABREF29 , respectively. Follow the work BIBREF18 , we use the approximate randomization as the statistical significance test method BIBREF32 with a Bonferroni correction for multiple comparisons, at the confidence level 0.01 ( INLINEFORM0 ). As we can see in these tables, on both datasets, the neural extractive models outperforms the traditional extractive models on informativeness (ROUGE-1,2) by a wide margin, but results are mixed on ROUGE-L. Presumably, this is due to the neural training process, which relies on a goal standard based on ROUGE-1. Exploring other training schemes and/or a combination of traditional and neural approaches is left as future work. Similarly, the neural extractive models also dominate the neural abstractive models on ROUGE-1,2, but these abstractive models tend to have the highest ROUGE-L scores, possibly because they are trained directly on gold standard abstract summaries. FLOAT SELECTED: Table 4.1: Results on the arXiv dataset. For models with an ∗, we report results from [8]. Models are traditional extractive in the first block, neural abstractive in the second block, while neural extractive in the third block. The Oracle (last row) corresponds to using the ground truth labels, obtained (for training) by the greedy algorithm, see Section 4.1.2. Results that are not significantly distinguished from the best systems are bold. FLOAT SELECTED: Table 4.2: Results on the Pubmed dataset. For models with an ∗, we report results from [8]. See caption of Table 4.1 above for details on compared models. Results that are not significantly distinguished from the best systems are bold. FLOAT SELECTED: Table 4.1: Results on the arXiv dataset. For models with an ∗, we report results from [8]. Models are traditional extractive in the first block, neural abstractive in the second block, while neural extractive in the third block. The Oracle (last row) corresponds to using the ground truth labels, obtained (for training) by the greedy algorithm, see Section 4.1.2. Results that are not significantly distinguished from the best systems are bold. FLOAT SELECTED: Table 4.2: Results on the Pubmed dataset. For models with an ∗, we report results from [8]. See caption of Table 4.1 above for details on compared models. Results that are not significantly distinguished from the best systems are bold.   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                     correct_answer                                                                                                                                                                           iris_answer    Rouge1    Rouge2    RougeL      Bleu       Chrf   ChrfPlus    Meteor       Ter      Bert       WMS       SMS     Wisdm    Bleurt       BEM      Bart  Prometheus  Faithfullnes  Relevancy  Correctness      RSim  Consistency  TSim  LLM       std  \n",
      "7                                                                                                                                                                                                                                                       They use the first principal component of a word's contextualized representation in a given layer as its static embedding.                                                     A very simple logistic regression classifier with default parameters, representing input instances with the length of the sentence  0.114286  0.000000  0.000000  2.276860  24.915056  19.991767  0.072115  0.009385  0.214404  0.448221  0.214404  0.457804 -0.578939  0.041528  0.004622           1           0.0   0.725124     0.683815  0.735260          0.2   0.0  0.0  6.444223  \n",
      "90                                                                                                                                                                                                                                           The annotations are based on evidence of depression and further annotated by the depressive symptom if there is evidence of depression  The message passing framework is a method for learning on graph-structured data, in which the representation of each vertex is updated based on messages received from its neighbors  0.272727  0.044444  0.044444  3.265885  24.833844  21.836397  0.195591  0.011532  0.176807  0.427253  0.176807  0.192577 -0.845302       NaN  0.007063           1           0.0   0.740975     0.646247  0.738835          0.0   0.0  0.0  6.818882  \n",
      "59  Best proposed model result vs best previous result:\\nArxiv dataset: Rouge 1 (43.62 vs 42.81), Rouge L (29.30 vs 31.80), Meteor (21.78 vs 21.35)\\nPubmed dataset: Rouge 1 (44.85 vs 44.29), Rouge L (31.48 vs 35.21), Meteor (20.83 vs 20.56) On arXiv dataset, the proposed model outperforms baselie model by (ROUGE-1,2,L)  0.67 0.72 0.77 respectively and by Meteor 0.31.\\n                       The proposed model achieved an execution accuracy of 83.3% and an operation sequence accuracy of 86.7% on the MathQA dataset, outperforming the baseline models  0.157895  0.021053  0.021053  1.341556  27.767673  23.580557  0.057471  0.004345  0.375197  0.483325  0.375197  0.292325 -0.909440  0.047479  0.017300           1           0.5   0.741733     0.687312  0.749248          0.2   0.0  0.0  7.352838  \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples with Highest Standard Deviation:\")\n",
    "print(highest_std_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
