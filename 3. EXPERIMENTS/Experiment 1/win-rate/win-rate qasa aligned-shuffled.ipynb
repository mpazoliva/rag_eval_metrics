{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aligned = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL ALIGNED/qasa_aligned_iris.csv\"\n",
    "df_aligned = pd.read_csv(path_aligned)\n",
    "path_shuffled = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasa_shuffled_iris.csv\"\n",
    "df_shuffled = pd.read_csv(path_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_aligned_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL ALIGNED/qasa_aligned_iris_100.csv\"\n",
    "df_aligned_100 = pd.read_csv(path_aligned_100)\n",
    "path_shuffled_100 = \"/home/ubuntu/iris_repos/llm_evaluation_thesis/analysis/computing scores/FULL SHUFFLED/qasa_shuffled_iris_100.csv\"\n",
    "df_shuffled_100 = pd.read_csv(path_shuffled_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'question', 'iris_answer', 'correct_answer', 'context',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'Prometheus',\n",
      "       'Faithfullness', 'Relevancy', 'RSim'],\n",
      "      dtype='object')\n",
      "(1542, 22)\n",
      "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', 'Faithfullness',\n",
      "       'Relevancy', 'RSim'],\n",
      "      dtype='object')\n",
      "(1542, 21)\n"
     ]
    }
   ],
   "source": [
    "print(df_aligned.columns)\n",
    "print(df_aligned.shape)\n",
    "print(df_shuffled.columns)\n",
    "print(df_shuffled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bleurt', 'BEM', 'Bart',\n",
      "       'Prometheus', 'Faithfullness', 'Relevancy', 'Correctness', 'RSim',\n",
      "       'Consistency', 'TSim', 'LLM'],\n",
      "      dtype='object')\n",
      "(100, 28)\n",
      "Index(['Unnamed: 0', 'question', 'context', 'correct_answer', 'iris_answer',\n",
      "       'Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor',\n",
      "       'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bleurt', 'BEM', 'Bart',\n",
      "       'Prometheus', 'Faithfullness', 'Relevancy', 'Correctness', 'RSim',\n",
      "       'Consistency', 'TSim', 'LLM'],\n",
      "      dtype='object')\n",
      "(100, 28)\n"
     ]
    }
   ],
   "source": [
    "print(df_aligned_100.columns)\n",
    "print(df_aligned_100.shape)\n",
    "print(df_shuffled_100.columns)\n",
    "print(df_shuffled_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics to compare\n",
    "metrics = ['Rouge1', 'Rouge2', 'RougeL', 'Bleu', 'Chrf', 'ChrfPlus', 'Meteor', \n",
    "           'Ter', 'Bert', 'WMS', 'SMS', 'Wisdm', 'Bart', \n",
    "           'Faithfullness', 'Relevancy', 'RSim']\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric in metrics:\n",
    "    # Drop rows where either df_aligned or df_shuffled has NaN values for the metric\n",
    "    valid_rows = df_aligned[metric].notna() & df_shuffled[metric].notna()\n",
    "    \n",
    "    # Filter the DataFrames to include only these valid rows\n",
    "    aligned_valid = df_aligned[valid_rows]\n",
    "    shuffled_valid = df_shuffled[valid_rows]\n",
    "    \n",
    "    # Compare the values row by row\n",
    "    wins = (aligned_valid[metric] > shuffled_valid[metric]).sum()\n",
    "    \n",
    "    # Calculate the win rate\n",
    "    win_rate = f\"{wins} / {len(aligned_valid)}\"\n",
    "    \n",
    "    # Calculate the win rate percentage\n",
    "    win_rate_percentage = (wins / len(aligned_valid)) * 100\n",
    "    \n",
    "    # Append the result to the list\n",
    "    results.append([metric, win_rate, win_rate_percentage])\n",
    "\n",
    "# Convert the results to a DataFrame to display them neatly\n",
    "win_rates_df = pd.DataFrame(results, columns=['Metric', 'Win Rate', 'Percentage (%)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Win Rate</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rouge1</td>\n",
       "      <td>1280 / 1539</td>\n",
       "      <td>83.170890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rouge2</td>\n",
       "      <td>1079 / 1539</td>\n",
       "      <td>70.110461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RougeL</td>\n",
       "      <td>1276 / 1539</td>\n",
       "      <td>82.910981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bleu</td>\n",
       "      <td>1239 / 1542</td>\n",
       "      <td>80.350195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chrf</td>\n",
       "      <td>1333 / 1542</td>\n",
       "      <td>86.446174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ChrfPlus</td>\n",
       "      <td>1339 / 1542</td>\n",
       "      <td>86.835279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meteor</td>\n",
       "      <td>1283 / 1542</td>\n",
       "      <td>83.203632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ter</td>\n",
       "      <td>980 / 1542</td>\n",
       "      <td>63.553826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bert</td>\n",
       "      <td>1430 / 1542</td>\n",
       "      <td>92.736706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMS</td>\n",
       "      <td>1356 / 1542</td>\n",
       "      <td>87.937743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SMS</td>\n",
       "      <td>1442 / 1542</td>\n",
       "      <td>93.514916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wisdm</td>\n",
       "      <td>1053 / 1209</td>\n",
       "      <td>87.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bart</td>\n",
       "      <td>1230 / 1541</td>\n",
       "      <td>79.818300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Faithfullness</td>\n",
       "      <td>653 / 859</td>\n",
       "      <td>76.018626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Relevancy</td>\n",
       "      <td>1453 / 1540</td>\n",
       "      <td>94.350649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RSim</td>\n",
       "      <td>1455 / 1542</td>\n",
       "      <td>94.357977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric     Win Rate  Percentage (%)\n",
       "0          Rouge1  1280 / 1539       83.170890\n",
       "1          Rouge2  1079 / 1539       70.110461\n",
       "2          RougeL  1276 / 1539       82.910981\n",
       "3            Bleu  1239 / 1542       80.350195\n",
       "4            Chrf  1333 / 1542       86.446174\n",
       "5        ChrfPlus  1339 / 1542       86.835279\n",
       "6          Meteor  1283 / 1542       83.203632\n",
       "7             Ter   980 / 1542       63.553826\n",
       "8            Bert  1430 / 1542       92.736706\n",
       "9             WMS  1356 / 1542       87.937743\n",
       "10            SMS  1442 / 1542       93.514916\n",
       "11          Wisdm  1053 / 1209       87.096774\n",
       "12           Bart  1230 / 1541       79.818300\n",
       "13  Faithfullness    653 / 859       76.018626\n",
       "14      Relevancy  1453 / 1540       94.350649\n",
       "15           RSim  1455 / 1542       94.357977"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of metrics to compare\n",
    "metrics_100 = ['BEM', 'Prometheus', 'Correctness','Bleurt', 'Consistency',\n",
    "       'TSim', 'LLM']\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results_100 = []\n",
    "\n",
    "# Iterate over each metric\n",
    "for metric in metrics_100:\n",
    "    # Drop rows where either df_aligned or df_shuffled has NaN values for the metric\n",
    "    valid_rows = df_aligned_100[metric].notna() & df_shuffled_100[metric].notna()\n",
    "    \n",
    "    # Filter the DataFrames to include only these valid rows\n",
    "    aligned_valid_100 = df_aligned_100[valid_rows]\n",
    "    shuffled_valid_100 = df_shuffled_100[valid_rows]\n",
    "    \n",
    "    # Compare the values row by row\n",
    "    wins = (aligned_valid_100[metric] > shuffled_valid_100[metric]).sum()\n",
    "    \n",
    "    # Calculate the win rate\n",
    "    win_rate_100 = f\"{wins} / {len(aligned_valid_100)}\"\n",
    "    \n",
    "    # Calculate the win rate percentage\n",
    "    win_rate_percentage_100 = (wins / len(aligned_valid_100)) * 100\n",
    "    \n",
    "    # Append the result to the list\n",
    "    results_100.append([metric, win_rate_100, win_rate_percentage_100])\n",
    "\n",
    "# Convert the results to a DataFrame to display them neatly\n",
    "win_rates_df_100 = pd.DataFrame(results_100, columns=['Metric', 'Win Rate', 'Percentage (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Win Rate</th>\n",
       "      <th>Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEM</td>\n",
       "      <td>92 / 98</td>\n",
       "      <td>93.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prometheus</td>\n",
       "      <td>91 / 100</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Correctness</td>\n",
       "      <td>72 / 98</td>\n",
       "      <td>73.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bleurt</td>\n",
       "      <td>94 / 98</td>\n",
       "      <td>95.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consistency</td>\n",
       "      <td>89 / 100</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TSim</td>\n",
       "      <td>89 / 100</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LLM</td>\n",
       "      <td>84 / 86</td>\n",
       "      <td>97.674419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric  Win Rate  Percentage (%)\n",
       "0          BEM   92 / 98       93.877551\n",
       "1   Prometheus  91 / 100       91.000000\n",
       "2  Correctness   72 / 98       73.469388\n",
       "3       Bleurt   94 / 98       95.918367\n",
       "4  Consistency  89 / 100       89.000000\n",
       "5         TSim  89 / 100       89.000000\n",
       "6          LLM   84 / 86       97.674419"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_rates_df_100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
